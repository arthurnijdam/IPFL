{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f9ad0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.special import binom \n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as tt\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.init as init\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from collections import Counter\n",
    "import operator\n",
    "import copy \n",
    "from itertools import product,combinations\n",
    "from time import time \n",
    "#from IPython.core.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## code extracted from https://www.kaggle.com/code/graymant/breast-cancer-diagnosis-with-pytorch\n",
    "## SV code extracted from https://github.com/mburaksayici/ExplainableAI-Pure-Numpy/blob/main/KernelSHAP-Pure-Numpy.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78962b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from os.path import join as osj\n",
    "from bisect import bisect\n",
    "from collections import defaultdict \n",
    "import pickle\n",
    "import json\n",
    "import wfdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba54f03d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a39bf92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:  local\n",
      "0\n",
      "full train loss:  tensor(0.0976, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0988, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  0.952020202020202\n",
      "test accuracy:  0.9354420589940808\n",
      "0\n",
      "accuracy is best accuracy\n",
      "[0.5, 1.0, 0.5]\n",
      "[0.5, 1.0, 0.5]\n",
      "0.9354420589940808\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_ROOT = osj(\"/mimer/NOBACKUP/groups/snic2022-22-122/arthur/\", \"dataset_beats\")\n",
    "DICT_BEATS = osj(DATA_ROOT, \"5min_normal_beats.pkl\")\n",
    "DATA_BEATS = osj(DATA_ROOT, \"30min_beats.pkl\")\n",
    "\n",
    "DATA_ROOT = \"/mimer/NOBACKUP/groups/snic2022-22-122/arthur/physionet.org/files/mitdb/1.0.0/\"\n",
    "RECORDS = osj(DATA_ROOT, \"RECORDS\")\n",
    "#print(RECORDS)\n",
    "patient_ids = pd.read_csv(RECORDS, header=None).to_numpy().reshape(-1)\n",
    "#print(patient_ids)\n",
    "paced_patients = get_paced_patients(patient_ids)\n",
    "excluded_patients = np.array([])#105, 114, 201, 202, 207, 209, 213, 222, 223, 234])  # according to paper\n",
    "#print(np.concatenate((paced_patients, excluded_patients)))\n",
    "\n",
    "dict_beats = read_dict_beats()\n",
    "data_beats = read_data_beats()\n",
    "ensure_normalized_and_detrended(dict_beats)\n",
    "ensure_normalized_and_detrended(data_beats)\n",
    "\n",
    "import collections\n",
    "\n",
    "patients_out = np.concatenate((paced_patients, excluded_patients))\n",
    "patients_left = list(copy.deepcopy(patient_ids))\n",
    "\n",
    "for idx, i in enumerate(patient_ids):\n",
    "    if i in patients_out:\n",
    "        patients_left.remove(i)\n",
    "\n",
    "labels = ['N', 'V', 'S', 'Q', 'F']\n",
    "dictionary = {}\n",
    "for i in labels:\n",
    "    dictionary[i] = 0\n",
    "\n",
    "list1 = []\n",
    "array = np.zeros((len(patients_left), 2))\n",
    "for idx, i in enumerate(patients_left):\n",
    "    list1.append(data_beats[i]['class'])\n",
    "    counter = collections.Counter(data_beats[i]['class'])\n",
    "    for j in counter.keys():\n",
    "        dictionary[j] += counter[j]\n",
    "        if j == 'N':\n",
    "            array[idx, 0] += counter[j]\n",
    "        else:\n",
    "            array[idx, 1] += counter[j]\n",
    "\n",
    "seconds = 5\n",
    "data_beats_train, data_beats_val, data_beats_test = train_test_split(data_beats, seconds)\n",
    "\n",
    "import collections\n",
    "from time import time\n",
    "import random\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pandas\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "experiment_name = settings['experiment_name']\n",
    "test = 'local' #settings['type']\n",
    "print('type: ',test)\n",
    "n_epochs = 1 #settings['n_epochs']\n",
    "patients_example = [205,212,232]#[200, 118, 232]\n",
    "p2p = P2P_AFPL(patients_example, data_beats_train, data_beats_val,data_beats_test,2, test)\n",
    "alphas = p2p.loop(n_epochs, p2p, experiment_name)\n",
    "\n",
    "local_acc = p2p.accuracy_list\n",
    "print(local_acc)\n",
    "local_best = p2p.best_accuracy\n",
    "print(local_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71732f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_dict_beats():\n",
    "    with open(DICT_BEATS, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def read_data_beats():\n",
    "    with open(DATA_BEATS, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def ensure_normalized_and_detrended(beats):\n",
    "    for key in beats.keys():\n",
    "        b = beats[key][\"beats\"]\n",
    "        if not np.allclose(np.linalg.norm(b, axis=1, ord=2), 1):\n",
    "            raise AssertionError(f\"Beats of patient {key} is not normalized.\")\n",
    "\n",
    "        p = np.polyfit(np.arange(b.shape[1]), b.T, deg=1)\n",
    "        if not np.allclose(p, 0):\n",
    "            raise AssertionError(f\"Beats of patient {key} is not detrended.\")\n",
    "\n",
    "\n",
    "def get_paced_patients(patient_ids):\n",
    "    paced = []\n",
    "    for id_ in patient_ids:\n",
    "        annotation = wfdb.rdann(osj(DATA_ROOT, str(id_)), extension='atr')\n",
    "        labels = np.unique(annotation.symbol)\n",
    "        if (\"/\" in labels):\n",
    "            paced.append(id_)\n",
    "    return np.array(paced)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# patient_ids = pd.read_csv(osj(\"..\", \"files\", \"patient_ids.csv\"), header=None).to_numpy().reshape(-1)\n",
    "# paced_patients = pd.read_csv(osj(\"..\", \"files\", \"paced_patients.csv\"), header=None).to_numpy().reshape(-1)\n",
    "# excluded_patients = pd.read_csv(osj(\"..\", \"files\", \"excluded_patients.csv\"), header=None).to_numpy().reshape(-1)\n",
    "def get_base_model(in_channels):\n",
    "    \"\"\"\n",
    "    Returns the model from paper: Personalized Monitoring and Advance Warning System for Cardiac Arrhythmias.\n",
    "    \"\"\"\n",
    "    # Input size: 128x1\n",
    "    # 128x1 -> 122x32 -> 40x32 -> 34x16 -> 11x16 -> 5x16 -> 1x16\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv1d(in_channels, 32, kernel_size=7, padding=0, bias=True),\n",
    "        nn.MaxPool1d(3),\n",
    "        nn.Tanh(),\n",
    "\n",
    "        nn.Conv1d(32, 16, kernel_size=7, padding=0, bias=True),\n",
    "        nn.MaxPool1d(3),\n",
    "        nn.Tanh(),\n",
    "\n",
    "        nn.Conv1d(16, 16, kernel_size=7, padding=0, bias=True),\n",
    "        nn.MaxPool1d(3),\n",
    "        nn.Tanh(),\n",
    "\n",
    "        nn.Flatten(),\n",
    "\n",
    "        nn.Linear(16, 32, bias=True),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        nn.Linear(32, 3, bias=True),\n",
    "\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# AAMI standards: only use the first 5 seconds, only use 'healthy' heartbeats for training.\n",
    "# They combine each client's dataset with other clients' datasets (with domain Adaptation)\n",
    "# and test on the other 25 seconds + the abnormal heartbeats of the client.\n",
    "\n",
    "\n",
    "def train_test_split(data_beats, seconds=5, data_fraction=1):\n",
    "    data_beats_train = {}\n",
    "    data_beats_val = {}\n",
    "    data_beats_test = {}\n",
    "    for i in data_beats.keys():\n",
    "        data_beats_train[i] = {'class': None, 'beats': None}\n",
    "        data_beats_val[i] = {'class': None, 'beats': None}\n",
    "        data_beats_test[i] = {'class': None, 'beats': None}\n",
    "\n",
    "    for patient in data_beats.keys():\n",
    "        length_train = int(np.ceil(len(data_beats[patient]['beats']) * (seconds / 30)))  # only take first 5 seconds\n",
    "\n",
    "        random_test = np.arange(int(np.ceil(len(data_beats[patient]['beats']))))\n",
    "        random_val= np.arange(length_train)\n",
    "        for ii in random_val:\n",
    "            random_test = np.delete(random_test,ii)\n",
    "\n",
    "        # Data fraction, take part of the data\n",
    "        random_val = np.random.choice(random_val, size=int(np.ceil(data_fraction* length_train)), replace=False)\n",
    "\n",
    "        random_train = np.random.choice(random_val, size=int(np.ceil(0.8 *data_fraction* length_train)), replace=False)\n",
    "        for ii in random_train:\n",
    "            index = np.where(random_val == ii)[0]\n",
    "            random_val = np.delete(random_val, index)\n",
    "\n",
    "\n",
    "        #random_val = np.arange(int(np.ceil(0.8 * length)))\n",
    "        #random_train = np.random.choice(random_val, size=int(np.ceil(0.8 * 0.8 * length)), replace=False)\n",
    "        #for ii in random_train:\n",
    "        #    index = np.where(random_val == ii)[0]\n",
    "        #    random_val = np.delete(random_val, index)\n",
    "\n",
    "        data_beats_train[patient]['class'] = data_beats[patient]['class'][np.sort(random_train)]\n",
    "        data_beats_test[patient]['class'] = data_beats[patient]['class'][random_test]\n",
    "        data_beats_val[patient]['class'] = data_beats[patient]['class'][random_val]\n",
    "        data_beats_train[patient]['beats'] = data_beats[patient]['beats'][np.sort(random_train)]\n",
    "        data_beats_test[patient]['beats'] = data_beats[patient]['beats'][random_test]\n",
    "        data_beats_val[patient]['beats'] = data_beats[patient]['beats'][random_val]\n",
    "\n",
    "    return data_beats_train, data_beats_val, data_beats_test\n",
    "import copy\n",
    "\n",
    "# Combinatorial UCB\n",
    "import math\n",
    "\n",
    "# Combinatorial UCB\n",
    "import math\n",
    "\n",
    "\n",
    "class combinatorial_UCB(object):\n",
    "    def __init__(self, n_clients, n_clients_selected=10, algorithm='UCB1_tuned'):\n",
    "        self.n_clients = n_clients\n",
    "\n",
    "        # define variables for storage\n",
    "        # which clients we select\n",
    "        self.times_selected = np.zeros((n_clients, n_clients))  # to record how often each client got selected\n",
    "        self.reward_per_client = np.zeros((n_clients, n_clients))  # to record what reward we collected per client\n",
    "        self.reward2_per_client = np.zeros(\n",
    "            (n_clients, n_clients))  # to record the squared reward per client (needed for UCB1-tuned)\n",
    "        # how many clients we select\n",
    "        self.n_clients_selected_arr = []\n",
    "        self.reward3_per_client = np.zeros((n_clients, n_clients - 1))\n",
    "        self.times_selected2 = np.zeros((n_clients, n_clients - 1))\n",
    "\n",
    "        if n_clients_selected == None:\n",
    "            self.n_clients_selected = np.zeros((n_clients, 1))\n",
    "        else:\n",
    "            self.n_clients_selected = np.ones((n_clients, 1)) * n_clients_selected\n",
    "\n",
    "        self.algorithm = algorithm\n",
    "\n",
    "    def UCB(self, this_client, n):\n",
    "        # for this_client in range(self.n_clients):\n",
    "        other_clients = [x for x in range(self.n_clients) if x != this_client[0]]\n",
    "\n",
    "        upper_bound = np.zeros(self.n_clients)\n",
    "        for i, other_client in enumerate(other_clients):\n",
    "            if self.times_selected[this_client, other_client] == 0:  # make first iteration value high\n",
    "                upper_bound[other_client] = 1e500\n",
    "            else:\n",
    "                # We first calculate the average reward gained for this client\n",
    "                average_reward = self.reward_per_client[this_client, other_client] / self.times_selected[\n",
    "                    this_client, other_client]\n",
    "\n",
    "                # Then we compute the confidence interval [avg_reward - delta, avg_reward + delta]\n",
    "                if self.algorithm == 'UCB1':\n",
    "                    delta = math.sqrt(2 * math.log(n) / self.times_selected[this_client, other_client])\n",
    "\n",
    "                if self.algorithm == 'UCB1_tuned':\n",
    "                    variance_bound = self.reward2_per_client[this_client, other_client] / self.times_selected[\n",
    "                        this_client, other_client] - average_reward ** 2\n",
    "                    variance_bound += math.sqrt(2 * math.log(n) / self.times_selected[this_client, other_client])\n",
    "\n",
    "                    factor = np.min([variance_bound, 1 / 4])\n",
    "                    delta = math.sqrt(factor * math.log(n) / self.times_selected[this_client, other_client])\n",
    "\n",
    "                # upper bound\n",
    "                upper_bound[other_client] = average_reward + delta\n",
    "\n",
    "        if self.algorithm == 'random':\n",
    "            upper_bound = np.random.rand(self.n_clients)\n",
    "\n",
    "        # select the client with the highest upper bound\n",
    "        sorted_upper_bound = np.flip(np.argsort(upper_bound))\n",
    "\n",
    "        # if epoch == 0:\n",
    "        #     n_clients_selected = self.n_clients -2\n",
    "\n",
    "        # else:\n",
    "        n_clients_selected = self.n_clients_selected[i]-1\n",
    "\n",
    "        # Run UCB again to determine the number of clients\n",
    "        # upper_bound2 = np.zeros(self.n_clients-1)\n",
    "        # for ii in range(1,self.n_clients-1):\n",
    "        #    if self.times_selected2[this_client,ii]==0: # make first iteration value high\n",
    "        #        upper_bound2[ii] = 1e500\n",
    "        #        n_clients_selected = self.n_clients -2\n",
    "        #    else:\n",
    "        # predict the reward when selecting these clients\n",
    "        #        average_reward_n_clients = self.reward3_per_client[this_client,ii] / self.times_selected2[this_client,ii]\n",
    "        #        delta = math.sqrt(2*math.log(n)) / np.sum(self.times_selected2[this_client,ii])\n",
    "\n",
    "        #        upper_bound2[ii] = average_reward_n_clients + delta\n",
    "\n",
    "        #        n_clients_selected = np.argmax(upper_bound2)\n",
    "\n",
    "        # n_clients_selected_arr.append(n_clients_selected)\n",
    "        selected_clients = sorted_upper_bound[:int(n_clients_selected + 1)]\n",
    "\n",
    "        self.times_selected[this_client, selected_clients] += 1\n",
    "        return selected_clients\n",
    "\n",
    "    def collect_reward(self, this_client, selected_clients, observations):\n",
    "        # collect the reward\n",
    "        reward = observations[selected_clients]  # df.iloc[n,selected_client]\n",
    "        self.reward_per_client[this_client, selected_clients] += reward\n",
    "        self.reward2_per_client[this_client, selected_clients] += reward ** 2\n",
    "\n",
    "        # reward for numbers of clients selected\n",
    "        # n_clients_selected = len(selected_clients)-1\n",
    "        # self.times_selected2[this_client,n_clients_selected] += 1\n",
    "\n",
    "    # if epoch == 0:\n",
    "    #     self.n_clients_selected[this_client] = np.sum(observations)\n",
    "    # reward2 = np.abs(n_clients_selected - np.sum(observations))\n",
    "    # self.reward3_per_client[this_client,n_clients_selected] += 1 - reward2 / self.n_clients\n",
    "\n",
    "    def to_client(self, this_client, n):\n",
    "        self.selected_clients = self.UCB(this_client, n)\n",
    "        return self.selected_clients\n",
    "\n",
    "    def to_server(self, this_client, observation):\n",
    "        self.collect_reward(this_client, self.selected_clients, observation)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MIT_BIH(Dataset):\n",
    "    def __init__(self, patients, data):\n",
    "        self.patients = patients\n",
    "        self.data = data\n",
    "        self.to_one_dataset()\n",
    "\n",
    "    def to_one_dataset(self):\n",
    "        data_vector = torch.zeros(self.__len__(), 128)\n",
    "        labels_vector = torch.zeros(self.__len__())\n",
    "        k = 0\n",
    "        for i, patient in enumerate(self.patients):\n",
    "            data_vector[k:k + len(self.data[patient]['beats']), :] = torch.from_numpy(self.data[patient]['beats'])\n",
    "            classes = copy.deepcopy(self.data[patient]['class'])\n",
    "            indices = classes == 'N'\n",
    "            indices2 = classes != 'N'\n",
    "            classes[indices] = 0\n",
    "            classes[indices2] = 1\n",
    "            classes = np.array(classes, dtype='int')\n",
    "            labels_vector[k:k + len(self.data[patient]['beats'])] = torch.from_numpy(classes)\n",
    "            k += len(self.data[patient]['beats'])\n",
    "        self.y = labels_vector.long()\n",
    "        self.X = data_vector.double()\n",
    "\n",
    "    def __len__(self):\n",
    "        length_total = 0\n",
    "        for patient in self.patients:\n",
    "            length_total += len(self.data[patient]['beats'])\n",
    "        # print(len(self.data[patient]['beats']))\n",
    "        return length_total\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx, :], self.y[idx])\n",
    "    \n",
    "    \n",
    "class MIT_BIH(Dataset):\n",
    "    def __init__(self, patients, data):\n",
    "        self.patients = patients\n",
    "        self.data = data\n",
    "        self.to_one_dataset()\n",
    "\n",
    "    def to_one_dataset(self):\n",
    "        length_total = 0\n",
    "        for patient in self.patients:\n",
    "            length_total += len(self.data[patient]['beats'])\n",
    "        # print(len(self.data[patient]['beats']))\n",
    "        data_vector = torch.zeros(length_total, 128)\n",
    "        labels_vector = torch.zeros(length_total)\n",
    "        k = 0\n",
    "        for i, patient in enumerate(self.patients):\n",
    "            data_vector[k:k + len(self.data[patient]['beats']), :] = torch.from_numpy(self.data[patient]['beats'])\n",
    "            classes = copy.deepcopy(self.data[patient]['class'])\n",
    "            indices = classes == 'N'\n",
    "            indices2 = classes == 'S'\n",
    "            indices3 = classes == 'V'\n",
    "            indices4 = classes == 'F'\n",
    "            indices5 = classes == 'Q'\n",
    "\n",
    "            classes[indices] = 0\n",
    "            classes[indices2] = 1\n",
    "            classes[indices3] = 2\n",
    "            classes[indices4] = 2  # classify F as V\n",
    "            classes[indices5] = 3\n",
    "            classes = np.array(classes, dtype='int')\n",
    "            labels_vector[k:k + len(self.data[patient]['beats'])] = torch.from_numpy(classes)\n",
    "            k += len(self.data[patient]['beats'])\n",
    "        # remove q entries\n",
    "        indices6 = np.array(labels_vector != 3)\n",
    "        self.y = torch.masked_select(labels_vector, torch.from_numpy(indices6)).long()\n",
    "        self.X = data_vector[indices6, :].double()\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx, :], self.y[idx])\n",
    "\n",
    "\n",
    "class P2P_AFPL():\n",
    "\n",
    "    def __init__(self, patients_left, train_data, val_data,test_data, n_clients_selected,test='local'):\n",
    "        self.selected_clients = patients_left\n",
    "        self.network = get_base_model(1)\n",
    "        self.best_test_loss = {}\n",
    "        self.best_test_loss_global = 1000000\n",
    "        self.current_test_loss = {}\n",
    "        self.current_train_loss = {}\n",
    "        self.test = test\n",
    "        self.total_clients = len(self.selected_clients)\n",
    "        self.patients_left = patients_left\n",
    "        self.client_models = {}\n",
    "        self.optimizers = {}\n",
    "        self.dataloaders = {}\n",
    "        self.len = {}\n",
    "        self.len_test = {}\n",
    "        self.len_really_test = {}\n",
    "        self.dataloaders_test = {}\n",
    "        self.dataloaders_really_test = {}\n",
    "        if self.test == 'AFPL':\n",
    "            self.client_models_global = {}\n",
    "\n",
    "        if self.test == 'bandits':\n",
    "            self.comb_UCB = combinatorial_UCB(self.total_clients,n_clients_selected)\n",
    "\n",
    "        for idx, i in enumerate(self.patients_left):\n",
    "            self.client_models[str(idx)] = copy.deepcopy(self.network).double().cuda()\n",
    "            self.optimizers[str(idx)] = torch.optim.SGD(self.client_models[str(idx)].parameters(), lr=0.01,\n",
    "                                                        momentum=0.5)\n",
    "            dataset_train = MIT_BIH([self.patients_left[idx]], train_data)\n",
    "            self.len[str(idx)] = len(dataset_train)\n",
    "            self.dataloaders[str(idx)] = DataLoader(dataset_train, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "            dataset_test = MIT_BIH([self.patients_left[idx]], val_data)\n",
    "            self.len_test[str(idx)] = len(dataset_test)\n",
    "            self.dataloaders_test[str(idx)] = DataLoader(dataset_test, batch_size=32, shuffle=False)\n",
    "            self.best_test_loss[str(idx)] = 10000000\n",
    "            self.current_test_loss[str(idx)] = 100000\n",
    "            self.current_train_loss[str(idx)] = 1000000\n",
    "            if self.test == 'AFPL':\n",
    "                self.client_models_global[str(idx)] = copy.deepcopy(self.network).double().cuda()\n",
    "                self.shared_model = copy.deepcopy(self.network).double().cuda()\n",
    "\n",
    "            dataset_really_test = MIT_BIH([self.patients_left[idx]], test_data)\n",
    "            self.len_really_test[str(idx)] = len(dataset_really_test)\n",
    "            self.dataloaders_really_test[str(idx)] = DataLoader(dataset_really_test, batch_size=32, shuffle=False)\n",
    "        self.dataset_train = dataset_train\n",
    "\n",
    "    def update_local_models(self, selected_clients):\n",
    "        self.dw = {}\n",
    "        loss_test = 0\n",
    "        loss_test2 = 0\n",
    "        losses = 0\n",
    "        losses2 = 0\n",
    "        loss_test3 = 0\n",
    "        losses3 = 0\n",
    "\n",
    "        for idx, i in enumerate(selected_clients):\n",
    "\n",
    "            dataloader = self.dataloaders[str(i)]\n",
    "            optimizer = torch.optim.Adam(self.client_models[str(i)].parameters(), lr=0.001 * 0.95 ** self.iteration)\n",
    "            self.client_models[str(i)].train()\n",
    "\n",
    "            if self.test == 'AFPL':\n",
    "                self.client_models_global[str(i)] = copy.deepcopy(self.shared_model)\n",
    "                self.client_models_global[str(i)].train()\n",
    "                optimizer_global = torch.optim.Adam(self.client_models_global[str(i)].parameters(),\n",
    "                                                    lr=0.001 * 0.95 ** self.iteration)\n",
    "\n",
    "            for batch_idx, (data, target) in enumerate(dataloader):\n",
    "                #print(target)\n",
    "                data = data.double().unsqueeze(1).cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.client_models[str(i)](data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "                # data = data.double().cuda()\n",
    "                # target=target.long().cuda()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                # output = self.client_models[str(i)](data)\n",
    "                loss = F.nll_loss(output, target)\n",
    "\n",
    "                if self.test == 'AFPL':\n",
    "                    optimizer_global.zero_grad()\n",
    "                    output_global = self.client_models_global[str(i)](data)\n",
    "                    loss_global = F.nll_loss(output_global, target)\n",
    "                    loss_global.backward()\n",
    "                    optimizer_global.step()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            self.client_models[str(i)].eval()\n",
    "            dataloader_test = self.dataloaders_test[str(i)]\n",
    "            loss_test = 0\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (data, target) in enumerate(dataloader_test):\n",
    "                    data = data.double().unsqueeze(1).cuda()\n",
    "                    target = target.long().cuda()\n",
    "                    output = self.client_models[str(i)](data)\n",
    "                    output = F.log_softmax(output, dim=-1)\n",
    "\n",
    "                    loss_test += F.nll_loss(output, target)\n",
    "                self.current_test_loss[str(i)] = loss_test / self.len_test[str(i)]\n",
    "                if self.current_test_loss[str(i)] < self.best_test_loss[str(i)]:\n",
    "                    torch.save(self.client_models[str(i)].state_dict(),\n",
    "                               os.path.join(save_dir, 'model', 'best_model' + str(i) + '.pt'))\n",
    "                    self.best_test_loss[str(i)] = self.current_test_loss[str(i)]\n",
    "\n",
    "            losses += loss_test / self.len_test[str(i)]\n",
    "            loss_test2 = 0\n",
    "            self.client_models[str(i)].eval()\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (data, target) in enumerate(dataloader):\n",
    "                    data = data.double().unsqueeze(1).cuda()\n",
    "                    target = target.long().cuda()\n",
    "                    output = self.client_models[str(i)](data)\n",
    "                    output = F.log_softmax(output, dim=-1)\n",
    "\n",
    "                    loss_test2 += F.nll_loss(output, target)\n",
    "\n",
    "            losses2 += loss_test2 / self.len[str(i)]\n",
    "            self.current_train_loss[str(i)] = loss_test2 / self.len[str(i)]\n",
    "\n",
    "        print('full train loss: ', losses2)\n",
    "        print('full loss: ', losses)\n",
    "\n",
    "        return losses2, losses\n",
    "\n",
    "    def combine_models(self, i, client_numbers, set_as=True):\n",
    "        zero_copy = copy.deepcopy(self.client_models[str(i)])  # This is used to collect the model in\n",
    "        j = 0\n",
    "        client_numbers_plus_client = np.concatenate((client_numbers, np.array([int(i)])))  # This is more efficient\n",
    "        #  alphas = zero_copy.alphas.detach()\n",
    "        # alphas[i] = 1 - torch.sum(\n",
    "        #     torch.tensor([iii for idx, iii in enumerate(alphas) if idx != i and idx in client_numbers]))\n",
    "        # It's not possible to set the value of self.alphas[i], so instead we determine it manually here\n",
    "        alphas = torch.ones(len(client_numbers_plus_client)).cuda() / (len(client_numbers_plus_client))\n",
    "        # print(alphas)\n",
    "        for ii in client_numbers_plus_client:\n",
    "            #  print(ii)\n",
    "            for (name, param), (name2, param2) in zip(zero_copy.named_parameters(), self.client_models[\n",
    "                str(ii)].named_parameters()):  # self.client_models[str(ii)].named_parameters()):\n",
    "\n",
    "                if name != 'alphas':\n",
    "                    if j == 0:\n",
    "                        param.data = torch.zeros(param.shape).cuda()\n",
    "\n",
    "                    param.data += alphas[j] * param2.data  # we add all participating client's models to the one here.\n",
    "\n",
    "            j += 1\n",
    "\n",
    "        # self.client_models[str(i)] = zero_copy.double()\n",
    "        if set_as == True:\n",
    "            for (name, param), (name2, param2) in zip(self.client_models[str(i)].named_parameters(),\n",
    "                                                      zero_copy.named_parameters()):\n",
    "                param.data = param2.data\n",
    "            self.client_models[str(i)].double()\n",
    "        else:\n",
    "            return zero_copy.double()\n",
    "\n",
    "    def federated_averaging(self):\n",
    "        self.shared_model = copy.deepcopy(self.network).double().cuda()\n",
    "        n_clients = len(self.selected_clients)\n",
    "        weight = [self.len[str(x)] for x in self.selected_clients]\n",
    "        weight = weight / np.sum(weight)\n",
    "\n",
    "        losses = 0\n",
    "        losses2 = 0\n",
    "        # print(\"weights \",weight)\n",
    "        for idx, i in enumerate(self.selected_clients):\n",
    "            for (name, param), (name2, param2) in zip(self.shared_model.named_parameters()\n",
    "                    , self.client_models[str(i)].named_parameters()):\n",
    "                if idx == 0:\n",
    "                    param.data = torch.zeros(param.shape).cuda().double()\n",
    "                param.data += weight[idx] * param2.data\n",
    "\n",
    "        self.shared_model = self.shared_model.double().eval()\n",
    "\n",
    "        for i in self.selected_clients:\n",
    "            self.client_models[str(i)] = copy.deepcopy(self.shared_model)  # copy global model to the clients\n",
    "            loss_test = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(i)]):\n",
    "                data = data.double().unsqueeze(1).cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.shared_model(data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "\n",
    "                loss_test += F.nll_loss(output, target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test = loss_test / self.len_test[str(i)]\n",
    "            losses += loss_test\n",
    "            if loss_test < self.best_test_loss[str(i)]:\n",
    "                torch.save(self.client_models[str(i)].state_dict(),\n",
    "                           os.path.join(save_dir, 'model', 'best_model' + str(i) + '.pt'))\n",
    "                self.best_test_loss[str(i)] = loss_test\n",
    "            self.client_models[str(i)].eval()\n",
    "            loss_test2 = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders[str(i)]):\n",
    "                data = data.double().unsqueeze(1).cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.shared_model(data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "\n",
    "                loss_test2 += F.nll_loss(output, target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test2 = loss_test2 / self.len[str(i)]\n",
    "            losses2 += loss_test2\n",
    "\n",
    "        return losses, losses2\n",
    "\n",
    "    def AFPL(self):  # use alpha = 0.25 = 0.75 global model + 0.25 local model\n",
    "        self.shared_model_old = copy.deepcopy(self.shared_model)\n",
    "        self.shared_model = copy.deepcopy(self.network).double().cuda()\n",
    "        n_clients = len(self.selected_clients)\n",
    "        weight = [self.len[str(x)] for x in self.selected_clients]\n",
    "        weight = weight / np.sum(weight)\n",
    "\n",
    "        losses = 0\n",
    "        losses2 = 0\n",
    "\n",
    "        # accumulate local weights\n",
    "        for idx, i in enumerate(self.selected_clients):\n",
    "            for (name, param), (name2, param2), (name3, param3), (name4, param4) in zip(\n",
    "                    self.shared_model.named_parameters()\n",
    "                    , self.client_models_global[str(i)].named_parameters(),\n",
    "                    self.shared_model_old.named_parameters(),\n",
    "                    self.client_models[str(i)].named_parameters()):\n",
    "                if idx == 0:\n",
    "                    param.data = torch.zeros(param.shape).cuda().double()\n",
    "                param.data += weight[idx] * param2.data  # accumulate local weights\n",
    "                param4.data = 0.25 * param4.data + 0.75 * param3.data  # do AFPL local model update: note that we take the previous global model\n",
    "            self.client_models[str(i)] = self.client_models[str(i)].double()\n",
    "            self.client_models[str(i)].eval()\n",
    "            loss_test = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(i)]):\n",
    "                data = data.double().unsqueeze(1).cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.client_models[str(i)](data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "\n",
    "                loss_test += F.nll_loss(output, target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test = loss_test / self.len_test[str(i)]\n",
    "            losses += loss_test\n",
    "            if loss_test < self.best_test_loss[str(i)]:\n",
    "                torch.save(self.client_models[str(i)].state_dict(),\n",
    "                           os.path.join(save_dir, 'model', 'best_model' + str(i) + '.pt'))\n",
    "                self.best_test_loss[str(i)] = loss_test\n",
    "            self.client_models[str(i)].eval()\n",
    "            loss_test2 = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders[str(i)]):\n",
    "                data = data.double().unsqueeze(1).cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.client_models[str(i)](data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "\n",
    "                loss_test2 += F.nll_loss(output, target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test2 = loss_test2 / self.len[str(i)]\n",
    "            losses2 += loss_test2\n",
    "\n",
    "        self.shared_model = self.shared_model.double()\n",
    "        return losses, losses2\n",
    "    \n",
    "    def calc_accuracy(self, dataloaders, length):\n",
    "        accuracies = np.zeros(len(self.selected_clients))\n",
    "        total = 0\n",
    "        self.accuracy_list = []\n",
    "        preds = []\n",
    "        trues = []\n",
    "        for i in self.selected_clients:\n",
    "            # dataloader = self.dataloaders_really_test[str(i)]\n",
    "            dataloader = dataloaders[str(i)]\n",
    "            intermediate_accuracy = 0\n",
    "            self.client_models[str(i)].eval()\n",
    "            y_pred = []\n",
    "            y_true = []\n",
    "            for batch_idx, (data, target) in enumerate(dataloader):\n",
    "                data = data.double().unsqueeze(1).cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.client_models[str(i)](data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "                output_array = output.detach().cpu().numpy()\n",
    "                output_class = np.argmax(output_array, axis=-1)\n",
    "                target_array = target.detach().cpu().numpy()\n",
    "                intermediate_accuracy += np.sum(output_class == target_array)\n",
    "                y_pred.append(list(output_class))\n",
    "                y_true.append(list(target_array))\n",
    "\n",
    "            # accuracy = intermediate_accuracy / p2p.len_really_test[str(i)] * 100\n",
    "            # print(i)\n",
    "            accuracy = intermediate_accuracy / length[str(i)] * 100\n",
    "\n",
    "            #self.accuracy_list.append(accuracy)\n",
    "            for sub in y_pred:\n",
    "                for j in sub:\n",
    "                    preds.append(j)\n",
    "            for sub in y_true:\n",
    "                for j in sub:\n",
    "                    trues.append(j)\n",
    "            #preds.append([j for sub in y_pred for j in sub])\n",
    "            pred = np.array([j for sub in y_pred for j in sub])\n",
    "            true = np.array([j for sub in y_true for j in sub])\n",
    "            #print(i)\n",
    "\n",
    "            #print(pred)\n",
    "            #print(true)\n",
    "            #print(balanced_accuracy_score(true, pred))\n",
    "            self.accuracy_list.append(balanced_accuracy_score(true,pred))\n",
    "\n",
    "            C = confusion_matrix(true, pred).ravel()\n",
    "            if len(C) == 4:\n",
    "                df = pandas.DataFrame([[C[3], C[1]], [C[2], C[0]]], columns=['Positive', 'Negative'],\n",
    "                                      index=['Predicted Positive', 'Predicted Negative'])\n",
    "\n",
    "            total += length[str(i)]\n",
    "            accuracies[i] = intermediate_accuracy\n",
    "\n",
    "        overall_accuracy = np.sum(accuracies) / total * 100\n",
    "        #print()\n",
    "\n",
    "       # breakpoint()\n",
    "    # just for debugging \n",
    "        self.trues = trues \n",
    "        self.preds = preds \n",
    "        print(np.unique(trues,return_counts=True))\n",
    "        print(np.unique(preds,return_counts=True))\n",
    "\n",
    "        return balanced_accuracy_score(trues,preds)#overall_accuracy\n",
    "\n",
    "    \n",
    "    def calc_accuracy2(self, dataloaders, length):\n",
    "        accuracies = np.zeros(len(self.selected_clients))\n",
    "        total = 0\n",
    "        self.accuracy_list = []\n",
    "        for i in self.selected_clients:\n",
    "            # dataloader = self.dataloaders_really_test[str(i)]\n",
    "            dataloader = dataloaders[str(i)]\n",
    "            intermediate_accuracy = 0\n",
    "            self.client_models[str(i)].eval()\n",
    "            y_pred = []\n",
    "            y_true = []\n",
    "            for batch_idx, (data, target) in enumerate(dataloader):\n",
    "                data = data.double().unsqueeze(1).cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.client_models[str(i)](data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "                \n",
    "                output_array = output.detach().cpu().numpy()\n",
    "                output_class = np.argmax(output_array, axis=-1)\n",
    "                target_array = target.detach().cpu().numpy()\n",
    "                intermediate_accuracy += np.sum(output_class == target_array)\n",
    "                y_pred.append(list(output_class))\n",
    "                y_true.append(list(target_array))\n",
    "\n",
    "            # accuracy = intermediate_accuracy / p2p.len_really_test[str(i)] * 100\n",
    "            # print(i)\n",
    "            accuracy = intermediate_accuracy / length[str(i)] * 100\n",
    "            #if self.iteration % 5 == 0:\n",
    "            #    print('client accuracy : ', str(i))\n",
    "             #   print(accuracy)\n",
    "            self.accuracy_list.append(accuracy)\n",
    "\n",
    "            pred = np.array([j for sub in y_pred for j in sub])\n",
    "            true = np.array([j for sub in y_true for j in sub])\n",
    "            C = confusion_matrix(true, pred).ravel()\n",
    "            if len(C) == 4:\n",
    "                df = pandas.DataFrame([[C[3], C[1]], [C[2], C[0]]], columns=['Positive', 'Negative'],\n",
    "                                      index=['Predicted Positive', 'Predicted Negative'])\n",
    "\n",
    "            total += length[str(i)]\n",
    "            accuracies[i] = intermediate_accuracy\n",
    "        overall_accuracy = np.sum(accuracies) / total * 100\n",
    "\n",
    "        return overall_accuracy\n",
    "\n",
    "    def my_method2(self, client, k=30):\n",
    "\n",
    "        selected_clients = []\n",
    "        other_clients = [x for x in range(self.total_clients) if x is not client]\n",
    "        ey = np.zeros(len(other_clients))  # fix indices\n",
    "        current_test = np.zeros(len(other_clients))\n",
    "        collected_clients = []\n",
    "        list1 = np.arange(len(other_clients))\n",
    "        np.random.shuffle(list1)\n",
    "        for i in list1[:k]:\n",
    "            shared_model = self.combine_models(client, [other_clients[i]], set_as=False)\n",
    "\n",
    "            if len(collected_clients) > 0:\n",
    "                all_clients = collected_clients + [other_clients[i]]\n",
    "                shared_model2 = self.combine_models(client, all_clients, set_as=False)\n",
    "\n",
    "            shared_model.eval().cuda()\n",
    "            self.client_models[str(client)].eval().cuda()\n",
    "            loss_test = 0\n",
    "            loss_test2 = 0\n",
    "            loss_test3 = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(client)]):\n",
    "                data = data.unsqueeze(1).double().cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = shared_model(data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "                local_output = self.client_models[str(client)](data)\n",
    "                local_output = F.log_softmax(local_output, dim=-1)\n",
    "\n",
    "                loss_test += F.nll_loss(output, target).detach().cpu().numpy()\n",
    "                loss_test2 += F.nll_loss(local_output, target).detach().cpu().numpy()\n",
    "\n",
    "                if len(collected_clients) > 0:\n",
    "                    output2 = shared_model2(data)\n",
    "                    output2 = F.log_softmax(output2, dim=-1)\n",
    "                    loss_test3 += F.nll_loss(output2, target).detach().cpu().numpy()\n",
    "\n",
    "            ey[i] = loss_test / self.len_test[str(client)]\n",
    "            current_test[i] = loss_test2 / self.len_test[str(client)]\n",
    "            if ey[i] < current_test[i]:\n",
    "                if len(collected_clients) > 0:\n",
    "                    test2 = loss_test3 / self.len_test[str(client)]\n",
    "                    if test2 < current_test[i]:\n",
    "                        collected_clients.append(other_clients[i])\n",
    "                else:\n",
    "                    collected_clients.append(other_clients[i])\n",
    "        loss_test = current_test[i]\n",
    "        # print(client)\n",
    "        # print(loss_test)\n",
    "        # print(self.current_test_loss[str(client)])\n",
    "        # print(ey)\n",
    "\n",
    "        selected_clients = np.where(ey <= self.current_test_loss[str(client)].detach().cpu().numpy())[0]\n",
    "        selected_clients = [other_clients[x] for x in selected_clients]\n",
    "        # print(selected_clients)\n",
    "        selected_clients = collected_clients\n",
    "\n",
    "        if len(selected_clients) > 0:\n",
    "            self.combine_models(client, selected_clients, set_as=True)\n",
    "            loss_test = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(client)]):\n",
    "                data = data.unsqueeze(1).double().cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.client_models[str(client)](data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "\n",
    "                loss_test += F.nll_loss(output, target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test = loss_test / self.len_test[str(client)]\n",
    "            if loss_test < self.best_test_loss[str(client)]:\n",
    "                torch.save(self.client_models[str(client)].state_dict(),\n",
    "                           os.path.join(save_dir, 'model', 'best_model' + str(i) + '.pt'))\n",
    "                self.best_test_loss[str(client)] = loss_test\n",
    "            self.client_models[str(client)].eval()\n",
    "            loss_test2 = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders[str(client)]):\n",
    "                data = data.unsqueeze(1).double().cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.client_models[str(client)](data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "                loss_test2 += F.nll_loss(output, target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test2 = loss_test2 / self.len[str(client)]\n",
    "        return loss_test, loss_test2, selected_clients\n",
    "\n",
    "    def bandits(self, client, n):\n",
    "\n",
    "        selected_clients = []\n",
    "        other_clients = [x for x in range(self.total_clients) if x != client]\n",
    "        # print(other_clients)\n",
    "        ey = np.zeros(self.total_clients)  # fix indices\n",
    "        current_test = np.zeros(self.total_clients)\n",
    "        collected_clients = []\n",
    "\n",
    "        selected_clients_UCB = self.comb_UCB.to_client([client], n)\n",
    "        if client == 1:\n",
    "            print('selected clients UCB: ', selected_clients_UCB)\n",
    "        for i in selected_clients_UCB:\n",
    "            shared_model = self.combine_models(client, [i], set_as=False)\n",
    "\n",
    "            if len(collected_clients) > 0:\n",
    "                all_clients = collected_clients + [i]\n",
    "                shared_model2 = self.combine_models(client, all_clients, set_as=False)\n",
    "\n",
    "            shared_model.eval().cuda()\n",
    "            self.client_models[str(client)].eval().cuda()\n",
    "            loss_test = 0\n",
    "            loss_test2 = 0\n",
    "            loss_test3 = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(client)]):\n",
    "                data = data.unsqueeze(1).double().cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = shared_model(data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "                output2 = self.client_models[str(client)](data)\n",
    "                output2 = F.log_softmax(output2, dim=-1)\n",
    "                loss_test += F.nll_loss(output, target).detach().cpu().numpy()\n",
    "                loss_test2 += F.nll_loss(output2, target).detach().cpu().numpy()\n",
    "\n",
    "                if len(collected_clients) > 0:\n",
    "                    output = shared_model2(data)\n",
    "                    output = F.log_softmax(output, dim=-1)\n",
    "                    loss_test3 += F.nll_loss(output, target).detach().cpu().numpy()\n",
    "\n",
    "            ey[i] = loss_test / self.len_test[str(client)]\n",
    "            current_test[i] = loss_test2 / self.len_test[str(client)]\n",
    "            if ey[i] < current_test[i]:\n",
    "                if len(collected_clients) > 0:\n",
    "                    test2 = loss_test3 / self.len_test[str(client)]\n",
    "                    if test2 < current_test[i]:\n",
    "                        collected_clients.append(i)\n",
    "                else:\n",
    "                    collected_clients.append(i)\n",
    "        loss_test = current_test[i]\n",
    "        selected_clients = np.where(ey <= self.current_test_loss[str(client)].detach().cpu().numpy())[0]\n",
    "        # selected_clients = [other_clients[x] for x in selected_clients]\n",
    "\n",
    "        selected_clients = collected_clients\n",
    "\n",
    "        observation = np.zeros(self.total_clients)\n",
    "        observation[selected_clients] = 1\n",
    "        if client == 1:\n",
    "            print(observation)\n",
    "\n",
    "        self.comb_UCB.to_server(client, observation)\n",
    "\n",
    "        if len(selected_clients) > 0:\n",
    "            self.combine_models(client, selected_clients, set_as=True)\n",
    "            loss_test = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(client)]):\n",
    "                data = data.unsqueeze(1).double().cuda()\n",
    "                target = target.long().cuda()\n",
    "                output2 = self.client_models[str(client)](data)\n",
    "                output2 = F.log_softmax(output2, dim=-1)\n",
    "\n",
    "                loss_test += F.nll_loss(output2, target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test = loss_test / self.len_test[str(client)]\n",
    "            if loss_test < self.best_test_loss[str(client)]:\n",
    "                torch.save(self.client_models[str(client)].state_dict(),\n",
    "                           os.path.join(save_dir, 'model', 'best_model' + str(i) + '.pt'))\n",
    "                self.best_test_loss[str(client)] = loss_test\n",
    "            self.client_models[str(client)].eval()\n",
    "            loss_test2 = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders[str(client)]):\n",
    "                data = data.unsqueeze(1).double().cuda()\n",
    "                target = target.long().cuda()\n",
    "                output2 = self.client_models[str(client)](data)\n",
    "                output2 = F.log_softmax(output2, dim=-1)\n",
    "\n",
    "                loss_test2 += F.nll_loss(output2, target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test2 = loss_test2 / self.len[str(client)]\n",
    "            \n",
    "        return loss_test, loss_test2, selected_clients, selected_clients_UCB\n",
    "\n",
    "    def loop(self, epochs, p2p, experiment_name):\n",
    "\n",
    "        loss_tests = []\n",
    "        loss_trains = []\n",
    "        loss_tests2 = []\n",
    "        loss_trains2 = []\n",
    "        accuracies = []\n",
    "        accuracies_train = []\n",
    "        self.p2p = p2p\n",
    "        self.phis = np.zeros((self.total_clients, self.total_clients))\n",
    "        self.phisUCB = np.zeros((self.total_clients, self.total_clients))\n",
    "        self.selected_clients_arr = np.zeros((epochs, self.total_clients, self.total_clients))\n",
    "        best_accuracy = 0\n",
    "\n",
    "        for i in range(epochs):\n",
    "            print(i)\n",
    "            self.iteration = i\n",
    "            list1 = []\n",
    "            self.selected_clients = [x for x in range(self.total_clients)]\n",
    "\n",
    "            loss_train, loss_test = self.update_local_models(self.selected_clients)\n",
    "            loss_tests.append(loss_test.detach().cpu().numpy())\n",
    "            loss_trains.append(loss_train.detach().cpu().numpy())\n",
    "\n",
    "            if self.test == 'AFPL':\n",
    "                losses2, losses3 = self.AFPL()\n",
    "\n",
    "            if self.test == 'local':\n",
    "                print('we are done')\n",
    "\n",
    "            if self.test == 'federated':\n",
    "                losses2, losses3 = self.federated_averaging()\n",
    "\n",
    "            if self.test == 'bandits':\n",
    "                losses2 = 0\n",
    "                losses3 = 0\n",
    "                for client in range(self.total_clients):\n",
    "                    loss_test2, loss_train2, selected_clients2,selected_clients_UCB = self.bandits(client, i)\n",
    "                    losses2 += loss_test2\n",
    "                    if len(selected_clients2) < 1:\n",
    "                        losses3 += self.current_train_loss[str(client)].detach().cpu().numpy()\n",
    "                    else:\n",
    "                        losses3 += loss_train2\n",
    "                    self.phis[client, selected_clients2] += 1\n",
    "                    self.phisUCB[client,selected_clients_UCB] += 1\n",
    "                    self.selected_clients_arr[i, client, selected_clients2] += 1\n",
    "                fname = os.path.join('checkpoints_bandits', experiment_name, 'phi' + str(i) + '.txt')\n",
    "                np.savetxt(fname, self.phis)\n",
    "                fname = os.path.join('checkpoints_bandits', experiment_name, 'phi_UCB' + str(i) + '.txt')\n",
    "                np.savetxt(fname, self.phisUCB)\n",
    "\n",
    "            if self.test == 'mine':\n",
    "                losses2 = 0\n",
    "                losses3 = 0\n",
    "                for client in range(self.total_clients):\n",
    "                    loss_test2, loss_train2, selected_clients2 = self.my_method2(client)\n",
    "                    losses2 += loss_test2\n",
    "                    if len(selected_clients2) < 1:\n",
    "                        losses3 += self.current_train_loss[str(client)].detach().cpu().numpy()\n",
    "\n",
    "                    else:\n",
    "                        losses3 += loss_train2\n",
    "                    self.phis[client, selected_clients2] += 1\n",
    "                    # print(selected_clients2)\n",
    "                fname = os.path.join('checkpoints_bandits', experiment_name, 'phi' + str(i) + '.txt')\n",
    "                np.savetxt(fname, self.phis)\n",
    "\n",
    "            if self.test == 'optimal':\n",
    "                losses2, losses3 = self.optimal_fedavg()\n",
    "                losses2 = losses2.detach().cpu().numpy()\n",
    "                losses3 = losses3.detach().cpu().numpy()\n",
    "\n",
    "            if self.test != 'local':\n",
    "                print('loss after my code: ', losses2)\n",
    "                print('train loss after my code: ', losses3)\n",
    "                loss_tests2.append(losses2)\n",
    "                loss_trains2.append(losses3)\n",
    "                fname = os.path.join('checkpoints_bandits', experiment_name, 'losses_test.txt')\n",
    "                np.savetxt(fname, loss_tests2)\n",
    "                fname = os.path.join('checkpoints_bandits', experiment_name, 'losses_train.txt')\n",
    "                np.savetxt(fname, loss_trains2)\n",
    "\n",
    "\n",
    "            else:\n",
    "                fname = os.path.join('checkpoints_bandits', experiment_name, 'losses_test.txt')\n",
    "                np.savetxt(fname, loss_tests)\n",
    "                fname = os.path.join('checkpoints_bandits', experiment_name, 'losses_train.txt')\n",
    "                np.savetxt(fname, loss_trains)\n",
    "\n",
    "            accuracy_val = self.calc_accuracy(self.dataloaders_test, self.len_test)\n",
    "            print('val accuracy: ', accuracy_val)\n",
    "\n",
    "            accuracy = self.calc_accuracy(self.dataloaders_really_test, self.len_really_test)\n",
    "            print('test accuracy: ', accuracy)\n",
    "            accuracies.append(accuracy)\n",
    "            if accuracy_val > best_accuracy:\n",
    "                print(best_accuracy)\n",
    "                print('accuracy is best accuracy')\n",
    "                print(self.accuracy_list)\n",
    "                best_accuracy = accuracy_val\n",
    "                self.best_accuracy = accuracy\n",
    "\n",
    "                # save all of this in a .txt file\n",
    "                fname = os.path.join('checkpoints_bandits', experiment_name, 'test_accuracies.txt')\n",
    "                np.savetxt(fname, self.accuracy_list)\n",
    "                fname = os.path.join('checkpoints_bandits', experiment_name, 'test_accuracy.txt')\n",
    "                np.savetxt(fname, [accuracy])\n",
    "            # accuracy_train = self.calc_accuracy(test=False)\n",
    "            # print(accuracy_train)\n",
    "            # accuracies_train.append(accuracy_train)\n",
    "        # print(self.phis)\n",
    "        fname = os.path.join('checkpoints_bandits', experiment_name, 'accuracies.txt')\n",
    "        np.savetxt(fname, accuracies)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_trains, label='train loss before')\n",
    "        plt.plot(loss_tests, label='test loss before')\n",
    "        plt.plot(loss_trains2, label='train loss after')\n",
    "        plt.plot(loss_tests2, label='test loss after')\n",
    "        plt.title('loss curve')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.savefig(os.path.join('checkpoints_bandits', experiment_name, 'loss_curve.png'))\n",
    "        plt.clf()\n",
    "        plt.plot(accuracies, label='test')\n",
    "        # plt.plot(accuracies_train,label='train')\n",
    "        plt.title('accuracy progression')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join('checkpoints_bandits', experiment_name, 'accuracy_progression.png'))\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "import shutil\n",
    "def init():\n",
    "    with open('settings/train_settings_bandits.yaml', 'r') as file:\n",
    "        settings = yaml.safe_load(file)\n",
    "    if not os.path.isdir('checkpoints_bandits'):\n",
    "        os.mkdir('checkpoints_bandits')\n",
    "    if not os.path.isdir(os.path.join('checkpoints_bandits', settings['experiment_name'])):\n",
    "        os.mkdir(os.path.join('checkpoints_bandits', settings['experiment_name']))\n",
    "    save_dir = os.path.join('checkpoints_bandits', settings['experiment_name'])\n",
    "    if not os.path.isdir(os.path.join(save_dir, 'model')):\n",
    "        os.mkdir(os.path.join(save_dir, 'model'))\n",
    "    shutil.copyfile('settings/train_settings.yaml', save_dir + '/train_settings.yaml')\n",
    "    return settings,save_dir\n",
    "\n",
    "\n",
    "\n",
    "settings, save_dir = init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12d403ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 1.0, 0.5]\n",
      "0.9354420589940808\n"
     ]
    }
   ],
   "source": [
    "local_acc = p2p.accuracy_list\n",
    "print(local_acc)\n",
    "local_best = p2p.best_accuracy\n",
    "print(local_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31a1c821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints_bandits/MIT3B_bandits_010_20_5\n",
      "type:  bandits\n",
      "0\n",
      "full train loss:  tensor(0.0993, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1092, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.10916934946328163\n",
      "train loss after my code:  0.0992658288852627\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "0\n",
      "accuracy is best accuracy\n",
      "[0.3333333333333333, 0.3333333333333333, 0.5]\n",
      "1\n",
      "full train loss:  tensor(0.0857, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0942, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[1. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after my code:  0.09304928429279295\n",
      "train loss after my code:  0.08473169607676784\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "2\n",
      "full train loss:  tensor(0.0744, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0817, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[1. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after my code:  0.0811608191243994\n",
      "train loss after my code:  0.07397291995938038\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "3\n",
      "full train loss:  tensor(0.0670, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0727, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.07274869325282003\n",
      "train loss after my code:  0.06699073196432614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "4\n",
      "full train loss:  tensor(0.0610, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0667, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.06669542765308259\n",
      "train loss after my code:  0.06096400669322717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "5\n",
      "full train loss:  tensor(0.0574, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0628, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.06275019594739666\n",
      "train loss after my code:  0.05738348088750596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "6\n",
      "full train loss:  tensor(0.0550, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0594, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.059399681592193936\n",
      "train loss after my code:  0.055036218100968884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "7\n",
      "full train loss:  tensor(0.0529, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0568, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.05679710932937756\n",
      "train loss after my code:  0.052868190752489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "8\n",
      "full train loss:  tensor(0.0509, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0544, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.054401793702163456\n",
      "train loss after my code:  0.050910973685631314\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "9\n",
      "full train loss:  tensor(0.0491, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0526, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.05262820125542901\n",
      "train loss after my code:  0.0490986972992091\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "10\n",
      "full train loss:  tensor(0.0466, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0501, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.05008620143659135\n",
      "train loss after my code:  0.046615419776773234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "11\n",
      "full train loss:  tensor(0.0446, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0474, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.047393806380618284\n",
      "train loss after my code:  0.044628582503301775\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "12\n",
      "full train loss:  tensor(0.0421, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0447, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.04472767702077404\n",
      "train loss after my code:  0.04214285065451804\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([161,  59,   1]))\n",
      "val accuracy:  0.6289528577388402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3947, 1481,  114]))\n",
      "test accuracy:  0.6612918850027537\n",
      "0.6191489361702128\n",
      "accuracy is best accuracy\n",
      "[0.3870056497175141, 0.3333333333333333, 0.5]\n",
      "13\n",
      "full train loss:  tensor(0.0400, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0425, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.042502378924339536\n",
      "train loss after my code:  0.039996132324143466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([140,  59,  22]))\n",
      "val accuracy:  0.8348352106800166\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3572, 1481,  489]))\n",
      "test accuracy:  0.8346622040041406\n",
      "0.6289528577388402\n",
      "accuracy is best accuracy\n",
      "[0.5635593220338984, 0.3333333333333333, 0.5]\n",
      "14\n",
      "full train loss:  tensor(0.0381, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0401, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.04012075858081926\n",
      "train loss after my code:  0.03811319308236151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([137,  59,  25]))\n",
      "val accuracy:  0.8642469753858991\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3503, 1481,  558]))\n",
      "test accuracy:  0.8665623427003958\n",
      "0.8348352106800166\n",
      "accuracy is best accuracy\n",
      "[0.596045197740113, 0.3333333333333333, 0.5]\n",
      "15\n",
      "full train loss:  tensor(0.0355, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0384, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.03839124687317928\n",
      "train loss after my code:  0.03546928990277162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([137,  59,  25]))\n",
      "val accuracy:  0.8642469753858991\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3497, 1481,  564]))\n",
      "test accuracy:  0.869336267804418\n",
      "16\n",
      "full train loss:  tensor(0.0337, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0365, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.03649978068958143\n",
      "train loss after my code:  0.03369220374098818\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([137,  59,  25]))\n",
      "val accuracy:  0.8642469753858991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3472, 1481,  589]))\n",
      "test accuracy:  0.8808942890711772\n",
      "17\n",
      "full train loss:  tensor(0.0322, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0345, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.03453643726282556\n",
      "train loss after my code:  0.03223896009120239\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([137,  59,  25]))\n",
      "val accuracy:  0.8642469753858991\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3461, 1481,  600]))\n",
      "test accuracy:  0.8859798184285511\n",
      "18\n",
      "full train loss:  tensor(0.0296, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0333, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.03327225547703537\n",
      "train loss after my code:  0.02964090110631852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([137,  59,  25]))\n",
      "val accuracy:  0.8642469753858991\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3458, 1481,  603]))\n",
      "test accuracy:  0.8873667809805622\n",
      "19\n",
      "full train loss:  tensor(0.0278, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0315, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.03151319134310507\n",
      "train loss after my code:  0.02779013996124264\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([135,  59,  27]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy:  0.883854818523154\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3448, 1481,  613]))\n",
      "test accuracy:  0.8919899894872659\n",
      "0.8642469753858991\n",
      "accuracy is best accuracy\n",
      "[0.621939736346516, 0.3333333333333333, 0.5]\n",
      "20\n",
      "full train loss:  tensor(0.0261, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0299, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.02988326396177452\n",
      "train loss after my code:  0.026086851668974814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([139,  55,  27]))\n",
      "val accuracy:  0.8933786280469634\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3548, 1376,  618]))\n",
      "test accuracy:  0.9036734959863227\n",
      "0.883854818523154\n",
      "accuracy is best accuracy\n",
      "[0.6238229755178908, 0.3333333333333333, 0.662037037037037]\n",
      "21\n",
      "full train loss:  tensor(0.0246, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0285, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.028515799927501757\n",
      "train loss after my code:  0.024630509661728923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([139,  55,  27]))\n",
      "val accuracy:  0.8933786280469634\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3552, 1371,  619]))\n",
      "test accuracy:  0.9040481330566609\n",
      "22\n",
      "full train loss:  tensor(0.0238, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0271, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.027126714525426213\n",
      "train loss after my code:  0.023806437097734594\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  51,  27]))\n",
      "val accuracy:  0.902902437570773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1320,  626]))\n",
      "test accuracy:  0.9115986808074941\n",
      "0.8933786280469634\n",
      "accuracy is best accuracy\n",
      "[0.6264148969350973, 0.3333333333333333, 0.7484567901234568]\n",
      "23\n",
      "full train loss:  tensor(0.0220, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0258, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.02575473324898885\n",
      "train loss after my code:  0.021996291919546704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  51,  27]))\n",
      "val accuracy:  0.902902437570773\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3597, 1313,  632]))\n",
      "test accuracy:  0.9131789373819265\n",
      "24\n",
      "full train loss:  tensor(0.0215, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0246, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.024619406120143374\n",
      "train loss after my code:  0.02153757024880988\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([145,  49,  27]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy:  0.9076643423326778\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3652, 1252,  638]))\n",
      "test accuracy:  0.9216660778086049\n",
      "0.902902437570773\n",
      "accuracy is best accuracy\n",
      "[0.6301813752778469, 0.3333333333333333, 0.8533950617283951]\n",
      "25\n",
      "full train loss:  tensor(0.0203, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0236, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[1. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after my code:  0.023508515105630266\n",
      "train loss after my code:  0.021675862924713678\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([144,  48,  29]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3658, 1239,  645]))\n",
      "test accuracy:  0.9246392724223006\n",
      "0.9076643423326778\n",
      "accuracy is best accuracy\n",
      "[0.631831677109366, 0.3333333333333333, 0.8734567901234568]\n",
      "26\n",
      "full train loss:  tensor(0.0207, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0226, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[1. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after my code:  0.022607000371029078\n",
      "train loss after my code:  0.020928993418185715\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([145,  47,  29]))\n",
      "val accuracy:  0.9320340902318375\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3681, 1213,  648]))\n",
      "test accuracy:  0.9284613759315095\n",
      "0.929653137850885\n",
      "accuracy is best accuracy\n",
      "[0.6332441064878971, 0.3333333333333333, 0.9135802469135803]\n",
      "27\n",
      "full train loss:  tensor(0.0203, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0217, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.021668719974949555\n",
      "train loss after my code:  0.020256379846656503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  46,  29]))\n",
      "val accuracy:  0.9344150426127898\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3686, 1207,  649]))\n",
      "test accuracy:  0.929485652387687\n",
      "0.9320340902318375\n",
      "accuracy is best accuracy\n",
      "[0.6337149162807408, 0.3333333333333333, 0.9228395061728395]\n",
      "28\n",
      "full train loss:  tensor(0.0194, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0206, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.020550169022611024\n",
      "train loss after my code:  0.019396339988063494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  46,  29]))\n",
      "val accuracy:  0.9344150426127898\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3681, 1204,  657]))\n",
      "test accuracy:  0.9320782344437925\n",
      "29\n",
      "full train loss:  tensor(0.0172, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0197, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.01967214726306728\n",
      "train loss after my code:  0.017167257233468746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([145,  46,  30]))\n",
      "val accuracy:  0.9344150426127898\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3680, 1202,  660]))\n",
      "test accuracy:  0.9331901946803022\n",
      "30\n",
      "full train loss:  tensor(0.0165, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0189, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.018899535341438407\n",
      "train loss after my code:  0.016471476592249738\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([145,  46,  30]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy:  0.9344150426127898\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3680, 1200,  662]))\n",
      "test accuracy:  0.9334820437895766\n",
      "31\n",
      "full train loss:  tensor(0.0154, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0184, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.018366139372612694\n",
      "train loss after my code:  0.015372948948877196\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([145,  46,  30]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy:  0.9344150426127898\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3681, 1197,  664]))\n",
      "test accuracy:  0.9337738928988509\n",
      "32\n",
      "full train loss:  tensor(0.0150, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0177, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.01771108145036094\n",
      "train loss after my code:  0.014980362036135973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  46,  32]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3677, 1194,  671]))\n",
      "test accuracy:  0.935160855450862\n",
      "33\n",
      "full train loss:  tensor(0.0135, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0172, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.01715767514447738\n",
      "train loss after my code:  0.013537474543544712\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  46,  32]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3651, 1194,  697]))\n",
      "test accuracy:  0.9363545239804519\n",
      "34\n",
      "full train loss:  tensor(0.0130, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0169, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.01689810569206175\n",
      "train loss after my code:  0.01301417787029845\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  46,  32]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3653, 1194,  695]))\n",
      "test accuracy:  0.9345988998453549\n",
      "35\n",
      "full train loss:  tensor(0.0124, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0164, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.01642741678749072\n",
      "train loss after my code:  0.012407591723610216\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  45,  33]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy:  0.9320340902318375\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3631, 1191,  720]))\n",
      "test accuracy:  0.9358153906559701\n",
      "36\n",
      "full train loss:  tensor(0.0122, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0161, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.01607103304105214\n",
      "train loss after my code:  0.012182574274042183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  45,  33]))\n",
      "val accuracy:  0.9320340902318375\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3612, 1193,  737]))\n",
      "test accuracy:  0.9373728249493771\n",
      "37\n",
      "full train loss:  tensor(0.0119, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0157, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.015694175583352385\n",
      "train loss after my code:  0.011871224472322767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  45,  33]))\n",
      "val accuracy:  0.9320340902318375\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3601, 1185,  756]))\n",
      "test accuracy:  0.9387934810889345\n",
      "38\n",
      "full train loss:  tensor(0.0108, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0155, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.015487095089383982\n",
      "train loss after my code:  0.010830284677645432\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  45,  33]))\n",
      "val accuracy:  0.9320340902318375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3607, 1183,  752]))\n",
      "test accuracy:  0.9372360467955275\n",
      "39\n",
      "full train loss:  tensor(0.0101, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0152, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.015184704389057245\n",
      "train loss after my code:  0.01009095528686952\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([143,  45,  33]))\n",
      "val accuracy:  0.9320340902318375\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3603, 1183,  756]))\n",
      "test accuracy:  0.9376983676461977\n",
      "40\n",
      "full train loss:  tensor(0.0099, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0147, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.01474261322579449\n",
      "train loss after my code:  0.009912654788388537\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([143,  45,  33]))\n",
      "val accuracy:  0.9320340902318375\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3599, 1180,  763]))\n",
      "test accuracy:  0.9388103278827077\n",
      "41\n",
      "full train loss:  tensor(0.0094, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0144, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.014366035488567698\n",
      "train loss after my code:  0.009388565171972044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  45,  33]))\n",
      "val accuracy:  0.9320340902318375\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3600, 1175,  767]))\n",
      "test accuracy:  0.9393831547947356\n",
      "42\n",
      "full train loss:  tensor(0.0094, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0141, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.014083690929174268\n",
      "train loss after my code:  0.009425367817477853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  45,  33]))\n",
      "val accuracy:  0.9320340902318375\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1178,  769]))\n",
      "test accuracy:  0.9403846089698877\n",
      "43\n",
      "full train loss:  tensor(0.0093, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0137, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.013741908043866302\n",
      "train loss after my code:  0.009318472849195897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1174,  773]))\n",
      "test accuracy:  0.9417884183156721\n",
      "44\n",
      "full train loss:  tensor(0.0085, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0135, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.013525453765686613\n",
      "train loss after my code:  0.008514405597057653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3594, 1173,  775]))\n",
      "test accuracy:  0.9418820775832565\n",
      "45\n",
      "full train loss:  tensor(0.0086, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0133, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.013337975974824248\n",
      "train loss after my code:  0.008645748200879934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  45,  33]))\n",
      "val accuracy:  0.9320340902318375\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1171,  776]))\n",
      "test accuracy:  0.9417116058418605\n",
      "46\n",
      "full train loss:  tensor(0.0082, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0132, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.013213719656769204\n",
      "train loss after my code:  0.008155122361281485\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([143,  45,  33]))\n",
      "val accuracy:  0.9320340902318375\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1171,  775]))\n",
      "test accuracy:  0.9412492849911902\n",
      "47\n",
      "full train loss:  tensor(0.0078, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0130, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.012980977698862656\n",
      "train loss after my code:  0.007798426019195813\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  45,  33]))\n",
      "val accuracy:  0.9320340902318375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3597, 1170,  775]))\n",
      "test accuracy:  0.9413429442587747\n",
      "48\n",
      "full train loss:  tensor(0.0077, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0128, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.012835610181746114\n",
      "train loss after my code:  0.007701345276732743\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  45,  33]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy:  0.9320340902318375\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3593, 1170,  779]))\n",
      "test accuracy:  0.9418052651094451\n",
      "49\n",
      "full train loss:  tensor(0.0076, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0127, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.012656130499791186\n",
      "train loss after my code:  0.007569629136311241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3592, 1169,  781]))\n",
      "test accuracy:  0.9428235660783703\n",
      "50\n",
      "full train loss:  tensor(0.0073, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0126, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.012590176317496145\n",
      "train loss after my code:  0.007258787949185701\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  45,  33]))\n",
      "val accuracy:  0.9320340902318375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1169,  778]))\n",
      "test accuracy:  0.9414366035263594\n",
      "51\n",
      "full train loss:  tensor(0.0075, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0125, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.012477188478895231\n",
      "train loss after my code:  0.007467110706079591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  45,  33]))\n",
      "val accuracy:  0.9320340902318375\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3593, 1170,  779]))\n",
      "test accuracy:  0.9422675859601154\n",
      "52\n",
      "full train loss:  tensor(0.0071, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0123, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.012253869736145166\n",
      "train loss after my code:  0.007098226780414986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3592, 1169,  781]))\n",
      "test accuracy:  0.9428235660783703\n",
      "53\n",
      "full train loss:  tensor(0.0076, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0122, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.012154490856070198\n",
      "train loss after my code:  0.0075998723773386834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3591, 1168,  783]))\n",
      "test accuracy:  0.9432858869290408\n",
      "54\n",
      "full train loss:  tensor(0.0069, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0121, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.012051881599550222\n",
      "train loss after my code:  0.006883773052373698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3593, 1166,  783]))\n",
      "test accuracy:  0.9431154151876449\n",
      "55\n",
      "full train loss:  tensor(0.0067, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0119, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.011933831769115551\n",
      "train loss after my code:  0.0066862581405168035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3591, 1168,  783]))\n",
      "test accuracy:  0.9432858869290408\n",
      "56\n",
      "full train loss:  tensor(0.0068, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0118, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.011824913498546252\n",
      "train loss after my code:  0.00679228222067731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3593, 1166,  783]))\n",
      "test accuracy:  0.9431154151876449\n",
      "57\n",
      "full train loss:  tensor(0.0066, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0117, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.011698384300958552\n",
      "train loss after my code:  0.006615315182854841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3592, 1167,  783]))\n",
      "test accuracy:  0.9430217559200603\n",
      "58\n",
      "full train loss:  tensor(0.0065, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0116, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.011639120769125023\n",
      "train loss after my code:  0.0065206799810505044\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3591, 1168,  783]))\n",
      "test accuracy:  0.9432858869290408\n",
      "59\n",
      "full train loss:  tensor(0.0066, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0116, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.011575193342492887\n",
      "train loss after my code:  0.006550058265354242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3593, 1166,  783]))\n",
      "test accuracy:  0.9431154151876449\n",
      "60\n",
      "full train loss:  tensor(0.0066, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0115, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.01145014830674939\n",
      "train loss after my code:  0.006589952755763549\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1164,  783]))\n",
      "test accuracy:  0.9433027337228138\n",
      "61\n",
      "full train loss:  tensor(0.0065, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0114, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.011421644607906095\n",
      "train loss after my code:  0.006529067390911416\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1163,  783]))\n",
      "test accuracy:  0.9433963929903983\n",
      "62\n",
      "full train loss:  tensor(0.0060, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0113, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.011310388748726698\n",
      "train loss after my code:  0.005992300966569824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1163,  783]))\n",
      "test accuracy:  0.9433963929903983\n",
      "63\n",
      "full train loss:  tensor(0.0061, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0113, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.011268937921575677\n",
      "train loss after my code:  0.006077514376247293\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1163,  783]))\n",
      "test accuracy:  0.9433963929903983\n",
      "64\n",
      "full train loss:  tensor(0.0059, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0112, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.011213067283818904\n",
      "train loss after my code:  0.005858859623462003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1163,  783]))\n",
      "test accuracy:  0.9433963929903983\n",
      "65\n",
      "full train loss:  tensor(0.0059, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0112, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.01115306589416608\n",
      "train loss after my code:  0.005910955815251546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1163,  783]))\n",
      "test accuracy:  0.9433963929903983\n",
      "66\n",
      "full train loss:  tensor(0.0060, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0111, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.011106349183598093\n",
      "train loss after my code:  0.006006447440698798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1163,  783]))\n",
      "test accuracy:  0.9433963929903983\n",
      "67\n",
      "full train loss:  tensor(0.0061, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0111, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.011064617014748897\n",
      "train loss after my code:  0.006055596375863644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1163,  783]))\n",
      "test accuracy:  0.9433963929903983\n",
      "68\n",
      "full train loss:  tensor(0.0057, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0110, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.011021388324935762\n",
      "train loss after my code:  0.0056725678272659535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1163,  783]))\n",
      "test accuracy:  0.9433963929903983\n",
      "69\n",
      "full train loss:  tensor(0.0061, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0110, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.01099828939351069\n",
      "train loss after my code:  0.006127558152615783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1163,  783]))\n",
      "test accuracy:  0.9433963929903983\n",
      "70\n",
      "full train loss:  tensor(0.0055, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0110, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010951350453824444\n",
      "train loss after my code:  0.005521038487731451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  45,  33]))\n",
      "val accuracy:  0.9320340902318375\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1163,  784]))\n",
      "test accuracy:  0.9438587138410687\n",
      "71\n",
      "full train loss:  tensor(0.0056, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0109, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010898685497447554\n",
      "train loss after my code:  0.0056290996609863475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1163,  784]))\n",
      "test accuracy:  0.9438587138410687\n",
      "72\n",
      "full train loss:  tensor(0.0055, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0108, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010829764034616472\n",
      "train loss after my code:  0.005475487430125911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1161,  785]))\n",
      "test accuracy:  0.9441505629503432\n",
      "73\n",
      "full train loss:  tensor(0.0055, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0108, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.01080262064661885\n",
      "train loss after my code:  0.005463076125795907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.929653137850885\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1161,  785]))\n",
      "test accuracy:  0.9441505629503432\n",
      "74\n",
      "full train loss:  tensor(0.0055, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0108, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010780609819620993\n",
      "train loss after my code:  0.005541936830629035\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  45,  33]))\n",
      "val accuracy:  0.9320340902318375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1161,  785]))\n",
      "test accuracy:  0.9441505629503432\n",
      "75\n",
      "full train loss:  tensor(0.0057, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0108, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010767090653866938\n",
      "train loss after my code:  0.005710798015774374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  45,  33]))\n",
      "val accuracy:  0.9320340902318375\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1161,  785]))\n",
      "test accuracy:  0.9441505629503432\n",
      "76\n",
      "full train loss:  tensor(0.0053, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0107, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010730231430438657\n",
      "train loss after my code:  0.005338988011107073\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([143,  45,  33]))\n",
      "val accuracy:  0.9320340902318375\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1161,  785]))\n",
      "test accuracy:  0.9441505629503432\n",
      "77\n",
      "full train loss:  tensor(0.0054, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0107, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.01071788302677629\n",
      "train loss after my code:  0.005397663759419738\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  45,  33]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy:  0.9320340902318375\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1161,  785]))\n",
      "test accuracy:  0.9441505629503432\n",
      "78\n",
      "full train loss:  tensor(0.0054, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0107, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010680231191668475\n",
      "train loss after my code:  0.005431657618735807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  45,  33]))\n",
      "val accuracy:  0.9320340902318375\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1161,  785]))\n",
      "test accuracy:  0.9441505629503432\n",
      "79\n",
      "full train loss:  tensor(0.0054, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0107, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010664324785863186\n",
      "train loss after my code:  0.005401501895506603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  45,  33]))\n",
      "val accuracy:  0.9320340902318375\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1161,  785]))\n",
      "test accuracy:  0.9441505629503432\n",
      "80\n",
      "full train loss:  tensor(0.0052, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0106, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.01063032572158755\n",
      "train loss after my code:  0.005246514415233522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([141,  45,  35]))\n",
      "val accuracy:  0.9394570594195125\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1161,  786]))\n",
      "test accuracy:  0.9446128838010136\n",
      "0.9344150426127898\n",
      "accuracy is best accuracy\n",
      "[0.6436117921567234, 0.5880806185684234, 0.9760489025470299]\n",
      "81\n",
      "full train loss:  tensor(0.0054, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0106, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010598785756712949\n",
      "train loss after my code:  0.005406978430575771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([141,  45,  35]))\n",
      "val accuracy:  0.9394570594195125\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1161,  786]))\n",
      "test accuracy:  0.9446128838010136\n",
      "82\n",
      "full train loss:  tensor(0.0055, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0106, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010570853792920686\n",
      "train loss after my code:  0.005536163530095536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([141,  45,  35]))\n",
      "val accuracy:  0.9394570594195125\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1161,  786]))\n",
      "test accuracy:  0.9446128838010136\n",
      "83\n",
      "full train loss:  tensor(0.0052, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0106, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010569011097337152\n",
      "train loss after my code:  0.005162950678302141\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([141,  45,  35]))\n",
      "val accuracy:  0.9394570594195125\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1161,  786]))\n",
      "test accuracy:  0.9446128838010136\n",
      "84\n",
      "full train loss:  tensor(0.0052, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0106, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010561704881540155\n",
      "train loss after my code:  0.0052314707659325554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([141,  45,  35]))\n",
      "val accuracy:  0.9394570594195125\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1161,  786]))\n",
      "test accuracy:  0.9446128838010136\n",
      "85\n",
      "full train loss:  tensor(0.0054, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0105, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.01054832622539939\n",
      "train loss after my code:  0.00543523607773193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([141,  45,  35]))\n",
      "val accuracy:  0.9394570594195125\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1161,  786]))\n",
      "test accuracy:  0.9446128838010136\n",
      "86\n",
      "full train loss:  tensor(0.0053, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0105, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010524859820292984\n",
      "train loss after my code:  0.00528397300584129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([141,  45,  35]))\n",
      "val accuracy:  0.9394570594195125\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1161,  786]))\n",
      "test accuracy:  0.9446128838010136\n",
      "87\n",
      "full train loss:  tensor(0.0054, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0105, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010502124405857688\n",
      "train loss after my code:  0.00540482889130084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([141,  45,  35]))\n",
      "val accuracy:  0.9394570594195125\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1161,  786]))\n",
      "test accuracy:  0.9446128838010136\n",
      "88\n",
      "full train loss:  tensor(0.0055, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0105, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010488298483247447\n",
      "train loss after my code:  0.005462633840351541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([141,  45,  35]))\n",
      "val accuracy:  0.9394570594195125\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1161,  786]))\n",
      "test accuracy:  0.9446128838010136\n",
      "89\n",
      "full train loss:  tensor(0.0051, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0105, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.0104779428234755\n",
      "train loss after my code:  0.005074787555372865\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([141,  45,  35]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy:  0.9394570594195125\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1161,  786]))\n",
      "test accuracy:  0.9446128838010136\n",
      "90\n",
      "full train loss:  tensor(0.0051, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0105, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010481975586049574\n",
      "train loss after my code:  0.0051011660240878965\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([141,  45,  35]))\n",
      "val accuracy:  0.9394570594195125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1161,  786]))\n",
      "test accuracy:  0.9446128838010136\n",
      "91\n",
      "full train loss:  tensor(0.0052, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0105, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.01047133205819037\n",
      "train loss after my code:  0.005195333083961676\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([141,  45,  35]))\n",
      "val accuracy:  0.9394570594195125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3596, 1160,  786]))\n",
      "test accuracy:  0.9447065430685981\n",
      "92\n",
      "full train loss:  tensor(0.0051, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0105, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010458393346824987\n",
      "train loss after my code:  0.005053510397308831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.9418380118004649\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1161,  786]))\n",
      "test accuracy:  0.9446128838010136\n",
      "0.9394570594195125\n",
      "accuracy is best accuracy\n",
      "[0.6436117921567234, 0.5880806185684234, 0.9760489025470299]\n",
      "93\n",
      "full train loss:  tensor(0.0052, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0104, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010439816351939458\n",
      "train loss after my code:  0.005248774374377612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.9418380118004649\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1161,  786]))\n",
      "test accuracy:  0.9446128838010136\n",
      "94\n",
      "full train loss:  tensor(0.0052, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0104, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010428017222434086\n",
      "train loss after my code:  0.00515585439175496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.9418380118004649\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1161,  786]))\n",
      "test accuracy:  0.9446128838010136\n",
      "95\n",
      "full train loss:  tensor(0.0052, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0104, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.01041055831740997\n",
      "train loss after my code:  0.005171004338157266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([141,  45,  35]))\n",
      "val accuracy:  0.9394570594195125\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1161,  786]))\n",
      "test accuracy:  0.9446128838010136\n",
      "96\n",
      "full train loss:  tensor(0.0051, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0104, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010409946519071843\n",
      "train loss after my code:  0.005058428926884167\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.9418380118004649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1161,  786]))\n",
      "test accuracy:  0.9446128838010136\n",
      "97\n",
      "full train loss:  tensor(0.0050, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0104, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010405852720877051\n",
      "train loss after my code:  0.005029068943211917\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([141,  45,  35]))\n",
      "val accuracy:  0.9394570594195125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1161,  786]))\n",
      "test accuracy:  0.9446128838010136\n",
      "98\n",
      "full train loss:  tensor(0.0050, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0104, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [2]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010396719620926309\n",
      "train loss after my code:  0.005027002961103294\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.9418380118004649\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1161,  786]))\n",
      "test accuracy:  0.9446128838010136\n",
      "99\n",
      "full train loss:  tensor(0.0050, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0104, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [0]\n",
      "[0. 0. 0.]\n",
      "loss after my code:  0.010389832434341604\n",
      "train loss after my code:  0.0049732598592699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([142,  45,  34]))\n",
      "val accuracy:  0.9418380118004649\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3595, 1161,  786]))\n",
      "test accuracy:  0.9446128838010136\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(save_dir)\n",
    "DATA_ROOT = osj(\"/mimer/NOBACKUP/groups/snic2022-22-122/arthur/\", \"dataset_beats\")\n",
    "DICT_BEATS = osj(DATA_ROOT, \"5min_normal_beats.pkl\")\n",
    "DATA_BEATS = osj(DATA_ROOT, \"30min_beats.pkl\")\n",
    "\n",
    "DATA_ROOT = \"/mimer/NOBACKUP/groups/snic2022-22-122/arthur/physionet.org/files/mitdb/1.0.0/\"\n",
    "RECORDS = osj(DATA_ROOT, \"RECORDS\")\n",
    "#print(RECORDS)\n",
    "patient_ids = pd.read_csv(RECORDS, header=None).to_numpy().reshape(-1)\n",
    "#print(patient_ids)\n",
    "paced_patients = get_paced_patients(patient_ids)\n",
    "excluded_patients = np.array([105, 114, 201, 202, 207, 209, 213, 222, 223, 234])  # according to paper\n",
    "#print(np.concatenate((paced_patients, excluded_patients)))\n",
    "\n",
    "dict_beats = read_dict_beats()\n",
    "data_beats = read_data_beats()\n",
    "ensure_normalized_and_detrended(dict_beats)\n",
    "ensure_normalized_and_detrended(data_beats)\n",
    "\n",
    "import collections\n",
    "\n",
    "patients_out = np.concatenate((paced_patients, excluded_patients))\n",
    "patients_left = list(copy.deepcopy(patient_ids))\n",
    "\n",
    "for idx, i in enumerate(patient_ids):\n",
    "    if i in patients_out:\n",
    "        patients_left.remove(i)\n",
    "\n",
    "labels = ['N', 'V', 'S', 'Q', 'F']\n",
    "dictionary = {}\n",
    "for i in labels:\n",
    "    dictionary[i] = 0\n",
    "\n",
    "list1 = []\n",
    "array = np.zeros((len(patients_left), 2))\n",
    "for idx, i in enumerate(patients_left):\n",
    "    list1.append(data_beats[i]['class'])\n",
    "    counter = collections.Counter(data_beats[i]['class'])\n",
    "    for j in counter.keys():\n",
    "        dictionary[j] += counter[j]\n",
    "        if j == 'N':\n",
    "            array[idx, 0] += counter[j]\n",
    "        else:\n",
    "            array[idx, 1] += counter[j]\n",
    "\n",
    "seconds = 5\n",
    "data_beats_train, data_beats_val, data_beats_test = train_test_split(data_beats, seconds)\n",
    "\n",
    "import collections\n",
    "from time import time\n",
    "import random\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pandas\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "experiment_name = settings['experiment_name']\n",
    "test = 'bandits'\n",
    "print('type: ',test)\n",
    "n_epochs = 100 #settings['n_epochs']\n",
    "patients_example = [200, 118,232]\n",
    "p2p = P2P_AFPL(patients_example, data_beats_train, data_beats_val,data_beats_test,1,test)\n",
    "alphas = p2p.loop(n_epochs, p2p, experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b97b9fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6436117921567234, 0.5880806185684234, 0.9760489025470299]\n",
      "0.9446128838010136\n"
     ]
    }
   ],
   "source": [
    "bandit_acc = p2p.accuracy_list\n",
    "print(bandit_acc)\n",
    "bandit_best = p2p.best_accuracy\n",
    "print(bandit_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7a372a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:  local\n",
      "0\n",
      "full train loss:  tensor(0.0993, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1092, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "0\n",
      "accuracy is best accuracy\n",
      "[0.3333333333333333, 0.3333333333333333, 0.5]\n",
      "1\n",
      "full train loss:  tensor(0.0856, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0944, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "2\n",
      "full train loss:  tensor(0.0752, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0829, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "3\n",
      "full train loss:  tensor(0.0678, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0750, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "4\n",
      "full train loss:  tensor(0.0630, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0689, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "5\n",
      "full train loss:  tensor(0.0588, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0640, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "6\n",
      "full train loss:  tensor(0.0554, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0606, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "7\n",
      "full train loss:  tensor(0.0535, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0573, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "8\n",
      "full train loss:  tensor(0.0519, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0556, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "9\n",
      "full train loss:  tensor(0.0497, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0537, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "10\n",
      "full train loss:  tensor(0.0476, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0512, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "11\n",
      "full train loss:  tensor(0.0456, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0483, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "12\n",
      "full train loss:  tensor(0.0441, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0462, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1]), array([162,  59]))\n",
      "val accuracy:  0.6191489361702128\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1]), array([4061, 1481]))\n",
      "test accuracy:  0.6085873080263321\n",
      "13\n",
      "full train loss:  tensor(0.0409, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0434, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([139,  59,  23]))\n",
      "val accuracy:  0.8446391322486443\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3559, 1481,  502]))\n",
      "test accuracy:  0.8406723750628554\n",
      "0.6191489361702128\n",
      "accuracy is best accuracy\n",
      "[0.5696798493408662, 0.3333333333333333, 0.5]\n",
      "14\n",
      "full train loss:  tensor(0.0385, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0413, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([137,  59,  25]))\n",
      "val accuracy:  0.8642469753858991\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3521, 1481,  540]))\n",
      "test accuracy:  0.8582405673883292\n",
      "0.8446391322486443\n",
      "accuracy is best accuracy\n",
      "[0.5875706214689266, 0.3333333333333333, 0.5]\n",
      "15\n",
      "full train loss:  tensor(0.0364, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0389, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([137,  59,  25]))\n",
      "val accuracy:  0.8642469753858991\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3479, 1481,  582]))\n",
      "test accuracy:  0.8776580431164845\n",
      "16\n",
      "full train loss:  tensor(0.0347, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0374, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([137,  59,  25]))\n",
      "val accuracy:  0.8642469753858991\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3473, 1481,  588]))\n",
      "test accuracy:  0.8804319682205067\n",
      "17\n",
      "full train loss:  tensor(0.0321, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0353, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([136,  59,  26]))\n",
      "val accuracy:  0.8740508969545265\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3456, 1481,  605]))\n",
      "test accuracy:  0.888291422681903\n",
      "0.8642469753858991\n",
      "accuracy is best accuracy\n",
      "[0.6181732580037664, 0.3333333333333333, 0.5]\n",
      "18\n",
      "full train loss:  tensor(0.0313, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0340, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([136,  59,  26]))\n",
      "val accuracy:  0.8740508969545265\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3456, 1481,  605]))\n",
      "test accuracy:  0.888291422681903\n",
      "19\n",
      "full train loss:  tensor(0.0292, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0322, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([135,  59,  27]))\n",
      "val accuracy:  0.883854818523154\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3447, 1481,  614]))\n",
      "test accuracy:  0.8924523103379363\n",
      "0.8740508969545265\n",
      "accuracy is best accuracy\n",
      "[0.6224105461393598, 0.3333333333333333, 0.5]\n",
      "20\n",
      "full train loss:  tensor(0.0274, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0310, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([135,  59,  27]))\n",
      "val accuracy:  0.883854818523154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3446, 1481,  615]))\n",
      "test accuracy:  0.8929146311886066\n",
      "21\n",
      "full train loss:  tensor(0.0262, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0296, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([135,  59,  27]))\n",
      "val accuracy:  0.883854818523154\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3443, 1481,  618]))\n",
      "test accuracy:  0.8943015937406177\n",
      "22\n",
      "full train loss:  tensor(0.0245, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0283, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([139,  55,  27]))\n",
      "val accuracy:  0.8933786280469634\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3530, 1387,  625]))\n",
      "test accuracy:  0.9053235098793307\n",
      "0.883854818523154\n",
      "accuracy is best accuracy\n",
      "[0.6264148969350973, 0.3333333333333333, 0.6450617283950617]\n",
      "23\n",
      "full train loss:  tensor(0.0236, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0270, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([140,  54,  27]))\n",
      "val accuracy:  0.8957595804279158\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3565, 1345,  632]))\n",
      "test accuracy:  0.9120311242219029\n",
      "0.8933786280469634\n",
      "accuracy is best accuracy\n",
      "[0.6292397556921595, 0.3333333333333333, 0.7098765432098766]\n",
      "24\n",
      "full train loss:  tensor(0.0225, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0259, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([140,  54,  27]))\n",
      "val accuracy:  0.8957595804279158\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3571, 1338,  633]))\n",
      "test accuracy:  0.9131490599456651\n",
      "25\n",
      "full train loss:  tensor(0.0224, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0250, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([143,  51,  27]))\n",
      "val accuracy:  0.902902437570773\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3608, 1301,  633]))\n",
      "test accuracy:  0.9166144528462926\n",
      "0.8957595804279158\n",
      "accuracy is best accuracy\n",
      "[0.6297105654850031, 0.3333333333333333, 0.7777777777777778]\n",
      "26\n",
      "full train loss:  tensor(0.0205, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0238, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([144,  49,  28]))\n",
      "val accuracy:  0.9174682639013052\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3619, 1278,  645]))\n",
      "test accuracy:  0.9224671828060996\n",
      "0.902902437570773\n",
      "accuracy is best accuracy\n",
      "[0.6334770438277527, 0.3333333333333333, 0.8132716049382716]\n",
      "27\n",
      "full train loss:  tensor(0.0195, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0230, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([145,  48,  28]))\n",
      "val accuracy:  0.9198492162822576\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3652, 1242,  648]))\n",
      "test accuracy:  0.9266698988728989\n",
      "0.9174682639013052\n",
      "accuracy is best accuracy\n",
      "[0.6341857260735845, 0.3333333333333333, 0.8688271604938271]\n",
      "28\n",
      "full train loss:  tensor(0.0189, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0223, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  47,  28]))\n",
      "val accuracy:  0.9222301686632101\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3674, 1221,  647]))\n",
      "test accuracy:  0.9287304027597584\n",
      "0.9198492162822576\n",
      "accuracy is best accuracy\n",
      "[0.63441866341344, 0.3333333333333333, 0.9012345679012346]\n",
      "29\n",
      "full train loss:  tensor(0.0183, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0213, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  47,  28]))\n",
      "val accuracy:  0.9222301686632101\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3673, 1215,  654]))\n",
      "test accuracy:  0.9315103033510329\n",
      "30\n",
      "full train loss:  tensor(0.0177, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0209, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([147,  46,  28]))\n",
      "val accuracy:  0.9246111210441624\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3684, 1207,  651]))\n",
      "test accuracy:  0.9308726149396981\n",
      "0.9222301686632101\n",
      "accuracy is best accuracy\n",
      "[0.635127345659272, 0.3333333333333333, 0.9228395061728395]\n",
      "31\n",
      "full train loss:  tensor(0.0176, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0200, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  46,  29]))\n",
      "val accuracy:  0.9344150426127898\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3677, 1206,  659]))\n",
      "test accuracy:  0.9337401993113047\n",
      "0.9246111210441624\n",
      "accuracy is best accuracy\n",
      "[0.637952204416334, 0.3333333333333333, 0.9243827160493827]\n",
      "32\n",
      "full train loss:  tensor(0.0164, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0195, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  46,  29]))\n",
      "val accuracy:  0.9344150426127898\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3679, 1203,  660]))\n",
      "test accuracy:  0.9344834979647287\n",
      "33\n",
      "full train loss:  tensor(0.0159, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0189, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  46,  29]))\n",
      "val accuracy:  0.9344150426127898\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3679, 1203,  660]))\n",
      "test accuracy:  0.9349458188153991\n",
      "34\n",
      "full train loss:  tensor(0.0157, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0186, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  46,  29]))\n",
      "val accuracy:  0.9344150426127898\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3683, 1201,  658]))\n",
      "test accuracy:  0.9342084956492274\n",
      "35\n",
      "full train loss:  tensor(0.0163, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0182, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  46,  29]))\n",
      "val accuracy:  0.9344150426127898\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3679, 1199,  664]))\n",
      "test accuracy:  0.9358873073105128\n",
      "36\n",
      "full train loss:  tensor(0.0148, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0178, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  46,  29]))\n",
      "val accuracy:  0.9344150426127898\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3679, 1198,  665]))\n",
      "test accuracy:  0.9359809665780974\n",
      "37\n",
      "full train loss:  tensor(0.0143, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0174, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  46,  29]))\n",
      "val accuracy:  0.9344150426127898\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3672, 1198,  672]))\n",
      "test accuracy:  0.9382925708314493\n",
      "38\n",
      "full train loss:  tensor(0.0145, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0169, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([145,  46,  30]))\n",
      "val accuracy:  0.9344150426127898\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3671, 1198,  673]))\n",
      "test accuracy:  0.9381989115638647\n",
      "39\n",
      "full train loss:  tensor(0.0140, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0167, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([145,  46,  30]))\n",
      "val accuracy:  0.9344150426127898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3673, 1198,  671]))\n",
      "test accuracy:  0.9378302499807788\n",
      "40\n",
      "full train loss:  tensor(0.0135, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0163, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([145,  46,  30]))\n",
      "val accuracy:  0.9344150426127898\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3675, 1194,  673]))\n",
      "test accuracy:  0.937500177804508\n",
      "41\n",
      "full train loss:  tensor(0.0133, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0160, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([145,  46,  30]))\n",
      "val accuracy:  0.9344150426127898\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3675, 1194,  673]))\n",
      "test accuracy:  0.937500177804508\n",
      "42\n",
      "full train loss:  tensor(0.0131, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0157, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([145,  46,  30]))\n",
      "val accuracy:  0.9344150426127898\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3676, 1193,  673]))\n",
      "test accuracy:  0.9375938370720925\n",
      "43\n",
      "full train loss:  tensor(0.0129, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0154, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([145,  46,  30]))\n",
      "val accuracy:  0.9344150426127898\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3675, 1194,  673]))\n",
      "test accuracy:  0.937500177804508\n",
      "44\n",
      "full train loss:  tensor(0.0131, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0155, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([145,  46,  30]))\n",
      "val accuracy:  0.9344150426127898\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3682, 1191,  669]))\n",
      "test accuracy:  0.9359318722045801\n",
      "45\n",
      "full train loss:  tensor(0.0125, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0151, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([145,  46,  30]))\n",
      "val accuracy:  0.9344150426127898\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3678, 1191,  673]))\n",
      "test accuracy:  0.9377811556072615\n",
      "46\n",
      "full train loss:  tensor(0.0129, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0148, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3678, 1190,  674]))\n",
      "test accuracy:  0.9383371357255164\n",
      "0.9344150426127898\n",
      "accuracy is best accuracy\n",
      "[0.6424273650049154, 0.3333333333333333, 0.9411726260977198]\n",
      "47\n",
      "full train loss:  tensor(0.0124, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0147, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3679, 1189,  674]))\n",
      "test accuracy:  0.938430794993101\n",
      "48\n",
      "full train loss:  tensor(0.0124, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0145, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3680, 1188,  674]))\n",
      "test accuracy:  0.9385244542606855\n",
      "49\n",
      "full train loss:  tensor(0.0119, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0143, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3683, 1185,  674]))\n",
      "test accuracy:  0.938805432063439\n",
      "50\n",
      "full train loss:  tensor(0.0122, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0142, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3684, 1184,  674]))\n",
      "test accuracy:  0.9388990913310234\n",
      "51\n",
      "full train loss:  tensor(0.0116, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0140, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3685, 1181,  676]))\n",
      "test accuracy:  0.9387286195896277\n",
      "52\n",
      "full train loss:  tensor(0.0125, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0139, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3686, 1181,  675]))\n",
      "test accuracy:  0.9387286195896277\n",
      "53\n",
      "full train loss:  tensor(0.0115, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0137, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3682, 1181,  679]))\n",
      "test accuracy:  0.939190940440298\n",
      "54\n",
      "full train loss:  tensor(0.0114, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0136, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3686, 1179,  677]))\n",
      "test accuracy:  0.939378258975467\n",
      "55\n",
      "full train loss:  tensor(0.0116, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0135, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3689, 1177,  676]))\n",
      "test accuracy:  0.9395655775106361\n",
      "56\n",
      "full train loss:  tensor(0.0113, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0134, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3686, 1177,  679]))\n",
      "test accuracy:  0.9395655775106361\n",
      "57\n",
      "full train loss:  tensor(0.0115, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0132, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3684, 1177,  681]))\n",
      "test accuracy:  0.9399342390937219\n",
      "58\n",
      "full train loss:  tensor(0.0111, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0131, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3683, 1177,  682]))\n",
      "test accuracy:  0.9403965599443923\n",
      "59\n",
      "full train loss:  tensor(0.0113, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0131, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3682, 1179,  681]))\n",
      "test accuracy:  0.9403029006768078\n",
      "60\n",
      "full train loss:  tensor(0.0112, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0129, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3680, 1178,  684]))\n",
      "test accuracy:  0.9403029006768078\n",
      "61\n",
      "full train loss:  tensor(0.0117, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0128, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3683, 1175,  684]))\n",
      "test accuracy:  0.9405838784795614\n",
      "62\n",
      "full train loss:  tensor(0.0111, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0128, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3686, 1175,  681]))\n",
      "test accuracy:  0.9406775377471459\n",
      "63\n",
      "full train loss:  tensor(0.0108, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0127, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3687, 1174,  681]))\n",
      "test accuracy:  0.9404134067381654\n",
      "64\n",
      "full train loss:  tensor(0.0106, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0127, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3688, 1174,  680]))\n",
      "test accuracy:  0.9399510858874951\n",
      "65\n",
      "full train loss:  tensor(0.0109, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0126, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3687, 1175,  680]))\n",
      "test accuracy:  0.9402152168964756\n",
      "66\n",
      "full train loss:  tensor(0.0109, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0126, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3687, 1175,  680]))\n",
      "test accuracy:  0.9402152168964756\n",
      "67\n",
      "full train loss:  tensor(0.0109, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0126, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3687, 1175,  680]))\n",
      "test accuracy:  0.9402152168964756\n",
      "68\n",
      "full train loss:  tensor(0.0112, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0125, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3688, 1175,  679]))\n",
      "test accuracy:  0.9402152168964756\n",
      "69\n",
      "full train loss:  tensor(0.0104, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0126, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3689, 1175,  678]))\n",
      "test accuracy:  0.9402152168964756\n",
      "70\n",
      "full train loss:  tensor(0.0107, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0125, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3689, 1175,  678]))\n",
      "test accuracy:  0.9402152168964756\n",
      "71\n",
      "full train loss:  tensor(0.0105, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0124, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3689, 1173,  680]))\n",
      "test accuracy:  0.9396869548785146\n",
      "72\n",
      "full train loss:  tensor(0.0107, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0124, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3687, 1175,  680]))\n",
      "test accuracy:  0.9402152168964756\n",
      "73\n",
      "full train loss:  tensor(0.0106, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0123, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3688, 1175,  679]))\n",
      "test accuracy:  0.9402152168964756\n",
      "74\n",
      "full train loss:  tensor(0.0112, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0123, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3687, 1175,  680]))\n",
      "test accuracy:  0.9402152168964756\n",
      "75\n",
      "full train loss:  tensor(0.0103, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0123, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3688, 1175,  679]))\n",
      "test accuracy:  0.9402152168964756\n",
      "76\n",
      "full train loss:  tensor(0.0108, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0123, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3691, 1172,  679]))\n",
      "test accuracy:  0.9397806141460991\n",
      "77\n",
      "full train loss:  tensor(0.0103, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0122, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3691, 1172,  679]))\n",
      "test accuracy:  0.9397806141460991\n",
      "78\n",
      "full train loss:  tensor(0.0105, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0122, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3691, 1172,  679]))\n",
      "test accuracy:  0.9397806141460991\n",
      "79\n",
      "full train loss:  tensor(0.0101, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0122, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3693, 1170,  679]))\n",
      "test accuracy:  0.9396101424047032\n",
      "80\n",
      "full train loss:  tensor(0.0105, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0122, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3693, 1170,  679]))\n",
      "test accuracy:  0.9396101424047032\n",
      "81\n",
      "full train loss:  tensor(0.0105, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0122, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3693, 1170,  679]))\n",
      "test accuracy:  0.9396101424047032\n",
      "82\n",
      "full train loss:  tensor(0.0101, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0121, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3693, 1170,  679]))\n",
      "test accuracy:  0.9396101424047032\n",
      "83\n",
      "full train loss:  tensor(0.0101, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0121, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3693, 1170,  679]))\n",
      "test accuracy:  0.9396101424047032\n",
      "84\n",
      "full train loss:  tensor(0.0101, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0121, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3693, 1170,  679]))\n",
      "test accuracy:  0.9396101424047032\n",
      "85\n",
      "full train loss:  tensor(0.0101, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0121, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3693, 1170,  679]))\n",
      "test accuracy:  0.9396101424047032\n",
      "86\n",
      "full train loss:  tensor(0.0104, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0121, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3693, 1170,  679]))\n",
      "test accuracy:  0.9396101424047032\n",
      "87\n",
      "full train loss:  tensor(0.0105, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0121, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3693, 1170,  679]))\n",
      "test accuracy:  0.9396101424047032\n",
      "88\n",
      "full train loss:  tensor(0.0104, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0120, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3694, 1170,  678]))\n",
      "test accuracy:  0.9396101424047032\n",
      "89\n",
      "full train loss:  tensor(0.0104, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0120, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3694, 1170,  678]))\n",
      "test accuracy:  0.9396101424047032\n",
      "90\n",
      "full train loss:  tensor(0.0101, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0121, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3694, 1170,  678]))\n",
      "test accuracy:  0.9396101424047032\n",
      "91\n",
      "full train loss:  tensor(0.0100, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0120, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3694, 1170,  678]))\n",
      "test accuracy:  0.9396101424047032\n",
      "92\n",
      "full train loss:  tensor(0.0100, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0120, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3694, 1170,  678]))\n",
      "test accuracy:  0.9396101424047032\n",
      "93\n",
      "full train loss:  tensor(0.0104, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0120, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3694, 1170,  678]))\n",
      "test accuracy:  0.9396101424047032\n",
      "94\n",
      "full train loss:  tensor(0.0107, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0120, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3694, 1170,  678]))\n",
      "test accuracy:  0.9396101424047032\n",
      "95\n",
      "full train loss:  tensor(0.0103, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0120, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3694, 1170,  678]))\n",
      "test accuracy:  0.9396101424047032\n",
      "96\n",
      "full train loss:  tensor(0.0103, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0120, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3694, 1170,  678]))\n",
      "test accuracy:  0.9396101424047032\n",
      "97\n",
      "full train loss:  tensor(0.0103, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0120, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3694, 1170,  678]))\n",
      "test accuracy:  0.9396101424047032\n",
      "98\n",
      "full train loss:  tensor(0.0100, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0120, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3694, 1170,  678]))\n",
      "test accuracy:  0.9396101424047032\n",
      "99\n",
      "full train loss:  tensor(0.0100, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0119, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0, 1, 2]), array([146,  45,  30]))\n",
      "val accuracy:  0.9367959949937422\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0, 1, 2]), array([3694, 1170,  678]))\n",
      "test accuracy:  0.9396101424047032\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seconds = 5\n",
    "data_beats_train, data_beats_val, data_beats_test = train_test_split(data_beats, seconds)\n",
    "\n",
    "import collections\n",
    "from time import time\n",
    "import random\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pandas\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "experiment_name = settings['experiment_name']\n",
    "test = 'local'\n",
    "print('type: ',test)\n",
    "n_epochs = 100 #settings['n_epochs']\n",
    "patients_example = [200, 118,232]\n",
    "p2p = P2P_AFPL(patients_example, data_beats_train, data_beats_val,data_beats_test,1,test)\n",
    "alphas = p2p.loop(n_epochs, p2p, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "931eb0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([3559, 1983]))\n",
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
      "(array([0, 1]), array([4061, 1481]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(p2p.trues,return_counts=True))\n",
    "print(np.count_nonzero(p2p.trues==0))\n",
    "print(p2p.trues[:10])\n",
    "print(np.unique(p2p.preds,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb008155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6431360472507471, 0.3333333333333333, 0.9641353756522296]\n",
      "0.9383371357255164\n"
     ]
    }
   ],
   "source": [
    "local_acc = p2p.accuracy_list\n",
    "print(local_acc)\n",
    "local_best = p2p.best_accuracy\n",
    "print(local_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cfee971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints_bandits/MIT3B_bandits_010_20_5\n",
      "type:  federated\n",
      "0\n",
      "full train loss:  tensor(0.0993, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1092, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11609631931580047\n",
      "train loss after my code:  0.10531331355315579\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "0\n",
      "accuracy is best accuracy\n",
      "[0.3333333333333333, 0.3333333333333333, 0.5]\n",
      "1\n",
      "full train loss:  tensor(0.0898, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0987, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11061497331674765\n",
      "train loss after my code:  0.10003225959487061\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "2\n",
      "full train loss:  tensor(0.0832, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0919, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.10690894731575476\n",
      "train loss after my code:  0.09619157993994909\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "3\n",
      "full train loss:  tensor(0.0798, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0883, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.1050391312261098\n",
      "train loss after my code:  0.09423476519116408\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "4\n",
      "full train loss:  tensor(0.0791, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0885, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.10502010475374929\n",
      "train loss after my code:  0.09291162679375473\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "5\n",
      "full train loss:  tensor(0.0810, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0901, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.10595640095521908\n",
      "train loss after my code:  0.09492477407381557\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "6\n",
      "full train loss:  tensor(0.0829, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0924, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.10763817183337415\n",
      "train loss after my code:  0.09567025374500111\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "7\n",
      "full train loss:  tensor(0.0844, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0945, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.10948914497027168\n",
      "train loss after my code:  0.09707163068057148\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "8\n",
      "full train loss:  tensor(0.0858, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0965, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11150192009196579\n",
      "train loss after my code:  0.0986648203220502\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "9\n",
      "full train loss:  tensor(0.0877, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0988, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11298833395779462\n",
      "train loss after my code:  0.09919401595461785\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "10\n",
      "full train loss:  tensor(0.0898, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1010, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11475086101388114\n",
      "train loss after my code:  0.10149338744901491\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "11\n",
      "full train loss:  tensor(0.0918, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1027, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.1158012919422863\n",
      "train loss after my code:  0.10190734495900095\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "12\n",
      "full train loss:  tensor(0.0934, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1044, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11643712442432678\n",
      "train loss after my code:  0.10308825952422437\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "13\n",
      "full train loss:  tensor(0.0943, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1055, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11707681840967454\n",
      "train loss after my code:  0.1032754181512191\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "14\n",
      "full train loss:  tensor(0.0946, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1064, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.117639047606701\n",
      "train loss after my code:  0.10468023894083898\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "15\n",
      "full train loss:  tensor(0.0954, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1075, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11792736020290853\n",
      "train loss after my code:  0.10289718326567471\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "16\n",
      "full train loss:  tensor(0.0965, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1083, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11825535708453591\n",
      "train loss after my code:  0.10443073718812018\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "17\n",
      "full train loss:  tensor(0.0975, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1090, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11883904968625165\n",
      "train loss after my code:  0.10499775774706499\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "18\n",
      "full train loss:  tensor(0.0982, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1099, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11943901583714514\n",
      "train loss after my code:  0.10465883224302883\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "19\n",
      "full train loss:  tensor(0.0994, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1108, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11990674355062807\n",
      "train loss after my code:  0.10603843826539357\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "20\n",
      "full train loss:  tensor(0.1006, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1118, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.12035160116058383\n",
      "train loss after my code:  0.10550129269479112\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "21\n",
      "full train loss:  tensor(0.1011, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1125, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.12073051647895237\n",
      "train loss after my code:  0.10575433109759136\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "22\n",
      "full train loss:  tensor(0.1001, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1131, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.12098245426328876\n",
      "train loss after my code:  0.10829431800300329\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "23\n",
      "full train loss:  tensor(0.1025, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1140, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.12139974327059407\n",
      "train loss after my code:  0.10648999165038331\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "24\n",
      "full train loss:  tensor(0.1016, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1143, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.121492133821184\n",
      "train loss after my code:  0.1073964293026852\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "25\n",
      "full train loss:  tensor(0.1022, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1144, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.12122891357687045\n",
      "train loss after my code:  0.10719927678184077\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "26\n",
      "full train loss:  tensor(0.1028, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1144, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.12113517678106965\n",
      "train loss after my code:  0.10745488024942222\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "27\n",
      "full train loss:  tensor(0.1016, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1147, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.12115998489942117\n",
      "train loss after my code:  0.10684997287245292\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "28\n",
      "full train loss:  tensor(0.1030, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1147, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.12103439806658105\n",
      "train loss after my code:  0.10753371544288476\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "29\n",
      "full train loss:  tensor(0.1023, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1148, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.12085908811265528\n",
      "train loss after my code:  0.10701616643890419\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "30\n",
      "full train loss:  tensor(0.1028, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1149, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.12085014445537592\n",
      "train loss after my code:  0.10694428065884873\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "31\n",
      "full train loss:  tensor(0.1028, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1151, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.12085074329447537\n",
      "train loss after my code:  0.10720943819933723\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "32\n",
      "full train loss:  tensor(0.1031, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1154, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.12096102811343493\n",
      "train loss after my code:  0.10668397821310871\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "33\n",
      "full train loss:  tensor(0.1024, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1157, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.12089564663204963\n",
      "train loss after my code:  0.10517345702914617\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "34\n",
      "full train loss:  tensor(0.1035, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1157, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.12080024011995477\n",
      "train loss after my code:  0.10752893518860399\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "35\n",
      "full train loss:  tensor(0.1028, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1158, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.12084594228271375\n",
      "train loss after my code:  0.10694920354720183\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "36\n",
      "full train loss:  tensor(0.1018, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1159, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.12067690712560829\n",
      "train loss after my code:  0.10773741243969849\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "37\n",
      "full train loss:  tensor(0.1042, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1161, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.1206788973072221\n",
      "train loss after my code:  0.1074626790387673\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "38\n",
      "full train loss:  tensor(0.1038, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1162, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.12062270190440394\n",
      "train loss after my code:  0.10715463568547817\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "39\n",
      "full train loss:  tensor(0.1037, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1162, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.12039798692879564\n",
      "train loss after my code:  0.10690167884953408\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "40\n",
      "full train loss:  tensor(0.1039, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1161, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.12016962191095654\n",
      "train loss after my code:  0.10829347772330444\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "41\n",
      "full train loss:  tensor(0.1048, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1159, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11974457157501667\n",
      "train loss after my code:  0.10670513878670386\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "42\n",
      "full train loss:  tensor(0.1046, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1157, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11957125411888136\n",
      "train loss after my code:  0.10604388168237382\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "43\n",
      "full train loss:  tensor(0.1032, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1157, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11926615808200186\n",
      "train loss after my code:  0.10643069734777841\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "44\n",
      "full train loss:  tensor(0.1035, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1156, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11915655239083676\n",
      "train loss after my code:  0.10701610716731354\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "45\n",
      "full train loss:  tensor(0.1027, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1155, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.1190027746113701\n",
      "train loss after my code:  0.10566506341688045\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "46\n",
      "full train loss:  tensor(0.1023, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1156, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11881504590955166\n",
      "train loss after my code:  0.10531841516881564\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "47\n",
      "full train loss:  tensor(0.1018, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1155, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11859881652504306\n",
      "train loss after my code:  0.10691112175852435\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "48\n",
      "full train loss:  tensor(0.1035, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1154, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.1183465435071217\n",
      "train loss after my code:  0.10614570989298885\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "49\n",
      "full train loss:  tensor(0.1038, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1152, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11797330446049487\n",
      "train loss after my code:  0.10632822139663942\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "50\n",
      "full train loss:  tensor(0.1015, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1150, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11773612659557878\n",
      "train loss after my code:  0.1035370183861093\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "51\n",
      "full train loss:  tensor(0.1030, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1148, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11754267657761763\n",
      "train loss after my code:  0.10535755626603545\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "52\n",
      "full train loss:  tensor(0.1024, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1149, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11744471224321551\n",
      "train loss after my code:  0.10425817218965232\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "53\n",
      "full train loss:  tensor(0.1023, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1147, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11716092749040488\n",
      "train loss after my code:  0.10390427812048822\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "54\n",
      "full train loss:  tensor(0.1026, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1147, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11705720226803326\n",
      "train loss after my code:  0.10371490975476223\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "55\n",
      "full train loss:  tensor(0.1025, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1146, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11682972463367536\n",
      "train loss after my code:  0.10500002216602577\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "56\n",
      "full train loss:  tensor(0.1031, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1145, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11662482069516596\n",
      "train loss after my code:  0.10338161367314042\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "57\n",
      "full train loss:  tensor(0.1023, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1143, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11637977947148881\n",
      "train loss after my code:  0.10302790329485444\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "58\n",
      "full train loss:  tensor(0.1021, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1142, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11616347603201753\n",
      "train loss after my code:  0.10348719147169666\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "59\n",
      "full train loss:  tensor(0.1014, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1141, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11596028774547228\n",
      "train loss after my code:  0.1027163114202736\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "60\n",
      "full train loss:  tensor(0.1022, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1141, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.1158749301694621\n",
      "train loss after my code:  0.10346444833207688\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "61\n",
      "full train loss:  tensor(0.1025, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1141, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11580215836049965\n",
      "train loss after my code:  0.10294781562329432\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "62\n",
      "full train loss:  tensor(0.1005, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1140, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11560685803625678\n",
      "train loss after my code:  0.10391584629264908\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "63\n",
      "full train loss:  tensor(0.1008, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1139, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.115432213723016\n",
      "train loss after my code:  0.10371539150554351\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "64\n",
      "full train loss:  tensor(0.1022, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1138, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11524975639877608\n",
      "train loss after my code:  0.10310424545264227\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "65\n",
      "full train loss:  tensor(0.1009, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1137, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11511088801923566\n",
      "train loss after my code:  0.10392086906500385\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "66\n",
      "full train loss:  tensor(0.1015, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1136, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11495143400783314\n",
      "train loss after my code:  0.10282487157162998\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "67\n",
      "full train loss:  tensor(0.1012, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1135, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11480194690279058\n",
      "train loss after my code:  0.10139232863499205\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "68\n",
      "full train loss:  tensor(0.1017, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1134, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11463632891229913\n",
      "train loss after my code:  0.10266407184792754\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "69\n",
      "full train loss:  tensor(0.1022, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1134, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11451695260542782\n",
      "train loss after my code:  0.10272568610528382\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "70\n",
      "full train loss:  tensor(0.1004, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1133, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11443913870763535\n",
      "train loss after my code:  0.10246580542031523\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "71\n",
      "full train loss:  tensor(0.1019, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1133, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11437281091395296\n",
      "train loss after my code:  0.10381065931073688\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "72\n",
      "full train loss:  tensor(0.1019, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1133, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11418119651606165\n",
      "train loss after my code:  0.10279064292217578\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "73\n",
      "full train loss:  tensor(0.1015, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1131, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11406950699316659\n",
      "train loss after my code:  0.10194479523799119\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "74\n",
      "full train loss:  tensor(0.1010, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1131, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11387682016321699\n",
      "train loss after my code:  0.09946198959545847\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "75\n",
      "full train loss:  tensor(0.1005, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11379846953233116\n",
      "train loss after my code:  0.10198002127828029\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "76\n",
      "full train loss:  tensor(0.0994, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.113772731757303\n",
      "train loss after my code:  0.10129653066004146\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "77\n",
      "full train loss:  tensor(0.1011, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11369724432681308\n",
      "train loss after my code:  0.10012681787607652\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "78\n",
      "full train loss:  tensor(0.0998, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.1136741978247581\n",
      "train loss after my code:  0.10172858622188485\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "79\n",
      "full train loss:  tensor(0.0997, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.1136691190312381\n",
      "train loss after my code:  0.10253148097957593\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "80\n",
      "full train loss:  tensor(0.1008, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1130, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11366728164338089\n",
      "train loss after my code:  0.10204693226780107\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "81\n",
      "full train loss:  tensor(0.1002, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1130, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11365134635029853\n",
      "train loss after my code:  0.10175329844199661\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "82\n",
      "full train loss:  tensor(0.1008, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1130, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11355816867478692\n",
      "train loss after my code:  0.09990047085867551\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "83\n",
      "full train loss:  tensor(0.0996, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11353605197810561\n",
      "train loss after my code:  0.10164664596484504\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "84\n",
      "full train loss:  tensor(0.1018, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1130, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.1135268723598265\n",
      "train loss after my code:  0.10034295511677506\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "85\n",
      "full train loss:  tensor(0.1015, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11345833516272262\n",
      "train loss after my code:  0.10042752224932422\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "86\n",
      "full train loss:  tensor(0.1000, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11343850927693051\n",
      "train loss after my code:  0.10095403600192766\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "87\n",
      "full train loss:  tensor(0.1003, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11338355602073447\n",
      "train loss after my code:  0.10216949770255127\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "88\n",
      "full train loss:  tensor(0.1010, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11337457865768857\n",
      "train loss after my code:  0.10117114888355902\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "89\n",
      "full train loss:  tensor(0.1006, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11334073998156544\n",
      "train loss after my code:  0.10162739283397551\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "90\n",
      "full train loss:  tensor(0.1001, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11330595937493844\n",
      "train loss after my code:  0.10104761314370138\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "91\n",
      "full train loss:  tensor(0.1010, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11328654843009263\n",
      "train loss after my code:  0.10013285421869036\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "92\n",
      "full train loss:  tensor(0.1013, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11326751267564174\n",
      "train loss after my code:  0.10092910408184164\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "93\n",
      "full train loss:  tensor(0.0989, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.1132407860704182\n",
      "train loss after my code:  0.10050020543460049\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "94\n",
      "full train loss:  tensor(0.1008, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11321113359634202\n",
      "train loss after my code:  0.10141473795977068\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "95\n",
      "full train loss:  tensor(0.1016, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.1131756629783606\n",
      "train loss after my code:  0.10128122252081606\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "96\n",
      "full train loss:  tensor(0.0980, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11315479204766818\n",
      "train loss after my code:  0.10056561938985133\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "97\n",
      "full train loss:  tensor(0.0991, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.1131686080673392\n",
      "train loss after my code:  0.10216212128441787\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "98\n",
      "full train loss:  tensor(0.0997, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11313936906631095\n",
      "train loss after my code:  0.09945455359698457\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n",
      "99\n",
      "full train loss:  tensor(0.0999, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1129, device='cuda:0', dtype=torch.float64)\n",
      "loss after my code:  0.11308563779713017\n",
      "train loss after my code:  0.0997467818718411\n",
      "(array([0, 1, 2]), array([140,  47,  34]))\n",
      "(array([0]), array([221]))\n",
      "val accuracy:  0.3333333333333333\n",
      "(array([0, 1, 2]), array([3559, 1262,  721]))\n",
      "(array([0]), array([5542]))\n",
      "test accuracy:  0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(save_dir)\n",
    "DATA_ROOT = osj(\"/mimer/NOBACKUP/groups/snic2022-22-122/arthur/\", \"dataset_beats\")\n",
    "DICT_BEATS = osj(DATA_ROOT, \"5min_normal_beats.pkl\")\n",
    "DATA_BEATS = osj(DATA_ROOT, \"30min_beats.pkl\")\n",
    "\n",
    "DATA_ROOT = \"/mimer/NOBACKUP/groups/snic2022-22-122/arthur/physionet.org/files/mitdb/1.0.0/\"\n",
    "RECORDS = osj(DATA_ROOT, \"RECORDS\")\n",
    "#print(RECORDS)\n",
    "patient_ids = pd.read_csv(RECORDS, header=None).to_numpy().reshape(-1)\n",
    "#print(patient_ids)\n",
    "paced_patients = get_paced_patients(patient_ids)\n",
    "excluded_patients = np.array([105, 114, 201, 202, 207, 209, 213, 222, 223, 234])  # according to paper\n",
    "#print(np.concatenate((paced_patients, excluded_patients)))\n",
    "\n",
    "dict_beats = read_dict_beats()\n",
    "data_beats = read_data_beats()\n",
    "ensure_normalized_and_detrended(dict_beats)\n",
    "ensure_normalized_and_detrended(data_beats)\n",
    "\n",
    "import collections\n",
    "\n",
    "patients_out = np.concatenate((paced_patients, excluded_patients))\n",
    "patients_left = list(copy.deepcopy(patient_ids))\n",
    "\n",
    "for idx, i in enumerate(patient_ids):\n",
    "    if i in patients_out:\n",
    "        patients_left.remove(i)\n",
    "\n",
    "labels = ['N', 'V', 'S', 'Q', 'F']\n",
    "dictionary = {}\n",
    "for i in labels:\n",
    "    dictionary[i] = 0\n",
    "\n",
    "list1 = []\n",
    "array = np.zeros((len(patients_left), 2))\n",
    "for idx, i in enumerate(patients_left):\n",
    "    list1.append(data_beats[i]['class'])\n",
    "    counter = collections.Counter(data_beats[i]['class'])\n",
    "    for j in counter.keys():\n",
    "        dictionary[j] += counter[j]\n",
    "        if j == 'N':\n",
    "            array[idx, 0] += counter[j]\n",
    "        else:\n",
    "            array[idx, 1] += counter[j]\n",
    "\n",
    "seconds = 5\n",
    "data_beats_train, data_beats_val, data_beats_test = train_test_split(data_beats, seconds)\n",
    "\n",
    "import collections\n",
    "from time import time\n",
    "import random\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pandas\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "experiment_name = settings['experiment_name']\n",
    "test = 'federated'\n",
    "print('type: ',test)\n",
    "n_epochs = 100 #settings['n_epochs']\n",
    "patients_example = [200, 118, 232]\n",
    "p2p = P2P_AFPL(patients_example, data_beats_train, data_beats_val,data_beats_test,1,test)\n",
    "alphas = p2p.loop(n_epochs, p2p, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b62d0a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3333333333333333, 0.3333333333333333, 0.5]\n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "federated_acc = p2p.accuracy_list\n",
    "print(federated_acc)\n",
    "federated_best = p2p.best_accuracy\n",
    "print(federated_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb19d43b",
   "metadata": {},
   "source": [
    "### Centralized training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fffffcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "validation\n",
      "0.3333333333333333\n",
      "test\n",
      "0.3333333333333333\n",
      "200\n",
      "0.3333333333333333\n",
      "118\n",
      "0.3333333333333333\n",
      "232\n",
      "0.5\n",
      "1\n",
      "validation\n",
      "0.3333333333333333\n",
      "2\n",
      "validation\n",
      "0.3333333333333333\n",
      "3\n",
      "validation\n",
      "0.3333333333333333\n",
      "4\n",
      "validation\n",
      "0.3333333333333333\n",
      "5\n",
      "validation\n",
      "0.3333333333333333\n",
      "6\n",
      "validation\n",
      "0.9046218487394958\n",
      "test\n",
      "0.9176017027328176\n",
      "200\n",
      "0.7477306831320263\n",
      "118\n",
      "0.5881304555278004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232\n",
      "0.9734546560389257\n",
      "7\n",
      "validation\n",
      "0.9242296918767506\n",
      "test\n",
      "0.9342715060979717\n",
      "200\n",
      "0.7837245891024806\n",
      "118\n",
      "0.6470174109105878\n",
      "232\n",
      "0.9777761772143795\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n",
      "0.9465492580010727\n",
      "test\n",
      "0.9415561491951463\n",
      "200\n",
      "0.7351291374849631\n",
      "118\n",
      "0.6741864701111382\n",
      "232\n",
      "0.9738868081564711\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n",
      "0.9462184873949581\n",
      "10\n",
      "validation\n",
      "0.9391262888133977\n",
      "11\n",
      "validation\n",
      "0.9489302103820251\n",
      "test\n",
      "0.9465045340588524\n",
      "200\n",
      "0.7766386018171542\n",
      "118\n",
      "0.7975230491439197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232\n",
      "0.9726517067341037\n",
      "12\n",
      "validation\n",
      "0.9658263305322129\n",
      "test\n",
      "0.9553243082613291\n",
      "200\n",
      "0.8284062682314467\n",
      "118\n",
      "0.817880997257348\n",
      "232\n",
      "0.9775294236904724\n",
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n",
      "0.9756302521008404\n",
      "test\n",
      "0.9513616104469858\n",
      "200\n",
      "0.8374603027092101\n",
      "118\n",
      "0.817880997257348\n",
      "232\n",
      "0.9766651194553817\n",
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n",
      "0.9830532212885155\n",
      "test\n",
      "0.9590832070865486\n",
      "200\n",
      "0.8326534265933051\n",
      "118\n",
      "0.8433372483233552\n",
      "232\n",
      "0.9753686631027455\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n",
      "0.9759610227069552\n",
      "16\n",
      "validation\n",
      "0.988145896656535\n",
      "test\n",
      "0.959074148127648\n",
      "200\n",
      "0.7967640690964432\n",
      "118\n",
      "0.887104353915098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232\n",
      "0.9754300180330143\n",
      "17\n",
      "validation\n",
      "0.9854341736694678\n",
      "18\n",
      "validation\n",
      "0.9904761904761905\n",
      "test\n",
      "0.9643609507983603\n",
      "200\n",
      "0.8627745479360446\n",
      "118\n",
      "0.8859957064649872\n",
      "232\n",
      "0.9733933011086568\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n",
      "0.988145896656535\n",
      "20\n",
      "validation\n",
      "0.9854341736694678\n",
      "21\n",
      "validation\n",
      "0.9854341736694678\n",
      "22\n",
      "validation\n",
      "0.9952380952380953\n",
      "test\n",
      "0.9603839318660294\n",
      "200\n",
      "0.8485119950582055\n",
      "118\n",
      "0.8614633282740725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232\n",
      "0.9762943222681051\n",
      "23\n",
      "validation\n",
      "0.9854341736694678\n",
      "24\n",
      "validation\n",
      "0.9854341736694678\n",
      "25\n",
      "validation\n",
      "0.9854341736694678\n",
      "26\n",
      "validation\n",
      "0.9854341736694678\n",
      "27\n",
      "validation\n",
      "0.9854341736694678\n",
      "28\n",
      "validation\n",
      "0.9830532212885155\n",
      "29\n",
      "validation\n",
      "0.9854341736694678\n",
      "30\n",
      "validation\n",
      "0.9830532212885155\n",
      "31\n",
      "validation\n",
      "0.9830532212885155\n",
      "32\n",
      "validation\n",
      "0.9854341736694678\n",
      "33\n",
      "validation\n",
      "0.9830532212885155\n",
      "34\n",
      "validation\n",
      "0.9854341736694678\n",
      "35\n",
      "validation\n",
      "0.9830532212885155\n",
      "36\n",
      "validation\n",
      "0.9830532212885155\n",
      "37\n",
      "validation\n",
      "0.9830532212885155\n",
      "38\n",
      "validation\n",
      "0.9830532212885155\n",
      "39\n",
      "validation\n",
      "0.9830532212885155\n",
      "40\n",
      "validation\n",
      "0.9830532212885155\n",
      "41\n",
      "validation\n",
      "0.9830532212885155\n",
      "42\n",
      "validation\n",
      "0.9854341736694678\n",
      "43\n",
      "validation\n",
      "0.9854341736694678\n",
      "44\n",
      "validation\n",
      "0.9854341736694678\n",
      "45\n",
      "validation\n",
      "0.9854341736694678\n",
      "46\n",
      "validation\n",
      "0.9854341736694678\n",
      "47\n",
      "validation\n",
      "0.9854341736694678\n",
      "48\n",
      "validation\n",
      "0.9854341736694678\n",
      "49\n",
      "validation\n",
      "0.9854341736694678\n",
      "50\n",
      "validation\n",
      "0.9854341736694678\n",
      "51\n",
      "validation\n",
      "0.9854341736694678\n",
      "52\n",
      "validation\n",
      "0.9854341736694678\n",
      "53\n",
      "validation\n",
      "0.9854341736694678\n",
      "54\n",
      "validation\n",
      "0.9854341736694678\n",
      "55\n",
      "validation\n",
      "0.9854341736694678\n",
      "56\n",
      "validation\n",
      "0.9854341736694678\n",
      "57\n",
      "validation\n",
      "0.9854341736694678\n",
      "58\n",
      "validation\n",
      "0.9854341736694678\n",
      "59\n",
      "validation\n",
      "0.9854341736694678\n",
      "60\n",
      "validation\n",
      "0.9854341736694678\n",
      "61\n",
      "validation\n",
      "0.9854341736694678\n",
      "62\n",
      "validation\n",
      "0.9854341736694678\n",
      "63\n",
      "validation\n",
      "0.9854341736694678\n",
      "64\n",
      "validation\n",
      "0.9854341736694678\n",
      "65\n",
      "validation\n",
      "0.9854341736694678\n",
      "66\n",
      "validation\n",
      "0.9854341736694678\n",
      "67\n",
      "validation\n",
      "0.9854341736694678\n",
      "68\n",
      "validation\n",
      "0.9854341736694678\n",
      "69\n",
      "validation\n",
      "0.9854341736694678\n",
      "70\n",
      "validation\n",
      "0.9854341736694678\n",
      "71\n",
      "validation\n",
      "0.9854341736694678\n",
      "72\n",
      "validation\n",
      "0.9854341736694678\n",
      "73\n",
      "validation\n",
      "0.9854341736694678\n",
      "74\n",
      "validation\n",
      "0.9854341736694678\n",
      "75\n",
      "validation\n",
      "0.9854341736694678\n",
      "76\n",
      "validation\n",
      "0.9854341736694678\n",
      "77\n",
      "validation\n",
      "0.9854341736694678\n",
      "78\n",
      "validation\n",
      "0.9854341736694678\n",
      "79\n",
      "validation\n",
      "0.9854341736694678\n",
      "80\n",
      "validation\n",
      "0.9854341736694678\n",
      "81\n",
      "validation\n",
      "0.9854341736694678\n",
      "82\n",
      "validation\n",
      "0.9854341736694678\n",
      "83\n",
      "validation\n",
      "0.9854341736694678\n",
      "84\n",
      "validation\n",
      "0.9854341736694678\n",
      "85\n",
      "validation\n",
      "0.9854341736694678\n",
      "86\n",
      "validation\n",
      "0.9854341736694678\n",
      "87\n",
      "validation\n",
      "0.9854341736694678\n",
      "88\n",
      "validation\n",
      "0.9854341736694678\n",
      "89\n",
      "validation\n",
      "0.9854341736694678\n",
      "90\n",
      "validation\n",
      "0.9854341736694678\n",
      "91\n",
      "validation\n",
      "0.9854341736694678\n",
      "92\n",
      "validation\n",
      "0.9878151260504202\n",
      "93\n",
      "validation\n",
      "0.9854341736694678\n",
      "94\n",
      "validation\n",
      "0.9878151260504202\n",
      "95\n",
      "validation\n",
      "0.9854341736694678\n",
      "96\n",
      "validation\n",
      "0.9878151260504202\n",
      "97\n",
      "validation\n",
      "0.9878151260504202\n",
      "98\n",
      "validation\n",
      "0.9878151260504202\n",
      "99\n",
      "validation\n",
      "0.9878151260504202\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pandas \n",
    "# Global model \n",
    "patients_train = [200,118, 232]\n",
    "best_accuracy = 0 \n",
    "mit_bih = MIT_BIH(patients_train,data_beats_test)\n",
    "dataloader_test = DataLoader(mit_bih,batch_size=32,shuffle=False,num_workers=0)\n",
    "mit_bih = MIT_BIH(patients_train,data_beats_val)\n",
    "dataloader_val = DataLoader(mit_bih,batch_size=32,shuffle=False,num_workers=0)\n",
    "\n",
    "\n",
    "mit_bih = MIT_BIH(patients_train,data_beats_train)\n",
    "dataloader = DataLoader(mit_bih,batch_size=32,shuffle=True,num_workers=0)\n",
    "model = get_base_model(1)\n",
    "model.double().train()\n",
    "#crit = nn.CrossEntropyLoss()\n",
    "optimizer= torch.optim.Adam(model.parameters())\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    losses = 0 \n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        data = data.double().unsqueeze(1)\n",
    "        target=target.long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        output = F.log_softmax(output,dim=-1)\n",
    "        loss = F.nll_loss(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.detach().cpu().numpy()\n",
    "\n",
    "# calculate accuracy on test set \n",
    "    with torch.no_grad():\n",
    "        model.double().eval()\n",
    "\n",
    "        losses = 0 \n",
    "        len_total = 0 \n",
    "        accuracy = 0 \n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for batch_idx, (data, target) in enumerate(dataloader_val):\n",
    "            data = data.double().unsqueeze(1)\n",
    "            target=target.long()\n",
    "            output = model(data)\n",
    "            output = F.log_softmax(output,dim=-1)\n",
    "            loss = F.nll_loss(output,target)\n",
    "            losses += loss.detach().cpu().numpy()\n",
    "\n",
    "            output1 = np.argmax(output.detach().cpu().numpy(),axis=1)\n",
    "            target1 = target.detach().cpu().numpy()\n",
    "            accuracy += sum(output1 == target1)\n",
    "            len_total += len(target)\n",
    "            y_pred.append(list(output1))\n",
    "            y_true.append(list(target1))\n",
    "       # val_accuracy = accuracy/len_total*100\n",
    "        pred = np.array([j for sub in y_pred for j in sub])\n",
    "        true = np.array([j for sub in y_true for j in sub])\n",
    "        val_accuracy = balanced_accuracy_score(true,pred)\n",
    "        print('validation')\n",
    "        print(val_accuracy)\n",
    "        \n",
    "    if val_accuracy > best_accuracy: \n",
    "        best_accuracy = val_accuracy \n",
    "        with torch.no_grad():\n",
    "            model.double().eval()\n",
    "\n",
    "            losses = 0 \n",
    "            len_total = 0 \n",
    "            accuracy = 0 \n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "            for batch_idx, (data, target) in enumerate(dataloader_test):\n",
    "                data = data.double().unsqueeze(1)\n",
    "                target=target.long()\n",
    "                output = model(data)\n",
    "                output = F.log_softmax(output,dim=-1)\n",
    "                loss = F.nll_loss(output,target)\n",
    "                losses += loss.detach().cpu().numpy()\n",
    "\n",
    "                output1 = np.argmax(output.detach().cpu().numpy(),axis=1)\n",
    "                target1 = target.detach().cpu().numpy()\n",
    "                accuracy += sum(output1 == target1)\n",
    "                len_total += len(target)\n",
    "                y_pred.append(list(output1))\n",
    "                y_true.append(list(target1))\n",
    "            pred = np.array([j for sub in y_pred for j in sub])\n",
    "            true = np.array([j for sub in y_true for j in sub])\n",
    "            test_accuracy = balanced_accuracy_score(true,pred) #accuracy/len_total*100\n",
    "            print('test')\n",
    "            print(test_accuracy)\n",
    "\n",
    "            # per-patient accuracy \n",
    "            for patient in patients_train: \n",
    "                mit_bih = MIT_BIH([patient],data_beats_test)\n",
    "                dataloader_testc = DataLoader(mit_bih,batch_size=32,shuffle=False,num_workers=0)\n",
    "                with torch.no_grad():\n",
    "                    model.double().eval()\n",
    "\n",
    "                    losses = 0 \n",
    "                    len_total = 0 \n",
    "                    accuracy = 0 \n",
    "                    y_true = []\n",
    "                    y_pred = []\n",
    "                    for batch_idx, (data, target) in enumerate(dataloader_testc):\n",
    "                        data = data.double().unsqueeze(1)\n",
    "                        target=target.long()\n",
    "                        output = model(data)\n",
    "                        output = F.log_softmax(output,dim=-1)\n",
    "                        loss = F.nll_loss(output,target)\n",
    "                        losses += loss.detach().cpu().numpy()\n",
    "\n",
    "                        output1 = np.argmax(output.detach().cpu().numpy(),axis=1)\n",
    "                        target1 = target.detach().cpu().numpy()\n",
    "                        accuracy += sum(output1 == target1)\n",
    "                        len_total += len(target)\n",
    "                        y_pred.append(list(output1))\n",
    "                        y_true.append(list(target1))\n",
    "                    test_accuracy = accuracy/len_total*100\n",
    "                    pred = np.array([j for sub in y_pred for j in sub])\n",
    "                    true = np.array([j for sub in y_true for j in sub])\n",
    "                    test_accuracy = balanced_accuracy_score(true,pred)\n",
    "                    print(patient)\n",
    "                    print(test_accuracy)\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8439e56c",
   "metadata": {},
   "source": [
    "# all patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff7afb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e901867d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf29f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8762bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27598380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints_bandits/test\n",
      "type:  local\n",
      "0\n",
      "full train loss:  tensor(0.7566, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.8835, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  58.56747130985358\n",
      "test accuracy:  58.415420258790526\n",
      "0\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 0.3221649484536082, 0.11527377521613834, 29.045643153526974, 1.2951601908657124, 98.43453510436433, 0.056561085972850686, 99.90539262062441, 0.2008032128514056, 0.24615384615384617, 95.26892430278885, 0.07830853563038372, 95.14767932489451, 21.825876662636034, 0.12903225806451613, 100.0, 0.23752969121140144, 4.305864884929473, 66.09699769053118, 85.24788391777508, 96.6078697421981, 53.82113821138211, 91.34179510426111, 100.0, 88.90069038767923, 95.10714285714286, 52.20301171221416, 48.328445747800586, 84.15841584158416, 16.910473961380927, 99.94675186368477, 0.07651109410864575, 78.12288993923025, 72.50390015600624]\n",
      "1\n",
      "full train loss:  tensor(0.5077, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5856, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  91.49188761377127\n",
      "test accuracy:  90.81467004996139\n",
      "58.56747130985358\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 78.17412333736397, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 66.09699769053118, 85.24788391777508, 96.6078697421981, 53.82113821138211, 91.34179510426111, 100.0, 88.90069038767923, 95.10714285714286, 96.65365309537088, 95.19061583577712, 84.15841584158416, 83.08952603861908, 99.94675186368477, 99.92348890589136, 78.12288993923025, 72.50390015600624]\n",
      "2\n",
      "full train loss:  tensor(0.3679, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4174, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  91.49188761377127\n",
      "test accuracy:  90.81467004996139\n",
      "3\n",
      "full train loss:  tensor(0.3033, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3387, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  92.87692916501781\n",
      "test accuracy:  92.1574808113603\n",
      "91.49188761377127\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 78.17412333736397, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 66.09699769053118, 85.24788391777508, 96.6078697421981, 88.45528455284553, 91.34179510426111, 100.0, 88.90069038767923, 95.10714285714286, 96.65365309537088, 95.19061583577712, 84.15841584158416, 83.08952603861908, 99.94675186368477, 99.92348890589136, 78.12288993923025, 72.50390015600624]\n",
      "4\n",
      "full train loss:  tensor(0.2680, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2965, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  92.8373565492679\n",
      "test accuracy:  92.08182950085896\n",
      "5\n",
      "full train loss:  tensor(0.2324, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2661, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  92.87692916501781\n",
      "test accuracy:  92.18585005279832\n",
      "6\n",
      "full train loss:  tensor(0.2109, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2427, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  93.78709932726554\n",
      "test accuracy:  93.12045895128371\n",
      "92.87692916501781\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 78.17412333736397, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 66.09699769053118, 85.24788391777508, 96.6078697421981, 92.35772357723577, 91.34179510426111, 100.0, 88.90069038767923, 95.10714285714286, 96.65365309537088, 95.19061583577712, 84.15841584158416, 83.08952603861908, 99.94675186368477, 99.92348890589136, 78.12288993923025, 92.58970358814352]\n",
      "7\n",
      "full train loss:  tensor(0.1945, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2215, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  95.17214087851207\n",
      "test accuracy:  94.56413812668443\n",
      "93.78709932726554\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 95.52599758162032, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 88.31408775981524, 85.24788391777508, 96.6078697421981, 96.17886178861788, 91.34179510426111, 100.0, 88.90069038767923, 95.10714285714286, 96.65365309537088, 95.19061583577712, 84.15841584158416, 83.08952603861908, 99.94675186368477, 99.92348890589136, 78.12288993923025, 94.69578783151326]\n",
      "8\n",
      "full train loss:  tensor(0.1746, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2044, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  95.56786703601108\n",
      "test accuracy:  94.98337247237939\n",
      "95.17214087851207\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 98.18621523579202, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 92.2863741339492, 85.24788391777508, 96.6078697421981, 96.78861788617887, 91.34179510426111, 100.0, 88.90069038767923, 95.10714285714286, 96.65365309537088, 95.19061583577712, 86.88118811881188, 83.08952603861908, 99.94675186368477, 99.92348890589136, 78.12288993923025, 97.26989079563182]\n",
      "9\n",
      "full train loss:  tensor(0.1625, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1890, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  95.92402057776019\n",
      "test accuracy:  95.41521536982458\n",
      "95.56786703601108\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 99.51632406287787, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 93.8568129330254, 85.24788391777508, 96.6078697421981, 97.3170731707317, 91.34179510426111, 100.0, 88.90069038767923, 95.10714285714286, 96.65365309537088, 95.19061583577712, 96.68316831683168, 83.08952603861908, 99.94675186368477, 99.92348890589136, 78.12288993923025, 97.54290171606864]\n",
      "10\n",
      "full train loss:  tensor(0.1481, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1778, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  95.96359319351009\n",
      "test accuracy:  95.4782581285757\n",
      "95.92402057776019\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 99.4558645707376, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 94.5958429561201, 85.24788391777508, 96.6078697421981, 97.52032520325203, 91.34179510426111, 100.0, 88.90069038767923, 95.10714285714286, 96.65365309537088, 95.19061583577712, 97.17821782178217, 83.08952603861908, 99.94675186368477, 99.92348890589136, 78.12288993923025, 97.93291731669267]\n",
      "11\n",
      "full train loss:  tensor(0.1397, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1657, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  96.3197467352592\n",
      "test accuracy:  95.73358130151776\n",
      "95.96359319351009\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 99.75816203143893, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 96.25866050808314, 85.24788391777508, 96.6078697421981, 97.23577235772358, 91.34179510426111, 100.0, 88.90069038767923, 95.10714285714286, 96.65365309537088, 95.19061583577712, 97.57425742574257, 83.08952603861908, 99.94675186368477, 99.92348890589136, 86.1580013504389, 97.97191887675507]\n",
      "12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full train loss:  tensor(0.1291, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1582, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  96.51760981400871\n",
      "test accuracy:  95.86281895695755\n",
      "96.3197467352592\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 99.75816203143893, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 96.44341801385681, 85.24788391777508, 96.6078697421981, 97.76422764227642, 91.34179510426111, 100.0, 88.90069038767923, 95.10714285714286, 96.65365309537088, 95.19061583577712, 98.06930693069307, 83.08952603861908, 99.94675186368477, 99.92348890589136, 89.66914247130318, 98.08892355694228]\n",
      "13\n",
      "full train loss:  tensor(0.1218, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1476, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  96.51760981400871\n",
      "test accuracy:  95.98417626755347\n",
      "14\n",
      "full train loss:  tensor(0.1117, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1395, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  96.5571824297586\n",
      "test accuracy:  96.00939337105392\n",
      "96.51760981400871\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 99.8186215235792, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.09006928406467, 85.24788391777508, 96.6078697421981, 97.6829268292683, 91.34179510426111, 100.0, 88.90069038767923, 95.10714285714286, 96.65365309537088, 95.19061583577712, 98.41584158415841, 83.32358104154476, 99.94675186368477, 99.92348890589136, 94.19311276164754, 98.16692667706708]\n",
      "15\n",
      "full train loss:  tensor(0.1072, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1331, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  96.7550455085081\n",
      "test accuracy:  96.23477123358917\n",
      "96.5571824297586\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 99.87908101571948, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.22863741339492, 85.2881902458686, 96.6078697421981, 98.08943089430893, 91.34179510426111, 100.0, 88.90069038767923, 95.25, 96.65365309537088, 95.19061583577712, 98.46534653465346, 90.69631363370392, 99.94675186368477, 99.92348890589136, 93.92302498311952, 98.20592823712948]\n",
      "16\n",
      "full train loss:  tensor(0.0989, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1259, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  97.03205381875742\n",
      "test accuracy:  96.56101751012625\n",
      "96.7550455085081\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 99.87908101571948, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.27482678983834, 87.30350665054414, 96.6078697421981, 98.130081300813, 91.34179510426111, 100.0, 88.90069038767923, 96.60714285714286, 96.65365309537088, 95.19061583577712, 98.56435643564356, 94.73376243417204, 99.94675186368477, 99.92348890589136, 97.02903443619176, 98.20592823712948]\n",
      "17\n",
      "full train loss:  tensor(0.0934, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1193, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  97.19034428175702\n",
      "test accuracy:  96.75960220019229\n",
      "97.03205381875742\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 71.96206283343213, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.22863741339492, 90.00403063280935, 96.6078697421981, 97.80487804878048, 91.34179510426111, 100.0, 88.90069038767923, 98.25, 96.65365309537088, 95.19061583577712, 98.76237623762376, 94.85078993563488, 99.94675186368477, 99.92348890589136, 96.89399054692775, 98.20592823712948]\n",
      "18\n",
      "full train loss:  tensor(0.0919, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1153, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  97.62564305500594\n",
      "test accuracy:  97.19459723557503\n",
      "97.19034428175702\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 80.55720213396562, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.27482678983834, 92.66424828698105, 96.6078697421981, 98.08943089430893, 91.34179510426111, 100.0, 88.95379713223579, 99.32142857142857, 96.65365309537088, 95.19061583577712, 98.7128712871287, 95.37741369221767, 99.94675186368477, 99.92348890589136, 98.04186360567184, 98.24492979719189]\n",
      "19\n",
      "full train loss:  tensor(0.0854, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1103, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  97.62564305500594\n",
      "test accuracy:  97.31910668410849\n",
      "20\n",
      "full train loss:  tensor(0.0820, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1070, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  97.82350613375544\n",
      "test accuracy:  97.51453923623697\n",
      "97.62564305500594\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 86.18850029638412, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.36720554272517, 93.67190648931883, 96.6078697421981, 97.88617886178862, 91.34179510426111, 100.0, 92.98990971853426, 99.46428571428572, 96.65365309537088, 95.19061583577712, 98.8118811881188, 95.55295494441194, 99.94675186368477, 99.92348890589136, 98.04186360567184, 98.28393135725429]\n",
      "21\n",
      "full train loss:  tensor(0.0778, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1032, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.02136921250495\n",
      "test accuracy:  97.642200822708\n",
      "97.82350613375544\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 89.38944872554832, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.4133949191686, 94.27650141072148, 96.6078697421981, 97.96747967479675, 91.34179510426111, 100.0, 93.5740839086564, 99.35714285714286, 96.65365309537088, 95.19061583577712, 98.8118811881188, 95.55295494441194, 99.94675186368477, 99.92348890589136, 98.10938555030386, 98.28393135725429]\n",
      "22\n",
      "full train loss:  tensor(0.0778, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1014, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.06094182825484\n",
      "test accuracy:  97.69578716764646\n",
      "98.02136921250495\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 89.62655601659752, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.50577367205543, 94.35711406690851, 96.6078697421981, 98.08943089430893, 91.34179510426111, 100.0, 94.15825809877855, 99.67857142857143, 96.65365309537088, 95.19061583577712, 98.86138613861387, 95.61146869514336, 99.94675186368477, 99.92348890589136, 98.17690749493585, 98.28393135725429]\n",
      "23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full train loss:  tensor(0.0722, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0986, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.02136921250495\n",
      "test accuracy:  97.75252565052247\n",
      "24\n",
      "full train loss:  tensor(0.0707, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0962, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.02136921250495\n",
      "test accuracy:  97.78247096092925\n",
      "25\n",
      "full train loss:  tensor(0.0675, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0948, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.06094182825484\n",
      "test accuracy:  97.81084020236726\n",
      "26\n",
      "full train loss:  tensor(0.0671, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0929, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.17965967550455\n",
      "test accuracy:  97.9227410991505\n",
      "98.06094182825484\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 92.5311203319502, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.55196304849885, 94.84079000403062, 96.6078697421981, 98.17073170731707, 92.88304623753399, 100.0, 96.17631439192778, 99.75, 96.65365309537088, 95.19061583577712, 98.96039603960396, 95.61146869514336, 99.94675186368477, 99.92348890589136, 98.17690749493585, 98.4399375975039]\n",
      "27\n",
      "full train loss:  tensor(0.0647, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0916, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.21923229125446\n",
      "test accuracy:  97.9952402717143\n",
      "98.17965967550455\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 92.9460580912863, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.55196304849885, 95.04232164449819, 96.6078697421981, 98.130081300813, 93.83499546690844, 100.0, 96.70738183749337, 99.82142857142857, 96.65365309537088, 95.19061583577712, 99.00990099009901, 95.61146869514336, 99.94675186368477, 99.92348890589136, 98.24442943956785, 98.4399375975039]\n",
      "28\n",
      "full train loss:  tensor(0.0629, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0903, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.25880490700435\n",
      "test accuracy:  98.05040268562152\n",
      "98.21923229125446\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 92.886781268524, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.50577367205543, 95.16324062877872, 96.6078697421981, 98.2520325203252, 94.1976427923844, 100.0, 97.50398300584175, 99.85714285714286, 96.65365309537088, 95.19061583577712, 99.00990099009901, 95.66998244587478, 99.94675186368477, 99.92348890589136, 98.24442943956785, 98.67394695787831]\n",
      "29\n",
      "full train loss:  tensor(0.0611, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0895, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.29837752275425\n",
      "test accuracy:  98.12763006509165\n",
      "98.25880490700435\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 94.0130409010077, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.64434180138568, 95.32446594115275, 96.6078697421981, 98.29268292682927, 94.15231187669991, 100.0, 98.35369091874668, 99.85714285714286, 96.65365309537088, 95.19061583577712, 99.05940594059406, 95.66998244587478, 99.94675186368477, 99.92348890589136, 98.31195138419987, 98.86895475819033]\n",
      "30\n",
      "full train loss:  tensor(0.0604, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0883, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.29837752275425\n",
      "test accuracy:  98.17175999621743\n",
      "31\n",
      "full train loss:  tensor(0.0587, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0865, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.33795013850416\n",
      "test accuracy:  98.20958565146812\n",
      "98.29837752275425\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 94.665085951393, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.59815242494227, 95.4453849254333, 96.6078697421981, 98.2520325203252, 95.24025385312783, 100.0, 98.99097185342538, 99.89285714285714, 96.65365309537088, 95.19061583577712, 99.05940594059406, 95.66998244587478, 99.94675186368477, 99.92348890589136, 98.31195138419987, 98.98595943837753]\n",
      "32\n",
      "full train loss:  tensor(0.0567, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0855, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.29837752275425\n",
      "test accuracy:  98.24583523775\n",
      "33\n",
      "full train loss:  tensor(0.0548, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0843, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.33795013850416\n",
      "test accuracy:  98.26001985846901\n",
      "34\n",
      "full train loss:  tensor(0.0552, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0832, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.33795013850416\n",
      "test accuracy:  98.29154123784457\n",
      "35\n",
      "full train loss:  tensor(0.0536, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0824, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.37752275425406\n",
      "test accuracy:  98.31518227237623\n",
      "98.33795013850416\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 96.2062833432128, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.64434180138568, 95.64691656590084, 96.6078697421981, 98.33333333333333, 95.92021758839529, 100.0, 99.25650557620817, 99.89285714285714, 96.65365309537088, 95.19061583577712, 99.10891089108911, 96.07957870099474, 99.94675186368477, 99.92348890589136, 98.31195138419987, 99.18096723868955]\n",
      "36\n",
      "full train loss:  tensor(0.0515, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0814, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.33795013850416\n",
      "test accuracy:  98.32621475515768\n",
      "37\n",
      "full train loss:  tensor(0.0513, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0800, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.37752275425406\n",
      "test accuracy:  98.35773613453324\n",
      "38\n",
      "full train loss:  tensor(0.0504, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0789, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.37752275425406\n",
      "test accuracy:  98.37507289318981\n",
      "39\n",
      "full train loss:  tensor(0.0503, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0780, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.37752275425406\n",
      "test accuracy:  98.39240965184636\n",
      "40\n",
      "full train loss:  tensor(0.0491, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0774, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.41709537000396\n",
      "test accuracy:  98.39398572081515\n",
      "98.37752275425406\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 96.8583283935981, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.6905311778291, 95.80814187827488, 96.6078697421981, 98.2520325203252, 96.23753399818676, 100.0, 99.41582580987786, 99.89285714285714, 96.65365309537088, 95.19061583577712, 99.10891089108911, 97.366881217086, 99.94675186368477, 99.92348890589136, 98.37947332883186, 99.29797191887675]\n",
      "41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full train loss:  tensor(0.0481, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0764, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.41709537000396\n",
      "test accuracy:  98.42708316915947\n",
      "42\n",
      "full train loss:  tensor(0.0477, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0757, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.41709537000396\n",
      "test accuracy:  98.46333275544139\n",
      "43\n",
      "full train loss:  tensor(0.0462, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0749, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.45666798575385\n",
      "test accuracy:  98.47909344512917\n",
      "98.41709537000396\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 97.0954356846473, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 96.46414342629483, 99.92169146436962, 95.14767932489451, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.64434180138568, 96.00967351874245, 96.6078697421981, 98.2520325203252, 96.55485040797825, 100.0, 99.52203929899098, 99.92857142857143, 96.65365309537088, 95.19061583577712, 99.15841584158416, 97.95201872440023, 99.94675186368477, 99.92348890589136, 98.37947332883186, 99.33697347893916]\n",
      "44\n",
      "full train loss:  tensor(0.0457, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0745, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.49624060150376\n",
      "test accuracy:  98.52322337625495\n",
      "98.45666798575385\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 97.1547125074096, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 97.80876494023904, 99.92169146436962, 95.14767932489451, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.64434180138568, 96.00967351874245, 96.6078697421981, 98.21138211382113, 96.50951949229375, 100.0, 99.57514604354753, 99.92857142857143, 96.65365309537088, 95.19061583577712, 99.15841584158416, 97.95201872440023, 99.94675186368477, 99.92348890589136, 98.37947332883186, 99.37597503900156]\n",
      "45\n",
      "full train loss:  tensor(0.0457, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0741, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.49624060150376\n",
      "test accuracy:  98.5405601349115\n",
      "46\n",
      "full train loss:  tensor(0.0445, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0732, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.49624060150376\n",
      "test accuracy:  98.56735330738073\n",
      "47\n",
      "full train loss:  tensor(0.0446, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0729, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.49624060150376\n",
      "test accuracy:  98.57208151428706\n",
      "48\n",
      "full train loss:  tensor(0.0464, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0724, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.49624060150376\n",
      "test accuracy:  98.57523365222463\n",
      "49\n",
      "full train loss:  tensor(0.0430, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0722, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.53581321725366\n",
      "test accuracy:  98.58784220397484\n",
      "98.49624060150376\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 97.3918197984588, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 98.90438247011953, 99.92169146436962, 95.14767932489451, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.73672055427252, 96.13059250302297, 96.6078697421981, 98.29268292682927, 96.64551223934723, 100.0, 99.57514604354753, 99.92857142857143, 96.65365309537088, 95.19061583577712, 99.15841584158416, 98.18607372732592, 99.94675186368477, 99.92348890589136, 98.37947332883186, 99.41497659906396]\n",
      "50\n",
      "full train loss:  tensor(0.0436, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0718, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.53581321725366\n",
      "test accuracy:  98.58941827294362\n",
      "51\n",
      "full train loss:  tensor(0.0423, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0713, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.53581321725366\n",
      "test accuracy:  98.6051789626314\n",
      "52\n",
      "full train loss:  tensor(0.0424, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0709, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.53581321725366\n",
      "test accuracy:  98.60833110056896\n",
      "53\n",
      "full train loss:  tensor(0.0420, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0704, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.53581321725366\n",
      "test accuracy:  98.60833110056896\n",
      "54\n",
      "full train loss:  tensor(0.0427, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0704, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.53581321725366\n",
      "test accuracy:  98.61463537644407\n",
      "55\n",
      "full train loss:  tensor(0.0418, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0699, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.53581321725366\n",
      "test accuracy:  98.62093965231918\n",
      "56\n",
      "full train loss:  tensor(0.0426, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0698, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.62409179025674\n",
      "98.53581321725366\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 97.7474807350326, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.20318725099602, 99.92169146436962, 95.14767932489451, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.92147806004618, 96.13059250302297, 96.6078697421981, 98.29268292682927, 96.91749773345421, 100.0, 99.57514604354753, 99.92857142857143, 96.65365309537088, 95.19061583577712, 99.15841584158416, 98.18607372732592, 99.94675186368477, 99.92348890589136, 98.37947332883186, 99.45397815912636]\n",
      "57\n",
      "full train loss:  tensor(0.0407, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0692, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.53581321725366\n",
      "test accuracy:  98.63039606613185\n",
      "58\n",
      "full train loss:  tensor(0.0410, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0691, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.53581321725366\n",
      "test accuracy:  98.63354820406941\n",
      "59\n",
      "full train loss:  tensor(0.0414, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0690, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.63670034200696\n",
      "60\n",
      "full train loss:  tensor(0.0408, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0689, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.53581321725366\n",
      "test accuracy:  98.63512427303819\n",
      "61\n",
      "full train loss:  tensor(0.0412, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0687, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.61495844875347\n",
      "test accuracy:  98.64300461788208\n",
      "98.57538583300357\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 97.8067575577949, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.25298804780877, 99.92169146436962, 95.14767932489451, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.9676674364896, 96.21120515921, 96.6078697421981, 98.3739837398374, 97.0534904805077, 100.0, 99.57514604354753, 99.92857142857143, 96.65365309537088, 95.19061583577712, 99.20792079207921, 98.30310122878878, 99.94675186368477, 99.92348890589136, 98.37947332883186, 99.41497659906396]\n",
      "62\n",
      "full train loss:  tensor(0.0401, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0687, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.64615675581963\n",
      "63\n",
      "full train loss:  tensor(0.0407, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0685, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  98.64458068685086\n",
      "64\n",
      "full train loss:  tensor(0.0407, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0683, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.53581321725366\n",
      "test accuracy:  98.64300461788208\n",
      "65\n",
      "full train loss:  tensor(0.0397, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0681, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.53581321725366\n",
      "test accuracy:  98.65088496272597\n",
      "66\n",
      "full train loss:  tensor(0.0401, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0679, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.65403710066353\n",
      "67\n",
      "full train loss:  tensor(0.0394, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0678, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.53581321725366\n",
      "test accuracy:  98.6556131696323\n",
      "68\n",
      "full train loss:  tensor(0.0398, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0676, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.65718923860108\n",
      "69\n",
      "full train loss:  tensor(0.0398, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0675, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.6493088937572\n",
      "70\n",
      "full train loss:  tensor(0.0390, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0675, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.53581321725366\n",
      "test accuracy:  98.64615675581963\n",
      "71\n",
      "full train loss:  tensor(0.0392, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0673, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.53581321725366\n",
      "test accuracy:  98.6556131696323\n",
      "72\n",
      "full train loss:  tensor(0.0418, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0674, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.53581321725366\n",
      "test accuracy:  98.65876530756987\n",
      "73\n",
      "full train loss:  tensor(0.0412, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0671, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.53581321725366\n",
      "test accuracy:  98.65403710066353\n",
      "74\n",
      "full train loss:  tensor(0.0417, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0672, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.65718923860108\n",
      "75\n",
      "full train loss:  tensor(0.0388, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0670, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.65876530756987\n",
      "76\n",
      "full train loss:  tensor(0.0382, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0669, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.6634935144762\n",
      "77\n",
      "full train loss:  tensor(0.0390, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0668, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.66506958344497\n",
      "78\n",
      "full train loss:  tensor(0.0390, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0667, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.66506958344497\n",
      "79\n",
      "full train loss:  tensor(0.0381, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0666, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.66664565241375\n",
      "80\n",
      "full train loss:  tensor(0.0398, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0667, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.66506958344497\n",
      "81\n",
      "full train loss:  tensor(0.0384, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0665, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.66664565241375\n",
      "82\n",
      "full train loss:  tensor(0.0383, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0665, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.66506958344497\n",
      "83\n",
      "full train loss:  tensor(0.0378, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0665, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.66979779035131\n",
      "84\n",
      "full train loss:  tensor(0.0389, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0665, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.66822172138254\n",
      "85\n",
      "full train loss:  tensor(0.0383, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0663, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.61495844875347\n",
      "test accuracy:  98.66822172138254\n",
      "86\n",
      "full train loss:  tensor(0.0376, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0663, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.61495844875347\n",
      "test accuracy:  98.67137385932008\n",
      "87\n",
      "full train loss:  tensor(0.0397, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0662, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.67294992828887\n",
      "88\n",
      "full train loss:  tensor(0.0377, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0662, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.61495844875347\n",
      "test accuracy:  98.67137385932008\n",
      "89\n",
      "full train loss:  tensor(0.0385, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0661, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.61495844875347\n",
      "test accuracy:  98.67294992828887\n",
      "90\n",
      "full train loss:  tensor(0.0419, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0660, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.61495844875347\n",
      "test accuracy:  98.67137385932008\n",
      "91\n",
      "full train loss:  tensor(0.0378, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0661, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.61495844875347\n",
      "test accuracy:  98.66979779035131\n",
      "92\n",
      "full train loss:  tensor(0.0374, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0661, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.67137385932008\n",
      "93\n",
      "full train loss:  tensor(0.0382, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0661, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.66822172138254\n",
      "94\n",
      "full train loss:  tensor(0.0392, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0660, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.66979779035131\n",
      "95\n",
      "full train loss:  tensor(0.0403, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0660, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.61495844875347\n",
      "test accuracy:  98.67452599725765\n",
      "96\n",
      "full train loss:  tensor(0.0421, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0660, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.61495844875347\n",
      "test accuracy:  98.67452599725765\n",
      "97\n",
      "full train loss:  tensor(0.0390, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0659, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.57538583300357\n",
      "test accuracy:  98.67452599725765\n",
      "98\n",
      "full train loss:  tensor(0.0381, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0659, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.65453106450336\n",
      "test accuracy:  98.67767813519521\n",
      "98.61495844875347\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 97.9253112033195, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.55179282868527, 99.92169146436962, 95.25316455696202, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.78290993071593, 96.53365578395808, 96.6078697421981, 98.3739837398374, 97.2348141432457, 100.0, 99.57514604354753, 99.92857142857143, 96.65365309537088, 95.19061583577712, 99.15841584158416, 98.36161497952018, 99.94675186368477, 99.92348890589136, 98.37947332883186, 99.57098283931357]\n",
      "99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full train loss:  tensor(0.0384, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0658, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "val accuracy:  98.61495844875347\n",
      "test accuracy:  98.67767813519521\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(save_dir)\n",
    "DATA_ROOT = osj(\"/mimer/NOBACKUP/groups/snic2022-22-122/arthur/\", \"dataset_beats\")\n",
    "DICT_BEATS = osj(DATA_ROOT, \"5min_normal_beats.pkl\")\n",
    "DATA_BEATS = osj(DATA_ROOT, \"30min_beats.pkl\")\n",
    "\n",
    "DATA_ROOT = \"/mimer/NOBACKUP/groups/snic2022-22-122/arthur/physionet.org/files/mitdb/1.0.0/\"\n",
    "RECORDS = osj(DATA_ROOT, \"RECORDS\")\n",
    "#print(RECORDS)\n",
    "patient_ids = pd.read_csv(RECORDS, header=None).to_numpy().reshape(-1)\n",
    "#print(patient_ids)\n",
    "paced_patients = get_paced_patients(patient_ids)\n",
    "excluded_patients = np.array([105, 114, 201, 202, 207, 209, 213, 222, 223, 234])  # according to paper\n",
    "#print(np.concatenate((paced_patients, excluded_patients)))\n",
    "\n",
    "dict_beats = read_dict_beats()\n",
    "data_beats = read_data_beats()\n",
    "ensure_normalized_and_detrended(dict_beats)\n",
    "ensure_normalized_and_detrended(data_beats)\n",
    "\n",
    "import collections\n",
    "\n",
    "patients_out = np.concatenate((paced_patients, excluded_patients))\n",
    "patients_left = list(copy.deepcopy(patient_ids))\n",
    "\n",
    "for idx, i in enumerate(patient_ids):\n",
    "    if i in patients_out:\n",
    "        patients_left.remove(i)\n",
    "\n",
    "labels = ['N', 'V', 'S', 'Q', 'F']\n",
    "dictionary = {}\n",
    "for i in labels:\n",
    "    dictionary[i] = 0\n",
    "\n",
    "list1 = []\n",
    "array = np.zeros((len(patients_left), 2))\n",
    "for idx, i in enumerate(patients_left):\n",
    "    list1.append(data_beats[i]['class'])\n",
    "    counter = collections.Counter(data_beats[i]['class'])\n",
    "    for j in counter.keys():\n",
    "        dictionary[j] += counter[j]\n",
    "        if j == 'N':\n",
    "            array[idx, 0] += counter[j]\n",
    "        else:\n",
    "            array[idx, 1] += counter[j]\n",
    "\n",
    "seconds = 5\n",
    "data_beats_train, data_beats_val, data_beats_test = train_test_split(data_beats, seconds)\n",
    "\n",
    "import collections\n",
    "from time import time\n",
    "import random\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pandas\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "experiment_name = settings['experiment_name']\n",
    "test = settings['type']\n",
    "print('type: ',test)\n",
    "n_epochs = 100 #settings['n_epochs']\n",
    "#patients_example = [119, 215, 232]\n",
    "p2p = P2P_AFPL(patients_left, data_beats_train, data_beats_val,data_beats_test,settings['n_clients_UCB'], test)\n",
    "alphas = p2p.loop(n_epochs, p2p, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a34c23da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 97.9253112033195, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.55179282868527, 99.92169146436962, 95.25316455696202, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 97.78290993071593, 96.49334945586457, 96.6078697421981, 98.3739837398374, 97.1894832275612, 100.0, 99.62825278810409, 99.92857142857143, 96.65365309537088, 95.19061583577712, 99.20792079207921, 98.36161497952018, 99.94675186368477, 99.92348890589136, 98.37947332883186, 99.57098283931357]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x153c8cf8dc40>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_accuracies_local = p2p.accuracy_list\n",
    "print(best_accuracies_local)\n",
    "plt.plot(best_accuracies_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4c1706b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 101, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 121, 122, 123, 124, 200, 203, 205, 208, 210, 212, 214, 215, 219, 220, 221, 228, 230, 231, 232, 233]\n",
      "118\n",
      "95.25316455696202\n",
      "124\n",
      "95.69413511507052\n",
      "220\n",
      "95.19061583577712\n"
     ]
    }
   ],
   "source": [
    "print(patients_left)\n",
    "print(patients_left[12])\n",
    "print(best_accuracies_local[12])\n",
    "print(patients_left[17])\n",
    "print(best_accuracies_local[17])\n",
    "print(patients_left[27])\n",
    "print(best_accuracies_local[27])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95cc60b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints_bandits/test\n",
      "type:  bandits\n",
      "0\n",
      "full train loss:  tensor(0.7566, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.8835, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [33 32  2  3  4  5  6  7  8  9]\n",
      "[0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "loss after my code:  0.8386080380543226\n",
      "train loss after my code:  0.7200478886191799\n",
      "val accuracy:  91.49188761377127\n",
      "test accuracy:  90.81467004996139\n",
      "0\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 78.17412333736397, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 66.09699769053118, 85.24788391777508, 96.6078697421981, 53.82113821138211, 91.34179510426111, 100.0, 88.90069038767923, 95.10714285714286, 96.65365309537088, 95.19061583577712, 84.15841584158416, 83.08952603861908, 99.94675186368477, 99.92348890589136, 78.12288993923025, 72.50390015600624]\n",
      "1\n",
      "full train loss:  tensor(0.4682, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5373, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [16 21 10 11 12 13 14 15 17 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.5002620124288578\n",
      "train loss after my code:  0.440274848947099\n",
      "val accuracy:  91.49188761377127\n",
      "test accuracy:  90.81467004996139\n",
      "2\n",
      "full train loss:  tensor(0.3321, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3731, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [ 0 26 19 20 22 24 25 23 27 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.33515887437834085\n",
      "train loss after my code:  0.3101404531661879\n",
      "val accuracy:  91.88761377127028\n",
      "test accuracy:  90.9360273605573\n",
      "91.49188761377127\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 78.17412333736397, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 66.09699769053118, 85.24788391777508, 96.6078697421981, 56.95121951219512, 91.34179510426111, 100.0, 88.90069038767923, 95.10714285714286, 96.65365309537088, 95.19061583577712, 84.15841584158416, 83.08952603861908, 99.94675186368477, 99.92348890589136, 78.12288993923025, 72.50390015600624]\n",
      "3\n",
      "full train loss:  tensor(0.2631, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2975, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [31 30 29 33 15  2  3  5  6  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "loss after my code:  0.28253742903831336\n",
      "train loss after my code:  0.2712860633887907\n",
      "val accuracy:  92.5207756232687\n",
      "test accuracy:  91.77764818988479\n",
      "91.88761377127028\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 78.17412333736397, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 66.09699769053118, 85.24788391777508, 96.6078697421981, 78.65853658536585, 91.34179510426111, 100.0, 88.90069038767923, 95.10714285714286, 96.65365309537088, 95.19061583577712, 84.15841584158416, 83.08952603861908, 99.94675186368477, 99.92348890589136, 78.12288993923025, 72.50390015600624]\n",
      "4\n",
      "full train loss:  tensor(0.2430, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2630, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [16 22  9 10 12 13 14 18 19 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.25686445431495236\n",
      "train loss after my code:  0.2511019134742003\n",
      "val accuracy:  92.95607439651761\n",
      "test accuracy:  92.28199025989377\n",
      "92.5207756232687\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 78.17412333736397, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 66.09699769053118, 85.24788391777508, 96.6078697421981, 91.66666666666666, 91.34179510426111, 100.0, 88.90069038767923, 95.10714285714286, 96.65365309537088, 95.19061583577712, 84.15841584158416, 83.08952603861908, 99.94675186368477, 99.92348890589136, 78.12288993923025, 72.50390015600624]\n",
      "5\n",
      "full train loss:  tensor(0.2275, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2445, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [ 0 27 24 25 26 23 30 31  2  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.24070278763043507\n",
      "train loss after my code:  0.23479133853756615\n",
      "val accuracy:  92.7582113177681\n",
      "test accuracy:  92.01721067313906\n",
      "6\n",
      "full train loss:  tensor(0.2163, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2332, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [ 0 15 30 27  6  7  9 23 10 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.22887938083508721\n",
      "train loss after my code:  0.223373283690305\n",
      "val accuracy:  92.95607439651761\n",
      "test accuracy:  92.280414190925\n",
      "7\n",
      "full train loss:  tensor(0.2121, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2245, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14 15  2 30 27  6  7  9 23 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.22032132553022113\n",
      "train loss after my code:  0.21960384996484653\n",
      "val accuracy:  93.07479224376732\n",
      "test accuracy:  92.46639032924081\n",
      "92.95607439651761\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 78.17412333736397, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 66.09699769053118, 85.24788391777508, 96.6078697421981, 96.42276422764228, 91.34179510426111, 100.0, 88.90069038767923, 95.10714285714286, 96.65365309537088, 95.19061583577712, 84.15841584158416, 83.08952603861908, 99.94675186368477, 99.92348890589136, 78.12288993923025, 72.50390015600624]\n",
      "8\n",
      "full train loss:  tensor(0.2027, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2112, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14 15  2 30  6  7  9 23 27 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.20716051444898642\n",
      "train loss after my code:  0.21694417662611715\n",
      "val accuracy:  94.61812425801345\n",
      "test accuracy:  93.77295150435782\n",
      "93.07479224376732\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 78.17412333736397, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 84.43418013856812, 85.24788391777508, 96.6078697421981, 95.6910569105691, 91.34179510426111, 100.0, 88.90069038767923, 95.10714285714286, 96.65365309537088, 95.19061583577712, 84.15841584158416, 83.08952603861908, 99.94675186368477, 99.92348890589136, 78.12288993923025, 90.05460218408736]\n",
      "9\n",
      "full train loss:  tensor(0.1935, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1998, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14 15  2 30  6  7  9 23 20  0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.19527483301681148\n",
      "train loss after my code:  0.20332264369638628\n",
      "val accuracy:  94.61812425801345\n",
      "test accuracy:  93.98729688411164\n",
      "10\n",
      "full train loss:  tensor(0.1846, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1884, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14 15  2 30  6  7  9 23 20  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.18129841358926962\n",
      "train loss after my code:  0.1845624569678054\n",
      "val accuracy:  95.13256826276218\n",
      "test accuracy:  94.4932150230894\n",
      "94.61812425801345\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 78.17412333736397, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 90.34642032332563, 85.24788391777508, 96.6078697421981, 97.35772357723577, 91.34179510426111, 100.0, 88.90069038767923, 95.10714285714286, 96.65365309537088, 95.19061583577712, 92.27722772277228, 83.08952603861908, 99.94675186368477, 99.92348890589136, 78.12288993923025, 94.89079563182527]\n",
      "11\n",
      "full train loss:  tensor(0.1637, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1762, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14  2 30  6  7  9 23 15 10 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.1617404245012828\n",
      "train loss after my code:  0.17037826181956267\n",
      "val accuracy:  95.80530273051049\n",
      "test accuracy:  94.87619978250248\n",
      "95.13256826276218\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 78.17412333736397, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 90.62355658198614, 85.24788391777508, 96.6078697421981, 96.34146341463415, 91.34179510426111, 100.0, 88.90069038767923, 95.10714285714286, 96.65365309537088, 95.19061583577712, 93.36633663366337, 83.08952603861908, 99.94675186368477, 99.92348890589136, 90.74949358541527, 96.9578783151326]\n",
      "12\n",
      "full train loss:  tensor(0.1422, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1563, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14  9 30  2 15  7  6 23 19 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.1357306804710529\n",
      "train loss after my code:  0.14534911938379433\n",
      "val accuracy:  96.00316580926\n",
      "test accuracy:  95.08896909328752\n",
      "95.80530273051049\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 70.95435684647303, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.26892430278885, 99.92169146436962, 95.14767932489451, 78.17412333736397, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 92.2863741339492, 85.24788391777508, 96.6078697421981, 97.52032520325203, 91.34179510426111, 100.0, 88.90069038767923, 95.28571428571428, 96.65365309537088, 95.19061583577712, 95.0, 83.08952603861908, 99.94675186368477, 99.92348890589136, 91.62727886563134, 97.69890795631825]\n",
      "13\n",
      "full train loss:  tensor(0.1199, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1297, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14 23 30  2 15  9  7  6 22 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.11205118216372677\n",
      "train loss after my code:  0.12388434489227453\n",
      "val accuracy:  96.87376335575782\n",
      "test accuracy:  96.12287033680595\n",
      "96.00316580926\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 85.41790160047421, 98.7048398091343, 98.43453510436433, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 95.46812749003985, 99.92169146436962, 97.94303797468355, 78.17412333736397, 99.87096774193547, 100.0, 99.7624703087886, 95.69413511507052, 94.82678983833718, 85.24788391777508, 96.6078697421981, 97.80487804878048, 93.78966455122394, 100.0, 94.74243228890069, 98.57142857142858, 96.65365309537088, 95.19061583577712, 95.74257425742574, 84.31831480397894, 99.94675186368477, 99.92348890589136, 91.69480081026333, 97.69890795631825]\n",
      "14\n",
      "full train loss:  tensor(0.0998, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1059, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14 15 30  2  9  7  6 23 13 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.09385279898729341\n",
      "train loss after my code:  0.10549193572056886\n",
      "val accuracy:  97.34863474475662\n",
      "test accuracy:  96.92981764882032\n",
      "96.87376335575782\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 86.01066982809722, 98.7048398091343, 99.24098671726756, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.05378486055777, 99.92169146436962, 97.36286919831224, 78.23458282950423, 99.87096774193547, 100.0, 99.7624703087886, 96.65924276169265, 94.8729792147806, 84.72390165255945, 96.6078697421981, 98.04878048780488, 96.19220308250227, 100.0, 98.7254381306426, 99.10714285714286, 96.5978806469604, 95.19061583577712, 96.28712871287128, 96.07957870099474, 99.94675186368477, 99.92348890589136, 95.40850776502363, 97.97191887675507]\n",
      "15\n",
      "full train loss:  tensor(0.0899, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0891, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14 23 30  9  7  6  2 15  3 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.07874608089819118\n",
      "train loss after my code:  0.09459566485229792\n",
      "val accuracy:  97.94222398100516\n",
      "test accuracy:  97.60910337436366\n",
      "97.34863474475662\n",
      "accuracy is best accuracy\n",
      "[98.36152219873149, 99.6778350515464, 99.88472622478386, 87.49259039715471, 98.7048398091343, 99.573055028463, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.45219123505976, 99.92169146436962, 97.31012658227847, 99.6372430471584, 99.87096774193547, 100.0, 99.7624703087886, 97.03043801039347, 95.84295612009238, 85.08665860540104, 96.6078697421981, 97.60162601626017, 95.19492293744334, 100.0, 99.41582580987786, 99.46428571428572, 94.7016174010039, 95.19061583577712, 97.42574257425743, 95.96255119953189, 99.94675186368477, 99.92348890589136, 97.16407832545578, 97.97191887675507]\n",
      "16\n",
      "full train loss:  tensor(0.0774, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0766, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14  9 30  7  2 23  6 15 31 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.06929402710117331\n",
      "train loss after my code:  0.08558184168975644\n",
      "val accuracy:  98.37752275425406\n",
      "test accuracy:  97.91013254740028\n",
      "97.94222398100516\n",
      "accuracy is best accuracy\n",
      "[98.89006342494714, 99.6778350515464, 99.88472622478386, 95.0800237107291, 98.7048398091343, 99.66793168880456, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.60159362549801, 99.92169146436962, 98.73417721518987, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 97.62435040831477, 95.98152424942263, 84.60298266827891, 96.6078697421981, 97.96747967479675, 95.05893019038984, 100.0, 99.41582580987786, 99.75, 91.74567763524819, 95.65982404692082, 97.92079207920791, 97.89350497366881, 99.94675186368477, 99.92348890589136, 97.23160027008778, 98.12792511700468]\n",
      "17\n",
      "full train loss:  tensor(0.0718, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0677, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14  2 30  9 15  7 23  6 24 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.061308603812258604\n",
      "train loss after my code:  0.08071059749793572\n",
      "val accuracy:  98.41709537000396\n",
      "test accuracy:  98.09295654777853\n",
      "98.37752275425406\n",
      "accuracy is best accuracy\n",
      "[99.36575052854123, 99.6778350515464, 99.88472622478386, 97.5696502667457, 98.7048398091343, 99.71537001897534, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.55179282868527, 99.92169146436962, 98.73417721518987, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 98.36674090571641, 98.01385681293301, 82.58766626360338, 96.6078697421981, 97.84552845528455, 96.19220308250227, 100.0, 99.57514604354753, 99.67857142857143, 91.57836029001673, 98.12316715542522, 98.11881188118812, 97.366881217086, 99.94675186368477, 99.92348890589136, 97.4341661039838, 98.16692667706708]\n",
      "18\n",
      "full train loss:  tensor(0.0678, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0611, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14  6 23  2 30  9 15  7 27 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.05539632267654432\n",
      "train loss after my code:  0.07975300750926953\n",
      "val accuracy:  98.61495844875347\n",
      "test accuracy:  98.37664896215858\n",
      "98.41709537000396\n",
      "accuracy is best accuracy\n",
      "[99.78858350951374, 99.6778350515464, 99.88472622478386, 99.8221695317131, 98.7048398091343, 99.81024667931689, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.60159362549801, 99.92169146436962, 98.94514767932489, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 98.21826280623608, 97.92147806004618, 85.24788391777508, 96.6078697421981, 98.130081300813, 96.69084315503173, 100.0, 99.4689325544344, 99.82142857142857, 91.41104294478528, 98.18181818181819, 98.41584158415841, 99.1808074897601, 99.94675186368477, 99.92348890589136, 98.10938555030386, 98.16692667706708]\n",
      "19\n",
      "full train loss:  tensor(0.0647, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0541, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14  6  2 30  9 15  7 23  5  0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.050545934094868655\n",
      "train loss after my code:  0.07471735266092433\n",
      "val accuracy:  98.73367629600317\n",
      "test accuracy:  98.49012592791061\n",
      "98.61495844875347\n",
      "accuracy is best accuracy\n",
      "[99.78858350951374, 99.6778350515464, 99.88472622478386, 99.8814463544754, 98.7048398091343, 99.85768500948767, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.60159362549801, 99.92169146436962, 99.10337552742617, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 98.44097995545657, 98.10623556581987, 87.22289399435711, 96.6078697421981, 97.92682926829268, 96.82683590208522, 100.0, 99.57514604354753, 99.92857142857143, 91.6899051868377, 98.18181818181819, 98.51485148514851, 99.35634874195436, 99.94675186368477, 99.92348890589136, 97.97434166103984, 98.16692667706708]\n",
      "20\n",
      "full train loss:  tensor(0.0623, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0505, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14 23  6  2 30 15  9  7 10  4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.046646331655420134\n",
      "train loss after my code:  0.0695157426443291\n",
      "val accuracy:  98.69410368025326\n",
      "test accuracy:  98.46806096234772\n",
      "21\n",
      "full train loss:  tensor(0.0606, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0486, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14  6 15  9  7 23 30  2 28 29]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.04446199731951368\n",
      "train loss after my code:  0.06721844140409033\n",
      "val accuracy:  98.81282152750298\n",
      "test accuracy:  98.58784220397484\n",
      "98.73367629600317\n",
      "accuracy is best accuracy\n",
      "[99.84143763213531, 99.6778350515464, 99.88472622478386, 99.8814463544754, 98.7048398091343, 99.90512333965845, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.7011952191235, 99.92169146436962, 98.99789029535864, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 98.44097995545657, 97.82909930715935, 89.92341797662233, 96.6078697421981, 97.92682926829268, 96.73617407071623, 100.0, 99.57514604354753, 99.89285714285714, 91.2994980479643, 98.18181818181819, 98.66336633663366, 99.59040374488005, 99.94675186368477, 99.92348890589136, 98.10938555030386, 98.16692667706708]\n",
      "22\n",
      "full train loss:  tensor(0.0600, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0458, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14  9  6 23  7 15 30  2  8 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.042079104409487915\n",
      "train loss after my code:  0.06250533717840323\n",
      "val accuracy:  98.65453106450336\n",
      "test accuracy:  98.60045075572506\n",
      "23\n",
      "full train loss:  tensor(0.0708, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0449, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14  9 23  2 30 15  6  7 21 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.04219744815246984\n",
      "train loss after my code:  0.0659466216441231\n",
      "val accuracy:  98.73367629600317\n",
      "test accuracy:  98.67610206622642\n",
      "24\n",
      "full train loss:  tensor(0.0606, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0420, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14  2 30  6  7  9 23 15 32 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.039577310246178186\n",
      "train loss after my code:  0.0589492277551913\n",
      "val accuracy:  98.85239414325287\n",
      "test accuracy:  98.79588330785354\n",
      "98.81282152750298\n",
      "accuracy is best accuracy\n",
      "[99.84143763213531, 99.6778350515464, 99.88472622478386, 99.8814463544754, 98.7048398091343, 99.90512333965845, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.7011952191235, 99.92169146436962, 99.26160337552743, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 98.29250185597624, 98.29099307159353, 91.01168883514713, 96.6078697421981, 98.17073170731707, 97.0534904805077, 100.0, 99.57514604354753, 99.92857142857143, 95.0362520914668, 98.12316715542522, 98.86138613861387, 99.64891749561147, 99.94675186368477, 99.92348890589136, 98.44699527346388, 98.24492979719189]\n",
      "25\n",
      "full train loss:  tensor(0.0542, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0407, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14  2 30  6  7  9 23 15 20 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.035415547373085346\n",
      "train loss after my code:  0.062176224595552616\n",
      "val accuracy:  99.01068460625247\n",
      "test accuracy:  98.806915790635\n",
      "98.85239414325287\n",
      "accuracy is best accuracy\n",
      "[99.89429175475686, 99.6778350515464, 99.88472622478386, 99.9407231772377, 98.7048398091343, 99.95256166982922, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.7011952191235, 99.92169146436962, 99.26160337552743, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 98.29250185597624, 98.66050808314087, 93.55098750503828, 96.6078697421981, 96.46341463414633, 97.1894832275612, 100.0, 99.57514604354753, 99.92857142857143, 93.58616843279421, 98.18181818181819, 98.91089108910892, 99.64891749561147, 99.94675186368477, 99.92348890589136, 98.17690749493585, 98.24492979719189]\n",
      "26\n",
      "full train loss:  tensor(0.0557, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0364, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14 23 30  2 15  9  7  6 22 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.033970354735251146\n",
      "train loss after my code:  0.061403279655104843\n",
      "val accuracy:  99.01068460625247\n",
      "test accuracy:  98.80218758372867\n",
      "27\n",
      "full train loss:  tensor(0.0533, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0348, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14 15  6 30  2  9  7 23 13 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.0326708405270725\n",
      "train loss after my code:  0.06516188675029407\n",
      "val accuracy:  99.05025722200237\n",
      "test accuracy:  98.96767482545036\n",
      "99.01068460625247\n",
      "accuracy is best accuracy\n",
      "[99.89429175475686, 99.6778350515464, 99.88472622478386, 99.9407231772377, 98.7048398091343, 99.95256166982922, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.75099601593625, 99.92169146436962, 99.36708860759494, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 98.44097995545657, 98.66050808314087, 93.91374445787989, 96.6078697421981, 96.6260162601626, 97.37080689029919, 100.0, 99.57514604354753, 99.89285714285714, 97.99219185722254, 98.18181818181819, 98.96039603960396, 99.64891749561147, 99.94675186368477, 99.92348890589136, 98.17690749493585, 98.28393135725429]\n",
      "28\n",
      "full train loss:  tensor(0.0583, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0328, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14 23 30  2  9  7  6 15 19 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.03173073965075992\n",
      "train loss after my code:  0.058632631132630855\n",
      "val accuracy:  99.05025722200237\n",
      "test accuracy:  98.96767482545036\n",
      "29\n",
      "full train loss:  tensor(0.0537, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0325, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14 15 30  2 23  6  7  9 16 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.03138512218735498\n",
      "train loss after my code:  0.058667484992727496\n",
      "val accuracy:  99.01068460625247\n",
      "test accuracy:  98.99762013585715\n",
      "30\n",
      "full train loss:  tensor(0.0550, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0313, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14 15  2 30  6 23  7  9 16  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.03004823984245191\n",
      "train loss after my code:  0.0571203514593872\n",
      "val accuracy:  99.08982983775228\n",
      "test accuracy:  98.95821841163769\n",
      "99.05025722200237\n",
      "accuracy is best accuracy\n",
      "[99.89429175475686, 99.6778350515464, 99.88472622478386, 99.9407231772377, 98.7048398091343, 99.90512333965845, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.60159362549801, 99.92169146436962, 99.26160337552743, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 98.44097995545657, 97.9676674364896, 94.6795646916566, 96.6078697421981, 97.07317073170731, 96.23753399818676, 100.0, 99.57514604354753, 99.92857142857143, 98.15950920245399, 98.18181818181819, 98.96039603960396, 99.64891749561147, 99.94675186368477, 99.92348890589136, 98.37947332883186, 98.4009360374415]\n",
      "31\n",
      "full train loss:  tensor(0.0529, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0300, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14 15  2 30  6  7 23  9 16 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.028793880047561525\n",
      "train loss after my code:  0.05378935399634134\n",
      "val accuracy:  99.05025722200237\n",
      "test accuracy:  98.98973979101325\n",
      "32\n",
      "full train loss:  tensor(0.0587, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0309, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14 15  2 30  6  7  9 23 25 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.029191485725934746\n",
      "train loss after my code:  0.05737143829543198\n",
      "val accuracy:  99.12940245350218\n",
      "test accuracy:  98.97713123926303\n",
      "99.08982983775228\n",
      "accuracy is best accuracy\n",
      "[99.89429175475686, 99.6778350515464, 99.88472622478386, 99.9407231772377, 98.7048398091343, 99.71537001897534, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.5019920318725, 99.92169146436962, 99.26160337552743, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 98.44097995545657, 98.56812933025404, 95.00201531640468, 96.6078697421981, 97.35772357723577, 95.87488667271079, 100.0, 99.57514604354753, 99.92857142857143, 98.15950920245399, 98.18181818181819, 98.91089108910892, 99.70743124634289, 99.94675186368477, 99.92348890589136, 98.24442943956785, 98.4009360374415]\n",
      "33\n",
      "full train loss:  tensor(0.0626, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0293, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14  2 30  6  7  9 23 15  0  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02826076969534514\n",
      "train loss after my code:  0.05710549982397182\n",
      "val accuracy:  99.05025722200237\n",
      "test accuracy:  99.04332613595172\n",
      "34\n",
      "full train loss:  tensor(0.0511, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0291, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14 15  2 30  6  7  9 23 10 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02796494448339392\n",
      "train loss after my code:  0.05707715063279899\n",
      "val accuracy:  99.05025722200237\n",
      "test accuracy:  99.0512064807956\n",
      "35\n",
      "full train loss:  tensor(0.0525, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0287, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14  2 30  6  7  9 23 15 16 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02746141179078639\n",
      "train loss after my code:  0.05519702550687523\n",
      "val accuracy:  99.20854768500197\n",
      "test accuracy:  99.01022868760737\n",
      "99.12940245350218\n",
      "accuracy is best accuracy\n",
      "[99.89429175475686, 99.6778350515464, 99.88472622478386, 99.9407231772377, 98.7048398091343, 99.71537001897534, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.60159362549801, 99.92169146436962, 99.26160337552743, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 98.29250185597624, 98.70669745958429, 95.20354695687223, 96.6078697421981, 97.6829268292683, 97.0988213961922, 100.0, 99.57514604354753, 99.89285714285714, 96.31901840490798, 98.18181818181819, 98.91089108910892, 99.70743124634289, 99.94675186368477, 99.92348890589136, 98.24442943956785, 98.86895475819033]\n",
      "36\n",
      "full train loss:  tensor(0.0511, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0285, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14 30  2 15  9  7 23  6 20 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.027239593735176502\n",
      "train loss after my code:  0.055013026535546385\n",
      "val accuracy:  99.20854768500197\n",
      "test accuracy:  99.07169537738972\n",
      "37\n",
      "full train loss:  tensor(0.0731, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0285, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14 23 30  2 15  9  7  6 22 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.026590256880987095\n",
      "train loss after my code:  0.05286650099664333\n",
      "val accuracy:  99.24812030075188\n",
      "test accuracy:  99.00865261863859\n",
      "99.20854768500197\n",
      "accuracy is best accuracy\n",
      "[99.89429175475686, 99.6778350515464, 99.88472622478386, 99.7628927089508, 98.7048398091343, 99.52561669829223, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.5019920318725, 99.92169146436962, 99.26160337552743, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 97.9955456570156, 98.75288683602771, 95.48569125352681, 96.6078697421981, 97.84552845528455, 97.28014505893019, 100.0, 99.57514604354753, 99.89285714285714, 96.09592861126603, 98.12316715542522, 98.91089108910892, 99.70743124634289, 99.94675186368477, 99.92348890589136, 98.31195138419987, 98.86895475819033]\n",
      "38\n",
      "full train loss:  tensor(0.0512, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0283, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [14 15  6 30  2  9  7 23 13 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02657127447695508\n",
      "train loss after my code:  0.05629007170897279\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  99.07327144635849\n",
      "99.24812030075188\n",
      "accuracy is best accuracy\n",
      "[99.89429175475686, 99.6778350515464, 99.88472622478386, 99.7628927089508, 98.7048398091343, 99.43074003795066, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.60159362549801, 99.92169146436962, 99.20886075949366, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 98.36674090571641, 98.75288683602771, 95.80814187827488, 96.6078697421981, 97.80487804878048, 97.28014505893019, 100.0, 99.57514604354753, 99.89285714285714, 97.82487451199108, 98.12316715542522, 98.91089108910892, 99.70743124634289, 99.94675186368477, 99.92348890589136, 98.24442943956785, 98.86895475819033]\n",
      "39\n",
      "full train loss:  tensor(0.0570, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0275, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23 30  2  9  7  6 15 14 19 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02604674437575195\n",
      "train loss after my code:  0.05406111893292793\n",
      "val accuracy:  99.24812030075188\n",
      "test accuracy:  99.01180475657615\n",
      "40\n",
      "full train loss:  tensor(0.0508, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0275, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [15 30  2  6 23  7  9 14 31  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02623333178412943\n",
      "train loss after my code:  0.057106792320578366\n",
      "val accuracy:  99.36683814800158\n",
      "test accuracy:  99.02126117038883\n",
      "99.28769291650178\n",
      "accuracy is best accuracy\n",
      "[99.89429175475686, 99.6778350515464, 99.88472622478386, 99.5850622406639, 98.7048398091343, 99.66793168880456, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.60159362549801, 99.92169146436962, 99.26160337552743, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 97.9955456570156, 98.89145496535797, 95.92906086255543, 96.6078697421981, 97.84552845528455, 97.41613780598368, 100.0, 99.57514604354753, 99.89285714285714, 95.31511433351925, 98.12316715542522, 98.91089108910892, 99.70743124634289, 99.94675186368477, 99.92348890589136, 98.31195138419987, 98.98595943837753]\n",
      "41\n",
      "full train loss:  tensor(0.0485, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0274, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [15  2 30  6  7  9 23 14 26 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.026299236030125288\n",
      "train loss after my code:  0.05798519435237808\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  99.07011930842093\n",
      "42\n",
      "full train loss:  tensor(0.0582, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0267, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [15  2 30  6  7  9 23 14  0  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02619753248904992\n",
      "train loss after my code:  0.054764645768216894\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.04332613595172\n",
      "43\n",
      "full train loss:  tensor(0.0535, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0272, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 10 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02538001622148554\n",
      "train loss after my code:  0.054990158098157674\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  98.98973979101325\n",
      "44\n",
      "full train loss:  tensor(0.0515, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0265, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 16 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.025855291126951018\n",
      "train loss after my code:  0.04968931360608706\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  99.07011930842093\n",
      "45\n",
      "full train loss:  tensor(0.0477, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0273, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 16 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.025811783315317548\n",
      "train loss after my code:  0.05875909376380728\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  99.01022868760737\n",
      "46\n",
      "full train loss:  tensor(0.0558, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0261, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.025810738288783684\n",
      "train loss after my code:  0.05900072410200901\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.0149568945137\n",
      "47\n",
      "full train loss:  tensor(0.0551, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0269, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.025644497578546775\n",
      "train loss after my code:  0.05695825945718739\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  98.98028337720058\n",
      "48\n",
      "full train loss:  tensor(0.0543, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0259, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.025369867127464238\n",
      "train loss after my code:  0.050272632336404326\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.04332613595172\n",
      "49\n",
      "full train loss:  tensor(0.0485, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0265, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.025482131467407024\n",
      "train loss after my code:  0.052962053400131825\n",
      "val accuracy:  99.24812030075188\n",
      "test accuracy:  99.00865261863859\n",
      "50\n",
      "full train loss:  tensor(0.0477, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0263, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.025616847526931677\n",
      "train loss after my code:  0.05822547744934218\n",
      "val accuracy:  99.36683814800158\n",
      "test accuracy:  99.02441330832637\n",
      "51\n",
      "full train loss:  tensor(0.0530, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0255, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.025531319027321697\n",
      "train loss after my code:  0.053405114168997375\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  99.08115179120239\n",
      "52\n",
      "full train loss:  tensor(0.0506, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0259, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02525690846277275\n",
      "train loss after my code:  0.05933273504761837\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  99.01968510142004\n",
      "53\n",
      "full train loss:  tensor(0.0523, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0252, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024885467978869515\n",
      "train loss after my code:  0.05272665482422047\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  99.04647827388926\n",
      "54\n",
      "full train loss:  tensor(0.0486, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0257, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.025337185645621516\n",
      "train loss after my code:  0.0522192781479082\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.01968510142004\n",
      "55\n",
      "full train loss:  tensor(0.0494, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0253, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 11 14 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02527385451684574\n",
      "train loss after my code:  0.05147289043907663\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.06223896357704\n",
      "56\n",
      "full train loss:  tensor(0.0494, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0258, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 11 14 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.025556375293983864\n",
      "train loss after my code:  0.06072155638181301\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  98.96137054957525\n",
      "57\n",
      "full train loss:  tensor(0.0539, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0253, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 11 14 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024757164595563326\n",
      "train loss after my code:  0.052256487550388864\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  98.99131585998204\n",
      "58\n",
      "full train loss:  tensor(0.0502, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0250, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 11 14 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024759930330214924\n",
      "train loss after my code:  0.05937532813138378\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.01338082554493\n",
      "59\n",
      "full train loss:  tensor(0.0547, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0250, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.025002595467341508\n",
      "train loss after my code:  0.0517498512079513\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  99.04017399801415\n",
      "60\n",
      "full train loss:  tensor(0.0497, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0252, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024901969350696405\n",
      "train loss after my code:  0.05270686738468875\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  98.99762013585715\n",
      "61\n",
      "full train loss:  tensor(0.0556, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0248, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024591029312084504\n",
      "train loss after my code:  0.0559833898263447\n",
      "val accuracy:  99.24812030075188\n",
      "test accuracy:  99.00865261863859\n",
      "62\n",
      "full train loss:  tensor(0.0502, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0249, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02475813657522333\n",
      "train loss after my code:  0.05163703727096326\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  99.0228372393576\n",
      "63\n",
      "full train loss:  tensor(0.0518, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0249, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02489118091095542\n",
      "train loss after my code:  0.051894628183877724\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  99.03544579110782\n",
      "64\n",
      "full train loss:  tensor(0.0491, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0254, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02511796476609829\n",
      "train loss after my code:  0.05521768829029438\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  99.05751075667071\n",
      "65\n",
      "full train loss:  tensor(0.0616, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0252, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.025091121956699998\n",
      "train loss after my code:  0.051771058759421326\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  99.01653296348249\n",
      "66\n",
      "full train loss:  tensor(0.0505, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0255, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02535052788130732\n",
      "train loss after my code:  0.05381318898910937\n",
      "val accuracy:  99.24812030075188\n",
      "test accuracy:  99.03859792904538\n",
      "67\n",
      "full train loss:  tensor(0.0520, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0256, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.025404457636261018\n",
      "train loss after my code:  0.053268796231832664\n",
      "val accuracy:  99.24812030075188\n",
      "test accuracy:  98.93142523916848\n",
      "68\n",
      "full train loss:  tensor(0.0510, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0249, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024628365293752466\n",
      "train loss after my code:  0.051212449842209455\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  98.95349020473135\n",
      "69\n",
      "full train loss:  tensor(0.0523, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0244, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024235888509694048\n",
      "train loss after my code:  0.05412725338701719\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  98.97082696338792\n",
      "70\n",
      "full train loss:  tensor(0.0573, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0241, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024089961809864408\n",
      "train loss after my code:  0.05019213467749878\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  98.99131585998204\n",
      "71\n",
      "full train loss:  tensor(0.0519, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0243, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.0241405517727927\n",
      "train loss after my code:  0.05114066756204237\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.01022868760737\n",
      "72\n",
      "full train loss:  tensor(0.0549, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0243, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02431174351474962\n",
      "train loss after my code:  0.05540211495542001\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  99.01810903245126\n",
      "73\n",
      "full train loss:  tensor(0.0511, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0246, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024322533202113944\n",
      "train loss after my code:  0.052621674864974065\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  98.98343551513814\n",
      "74\n",
      "full train loss:  tensor(0.0506, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0242, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024094927879911254\n",
      "train loss after my code:  0.051677469754868074\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.01180475657615\n",
      "75\n",
      "full train loss:  tensor(0.0552, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0240, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02401534671682831\n",
      "train loss after my code:  0.05055621135244055\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.00865261863859\n",
      "76\n",
      "full train loss:  tensor(0.0518, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0241, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024068596202032624\n",
      "train loss after my code:  0.05046653883678418\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.01653296348249\n",
      "77\n",
      "full train loss:  tensor(0.0529, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0242, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024196175090357173\n",
      "train loss after my code:  0.05291201999960255\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.02914151523271\n",
      "78\n",
      "full train loss:  tensor(0.0518, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0244, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02440919378681007\n",
      "train loss after my code:  0.050916026979074935\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.03386972213904\n",
      "79\n",
      "full train loss:  tensor(0.0519, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0245, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024464042444697357\n",
      "train loss after my code:  0.049447084511861895\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  99.04647827388926\n",
      "80\n",
      "full train loss:  tensor(0.0565, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0247, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024677134606847416\n",
      "train loss after my code:  0.04932808714170448\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.05908682563948\n",
      "81\n",
      "full train loss:  tensor(0.0490, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0249, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024053577462646056\n",
      "train loss after my code:  0.055840611123796915\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  98.99919620482592\n",
      "82\n",
      "full train loss:  tensor(0.0509, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0240, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02386189269108193\n",
      "train loss after my code:  0.05066658381370486\n",
      "val accuracy:  99.36683814800158\n",
      "test accuracy:  99.01968510142004\n",
      "83\n",
      "full train loss:  tensor(0.0494, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0239, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02389648047883913\n",
      "train loss after my code:  0.052842359184704604\n",
      "val accuracy:  99.36683814800158\n",
      "test accuracy:  99.03859792904538\n",
      "84\n",
      "full train loss:  tensor(0.0568, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0240, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02390161882803876\n",
      "train loss after my code:  0.0499634461829399\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.0370218600766\n",
      "85\n",
      "full train loss:  tensor(0.0500, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0240, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.023999894592609004\n",
      "train loss after my code:  0.05024296413818718\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.03859792904538\n",
      "86\n",
      "full train loss:  tensor(0.0522, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0240, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024012859376407604\n",
      "train loss after my code:  0.05448578186393258\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.04647827388926\n",
      "87\n",
      "full train loss:  tensor(0.0493, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0241, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024136483591261283\n",
      "train loss after my code:  0.054022516609789385\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.0512064807956\n",
      "88\n",
      "full train loss:  tensor(0.0492, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0242, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024193559138783443\n",
      "train loss after my code:  0.050103149730128256\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.05751075667071\n",
      "89\n",
      "full train loss:  tensor(0.0593, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0242, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024236981833577767\n",
      "train loss after my code:  0.0523959491133035\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.06696717048338\n",
      "90\n",
      "full train loss:  tensor(0.0495, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0244, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02437145600251068\n",
      "train loss after my code:  0.04982614149956172\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  99.07169537738972\n",
      "91\n",
      "full train loss:  tensor(0.0495, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0244, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024368894132243087\n",
      "train loss after my code:  0.054520989418680846\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  99.07169537738972\n",
      "92\n",
      "full train loss:  tensor(0.0524, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0245, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02445069757866941\n",
      "train loss after my code:  0.05241328370423872\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  99.07484751532726\n",
      "93\n",
      "full train loss:  tensor(0.0526, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0245, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.02450183593539886\n",
      "train loss after my code:  0.05481283342712084\n",
      "val accuracy:  99.24812030075188\n",
      "test accuracy:  99.08272786017116\n",
      "94\n",
      "full train loss:  tensor(0.0487, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0246, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [23  6  2 30 15  9  7 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024620013958043627\n",
      "train loss after my code:  0.04990750041832876\n",
      "val accuracy:  99.28769291650178\n",
      "test accuracy:  99.09218427398383\n",
      "95\n",
      "full train loss:  tensor(0.0520, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0246, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [ 7  6  9 23 15 30  2 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024629021556046876\n",
      "train loss after my code:  0.04955822382143285\n",
      "val accuracy:  99.24812030075188\n",
      "test accuracy:  99.09848854985894\n",
      "96\n",
      "full train loss:  tensor(0.0492, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0247, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [ 7  6  9 23 15 30  2 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.024742312251778194\n",
      "train loss after my code:  0.051707983276923476\n",
      "val accuracy:  99.24812030075188\n",
      "test accuracy:  99.1016406877965\n",
      "97\n",
      "full train loss:  tensor(0.0487, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0247, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [ 7  6  9 23 15 30  2 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.023844393469252382\n",
      "train loss after my code:  0.06879324120432173\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  98.9787073082318\n",
      "98\n",
      "full train loss:  tensor(0.0555, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0238, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [ 7  6  9 23 15 30  2 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.023607364226497105\n",
      "train loss after my code:  0.051496387865494125\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  98.99604406688837\n",
      "99\n",
      "full train loss:  tensor(0.0511, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.0236, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [ 7  6  9 23 15 30  2 14 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.023555611533878102\n",
      "train loss after my code:  0.05385882668016211\n",
      "val accuracy:  99.32726553225169\n",
      "test accuracy:  99.00550048070103\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(save_dir)\n",
    "DATA_ROOT = osj(\"/mimer/NOBACKUP/groups/snic2022-22-122/arthur/\", \"dataset_beats\")\n",
    "DICT_BEATS = osj(DATA_ROOT, \"5min_normal_beats.pkl\")\n",
    "DATA_BEATS = osj(DATA_ROOT, \"30min_beats.pkl\")\n",
    "\n",
    "DATA_ROOT = \"/mimer/NOBACKUP/groups/snic2022-22-122/arthur/physionet.org/files/mitdb/1.0.0/\"\n",
    "RECORDS = osj(DATA_ROOT, \"RECORDS\")\n",
    "#print(RECORDS)\n",
    "patient_ids = pd.read_csv(RECORDS, header=None).to_numpy().reshape(-1)\n",
    "#print(patient_ids)\n",
    "paced_patients = get_paced_patients(patient_ids)\n",
    "excluded_patients = np.array([105, 114, 201, 202, 207, 209, 213, 222, 223, 234])  # according to paper\n",
    "#print(np.concatenate((paced_patients, excluded_patients)))\n",
    "\n",
    "dict_beats = read_dict_beats()\n",
    "data_beats = read_data_beats()\n",
    "ensure_normalized_and_detrended(dict_beats)\n",
    "ensure_normalized_and_detrended(data_beats)\n",
    "\n",
    "import collections\n",
    "\n",
    "patients_out = np.concatenate((paced_patients, excluded_patients))\n",
    "patients_left = list(copy.deepcopy(patient_ids))\n",
    "\n",
    "for idx, i in enumerate(patient_ids):\n",
    "    if i in patients_out:\n",
    "        patients_left.remove(i)\n",
    "\n",
    "labels = ['N', 'V', 'S', 'Q', 'F']\n",
    "dictionary = {}\n",
    "for i in labels:\n",
    "    dictionary[i] = 0\n",
    "\n",
    "list1 = []\n",
    "array = np.zeros((len(patients_left), 2))\n",
    "for idx, i in enumerate(patients_left):\n",
    "    list1.append(data_beats[i]['class'])\n",
    "    counter = collections.Counter(data_beats[i]['class'])\n",
    "    for j in counter.keys():\n",
    "        dictionary[j] += counter[j]\n",
    "        if j == 'N':\n",
    "            array[idx, 0] += counter[j]\n",
    "        else:\n",
    "            array[idx, 1] += counter[j]\n",
    "\n",
    "seconds = 5\n",
    "data_beats_train, data_beats_val, data_beats_test = train_test_split(data_beats, seconds)\n",
    "\n",
    "import collections\n",
    "from time import time\n",
    "import random\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pandas\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "experiment_name = settings['experiment_name']\n",
    "test = 'bandits'\n",
    "print('type: ',test)\n",
    "n_epochs = 100 #settings['n_epochs']\n",
    "patients_example = [119, 215, 232]\n",
    "p2p2 = P2P_AFPL(patients_left, data_beats_train, data_beats_val,data_beats_test,settings['n_clients_UCB'], test)\n",
    "alphas = p2p2.loop(n_epochs, p2p2, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da98238d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99.89429175475686, 99.6778350515464, 99.88472622478386, 99.7628927089508, 98.7048398091343, 99.90512333965845, 99.94343891402715, 99.90539262062441, 99.79919678714859, 100.0, 99.45219123505976, 99.92169146436962, 99.10337552742617, 99.93954050785973, 99.87096774193547, 100.0, 99.7624703087886, 98.36674090571641, 99.03002309468822, 96.57396211205159, 96.6078697421981, 97.72357723577237, 96.23753399818676, 100.0, 99.57514604354753, 99.89285714285714, 93.80925822643614, 98.18181818181819, 99.20792079207921, 99.70743124634289, 99.94675186368477, 99.92348890589136, 98.37947332883186, 99.45397815912636]\n",
      "[100, 101, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 121, 122, 123, 124, 200, 203, 205, 208, 210, 212, 214, 215, 219, 220, 221, 228, 230, 231, 232, 233]\n",
      "118\n",
      "99.10337552742617\n",
      "124\n",
      "98.36674090571641\n",
      "220\n",
      "98.18181818181819\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1850x1050 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_accuracies_bandit = p2p2.accuracy_list\n",
    "print(best_accuracies_bandit)\n",
    "fig = plt.gcf()\n",
    "plt.plot(best_accuracies_local)\n",
    "plt.plot(best_accuracies_bandit)\n",
    "plt.xticks(ticks = [x for x in range(34)],labels=patients_left)\n",
    "fig.set_size_inches(18.5,10.5)\n",
    "print(patients_left)\n",
    "print(patients_left[12])\n",
    "print(best_accuracies_bandit[12])\n",
    "print(patients_left[17])\n",
    "print(best_accuracies_bandit[17])\n",
    "print(patients_left[27])\n",
    "print(best_accuracies_bandit[27])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b07cf19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
