{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1689631511242,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "liJLGi6XuKZn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.special import binom\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as tt\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.init as init\n",
    "\n",
    "from collections import Counter\n",
    "import operator\n",
    "import copy\n",
    "from itertools import product,combinations\n",
    "from time import time\n",
    "#from IPython.core.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## code extracted from https://www.kaggle.com/code/graymant/breast-cancer-diagnosis-with-pytorch\n",
    "## SV code extracted from https://"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3662,
     "status": "ok",
     "timestamp": 1689631515231,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "pEEQKRK6udJH",
    "outputId": "3a75b7ac-5429-4f8f-ccc6-4fba2835bcb6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from os.path import join as osj\n",
    "from bisect import bisect\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import json\n",
    "#!pip install wfdb\n",
    "import wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1689631518054,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "hj66LjJEuVpr",
    "outputId": "fd8cce1a-d490-4385-ba8f-26eb6e4c8879"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/data/RECORDS\n",
      "[100 101 102 103 104 105 106 107 108 109 111 112 113 114 115 116 117 118\n",
      " 119 121 122 123 124 200 201 202 203 205 207 208 209 210 212 213 214 215\n",
      " 217 219 220 221 222 223 228 230 231 232 233 234]\n"
     ]
    }
   ],
   "source": [
    "def read_dict_beats():\n",
    "    with open(DICT_BEATS, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def read_data_beats():\n",
    "    with open(DATA_BEATS, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def ensure_normalized_and_detrended(beats):\n",
    "    for key in beats.keys():\n",
    "        b = beats[key][\"beats\"]\n",
    "        if not np.allclose(np.linalg.norm(b, axis=1, ord=2), 1):\n",
    "            raise AssertionError(f\"Beats of patient {key} is not normalized.\")\n",
    "\n",
    "        p = np.polyfit(np.arange(b.shape[1]), b.T, deg=1)\n",
    "        if not np.allclose(p, 0):\n",
    "            raise AssertionError(f\"Beats of patient {key} is not detrended.\")\n",
    "\n",
    "DATA_ROOT =  \"/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/data\"\n",
    "DATA_BEATS = osj(DATA_ROOT, \"30min_beats.pkl\")\n",
    "\n",
    "RECORDS = osj(DATA_ROOT, \"RECORDS\")\n",
    "print(RECORDS)\n",
    "patient_ids = pd.read_csv(RECORDS,  header=None).to_numpy().reshape(-1)\n",
    "print(patient_ids)\n",
    "data_beats = read_data_beats()\n",
    "ensure_normalized_and_detrended(data_beats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39195,
     "status": "ok",
     "timestamp": 1689631557239,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "PjqoM_-5uxp2",
    "outputId": "5eb9cc02-3047-4770-e118-3a35a7d68657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102. 104. 107. 217.]\n"
     ]
    }
   ],
   "source": [
    "def get_paced_patients(patient_ids):\n",
    "    paced = []\n",
    "    for id_ in patient_ids:\n",
    "        annotation = wfdb.rdann(osj(DATA_ROOT, str(id_)), extension='atr')\n",
    "        labels = np.unique(annotation.symbol)\n",
    "        if (\"/\" in labels):\n",
    "            paced.append(id_)\n",
    "    return np.array(paced)\n",
    "#paced_patients = get_paced_patients(patient_ids)\n",
    "paced_patients = np.array([102, 104, 107, 217])\n",
    "excluded_patients = np.array([]) #np.array([105, 114, 201, 202,207, 209, 213, 222, 223, 234]) # according to paper\n",
    "print(np.concatenate((paced_patients,excluded_patients)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1689631557241,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "cY_UihBsvO4R",
    "outputId": "7f9e0efc-b44e-4912-e748-8baea250bc23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102. 104. 107. 217.]\n",
      "[100, 101, 103, 105, 106, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 200, 201, 202, 203, 205, 207, 208, 209, 210, 212, 213, 214, 215, 219, 220, 221, 222, 223, 228, 230, 231, 232, 233, 234]\n",
      "['N', 'A', 'V', 'Q', 'F', 'j', 'L', 'a', 'J', 'R', 'E', 'S', 'e']\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "patients_out = np.concatenate((paced_patients,excluded_patients))\n",
    "print(patients_out)\n",
    "patients_left = list(copy.deepcopy(patient_ids))\n",
    "\n",
    "for idx,i in enumerate(patient_ids):\n",
    "    if i in patients_out:\n",
    "        patients_left.remove(i)\n",
    "\n",
    "print(patients_left)\n",
    "\n",
    "#print(dict_beats[101]['beats'])\n",
    "#print(dict_beats[101]['class'])\n",
    "labels = ['N','V','S','Q','F']\n",
    "dictionary = {}\n",
    "for i in labels:\n",
    "    dictionary[i] = 0\n",
    "\n",
    "list1 = []\n",
    "array = np.zeros((len(patients_left),2))\n",
    "labels2 = []\n",
    "for idx,i in enumerate(patients_left):\n",
    "    for ii in data_beats[i]['label']:\n",
    "        if ii not in labels2:\n",
    "            labels2.append(ii)\n",
    "    #print(len(data_beats[i]['class']))\n",
    "    list1.append(data_beats[i]['class'])\n",
    "    counter = collections.Counter(data_beats[i]['class'])\n",
    "    for j in counter.keys():\n",
    "        dictionary[j] += counter[j]\n",
    "        if j == 'N':\n",
    "            array[idx,0] += counter[j]\n",
    "        else:\n",
    "            array[idx,1] += counter[j]\n",
    "print(labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1689631557684,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "aB8si8DCvnLj"
   },
   "outputs": [],
   "source": [
    "def train_test_split(data_beats,seconds=5,factor=0.8):\n",
    "    data_beats_train = {}\n",
    "    data_beats_val = {}\n",
    "    data_beats_test = {}\n",
    "    for i in data_beats.keys():\n",
    "        data_beats_train[i] = {'class':None, 'beats':None}\n",
    "        data_beats_val[i] = {'class':None, 'beats':None}\n",
    "        data_beats_test[i] ={'class':None, 'beats':None}\n",
    "\n",
    "    for patient in data_beats.keys():\n",
    "        length = int(np.ceil(len(data_beats[patient]['beats'])*(seconds/30))) # only take first 5 seconds\n",
    "\n",
    "        random_test = np.arange(length)\n",
    "        random_train = np.random.choice(random_test,size=int(np.ceil(0.8*length)),replace=False)\n",
    "        for ii in random_train:\n",
    "            index = np.where(random_test == ii)[0]\n",
    "            random_test = np.delete(random_test,index)\n",
    "\n",
    "        random_val = np.arange(int(np.ceil(0.8*length)))\n",
    "        random_train = np.random.choice(random_val,size=int(np.ceil(0.8*0.8*length)),replace=False)\n",
    "        for ii in random_train:\n",
    "            index = np.where(random_val == ii)[0]\n",
    "            random_val = np.delete(random_val,index)\n",
    "\n",
    "        data_beats_train[patient]['class'] = data_beats[patient]['class'][np.sort(random_train)]\n",
    "        data_beats_test[patient]['class'] = data_beats[patient]['class'][random_test]\n",
    "        data_beats_val[patient]['class'] = data_beats[patient]['class'][random_val]\n",
    "        data_beats_train[patient]['beats'] = data_beats[patient]['beats'][np.sort(random_train)]\n",
    "        data_beats_test[patient]['beats'] = data_beats[patient]['beats'][random_test]\n",
    "        data_beats_val[patient]['beats'] = data_beats[patient]['beats'][random_val]\n",
    "\n",
    "\n",
    "    return data_beats_train, data_beats_val, data_beats_test\n",
    "#print(data_beats_train)\n",
    "seconds = 5\n",
    "data_beats_train, data_beats_val, data_beats_test  = train_test_split(data_beats,seconds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1689631557243,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "wyoYR2oQvlKP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/data/RECORDS_S\n",
      "[100 101 102 103 104 105 106 107 108 109 111 112 113 114 115 116 117 118\n",
      " 119 121 122 123 124 200 201 202 203 205 207 208 209 210 212 213 214 215\n",
      " 217 219 220 221 222 223 228 230 231 232 233 234]\n",
      "[800 801 802 803 804 805 806 807 808 809 810 811 812 820 821 822 823 824\n",
      " 825 826 827 828 829 840 841 842 843 844 845 846 847 848 849 850 851 852\n",
      " 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870\n",
      " 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888\n",
      " 889 890 891 892 893 894]\n"
     ]
    }
   ],
   "source": [
    "# TODO: concatenate the two datasets here\n",
    "# Load supraventricular dataset: \n",
    "DATA_ROOT =  \"/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/data\"\n",
    "DATA_BEATS = osj(DATA_ROOT, \"30min_beats_supraventricular.pkl\")\n",
    "\n",
    "RECORDS = osj(DATA_ROOT, \"RECORDS_S\")\n",
    "print(RECORDS)\n",
    "patient_ids_sup = pd.read_csv(RECORDS,  header=None).to_numpy().reshape(-1)\n",
    "print(patient_ids)\n",
    "print(patient_ids_sup)\n",
    "data_beats_sup = read_data_beats()\n",
    "ensure_normalized_and_detrended(data_beats_sup)\n",
    "seconds = 5\n",
    "data_beats_train_sup, data_beats_val_sup, data_beats_test_sup  = train_test_split(data_beats_sup,seconds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 200, 201, 202, 203, 205, 207, 208, 209, 210, 212, 213, 214, 215, 217, 219, 220, 221, 222, 223, 228, 230, 231, 232, 233, 234])\n",
      "dict_keys([800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894])\n"
     ]
    }
   ],
   "source": [
    "print(data_beats_train.keys())\n",
    "print(data_beats_train_sup.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 101, 103, 105, 106, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 200, 201, 202, 203, 205, 207, 208, 209, 210, 212, 213, 214, 215, 219, 220, 221, 222, 223, 228, 230, 231, 232, 233, 234]\n",
      "[100 101 102 103 104 105 106 107 108 109 111 112 113 114 115 116 117 118\n",
      " 119 121 122 123 124 200 201 202 203 205 207 208 209 210 212 213 214 215\n",
      " 217 219 220 221 222 223 228 230 231 232 233 234]\n",
      "[100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 200, 201, 202, 203, 205, 207, 208, 209, 210, 212, 213, 214, 215, 217, 219, 220, 221, 222, 223, 228, 230, 231, 232, 233, 234, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894]\n"
     ]
    }
   ],
   "source": [
    "# concatenate the datasets\n",
    "data_beats_tr = {}\n",
    "data_beats_tr.update(data_beats_train)\n",
    "data_beats_tr.update(data_beats_train_sup)\n",
    "\n",
    "data_beats_v = {}\n",
    "data_beats_v.update(data_beats_val)\n",
    "data_beats_v.update(data_beats_val_sup)\n",
    "\n",
    "data_beats_t = {}\n",
    "data_beats_t.update(data_beats_test)\n",
    "data_beats_t.update(data_beats_test_sup)\n",
    "print(patients_left)\n",
    "print(patient_ids)\n",
    "print(list(data_beats_tr.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1689631557685,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "qBVooYjHvy1s"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "class MIT_BIH(Dataset):\n",
    "    def __init__(self,patients,data):\n",
    "        self.patients = patients\n",
    "        self.data = data\n",
    "        self.to_one_dataset()\n",
    "\n",
    "    def to_one_dataset(self):\n",
    "        data_vector = torch.zeros(self.__len__(),128)\n",
    "        labels_vector = torch.zeros(self.__len__())\n",
    "        k = 0\n",
    "        for i,patient in enumerate(self.patients):\n",
    "            data_vector[k:k+len(self.data[patient]['beats']),:] = torch.from_numpy(self.data[patient]['beats'])\n",
    "            classes = copy.deepcopy(self.data[patient]['class'])\n",
    "            indices = classes=='N'\n",
    "            indices2 = classes!='N'\n",
    "            classes[indices] = 0\n",
    "            classes[indices2] = 1\n",
    "            classes = np.array(classes,dtype='int')\n",
    "            labels_vector[k:k+len(self.data[patient]['beats'])] = torch.from_numpy(classes)\n",
    "            k += len(self.data[patient]['beats'])\n",
    "        self.y = labels_vector.long()\n",
    "        self.X = data_vector.double()\n",
    "\n",
    "    def __len__(self):\n",
    "        length_total = 0\n",
    "        for patient in self.patients:\n",
    "            length_total += len(self.data[patient]['beats'])\n",
    "           # print(len(self.data[patient]['beats']))\n",
    "        return length_total\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return (self.X[idx,:],self.y[idx])\n",
    "patients_left = [x for x in list(data_beats_tr.keys()) if x not in paced_patients]\n",
    "mit_bih = MIT_BIH(patients_left,data_beats_tr)\n",
    "x_sample,y_sample = mit_bih.__getitem__(0)\n",
    "dataloader = DataLoader(mit_bih,batch_size=32,shuffle=True,num_workers=0)\n",
    "mit_bih_test = MIT_BIH(patients_left,data_beats_v)\n",
    "x_sample,y_sample = mit_bih_test.__getitem__(0)\n",
    "dataloader_test = DataLoader(mit_bih_test,batch_size=32,shuffle=False,num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1689631557686,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "-GlNOOk0xzXM"
   },
   "outputs": [],
   "source": [
    "# So, in the S dataset, there are a lot more 'unhealthy' patients than heal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6j5U13Lx33T"
   },
   "source": [
    "So, in the Supraventricular dataset, there are a lot more very 'unhealthy' patients than healthy or moderately unhealthy patients. Maybe, for the purposes of my paper, I should leave out patients that don't have arrhythmia episodes in their training/entire dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1689631557687,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "DckUDmpnF_Kw"
   },
   "outputs": [],
   "source": [
    "def get_base_model(in_channels):\n",
    "    \"\"\"\n",
    "    Returns the model from paper: Personalized Monitoring and Advance Warning System for Cardiac Arrhythmias.\n",
    "    \"\"\"\n",
    "    # Input size: 128x1\n",
    "    # 128x1 -> 122x32 -> 40x32 -> 34x16 -> 11x16 -> 5x16 -> 1x16\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv1d(in_channels, 32, kernel_size=7, padding=0, bias=True),\n",
    "        nn.MaxPool1d(3),\n",
    "        nn.Tanh(),\n",
    "\n",
    "        nn.Conv1d(32, 16, kernel_size=7, padding=0, bias=True),\n",
    "        nn.MaxPool1d(3),\n",
    "        nn.Tanh(),\n",
    "\n",
    "        nn.Conv1d(16, 16, kernel_size=7, padding=0, bias=True),\n",
    "        nn.MaxPool1d(3),\n",
    "        nn.Tanh(),\n",
    "\n",
    "        nn.Flatten(),\n",
    "\n",
    "        nn.Linear(16, 32, bias=True),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        nn.Linear(32, 2, bias=True),\n",
    "\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1689631558104,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "ElXCrmf5F_h-"
   },
   "outputs": [],
   "source": [
    "# Combinatorial UCB\n",
    "import math\n",
    "\n",
    "class combinatorial_UCB(object):\n",
    "    def __init__(self,n_clients,algorithm='UCB1_tuned'):\n",
    "        self.n_clients = n_clients\n",
    "\n",
    "        # define variables for storage\n",
    "        # which clients we select\n",
    "        self.times_selected = np.zeros((n_clients,n_clients)) # to record how often each client got selected\n",
    "        self.reward_per_client = np.zeros((n_clients,n_clients)) # to record what reward we collected per client\n",
    "        self.reward2_per_client = np.zeros((n_clients,n_clients)) # to record the squared reward per client (needed for UCB1-tuned)\n",
    "        # how many clients we select\n",
    "        self.n_clients_selected_arr = []\n",
    "        self.reward3_per_client = np.zeros((n_clients,n_clients-1))\n",
    "        self.times_selected2 = np.zeros((n_clients,n_clients-1))\n",
    "\n",
    "        self.algorithm = algorithm\n",
    "\n",
    "    def UCB(self,this_client,n):\n",
    "        #for this_client in range(self.n_clients):\n",
    "        other_clients = [x for x in range(self.n_clients) if x != this_client[0]]\n",
    "\n",
    "        upper_bound = np.zeros(self.n_clients)\n",
    "        for i,other_client in enumerate(other_clients):\n",
    "            if self.times_selected[this_client,other_client]==0: # make first iteration value high\n",
    "                upper_bound[other_client] = 1e500\n",
    "            else:\n",
    "                # We first calculate the average reward gained for this client\n",
    "                average_reward = self.reward_per_client[this_client,other_client] / self.times_selected[this_client,other_client]\n",
    "\n",
    "                # Then we compute the confidence interval [avg_reward - delta, avg_reward + delta]\n",
    "                if self.algorithm == 'UCB1':\n",
    "                    delta = math.sqrt( 2 * math.log(n) / self.times_selected[this_client,other_client])\n",
    "\n",
    "                if self.algorithm == 'UCB1_tuned':\n",
    "                    variance_bound = self.reward2_per_client[this_client,other_client] / self.times_selected[this_client,other_client] - average_reward**2\n",
    "                    variance_bound += math.sqrt(2 * math.log(n)/self.times_selected[this_client,other_client])\n",
    "\n",
    "                    factor = np.min([variance_bound, 1/4])\n",
    "                    delta = math.sqrt( factor * math.log(n) / self.times_selected[this_client,other_client] )\n",
    "\n",
    "                # upper bound\n",
    "                upper_bound[other_client] = average_reward + delta\n",
    "\n",
    "        if self.algorithm == 'random':\n",
    "            upper_bound = np.random.rand(self.n_clients)\n",
    "\n",
    "        # select the client with the highest upper bound\n",
    "        sorted_upper_bound = np.flip(np.argsort(upper_bound))\n",
    "\n",
    "        #n_clients_selected_arr.append(n_clients_selected)\n",
    "        selected_clients = sorted_upper_bound[:int(n+1)]\n",
    "\n",
    "        self.times_selected[this_client,selected_clients] += 1\n",
    "        return selected_clients\n",
    "\n",
    "    def collect_reward(self,this_client,selected_clients,observations):\n",
    "        # collect the reward\n",
    "        reward = observations[selected_clients]#df.iloc[n,selected_client]\n",
    "        self.reward_per_client[this_client,selected_clients] += reward\n",
    "        self.reward2_per_client[this_client,selected_clients] += reward**2\n",
    "\n",
    "        # reward for numbers of clients selected\n",
    "        n_clients_selected = len(selected_clients)-1\n",
    "        self.times_selected2[this_client,n_clients_selected] += 1\n",
    "        reward2 = np.abs(n_clients_selected - np.sum(observations))\n",
    "        self.reward3_per_client[this_client,n_clients_selected] += 1 - reward2 / self.n_clients\n",
    "\n",
    "\n",
    "    def to_client(self,this_client,n):\n",
    "        self.selected_clients = self.UCB(this_client,n)\n",
    "        return self.selected_clients\n",
    "\n",
    "    # Combinatorial UCB\n",
    "import math\n",
    "\n",
    "class combinatorial_UCB(object):\n",
    "    def __init__(self,n_clients,algorithm='UCB1_tuned'):\n",
    "        self.n_clients = n_clients\n",
    "\n",
    "        # define variables for storage\n",
    "        # which clients we select\n",
    "        self.times_selected = np.zeros((n_clients,n_clients)) # to record how often each client got selected\n",
    "        self.reward_per_client = np.zeros((n_clients,n_clients)) # to record what reward we collected per client\n",
    "        self.reward2_per_client = np.zeros((n_clients,n_clients)) # to record the squared reward per client (needed for UCB1-tuned)\n",
    "        # how many clients we select\n",
    "        self.n_clients_selected_arr = []\n",
    "        self.reward3_per_client = np.zeros((n_clients,n_clients-1))\n",
    "        self.times_selected2 = np.zeros((n_clients,n_clients-1))\n",
    "\n",
    "        self.algorithm = algorithm\n",
    "\n",
    "    def UCB(self,this_client,n):\n",
    "        #for this_client in range(self.n_clients):\n",
    "        other_clients = [x for x in range(self.n_clients) if x != this_client[0]]\n",
    "\n",
    "        upper_bound = np.zeros(self.n_clients)\n",
    "        for i,other_client in enumerate(other_clients):\n",
    "            if self.times_selected[this_client,other_client]==0: # make first iteration value high\n",
    "                upper_bound[other_client] = 1e500\n",
    "            else:\n",
    "                # We first calculate the average reward gained for this client\n",
    "                average_reward = self.reward_per_client[this_client,other_client] / self.times_selected[this_client,other_client]\n",
    "\n",
    "                # Then we compute the confidence interval [avg_reward - delta, avg_reward + delta]\n",
    "                if self.algorithm == 'UCB1':\n",
    "                    delta = math.sqrt( 2 * math.log(n) / self.times_selected[this_client,other_client])\n",
    "\n",
    "                if self.algorithm == 'UCB1_tuned':\n",
    "                    variance_bound = self.reward2_per_client[this_client,other_client] / self.times_selected[this_client,other_client] - average_reward**2\n",
    "                    variance_bound += math.sqrt(2 * math.log(n)/self.times_selected[this_client,other_client])\n",
    "\n",
    "                    factor = np.min([variance_bound, 1/4])\n",
    "                    delta = math.sqrt( factor * math.log(n) / self.times_selected[this_client,other_client] )\n",
    "\n",
    "                # upper bound\n",
    "                upper_bound[other_client] = average_reward + delta\n",
    "\n",
    "        if self.algorithm == 'random':\n",
    "            upper_bound = np.random.rand(self.n_clients)\n",
    "\n",
    "        # select the client with the highest upper bound\n",
    "        sorted_upper_bound = np.flip(np.argsort(upper_bound))\n",
    "\n",
    "        #n_clients_selected_arr.append(n_clients_selected)\n",
    "        selected_clients = sorted_upper_bound[:int(n+1)]\n",
    "\n",
    "        self.times_selected[this_client,selected_clients] += 1\n",
    "        return selected_clients\n",
    "\n",
    "    def collect_reward(self,this_client,selected_clients,observations):\n",
    "        # collect the reward\n",
    "        reward = observations[selected_clients]#df.iloc[n,selected_client]\n",
    "        self.reward_per_client[this_client,selected_clients] += reward\n",
    "        self.reward2_per_client[this_client,selected_clients] += reward**2\n",
    "\n",
    "        # reward for numbers of clients selected\n",
    "        n_clients_selected = len(selected_clients)-1\n",
    "        self.times_selected2[this_client,n_clients_selected] += 1\n",
    "        reward2 = np.abs(n_clients_selected - np.sum(observations))\n",
    "        self.reward3_per_client[this_client,n_clients_selected] += 1 - reward2 / self.n_clients\n",
    "\n",
    "\n",
    "    def to_client(self,this_client,n):\n",
    "        self.selected_clients = self.UCB(this_client,n)\n",
    "        return self.selected_clients\n",
    "\n",
    "    def to_server(self,this_client,observation):\n",
    "        self.collect_reward(this_client,self.selected_clients,observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1689632023097,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "LPVJ0bDBF_kn"
   },
   "outputs": [],
   "source": [
    "class P2P_AFPL():\n",
    "\n",
    "    def __init__(self,patients_left,train_data,test_data,test='local'):\n",
    "        self.selected_clients = patients_left\n",
    "        self.network = get_base_model(1)\n",
    "        self.best_test_loss = {}\n",
    "        self.best_test_loss_global = 1000000\n",
    "        self.current_test_loss = {}\n",
    "        self.current_train_loss = {}\n",
    "        self.test = test\n",
    "        self.total_clients = len(self.selected_clients)\n",
    "        self.patients_left = patients_left\n",
    "        self.client_models = {}\n",
    "        self.optimizers = {}\n",
    "        self.dataloaders = {}\n",
    "        self.len = {}\n",
    "        self.len_test = {}\n",
    "        self.dataloaders_test = {}\n",
    "        if self.test == 'AFPL':\n",
    "            self.client_models_global = {}\n",
    "\n",
    "        if self.test == 'bandits':\n",
    "            self.comb_UCB = combinatorial_UCB(self.total_clients)\n",
    "\n",
    "        for idx,i in enumerate(self.patients_left):\n",
    "            self.client_models[str(idx)] = copy.deepcopy(self.network).double().cuda()\n",
    "            self.optimizers[str(idx)] = torch.optim.SGD(self.client_models[str(idx)].parameters(),lr=0.01,momentum=0.5)\n",
    "            dataset_train=  MIT_BIH([self.patients_left[idx]],train_data)\n",
    "            self.len[str(idx)] = len(dataset_train)\n",
    "            self.dataloaders[str(idx)] = DataLoader(dataset_train,batch_size=32,shuffle=True,num_workers=0)\n",
    "\n",
    "\n",
    "            dataset_test= MIT_BIH([self.patients_left[idx]],test_data)\n",
    "            self.len_test[str(idx)] = len(dataset_test)\n",
    "            self.dataloaders_test[str(idx)] = DataLoader(dataset_test,batch_size=32,shuffle=False)\n",
    "            self.best_test_loss[str(idx)] = 10000000\n",
    "            self.current_test_loss[str(idx)] = 100000\n",
    "            self.current_train_loss[str(idx)] = 1000000\n",
    "            if self.test == 'AFPL':\n",
    "                self.client_models_global[str(idx)] = copy.deepcopy(self.network).double().cuda()\n",
    "                self.shared_model = copy.deepcopy(self.network).double().cuda()\n",
    "        self.dataset_train = dataset_train\n",
    "\n",
    "    def update_local_models(self,selected_clients):\n",
    "        self.dw = {}\n",
    "        loss_test = 0\n",
    "        loss_test2 = 0\n",
    "        losses = 0\n",
    "        losses2 = 0\n",
    "        loss_test3 = 0\n",
    "        losses3 = 0\n",
    "\n",
    "        for idx,i in enumerate(selected_clients):\n",
    "\n",
    "            dataloader = self.dataloaders[str(i)]\n",
    "            optimizer= torch.optim.Adam(self.client_models[str(i)].parameters(),lr=0.001*0.95**self.iteration)\n",
    "            self.client_models[str(i)].train()\n",
    "\n",
    "            if self.test == 'AFPL':\n",
    "                self.client_models_global[str(i)] = copy.deepcopy(self.shared_model)\n",
    "                self.client_models_global[str(i)].train()\n",
    "                optimizer_global = torch.optim.Adam(self.client_models_global[str(i)].parameters(),lr=0.001*0.95**self.iteration)\n",
    "\n",
    "            for batch_idx, (data, target) in enumerate(dataloader):\n",
    "                data   = data.double().unsqueeze(1).cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.client_models[str(i)](data)\n",
    "                output = F.log_softmax(output,dim=-1)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                #output = self.client_models[str(i)](data)\n",
    "                loss = F.nll_loss(output,target)\n",
    "\n",
    "                if self.test == 'AFPL':\n",
    "                    optimizer_global.zero_grad()\n",
    "                    output_global= self.client_models_global[str(i)](data)\n",
    "                    loss_global = F.nll_loss(output_global,target)\n",
    "                    loss_global.backward()\n",
    "                    optimizer_global.step()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            self.client_models[str(i)].eval()\n",
    "            dataloader_test = self.dataloaders_test[str(i)]\n",
    "            loss_test = 0\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (data, target) in enumerate(dataloader_test):\n",
    "                    data   = data.double().unsqueeze(1).cuda()\n",
    "                    target = target.long().cuda()\n",
    "                    output = self.client_models[str(i)](data)\n",
    "                    output = F.log_softmax(output,dim=-1)\n",
    "\n",
    "                    loss_test += F.nll_loss(output,target)\n",
    "                self.current_test_loss[str(i)] = loss_test/self.len_test[str(i)]\n",
    "                if self.current_test_loss[str(i)] < self.best_test_loss[str(i)]:\n",
    "                    torch.save(self.client_models[str(i)].state_dict(), os.path.join(save_dir, 'model', 'best_model'+str(i)+'.pt'))\n",
    "                    self.best_test_loss[str(i)] = self.current_test_loss[str(i)]\n",
    "\n",
    "            losses += loss_test /self.len_test[str(i)]\n",
    "            loss_test2 = 0\n",
    "            self.client_models[str(i)].eval()\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (data, target) in enumerate(dataloader):\n",
    "                    data   = data.double().unsqueeze(1).cuda()\n",
    "                    target = target.long().cuda()\n",
    "                    output = self.client_models[str(i)](data)\n",
    "                    output = F.log_softmax(output,dim=-1)\n",
    "\n",
    "                    loss_test2 += F.nll_loss(output,target)\n",
    "\n",
    "                losses2 += loss_test2/ self.len[str(i)]\n",
    "                self.current_train_loss[str(i)] = loss_test2/self.len[str(i)]\n",
    "\n",
    "        print('full train loss: ',losses2)\n",
    "        print('full loss: ',losses)\n",
    "\n",
    "        return losses2,losses\n",
    "\n",
    "    def combine_models(self,i,client_numbers,set_as=True):\n",
    "        zero_copy = copy.deepcopy(self.client_models[str(i)]) # This is used to collect the model in\n",
    "        j =0\n",
    "        client_numbers_plus_client = np.concatenate((client_numbers,np.array([int(i)])))# This is more efficient\n",
    "      #  alphas = zero_copy.alphas.detach()\n",
    "       # alphas[i] = 1 - torch.sum(\n",
    "       #     torch.tensor([iii for idx, iii in enumerate(alphas) if idx != i and idx in client_numbers]))\n",
    "        # It's not possible to set the value of self.alphas[i], so instead we determine it manually here\n",
    "        alphas = torch.ones(len(client_numbers_plus_client)).cuda()/(len(client_numbers_plus_client))\n",
    "        #print(alphas)\n",
    "        for ii in client_numbers_plus_client:\n",
    "          #  print(ii)\n",
    "            for (name, param),(name2,param2) in zip(zero_copy.named_parameters(),self.client_models[str(ii)].named_parameters()): #self.client_models[str(ii)].named_parameters()):\n",
    "\n",
    "                if name != 'alphas':\n",
    "                    if j == 0:\n",
    "                        param.data = torch.zeros(param.shape).cuda()\n",
    "\n",
    "                    param.data += alphas[j]*param2.data # we add all participating client's models to the one here.\n",
    "\n",
    "            j += 1\n",
    "\n",
    "        #self.client_models[str(i)] = zero_copy.double()\n",
    "        if set_as == True:\n",
    "            for (name,param),(name2,param2) in zip(self.client_models[str(i)].named_parameters(),zero_copy.named_parameters()):\n",
    "                param.data = param2.data\n",
    "            self.client_models[str(i)].double()\n",
    "        else:\n",
    "            return zero_copy.double()\n",
    "\n",
    "    def federated_averaging(self):\n",
    "        self.shared_model = copy.deepcopy(self.network).double().cuda()\n",
    "        n_clients = len(self.selected_clients)\n",
    "        weight = [self.len[str(x)] for x in self.selected_clients]\n",
    "        weight = weight / np.sum(weight)\n",
    "\n",
    "        losses = 0\n",
    "        losses2 = 0\n",
    "        #print(\"weights \",weight)\n",
    "        for idx,i in enumerate(self.selected_clients):\n",
    "            for (name, param),(name2,param2) in zip(self.shared_model.named_parameters()\n",
    "                                                      ,self.client_models[str(i)].named_parameters()):\n",
    "                if idx == 0:\n",
    "                    param.data = torch.zeros(param.shape).cuda().double()\n",
    "                param.data += weight[idx]*param2.data\n",
    "\n",
    "        self.shared_model = self.shared_model.double().eval()\n",
    "\n",
    "        for i in self.selected_clients:\n",
    "            self.client_models[str(i)] = copy.deepcopy(self.shared_model) #copy global model to the clients\n",
    "            loss_test = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(i)]):\n",
    "                data   = data.double().unsqueeze(1).cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.shared_model(data)\n",
    "\n",
    "                output = F.log_softmax(output,dim=-1)\n",
    "\n",
    "                loss_test += F.nll_loss(output,target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test = loss_test/self.len_test[str(i)]\n",
    "            losses += loss_test\n",
    "            if loss_test < self.best_test_loss[str(i)]:\n",
    "                    torch.save(self.client_models[str(i)].state_dict(), os.path.join(save_dir, 'model', 'best_model'+str(i)+'.pt'))\n",
    "                    self.best_test_loss[str(i)] = loss_test\n",
    "            self.client_models[str(i)].eval()\n",
    "            loss_test2 = 0\n",
    "            for batch_idx, (data,target) in enumerate(self.dataloaders[str(i)]):\n",
    "                data   = data.double().unsqueeze(1).cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.shared_model(data)\n",
    "                output = F.log_softmax(output,dim=-1)\n",
    "\n",
    "                loss_test2 += F.nll_loss(output,target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test2 = loss_test2/self.len[str(i)]\n",
    "            losses2 += loss_test2\n",
    "\n",
    "\n",
    "        return losses, losses2\n",
    "\n",
    "    def AFPL(self): #use alpha = 0.25 = 0.75 global model + 0.25 local model\n",
    "        self.shared_model_old = copy.deepcopy(self.shared_model)\n",
    "        self.shared_model = copy.deepcopy(self.network).double().cuda()\n",
    "        n_clients = len(self.selected_clients)\n",
    "        weight = [self.len[str(x)] for x in self.selected_clients]\n",
    "        weight = weight / np.sum(weight)\n",
    "\n",
    "        losses = 0\n",
    "        losses2 = 0\n",
    "\n",
    "        #accumulate local weights\n",
    "        for idx,i in enumerate(self.selected_clients):\n",
    "            for (name, param),(name2,param2),(name3,param3),(name4,param4) in zip(self.shared_model.named_parameters()\n",
    "                                                      ,self.client_models_global[str(i)].named_parameters(),\n",
    "                                                                  self.shared_model_old.named_parameters(),\n",
    "                                                        self.client_models[str(i)].named_parameters()):\n",
    "                if idx == 0:\n",
    "                    param.data = torch.zeros(param.shape).cuda().double()\n",
    "                param.data += weight[idx]*param2.data # accumulate local weights\n",
    "                param4.data = 0.25*param4.data + 0.75*param3.data # do AFPL local model update: note that we take the previous global model\n",
    "            self.client_models[str(i)] = self.client_models[str(i)].double()\n",
    "            self.client_models[str(i)].eval()\n",
    "            loss_test = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(i)]):\n",
    "                data   = data.double().unsqueeze(1).cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.client_models[str(i)](data)\n",
    "                output = F.log_softmax(output,dim=-1)\n",
    "\n",
    "                loss_test += F.nll_loss(output,target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test = loss_test/self.len_test[str(i)]\n",
    "            losses += loss_test\n",
    "            if loss_test < self.best_test_loss[str(i)]:\n",
    "                    torch.save(self.client_models[str(i)].state_dict(), os.path.join(save_dir, 'model', 'best_model'+str(i)+'.pt'))\n",
    "                    self.best_test_loss[str(i)] = loss_test\n",
    "            self.client_models[str(i)].eval()\n",
    "            loss_test2 = 0\n",
    "            for batch_idx, (data,target) in enumerate(self.dataloaders[str(i)]):\n",
    "                data   = data.double().unsqueeze(1).cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.client_models[str(i)](data)\n",
    "                output = F.log_softmax(output,dim=-1)\n",
    "\n",
    "                loss_test2 += F.nll_loss(output,target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test2 = loss_test2/self.len[str(i)]\n",
    "            losses2 += loss_test2\n",
    "\n",
    "        self.shared_model = self.shared_model.double()\n",
    "        return losses, losses2\n",
    "\n",
    "    def calc_accuracy(self):\n",
    "        accuracies = np.zeros(len(self.selected_clients))\n",
    "        total = 0\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for i in self.selected_clients:\n",
    "            dataloader = self.dataloaders_test[str(i)]\n",
    "            intermediate_accuracy = 0\n",
    "            self.client_models[str(i)].eval()\n",
    "              #y_pred = []\n",
    "              #y_true = []\n",
    "            for batch_idx, (data, target) in enumerate(dataloader):\n",
    "                data = data.unsqueeze(1).double().cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.client_models[str(i)](data)\n",
    "                output = F.log_softmax(output,dim=-1)\n",
    "                output_array = output.detach().cpu().numpy()\n",
    "                output_class = np.argmax(output_array,axis=-1)\n",
    "                target_array = target.detach().cpu().numpy()\n",
    "                intermediate_accuracy += np.sum(output_class == target_array)\n",
    "                 # y_pred.append(list(output_class))\n",
    "                 # y_true.append(list(target_array))\n",
    "                y_true = np.hstack((y_true,[x for x in list(target_array)]))\n",
    "                y_pred = np.hstack((y_pred,[x for x in list(output_class)]))\n",
    "                 # preds2 = np.hstack((preds2, [x for x in list(output_class2)]))\n",
    "\n",
    "\n",
    "            accuracy = intermediate_accuracy/p2p.len_test[str(i)]*100\n",
    "              #print(i)\n",
    "\n",
    "            total += self.len_test[str(i)]\n",
    "            accuracies[i] = intermediate_accuracy\n",
    "        overall_accuracy = np.sum(accuracies)/total*100\n",
    "     #     print(y_true)\n",
    "     #     print(y_pred)\n",
    "        overall_accuracy = sklearn.metrics.balanced_accuracy_score(y_true,y_pred)\n",
    "        return overall_accuracy\n",
    "\n",
    "    def bandits(self,client,n):\n",
    "\n",
    "        selected_clients = []\n",
    "        other_clients = [x for x in range(self.total_clients) if x != client]\n",
    "          #print(other_clients)\n",
    "        ey = np.zeros(self.total_clients)# fix indices\n",
    "        current_test = np.zeros(self.total_clients)\n",
    "        collected_clients = []\n",
    "\n",
    "        selected_clients_UCB = self.comb_UCB.to_client([client],n)\n",
    "        if client == 14:\n",
    "            print('selected clients UCB: ',selected_clients_UCB)\n",
    "        old_accuracy = 0\n",
    "        for i in selected_clients_UCB:\n",
    "            shared_model = self.combine_models(client,[i],set_as=False)\n",
    "\n",
    "            if len(collected_clients)>0:\n",
    "                all_clients = collected_clients+[i]\n",
    "                shared_model2 = self.combine_models(client,all_clients,set_as=False)\n",
    "\n",
    "            shared_model.eval().cuda()\n",
    "            self.client_models[str(client)].eval().cuda()\n",
    "            loss_test = 0\n",
    "            loss_test2 = 0\n",
    "            loss_test3 = 0\n",
    "            accuracy_local = 0\n",
    "            accuracy_shared = 0\n",
    "\n",
    "            preds1 = []\n",
    "            targets = []\n",
    "            preds2 = []\n",
    "\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(client)]):\n",
    "                data = data.unsqueeze(1).double().cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = shared_model(data)\n",
    "                output = F.log_softmax(output,dim=-1)\n",
    "                output2 = self.client_models[str(client)](data)\n",
    "                output2 = F.log_softmax(output2,dim=-1)\n",
    "                loss_test += F.nll_loss(output,target).detach().cpu().numpy()\n",
    "                loss_test2 += F.nll_loss(output2,target).detach().cpu().numpy()\n",
    "\n",
    "                if len(collected_clients)>0:\n",
    "                    output = shared_model2(data)\n",
    "                    output = F.log_softmax(output,dim=-1)\n",
    "                    loss_test3 += F.nll_loss(output,target).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "                output_array = output.detach().cpu().numpy()\n",
    "                output_class = np.argmax(output_array, axis=-1)\n",
    "                target_array = target.detach().cpu().numpy()\n",
    "                accuracy_shared += np.sum(output_class == target_array)\n",
    "\n",
    "                output_array2 = output2.detach().cpu().numpy()\n",
    "                output_class2 = np.argmax(output_array2, axis=-1)\n",
    "                accuracy_local += np.sum(output_class2 == target_array)\n",
    "\n",
    "                targets = np.hstack((targets,[x for x in list(target_array)]))\n",
    "                preds1 = np.hstack((preds1,[x for x in list(output_class)]))\n",
    "                preds2 = np.hstack((preds2, [x for x in list(output_class2)]))\n",
    "\n",
    "\n",
    "            accuracy_locals = accuracy_local / self.len_test[str(client)] * 100\n",
    "            accuracy_shareds = accuracy_shared / self.len_test[str(client)] *100\n",
    "            accuracy_locals = sklearn.metrics.balanced_accuracy_score(targets,preds2)\n",
    "            accuracy_shareds = sklearn.metrics.balanced_accuracy_score(targets,preds1)\n",
    "            #  if client == 14:\n",
    "            #    print('CLIENT: ',i)\n",
    "            #    print(accuracy_locals)\n",
    "            #    print(old_accuracy)\n",
    "            #    print(accuracy_shareds)\n",
    "\n",
    "              # ACCURACY-based client selection\n",
    "            if accuracy_shareds > accuracy_locals and accuracy_shareds > old_accuracy:\n",
    "                collected_clients.append(i)\n",
    "             #     if client == 14:\n",
    "             #       print('added i to collected clients')\n",
    "                old_accuracy = accuracy_shareds\n",
    "        loss_test = current_test[i]\n",
    "        #selected_clients = np.where(ey<=self.current_test_loss[str(client)].detach().cpu().numpy() )[0]\n",
    "        ###selected_clients = [other_clients[x] for x in selected_clients]\n",
    "\n",
    "        selected_clients = collected_clients\n",
    "\n",
    "        observation = np.zeros(self.total_clients)\n",
    "        observation[selected_clients] = 1\n",
    "        if client == 14:\n",
    "            print(observation)\n",
    "\n",
    "        self.comb_UCB.to_server(client,observation)\n",
    "\n",
    "\n",
    "        if len(selected_clients) > 0 :\n",
    "            self.combine_models(client,selected_clients,set_as=True)\n",
    "            loss_test = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(client)]):\n",
    "                data = data.unsqueeze(1).double().cuda()\n",
    "                target = target.long().cuda()\n",
    "                output2 = self.client_models[str(client)](data)\n",
    "                output2 = F.log_softmax(output2,dim=-1)\n",
    "\n",
    "                loss_test += F.nll_loss(output2,target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test = loss_test/self.len_test[str(client)]\n",
    "            if loss_test < self.best_test_loss[str(client)]:\n",
    "                    torch.save(self.client_models[str(client)].state_dict(), os.path.join(save_dir, 'model', 'best_model'+str(i)+'.pt'))\n",
    "                    self.best_test_loss[str(client)] = loss_test\n",
    "            self.client_models[str(client)].eval()\n",
    "            loss_test2 = 0\n",
    "            for batch_idx, (data,target) in enumerate(self.dataloaders[str(client)]):\n",
    "                data = data.unsqueeze(1).double().cuda()\n",
    "                target = target.long().cuda()\n",
    "                output2 = self.client_models[str(client)](data)\n",
    "                output2 = F.log_softmax(output2,dim=-1)\n",
    "\n",
    "                loss_test2 += F.nll_loss(output2,target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test2 = loss_test2/self.len[str(client)]\n",
    "        return loss_test,loss_test2,selected_clients\n",
    "\n",
    "    def loop(self,epochs,p2p,experiment_name):\n",
    "\n",
    "        loss_tests = []\n",
    "        loss_trains = []\n",
    "        loss_tests2 = []\n",
    "        loss_trains2 = []\n",
    "        accuracies = []\n",
    "        accuracies_train = []\n",
    "        self.p2p = p2p\n",
    "        self.phis = np.zeros((self.total_clients, self.total_clients))\n",
    "        self.selected_clients_arr = np.zeros((epochs,self.total_clients,self.total_clients))\n",
    "\n",
    "        for i in range(epochs):\n",
    "            print(i)\n",
    "            self.iteration = i\n",
    "            list1 = []\n",
    "            self.selected_clients = [x for x in range(self.total_clients)]\n",
    "\n",
    "            loss_train,loss_test = self.update_local_models(self.selected_clients)\n",
    "            loss_tests.append(loss_test.detach().cpu().numpy())\n",
    "            loss_trains.append(loss_train.detach().cpu().numpy())\n",
    "\n",
    "            if self.test == 'AFPL':\n",
    "                losses2, losses3 = self.AFPL()\n",
    "\n",
    "            if self.test == 'local':\n",
    "                print('we are done')\n",
    "\n",
    "            if self.test == 'federated':\n",
    "                losses2, losses3 = self.federated_averaging()\n",
    "\n",
    "            if self.test == 'bandits':\n",
    "                losses2 = 0\n",
    "                losses3 = 0\n",
    "                for client in range(self.total_clients):\n",
    "                    loss_test2,loss_train2,selected_clients2= self.bandits(client,20)\n",
    "                    losses2 += loss_test2\n",
    "                    if len(selected_clients2)< 1:\n",
    "                        losses3+= self.current_train_loss[str(client)].detach().cpu().numpy()\n",
    "                    else:\n",
    "                        losses3 += loss_train2\n",
    "                    self.phis[client,selected_clients2] += 1\n",
    "                    self.selected_clients_arr[i,client,selected_clients2] += 1\n",
    "                fname = os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', experiment_name, 'phi'+str(i)+'.txt')\n",
    "                print(fname)\n",
    "                np.savetxt(fname,self.phis)\n",
    "                print('saved?')\n",
    "\n",
    "            if self.test == 'mine':\n",
    "                losses2 = 0\n",
    "                losses3 = 0\n",
    "                for client in range(self.total_clients):\n",
    "                    loss_test2,loss_train2,selected_clients2= self.my_method2(client)\n",
    "                    losses2 += loss_test2\n",
    "                    if len(selected_clients2)< 1:\n",
    "                        losses3+= self.current_train_loss[str(client)].detach().cpu().numpy()\n",
    "\n",
    "                    else:\n",
    "                        losses3 += loss_train2\n",
    "                    self.phis[client,selected_clients2] += 1\n",
    "                    #print(selected_clients2)\n",
    "                fname = os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', experiment_name, 'phi'+str(i)+'.txt')\n",
    "                np.savetxt(fname,self.phis)\n",
    "\n",
    "            if self.test == 'optimal':\n",
    "                losses2, losses3 = self.optimal_fedavg()\n",
    "                losses2 = losses2.detach().cpu().numpy()\n",
    "                losses3 = losses3.detach().cpu().numpy()\n",
    "\n",
    "            if self.test != 'local':\n",
    "                print('loss after my code: ',losses2)\n",
    "                print('train loss after my code: ',losses3)\n",
    "                loss_tests2.append(losses2)\n",
    "                loss_trains2.append(losses3)\n",
    "                fname = os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', experiment_name, 'losses_test.txt')\n",
    "                np.savetxt(fname,loss_tests2)\n",
    "                fname = os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', experiment_name, 'losses_train.txt')\n",
    "                np.savetxt(fname,loss_trains2)\n",
    "\n",
    "\n",
    "            else:\n",
    "                fname = os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', experiment_name, 'losses_test.txt')\n",
    "                np.savetxt(fname,loss_tests)\n",
    "                fname = os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', experiment_name, 'losses_train.txt')\n",
    "                np.savetxt(fname,loss_trains)\n",
    "\n",
    "\n",
    "\n",
    "            accuracy = self.calc_accuracy()\n",
    "            print(accuracy)\n",
    "            accuracies.append(accuracy)\n",
    "            #accuracy_train = self.calc_accuracy(test=False)\n",
    "            #print(accuracy_train)\n",
    "            #accuracies_train.append(accuracy_train)\n",
    "        #print(self.phis)\n",
    "        fname = os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', experiment_name, 'accuracies.txt')\n",
    "        np.savetxt(fname, accuracies)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_trains,label='train loss before')\n",
    "        plt.plot(loss_tests,label='test loss before')\n",
    "        plt.plot(loss_trains2,label='train loss after')\n",
    "        plt.plot(loss_tests2,label='test loss after')\n",
    "        plt.title('loss curve')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.savefig(os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', experiment_name, 'loss_curve.png'))\n",
    "        plt.clf()\n",
    "        plt.plot(accuracies,label='test')\n",
    "       # plt.plot(accuracies_train,label='train')\n",
    "        plt.title('accuracy progression')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', experiment_name, 'accuracy_progression.png'))\n",
    "        return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 371,
     "status": "ok",
     "timestamp": 1689631803563,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "TgLifLgsMso1",
    "outputId": "49265473-d319-4ee3-ee57-fbcc7d1e1d02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made dir\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits\n"
     ]
    }
   ],
   "source": [
    "#DATA_ROOT =  \"drive/MyDrive/mit-bih-supraventricular-arrhythmia-database-1.0.0\"\n",
    "#os.mkdir(\"drive/MyDrive/checkpoints_bandits\")\n",
    "import yaml\n",
    "import os\n",
    "import shutil\n",
    "dir = \"test2\"\n",
    "def init():\n",
    "\n",
    "    if not os.path.isdir('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits'):\n",
    "        os.mkdir('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits')\n",
    "    if not os.path.isdir(os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', dir)):\n",
    "        os.mkdir(os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits',dir))\n",
    "    save_dir = os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', )\n",
    "    if not os.path.isdir(os.path.join(save_dir, 'model')):\n",
    "        os.mkdir(os.path.join(save_dir, 'model'))\n",
    "        print('made dir')\n",
    "    #shutil.copyfile('settings/train_settings.yaml', save_dir + '/train_settings.yaml')\n",
    "    return save_dir\n",
    "\n",
    "save_dir = init()\n",
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 341130,
     "status": "ok",
     "timestamp": 1689632369268,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "TRYGf4FhsHMu",
    "outputId": "fe213a66-7e69-4768-aaf5-ea5bca308d8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "full train loss:  tensor(2.8744, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(3.3875, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [121 120  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi0.txt\n",
      "saved?\n",
      "loss after my code:  1.7388632402145159\n",
      "train loss after my code:  2.83593617040639\n",
      "0.6888047936414892\n",
      "1\n",
      "full train loss:  tensor(2.0657, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.4528, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [60 56 27 28 29 30 31 51 52 53 54 55 57 70 58 59 61 62 63 64 65]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi1.txt\n",
      "saved?\n",
      "loss after my code:  0.04777973681412571\n",
      "train loss after my code:  2.0661618624537024\n",
      "0.5548878504162488\n",
      "2\n",
      "full train loss:  tensor(1.5578, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.8568, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [ 0 81  5  4  3  2 66 67 68 69  1 71 72 73 74 75 76 77 79  6  7]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi2.txt\n",
      "saved?\n",
      "loss after my code:  0.029445209595553735\n",
      "train loss after my code:  1.5609001374192923\n",
      "0.5098887515451175\n",
      "3\n",
      "full train loss:  tensor(1.3038, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.5537, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [87 24 90 89 88 86 85 84 83 82 26 80 25 78 23 19 22 21 20  8  9]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi3.txt\n",
      "saved?\n",
      "loss after my code:  0.029405780011504092\n",
      "train loss after my code:  1.305921255453671\n",
      "0.530902348578492\n",
      "4\n",
      "full train loss:  tensor(1.1609, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.3894, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [ 93 102 100  15  98  97  96  95  94  92  91  18  17  16  10  11  12 101\n",
      "  99 103 112]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi4.txt\n",
      "saved?\n",
      "loss after my code:  0.0\n",
      "train loss after my code:  1.1609192515842184\n",
      "0.569102930762355\n",
      "5\n",
      "full train loss:  tensor(1.0673, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.2862, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [107 110 104 105 106  13 108 109 111 113 114 115 116 117 118 119  38  34\n",
      "  37  36  35]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi5.txt\n",
      "saved?\n",
      "loss after my code:  0.029643993479917755\n",
      "train loss after my code:  1.0701307108811664\n",
      "0.5679851668726823\n",
      "6\n",
      "full train loss:  tensor(1.0143, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.2084, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [121  48  31  32  33  39  40  41  42  43  44  45  46  47  49  63  50  51\n",
      "  52  53  54]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi6.txt\n",
      "saved?\n",
      "loss after my code:  0.1288620299159965\n",
      "train loss after my code:  1.0275130384533935\n",
      "0.6128816826897695\n",
      "7\n",
      "full train loss:  tensor(0.9613, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.1566, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [ 60  73  26  27  28  29  30  55  56  57  58  59 120  61  62  64  65  66\n",
      "  67  68  69]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi7.txt\n",
      "saved?\n",
      "loss after my code:  0.15230278845517192\n",
      "train loss after my code:  0.9735964358891864\n",
      "0.6358230583403572\n",
      "8\n",
      "full train loss:  tensor(0.9222, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.1087, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [ 0  7  5  4  3  2 70 71 72  1 74 75 76 77 78 80 81  6  8 83  9]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi8.txt\n",
      "saved?\n",
      "loss after my code:  0.14844518923336036\n",
      "train loss after my code:  0.9302572275546482\n",
      "0.6375299238500595\n",
      "9\n",
      "full train loss:  tensor(0.8858, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.0568, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [82 12 92 91 90 88 87 86 85 84 79 10 11 13 94 15 16 17 18 19 20]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi9.txt\n",
      "saved?\n",
      "loss after my code:  0.11637819858276399\n",
      "train loss after my code:  0.8922790444589945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6686821308876029\n",
      "10\n",
      "full train loss:  tensor(0.8438, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.0046, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [ 95 104  24  23  22  21  89  93  96  97  98  99 100 101 102 103  25 105\n",
      " 113 106 115]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi10.txt\n",
      "saved?\n",
      "loss after my code:  0.17858542537615757\n",
      "train loss after my code:  0.8513942079278242\n",
      "0.7032927612955138\n",
      "11\n",
      "full train loss:  tensor(0.8060, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.9570, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [109 108 119 118 117 116 114 107 112 111 110  36  38  37  34  39  35 121\n",
      "  33  32  41]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi11.txt\n",
      "saved?\n",
      "loss after my code:  0.18652270314637046\n",
      "train loss after my code:  0.8110178385813117\n",
      "0.7411409019662814\n",
      "12\n",
      "full train loss:  tensor(0.7542, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.9080, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [60 65 30 31 40 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi12.txt\n",
      "saved?\n",
      "loss after my code:  0.16919715542445596\n",
      "train loss after my code:  0.7664035147069276\n",
      "0.7655682300190603\n",
      "13\n",
      "full train loss:  tensor(0.7294, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.8638, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [  0   6   4   3   2  58  59 120  61  62  63  64   1  66  67  68  69  70\n",
      "  71  72  73]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi13.txt\n",
      "saved?\n",
      "loss after my code:  0.14634583305264162\n",
      "train loss after my code:  0.7457169266553919\n",
      "0.7699971418740932\n",
      "14\n",
      "full train loss:  tensor(0.6991, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.8359, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [80 76  9  8  7  5 74 75 77 86 78 79 81 82 83 29 10 11 12 13 15]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi14.txt\n",
      "saved?\n",
      "loss after my code:  0.1212752136553926\n",
      "train loss after my code:  0.7100550178764394\n",
      "0.7780317525045011\n",
      "15\n",
      "full train loss:  tensor(0.6767, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.8041, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [90 96 94 93 92 91 27 89 88 87 85 84 28 16 17 18 19 20 21 22 23]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi15.txt\n",
      "saved?\n",
      "loss after my code:  0.11485164438021517\n",
      "train loss after my code:  0.6771136673791425\n",
      "0.7938511153062655\n",
      "16\n",
      "full train loss:  tensor(0.6436, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.7667, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [ 97 107  26  95  24  98  99 100 101 102 103 104 105 106  25 108 115 109\n",
      " 118 117 116]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi16.txt\n",
      "saved?\n",
      "loss after my code:  0.1035874842797021\n",
      "train loss after my code:  0.6469838669155688\n",
      "0.800252498129475\n",
      "17\n",
      "full train loss:  tensor(0.6124, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.7375, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [111 119 114 113 112 110  36  41  40  39  38  37 121  35  43  34  33  32\n",
      "  31  42  46]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi17.txt\n",
      "saved?\n",
      "loss after my code:  0.09467503781481425\n",
      "train loss after my code:  0.6160369396264761\n",
      "0.809993974269585\n",
      "18\n",
      "full train loss:  tensor(0.5942, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.7083, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [ 60  27  29  30  44  45  47  48  49  50  51  52  53  54  55  56  57  58\n",
      "  59 120  61]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi18.txt\n",
      "saved?\n",
      "loss after my code:  0.12058869568451391\n",
      "train loss after my code:  0.604017950610807\n",
      "0.8191174034381252\n",
      "19\n",
      "full train loss:  tensor(0.5787, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.6878, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [ 0 66  4  3  2  1 62 63 64 65 67  6 68 69 70 71 72 73 74 75  5]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi19.txt\n",
      "saved?\n",
      "loss after my code:  0.12328653849712866\n",
      "train loss after my code:  0.5838046477016161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8250033223438089\n",
      "20\n",
      "full train loss:  tensor(0.5604, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.6604, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [80 88 86 28 84 83 82 81 79 78 77 76  7  8  9 10 11 12 13 15 16]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi20.txt\n",
      "saved?\n",
      "loss after my code:  0.11837891947256603\n",
      "train loss after my code:  0.5690134646567664\n",
      "0.8356863416170439\n",
      "21\n",
      "full train loss:  tensor(0.5412, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.6439, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [91 99 97 96 95 94 93 92 90 89 87 85 17 18 19 20 21 22 23 24 25]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi21.txt\n",
      "saved?\n",
      "loss after my code:  0.10950167209424576\n",
      "train loss after my code:  0.5457255076644641\n",
      "0.850416885880676\n",
      "22\n",
      "full train loss:  tensor(0.5246, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.6150, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [ 98 109 100 101 102 103 104 105 106 107 108  26 110 112 113 114 115 116\n",
      " 117 118 119]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi22.txt\n",
      "saved?\n",
      "loss after my code:  0.10925302447549638\n",
      "train loss after my code:  0.5303509339629892\n",
      "0.8568182687038854\n",
      "23\n",
      "full train loss:  tensor(0.5022, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5880, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [111 121  45  32  33  34  35  36  37  38  39  40  41  42  43  44  46  30\n",
      "  47  48  49]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi23.txt\n",
      "saved?\n",
      "loss after my code:  0.10825125623160219\n",
      "train loss after my code:  0.5210481530303769\n",
      "0.865868060169922\n",
      "24\n",
      "full train loss:  tensor(0.4925, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5799, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [ 60  57  28  29  31  50  51  52  53  54  55  56  58  26  59 120  61  62\n",
      "  63  64  65]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test2/phi24.txt\n",
      "saved?\n",
      "loss after my code:  0.07271932707225175\n",
      "train loss after my code:  0.5046382595970538\n",
      "0.8662651940339807\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import collections\n",
    "from time import time\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pandas\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "experiment_name = 'test2' #settings['experiment_name']\n",
    "test = 'bandits' #[20:]\n",
    "n_epochs = 25 #settings['n_epochs']\n",
    "\n",
    "p2p = P2P_AFPL(patients_left,data_beats_tr,data_beats_v,test)\n",
    "accuracies_bandits_2 = p2p.loop(n_epochs,p2p,experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  0,   1,   2,   4,   4,   4,   4,   4,   4,   4,   4,   4,   5,\n",
      "         5,   5,   7,   8,  10,  11,  12,  13,  13,  13,  15,  15,  16,\n",
      "        17,  18,  18,  20,  21,  22,  23,  23,  23,  24,  25,  25,  25,\n",
      "        25,  25,  25,  25,  26,  26,  26,  27,  27,  28,  31,  32,  32,\n",
      "        32,  33,  34,  35,  36,  37,  37,  38,  38,  39,  41,  41,  41,\n",
      "        41,  42,  42,  42,  42,  42,  42,  42,  44,  47,  48,  49,  49,\n",
      "        49,  50,  50,  53,  57,  58,  58,  58,  58,  58,  59,  60,  60,\n",
      "        60,  60,  60,  61,  63,  63,  63,  63,  65,  65,  65,  65,  67,\n",
      "        69,  72,  72,  72,  72,  72,  72,  72,  72,  78,  78,  79,  80,\n",
      "        80,  80,  81,  81,  81,  81,  81,  81,  81,  81,  82,  82,  82,\n",
      "        82,  82,  82,  84,  84,  84,  84,  85,  86,  87,  87,  88,  90,\n",
      "        90,  90,  90,  90,  91,  92,  92,  92,  94,  94,  94,  95,  95,\n",
      "        96,  97,  97,  97,  97,  97,  97,  97,  97,  97,  97,  97, 102,\n",
      "       102, 102, 102, 105, 105, 106, 107, 108, 108, 108, 108, 108, 108,\n",
      "       110, 110, 112, 113, 114, 114, 114, 114, 114, 115, 115, 115, 115,\n",
      "       118, 118, 118, 118, 118, 118, 118, 118, 119, 119, 119, 120, 120,\n",
      "       120, 120, 120]), array([ 30,  32,  32,  15,  32,  35,  59,  78,  96,  97, 107, 119,  32,\n",
      "        36,  42,  32,  32,  50,  32,  32,  32,  36,  42,  50, 119,  32,\n",
      "        32,  32,  42,  41,  50,  32,  45,  49,  78,  32,  32,  36,  41,\n",
      "        42,  48,  59, 108,  41,  42,  59,  34,  36,  37,  43,  40,  41,\n",
      "        87,  43,  50,  59,  42,  31,  33,  88,  96,  42,   2,  25,  42,\n",
      "       105,  25,  31,  33,  37,  41, 120, 121,  50,  50,  49,  36,  42,\n",
      "        48,  38,  39,  36,  43,  45,  90,  97, 102, 108,  55,  35,  37,\n",
      "        42,  44,  59,  97,  33,  34,  39,  42,  15, 102, 108, 119,  30,\n",
      "        39,  32,  33,  34,  39,  42,  96,  97, 121,  39,  42,  39,  36,\n",
      "        42,  44,  20,  32,  59,  82,  88, 102, 107, 119,  39,  41,  42,\n",
      "        59,  88, 119,  39,  42,  44,  47,  30, 107,  26,  43, 119,  32,\n",
      "        33,  34,  41, 121,  30,  88,  96,  97,  38,  39,  47,  38,  49,\n",
      "       119,  33,  34,  36,  37,  44,  47,  48,  81,  88, 112, 119,  30,\n",
      "        33,  39,  41,  41,  88, 119,  95,  20,  25,  30,  33,  39,  41,\n",
      "        30,  39, 119,  30,  33,  34,  39,  42, 119,  36,  39,  44,  47,\n",
      "        39,  42,  44,  45,  47,  50,  88, 102,  36,  42,  44,  32,  33,\n",
      "        39,  41,  42]))\n"
     ]
    }
   ],
   "source": [
    "print(np.where(p2p.phis>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 152,
     "status": "aborted",
     "timestamp": 1689630833968,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "Q081gVvrZpPQ"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "from time import time\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pandas\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "experiment_name = 'test' #settings['experiment_name']\n",
    "test = 'local' #[20:]\n",
    "n_epochs = 25 #settings['n_epochs']\n",
    "\n",
    "p2p = P2P_AFPL(patients_left,data_beats_train,data_beats_val,test)\n",
    "accuracies_bandits_2 = p2p.loop(n_epochs,p2p,experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 152,
     "status": "aborted",
     "timestamp": 1689630833968,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "Gvs-88a60noV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "#print(phi)\n",
    "phi_binary =np.array(np.array(p2p.phis,dtype='bool'),dtype='int')\n",
    "#print(phi_binary)\n",
    "phi_graph = nx.from_numpy_array(p2p.phis)\n",
    "\n",
    "def community_layout(g, partition):\n",
    "    \"\"\"\n",
    "    Compute the layout for a modular graph.\n",
    "\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    g -- networkx.Graph or networkx.DiGraph instance\n",
    "        graph to plot\n",
    "\n",
    "    partition -- dict mapping int node -> int community\n",
    "        graph partitions\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pos -- dict mapping int node -> (float x, float y)\n",
    "        node positions\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    pos_communities = _position_communities(g, partition, scale=3.)\n",
    "\n",
    "    pos_nodes = _position_nodes(g, partition, scale=1.)\n",
    "\n",
    "    # combine positions\n",
    "    pos = dict()\n",
    "    for node in g.nodes():\n",
    "        pos[node] = pos_communities[node] + pos_nodes[node]\n",
    "\n",
    "    return pos\n",
    "\n",
    "def _position_communities(g, partition, **kwargs):\n",
    "\n",
    "    # create a weighted graph, in which each node corresponds to a community,\n",
    "    # and each edge weight to the number of edges between communities\n",
    "    between_community_edges = _find_between_community_edges(g, partition)\n",
    "\n",
    "    communities = set(partition.values())\n",
    "    hypergraph = nx.DiGraph()\n",
    "    hypergraph.add_nodes_from(communities)\n",
    "    for (ci, cj), edges in between_community_edges.items():\n",
    "        hypergraph.add_edge(ci, cj, weight=len(edges))\n",
    "\n",
    "    # find layout for communities\n",
    "    pos_communities = nx.spring_layout(hypergraph, **kwargs)\n",
    "\n",
    "    # set node positions to position of community\n",
    "    pos = dict()\n",
    "    for node, community in partition.items():\n",
    "        pos[node] = pos_communities[community]\n",
    "\n",
    "    return pos\n",
    "\n",
    "def _find_between_community_edges(g, partition):\n",
    "\n",
    "    edges = dict()\n",
    "\n",
    "    for (ni, nj) in g.edges():\n",
    "        ci = partition[ni]\n",
    "        cj = partition[nj]\n",
    "\n",
    "        if ci != cj:\n",
    "            try:\n",
    "                edges[(ci, cj)] += [(ni, nj)]\n",
    "            except KeyError:\n",
    "                edges[(ci, cj)] = [(ni, nj)]\n",
    "\n",
    "    return edges\n",
    "\n",
    "def _position_nodes(g, partition, **kwargs):\n",
    "    \"\"\"\n",
    "    Positions nodes within communities.\n",
    "    \"\"\"\n",
    "\n",
    "    communities = dict()\n",
    "    for node, community in partition.items():\n",
    "        try:\n",
    "            communities[community] += [node]\n",
    "        except KeyError:\n",
    "            communities[community] = [node]\n",
    "\n",
    "    pos = dict()\n",
    "    for ci, nodes in communities.items():\n",
    "        subgraph = g.subgraph(nodes)\n",
    "        pos_subgraph = nx.spring_layout(subgraph, **kwargs)\n",
    "        pos.update(pos_subgraph)\n",
    "\n",
    "    return pos\n",
    "\n",
    "def test(g):\n",
    "# to install networkx 2.0 compatible version of python-louvain use:\n",
    "    # pip install -U git+https://github.com/taynaud/python-louvain.git@networkx2\n",
    "    from community import community_louvain\n",
    "\n",
    "    #g = nx.karate_club_graph()\n",
    "    partition = community_louvain.best_partition(g)\n",
    "    print(partition)\n",
    "    pos = community_layout(g, partition)\n",
    "\n",
    "    #nx.draw(g, pos, node_color=list(dict_partition.values())); plt.show()\n",
    "\n",
    "    nodelist = g.nodes()\n",
    "    widths = nx.get_edge_attributes(g,'weight')\n",
    "    cmap = plt.cm.get_cmap('cool')#Spectral\n",
    "    maxval = 27\n",
    "    plt.figure(figsize=(7,7))\n",
    "    nx.draw_networkx_nodes(g,pos,nodelist=nodelist,node_size=100,\n",
    "                          node_color= [cmap(v/maxval) for v in partition.values()])#list(partition.values()))\n",
    "    print(list(partition.values()))\n",
    "    labels = [str(i) for i in range(78)]\n",
    "    #labels = ['healthy','moderately unhealthy','very unhealthy']\n",
    "    for v in set(partition.values()):\n",
    "        plt.scatter([],[],c=[cmap(v/maxval)],label=labels[v])\n",
    "\n",
    "    nx.draw_networkx_edges(g,pos,edgelist=widths.keys(),width=list(widths.values()),edge_color='k')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return partition\n",
    "\n",
    "partition = test(phi_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 152,
     "status": "aborted",
     "timestamp": 1689630833969,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "k6kotP0C2Ly0"
   },
   "outputs": [],
   "source": [
    "print(partition)\n",
    "values = [x for x in partition.values()]\n",
    "print(values)\n",
    "values = np.array(values)\n",
    "unique_partitions = np.unique(values)\n",
    "print(np.histogram(values,bins=23)[0])\n",
    "print(np.argwhere(values==4))\n",
    "print(np.argwhere(values==7))\n",
    "print(np.argwhere(values==1))\n",
    "print(np.argwhere(values==11))\n",
    "print(np.argwhere(values==12))\n",
    "print(np.argwhere(values==13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 153,
     "status": "aborted",
     "timestamp": 1689630833971,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "PiOwweQhF_nd"
   },
   "outputs": [],
   "source": [
    "#print(p2p.phis[15,:])\n",
    "print(np.max(p2p.phis))\n",
    "print(np.where(p2p.phis>=5))\n",
    "print(p2p.phis[14,64])\n",
    "print(p2p.phis[64,14])\n",
    "#print(np.where(p2p.phis>0))\n",
    "print(np.sum(p2p.phis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 153,
     "status": "aborted",
     "timestamp": 1689630833972,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "Bwep8PWt9QWu"
   },
   "outputs": [],
   "source": [
    "print(np.where(p2p.phis>=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1689631580653,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "noIzKFz-v4-F",
    "outputId": "b92743ca-5200-48ca-810d-a9ebbacc4904"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient  0\n",
      "N:  198\n",
      "V:  0\n",
      "S:  3\n",
      "F:  0\n",
      "patient  1\n",
      "N:  154\n",
      "V:  89\n",
      "S:  25\n",
      "F:  0\n",
      "patient  2\n",
      "N:  178\n",
      "V:  1\n",
      "S:  0\n",
      "F:  0\n",
      "patient  3\n",
      "N:  206\n",
      "V:  15\n",
      "S:  0\n",
      "F:  0\n",
      "patient  4\n",
      "N:  294\n",
      "V:  9\n",
      "S:  0\n",
      "F:  0\n",
      "patient  5\n",
      "N:  232\n",
      "V:  14\n",
      "S:  0\n",
      "F:  0\n",
      "patient  6\n",
      "N:  317\n",
      "V:  2\n",
      "S:  4\n",
      "F:  0\n",
      "patient  7\n",
      "N:  205\n",
      "V:  0\n",
      "S:  3\n",
      "F:  0\n",
      "patient  10\n",
      "N:  197\n",
      "V:  6\n",
      "S:  0\n",
      "F:  0\n",
      "patient  11\n",
      "N:  151\n",
      "V:  2\n",
      "S:  0\n",
      "F:  0\n",
      "patient  12\n",
      "N:  178\n",
      "V:  19\n",
      "S:  0\n",
      "F:  0\n",
      "patient  13\n",
      "N:  230\n",
      "V:  1\n",
      "S:  20\n",
      "F:  0\n",
      "patient  14\n",
      "N:  275\n",
      "V:  5\n",
      "S:  55\n",
      "F:  0\n",
      "patient  15\n",
      "N:  128\n",
      "V:  0\n",
      "S:  121\n",
      "F:  0\n",
      "patient  16\n",
      "N:  259\n",
      "V:  0\n",
      "S:  47\n",
      "F:  0\n",
      "patient  17\n",
      "N:  223\n",
      "V:  2\n",
      "S:  33\n",
      "F:  0\n",
      "patient  18\n",
      "N:  270\n",
      "V:  0\n",
      "S:  29\n",
      "F:  0\n",
      "patient  19\n",
      "N:  266\n",
      "V:  0\n",
      "S:  19\n",
      "F:  0\n",
      "patient  20\n",
      "N:  198\n",
      "V:  0\n",
      "S:  1\n",
      "F:  0\n",
      "patient  21\n",
      "N:  158\n",
      "V:  0\n",
      "S:  47\n",
      "F:  0\n",
      "patient  22\n",
      "N:  201\n",
      "V:  0\n",
      "S:  9\n",
      "F:  0\n",
      "patient  24\n",
      "N:  195\n",
      "V:  1\n",
      "S:  2\n",
      "F:  0\n",
      "patient  25\n",
      "N:  267\n",
      "V:  2\n",
      "S:  5\n",
      "F:  0\n",
      "patient  26\n",
      "N:  287\n",
      "V:  2\n",
      "S:  0\n",
      "F:  0\n",
      "patient  28\n",
      "N:  296\n",
      "V:  3\n",
      "S:  9\n",
      "F:  0\n",
      "patient  30\n",
      "N:  175\n",
      "V:  8\n",
      "S:  6\n",
      "F:  0\n",
      "patient  32\n",
      "N:  226\n",
      "V:  0\n",
      "S:  5\n",
      "F:  0\n",
      "patient  34\n",
      "N:  226\n",
      "V:  53\n",
      "S:  2\n",
      "F:  0\n",
      "patient  35\n",
      "N:  274\n",
      "V:  7\n",
      "S:  4\n",
      "F:  0\n",
      "patient  36\n",
      "N:  223\n",
      "V:  5\n",
      "S:  9\n",
      "F:  0\n",
      "patient  37\n",
      "N:  189\n",
      "V:  54\n",
      "S:  49\n",
      "F:  0\n",
      "patient  38\n",
      "N:  207\n",
      "V:  20\n",
      "S:  44\n",
      "F:  0\n",
      "patient  39\n",
      "N:  292\n",
      "V:  5\n",
      "S:  8\n",
      "F:  0\n",
      "patient  40\n",
      "N:  248\n",
      "V:  16\n",
      "S:  12\n",
      "F:  0\n",
      "patient  42\n",
      "N:  338\n",
      "V:  37\n",
      "S:  3\n",
      "F:  0\n",
      "patient  43\n",
      "N:  177\n",
      "V:  72\n",
      "S:  9\n",
      "F:  0\n",
      "patient  44\n",
      "N:  203\n",
      "V:  1\n",
      "S:  59\n",
      "F:  0\n",
      "patient  45\n",
      "N:  230\n",
      "V:  3\n",
      "S:  1\n",
      "F:  0\n",
      "patient  46\n",
      "N:  274\n",
      "V:  23\n",
      "S:  37\n",
      "F:  0\n",
      "patient  47\n",
      "N:  180\n",
      "V:  22\n",
      "S:  1\n",
      "F:  0\n",
      "patient  48\n",
      "N:  311\n",
      "V:  16\n",
      "S:  10\n",
      "F:  0\n",
      "patient  49\n",
      "N:  256\n",
      "V:  17\n",
      "S:  12\n",
      "F:  0\n",
      "patient  50\n",
      "N:  301\n",
      "V:  4\n",
      "S:  16\n",
      "F:  0\n",
      "patient  51\n",
      "N:  262\n",
      "V:  61\n",
      "S:  34\n",
      "F:  0\n",
      "patient  52\n",
      "N:  161\n",
      "V:  0\n",
      "S:  70\n",
      "F:  0\n",
      "patient  53\n",
      "N:  204\n",
      "V:  58\n",
      "S:  24\n",
      "F:  0\n",
      "patient  54\n",
      "N:  191\n",
      "V:  0\n",
      "S:  1\n",
      "F:  0\n",
      "patient  55\n",
      "N:  207\n",
      "V:  4\n",
      "S:  1\n",
      "F:  0\n",
      "patient  57\n",
      "N:  230\n",
      "V:  9\n",
      "S:  0\n",
      "F:  0\n",
      "patient  58\n",
      "N:  189\n",
      "V:  28\n",
      "S:  2\n",
      "F:  0\n",
      "patient  59\n",
      "N:  214\n",
      "V:  0\n",
      "S:  15\n",
      "F:  0\n",
      "patient  60\n",
      "N:  197\n",
      "V:  1\n",
      "S:  20\n",
      "F:  0\n",
      "patient  61\n",
      "N:  156\n",
      "V:  44\n",
      "S:  5\n",
      "F:  0\n",
      "patient  62\n",
      "N:  133\n",
      "V:  86\n",
      "S:  2\n",
      "F:  0\n",
      "patient  63\n",
      "N:  315\n",
      "V:  14\n",
      "S:  43\n",
      "F:  0\n",
      "patient  64\n",
      "N:  152\n",
      "V:  35\n",
      "S:  55\n",
      "F:  0\n",
      "patient  65\n",
      "N:  203\n",
      "V:  0\n",
      "S:  4\n",
      "F:  0\n",
      "patient  66\n",
      "N:  186\n",
      "V:  1\n",
      "S:  7\n",
      "F:  0\n",
      "patient  67\n",
      "N:  294\n",
      "V:  12\n",
      "S:  2\n",
      "F:  0\n",
      "patient  68\n",
      "N:  170\n",
      "V:  8\n",
      "S:  31\n",
      "F:  0\n",
      "patient  70\n",
      "N:  257\n",
      "V:  30\n",
      "S:  0\n",
      "F:  0\n",
      "patient  71\n",
      "N:  233\n",
      "V:  8\n",
      "S:  7\n",
      "F:  0\n",
      "patient  72\n",
      "N:  166\n",
      "V:  4\n",
      "S:  13\n",
      "F:  0\n",
      "patient  73\n",
      "N:  217\n",
      "V:  15\n",
      "S:  0\n",
      "F:  0\n",
      "patient  74\n",
      "N:  223\n",
      "V:  22\n",
      "S:  33\n",
      "F:  0\n",
      "patient  75\n",
      "N:  179\n",
      "V:  57\n",
      "S:  68\n",
      "F:  0\n",
      "patient  76\n",
      "N:  247\n",
      "V:  23\n",
      "S:  0\n",
      "F:  0\n",
      "patient  77\n",
      "N:  235\n",
      "V:  7\n",
      "S:  9\n",
      "F:  0\n",
      "healthy patients:  [808, 809, 840, 844, 846, 848, 850, 858, 873, 886]\n",
      "moderately unhealthy patients:  [800, 802, 804, 806, 807, 810, 811, 827, 829, 841, 842, 843, 849, 862, 871, 872, 874, 882, 883]\n",
      "very unhealthy patients:  [801, 803, 805, 812, 820, 821, 822, 823, 824, 825, 826, 828, 845, 847, 851, 852, 853, 854, 855, 856, 857, 859, 860, 861, 863, 864, 865, 866, 867, 868, 869, 870, 875, 876, 877, 878, 879, 880, 881, 884, 885, 887, 888, 889, 890, 891, 892, 893, 894]\n"
     ]
    }
   ],
   "source": [
    "patients_healthy = []\n",
    "patients_unhealthy = []\n",
    "patients_really_unhealthy = []\n",
    "for i in range(len(patients_left)):\n",
    "\n",
    "    mit_bih = MIT_BIH([patients_left[i]],data_beats_train)\n",
    "    #print('train ',torch.sum(mit_bih.y).numpy()/len(mit_bih.y))\n",
    "    fraction_train = torch.sum(mit_bih.y).numpy()/len(mit_bih.y)\n",
    "    mit_bih = MIT_BIH([patients_left[i]],data_beats_test)\n",
    "    #print('test ',torch.sum(mit_bih.y).numpy()/len(mit_bih.y))\n",
    "    fraction_test = torch.sum(mit_bih.y).numpy()/len(mit_bih.y)\n",
    "    if fraction_train == 0:\n",
    "        patients_healthy.append(patients_left[i])\n",
    "    else:\n",
    "        print('patient ',i)\n",
    "        print('N: ',np.count_nonzero(data_beats_train[patients_left[i]]['class']=='N'))\n",
    "        print('V: ',np.count_nonzero(data_beats_train[patients_left[i]]['class']=='V'))\n",
    "        V = np.count_nonzero(data_beats_train[patients_left[i]]['class']=='V')\n",
    "        S = np.count_nonzero(data_beats_train[patients_left[i]]['class']=='S')\n",
    "        F = np.count_nonzero(data_beats_train[patients_left[i]]['class']=='F')\n",
    "        print('S: ',np.count_nonzero(data_beats_train[patients_left[i]]['class']=='S'))\n",
    "        print('F: ',np.count_nonzero(data_beats_train[patients_left[i]]['class']=='F'))\n",
    "        if V + S + F >= 10:\n",
    "          patients_really_unhealthy.append(patients_left[i])\n",
    "        else:\n",
    "          patients_unhealthy.append(patients_left[i])\n",
    "print('healthy patients: ',patients_healthy)\n",
    "print('moderately unhealthy patients: ',patients_unhealthy)\n",
    "print('very unhealthy patients: ',patients_really_unhealthy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 153,
     "status": "aborted",
     "timestamp": 1689630833974,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "Ifg5yp_kwUPi"
   },
   "outputs": [],
   "source": [
    "patients_healthy = []\n",
    "for i in range(len(patients_left)):\n",
    "\n",
    "    print('patient ',i)\n",
    "    print('N: ',np.count_nonzero(data_beats[patients_left[i]]['class']=='N'))\n",
    "    print('V: ',np.count_nonzero(data_beats[patients_left[i]]['class']=='V'))\n",
    "    print('S: ',np.count_nonzero(data_beats[patients_left[i]]['class']=='S'))\n",
    "    print('F: ',np.count_nonzero(data_beats[patients_left[i]]['class']=='F'))\n",
    "print('healthy patients: ',patients_healthy)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNgGa4yshAUa84ITihKtTaw",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
