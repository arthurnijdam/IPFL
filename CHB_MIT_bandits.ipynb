{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae002a63",
   "metadata": {},
   "source": [
    "Todo: (Sunday?) \n",
    "\n",
    "* Fix the seed and repeat the two experiments \n",
    "* Put this code into bandits code and run APFL, FedAvg and Bandits \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef194b8",
   "metadata": {},
   "source": [
    "### Client collaboration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cddff8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandits\n",
      "local\n",
      "[98.13953488 94.85714286 90.         72.91338583 91.30952381 50.55555556\n",
      " 87.95180723 91.35802469 98.08219178 94.14965986 96.05633803 49.\n",
      " 67.14285714 79.06976744 88.3882149  63.84615385 92.8358209  95.34246575\n",
      " 93.71428571 84.72727273 62.96296296 97.81818182 81.70542636]\n",
      "better:  [2, 3, 4, 5, 6, 8, 9, 12, 14, 15, 18, 19, 20, 21, 22]\n",
      "8.375439789258474\n",
      "9.978761011436283\n",
      "worse:  [7, 10, 11, 13, 16, 17]\n",
      "5.207151930757796\n",
      "5.043131857280052\n",
      "same:  [0, 1]\n"
     ]
    }
   ],
   "source": [
    "#FL\n",
    "import os \n",
    "experiments = ['CHB_bandits_10_1','CHB_bandits_10_2','CHB_bandits_10_3','CHB_bandits_10_4','CHB_bandits_10_5']\n",
    "print('bandits')\n",
    "accuracies = np.zeros((5,23))\n",
    "for i,experiment in enumerate(experiments): \n",
    "    accuracies[i,:] = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracies.txt'))\n",
    "accuracies_bandits = np.mean(accuracies,axis=0)\n",
    "#FL\n",
    "experiments = ['CHB_local_1','CHB_local_2','CHB_local_3','CHB_local_4','CHB_local_5']\n",
    "print('local')\n",
    "accuracies = np.zeros((5,23))\n",
    "for i,experiment in enumerate(experiments): \n",
    "    accuracies[i,:] = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracies.txt'))\n",
    "accuracies_local = np.mean(accuracies,axis=0)\n",
    "print(accuracies_local)\n",
    "better = []\n",
    "how_better = []\n",
    "worse = []\n",
    "how_worse = []\n",
    "same = []\n",
    "for i in range(len(accuracies_bandits)):\n",
    "    if accuracies_local[i]<accuracies_bandits[i]:\n",
    "        better.append(i)\n",
    "        how_better.append(accuracies_bandits[i]-accuracies_local[i])\n",
    "    if accuracies_local[i]>accuracies_bandits[i]:\n",
    "        worse.append(i)\n",
    "        how_worse.append(accuracies_local[i]-accuracies_bandits[i])\n",
    "    if accuracies_local[i]==accuracies_bandits[i]:\n",
    "        same.append(i)\n",
    "print('better: ',better)\n",
    "print(np.mean(how_better))\n",
    "print(np.std(how_better))\n",
    "print('worse: ',worse)\n",
    "print(np.mean(how_worse))\n",
    "print(np.std(how_worse))\n",
    "print('same: ',same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "106d0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.0\n",
      "5.0\n",
      "51.0\n",
      "18.0\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "A = []\n",
    "N = []\n",
    "for patient in same: #,24):\n",
    "    # Hyper parameters\n",
    "    num_epochs = 10\n",
    "    num_classes = 2\n",
    "    learning_rate = 0.005\n",
    "    \n",
    "    filepath = '/mimer/NOBACKUP/groups/snic2022-22-122/arthur/'\n",
    "    train_dataset = CustomDataset(filepath,patient+1,10,'train')\n",
    "    labels = train_dataset.labels\n",
    "    A.append(np.sum(labels==1.))\n",
    "    N.append(len(labels)-np.sum(labels==1.))\n",
    "print(np.mean(A))\n",
    "print(np.std(A))\n",
    "print(np.mean(N))\n",
    "print(np.std(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c16964f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.99153140437544\n",
      "84.65067043048694\n",
      "85.7092448835568\n",
      "85.63867325335215\n",
      "85.63867325335215\n",
      "89.41425546930134\n",
      "87.89696541990119\n",
      "88.60268172194777\n",
      "88.60268172194777\n",
      "89.27311220889203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy (%)')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "ax = plt.gca()\n",
    "experiments = ['CHB_MIT_local_1','CHB_MIT_local_2',\n",
    "               'CHB_MIT_local_3','CHB_MIT_local_4','CHB_MIT_local_5'\n",
    "              ,'CHB_MIT_federated_1','CHB_MIT_federated_2','CHB_MIT_federated_3','CHB_MIT_federated_4','CHB_MIT_federated_5']\n",
    "labels = ['local 1','local 2','local 3','local 4','local 5','bandits 1','bandits 2','bandits 3','bandits 4','bandits 5']\n",
    "for i,experiment in enumerate(experiments): \n",
    "    accuracies = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'accuracies.txt'))\n",
    "    plt.plot(accuracies,label=labels[i]);\n",
    "    print(np.max(accuracies))\n",
    "plt.legend()\n",
    "ax.set_ylim([50,91])\n",
    "ax.set_title('accuracy for different ' +r'$\\zeta$')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('accuracy (%)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64629ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy local:  84.94707127734651\n",
      "accuracy mine:  87.22653493295695\n",
      "accuracy local:  [98.4496124  93.14285714 88.03921569 74.80314961 91.42857143 87.71084337\n",
      " 92.09876543 98.08219178 92.24489796 96.15023474 49.71428571 68.83116883\n",
      " 89.01213172 92.8358209  95.34246575 94.57142857 82.54545455 64.07407407\n",
      " 98.54545455 85.11627907]\n",
      "accuracy mine:  [97.05426357 96.57142857 94.31372549 85.19685039 91.66666667 87.71084337\n",
      " 89.5473251  98.08219178 95.51020408 95.68075117 54.85714286 83.63636364\n",
      " 89.53206239 87.76119403 87.67123288 98.         80.36363636 80.37037037\n",
      " 99.63636364 89.6124031 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(45.0, 100.0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGiCAYAAADNzj2mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoFUlEQVR4nO3df1TUdb7H8dcEMoJLbP5imAQkIy01M+2a6A0qpVzzR3RTox+41j16tBLb1My6zbYrKK1kxWZXr+uiXq+dPaW5tQW4G5THm+KvlliP2pWrqMxycwlQWVD43j9cpwjLH/Md/Yw+H+fMOfGdLy/eEl95+fl+vzMOy7IsAQAAGOSqSz0AAADAd1FQAACAcSgoAADAOBQUAABgHAoKAAAwDgUFAAAYh4ICAACMQ0EBAADGoaAAAADjUFAAAIBxzrugfPLJJxo1apTcbrccDofWrVvX6nnLsuTxeOR2uxUeHq6UlBSVl5e32qexsVFPPfWUOnfurA4dOmj06NE6ePCgX38QAABw+TjvgnLs2DH169dPeXl5Z3w+JydHubm5ysvLU2lpqVwul4YPH676+nrfPpmZmVq7dq3WrFmjjRs36ujRo7rvvvvU3Nx84X8SAABw2XD482aBDodDa9eu1dixYyWdWj1xu93KzMzU7NmzJZ1aLYmOjtaCBQs0efJk1dbWqkuXLlq5cqXGjx8vSTp8+LBiY2P1hz/8Qffcc4//fyoAABDUQu0Mq6iokNfrVWpqqm+b0+lUcnKyNm3apMmTJ2vbtm06ceJEq33cbrf69OmjTZs2nbGgNDY2qrGx0fdxS0uL/va3v6lTp05yOBx2/hEAAECAWJal+vp6ud1uXXXVD5/EsbWgeL1eSVJ0dHSr7dHR0dq/f79vn7CwMF1zzTVt9jn9+d+VnZ2tn//853aOCgAALpHKykp169btB/extaCc9t1VDcuyzrrS8UP7zJkzR88884zv49raWsXFxamyslJXX321/wMDAICAq6urU2xsrCIjI8+6r60FxeVySTq1ShITE+PbXl1d7VtVcblcampqUk1NTatVlOrqaiUlJZ0x1+l0yul0ttl+9dVXU1AAAMHH4zEr5yI7l8szbH0dlISEBLlcLhUVFfm2NTU1qaSkxFc+BgwYoHbt2rXap6qqSl988cX3FhQAAHBlOe8VlKNHj+rLL7/0fVxRUaGdO3eqY8eOiouLU2ZmprKyspSYmKjExERlZWUpIiJC6enpkqSoqCg9/vjj+tnPfqZOnTqpY8eOevbZZ9W3b18NGzbMvj8ZAAAIWuddULZu3ao777zT9/Hpa0MyMjL029/+VrNmzVJDQ4OmTp2qmpoaDRo0SIWFha3ON7366qsKDQ3VuHHj1NDQoLvvvlu//e1vFRISYsMfCQAABDu/XgflUqmrq1NUVJRqa2u5BgUAEHyu0GtQzuf3N+/FAwAAjENBAQAAxgnI66AAAIDvV1xsT06KPTFGoqCcwRV6ahAAAGNwigcAABiHggIAAIzDKR7AIMUpHtuyUortywL8Yuf5bs6dXzFYQQEAAMahoAAAAONQUAAAgHEoKAAAwDgUFAAAYBzu4jkD++5+sCsHAIArCysoAADAOBQUAABgHAoKAAAwDtegXGy8EyEAAGfFCgoAADAOBQUAABiHUzwA/MaZSwB2YwUFAAAYh4ICAACMwykeAH7j1ZcB2I2CAlwpuFAEQBChoAAAJNFhYRauQQEAAMahoAAAAONQUAAAgHEoKAAAwDhcJAsACKjiYvuyUuyLguFYQQEAAMZhBeVyYed9fdwjCAC4xFhBAQAAxqGgAAAA41BQAACAcSgoAADAOBQUAABgHAoKAAAwDgUFAAAYh9dBucjsekXFFHtiAAAwEisoAADAOKygAEAQseuFnnnBaJiOFRQAAGAcCgoAADAOBQUAABiHa1CAKwR3kAEIJhQU4AJwoSIABBaneAAAgHEoKAAAwDic4sGlxbkSAMAZUFBwSXHhJgDgTDjFAwAAjENBAQAAxqGgAAAA41BQAACAcSgoAADAOAEpKPX19crMzFR8fLzCw8OVlJSk0tJS3/OWZcnj8cjtdis8PFwpKSkqLy8PxCgAACAIBaSgPPHEEyoqKtLKlStVVlam1NRUDRs2TIcOHZIk5eTkKDc3V3l5eSotLZXL5dLw4cNVX18fiHEAAECQsb2gNDQ06J133lFOTo7uuOMOXX/99fJ4PEpISNDixYtlWZYWLVqkuXPnKi0tTX369FF+fr6OHz+u1atX2z0OAAAIQrYXlJMnT6q5uVnt27dvtT08PFwbN25URUWFvF6vUlNTfc85nU4lJydr06ZNZ8xsbGxUXV1dqwcAALh82V5QIiMjNXjwYP3iF7/Q4cOH1dzcrFWrVmnz5s2qqqqS1+uVJEVHR7f6vOjoaN9z35Wdna2oqCjfIzY21u6xAQCAQQJyDcrKlStlWZauvfZaOZ1Ovf7660pPT1dISIhvH4fD0epzLMtqs+20OXPmqLa21veorKwMxNgAAMAQAXkvnh49eqikpETHjh1TXV2dYmJiNH78eCUkJMjlckmSvF6vYmJifJ9TXV3dZlXlNKfTKafTGYhRAQC4vFwmb8Ia0DcL7NChgzp06KCamhoVFBQoJyfHV1KKiorUv39/SVJTU5NKSkq0YMGCQI4D2Cal2GNTkl05MMpl8gsCuJQCUlAKCgpkWZZ69uypL7/8UjNnzlTPnj3105/+VA6HQ5mZmcrKylJiYqISExOVlZWliIgIpaenB2IcAAAQZAJSUGprazVnzhwdPHhQHTt21AMPPKB58+apXbt2kqRZs2apoaFBU6dOVU1NjQYNGqTCwkJFRkYGYhwAABBkAlJQxo0bp3Hjxn3v8w6HQx6PRx6WLwEAwBkE9BoUALgSFRfbk5NiTwwQlHizQAAAYBwKCgAAMA4FBQAAGIeCAgAAjENBAQAAxuEunsuEXXcNSNw5AAC49FhBAQAAxmEFBZet4hSPLTn2ve8O4D/eBwpXCgoKAEAS5Qdm4RQPAAAwDgUFAAAYh4ICAACMQ0EBAADGoaAAAADjUFAAAIBxKCgAAMA4FBQAAGAcCgoAADAOBQUAABiHggIAAIxDQQEAAMahoAAAAONQUAAAgHEoKAAAwDihl3oABAGPx6wcAMBlj4ICAMBlpLjYnpwUe2IuGKd4AACAcSgoAADAOBQUAABgHAoKAAAwDgUFAAAYh4ICAACMQ0EBAADGoaAAAADjUFAAAIBxeCVZAFcmO996gbdxAGzHCgoAADAOBQUAABiHggIAAIxDQQEAAMahoAAAAONQUAAAgHG4zRgAELTsusObO8XNwwoKAAAwDgUFAAAYh4ICAACMQ0EBAADGoaAAAADjUFAAAIBxKCgAAMA4FBQAAGAcCgoAADAOBQUAABiHggIAAIxDQQEAAMaxvaCcPHlSL7zwghISEhQeHq7rrrtOL7/8slpaWnz7WJYlj8cjt9ut8PBwpaSkqLy83O5RAABAkLK9oCxYsEBvvfWW8vLytGvXLuXk5OiVV17RG2+84dsnJydHubm5ysvLU2lpqVwul4YPH676+nq7xwEAAEEo1O7A//7v/9aYMWM0cuRISVL37t31X//1X9q6daukU6snixYt0ty5c5WWliZJys/PV3R0tFavXq3JkyfbPRIA4DKVUuyxKekMOR6bsu3KucLYvoIydOhQ/fGPf9SePXskSZ9//rk2btyon/zkJ5KkiooKeb1epaam+j7H6XQqOTlZmzZtOmNmY2Oj6urqWj0AAMDly/YVlNmzZ6u2tla9evVSSEiImpubNW/ePD300EOSJK/XK0mKjo5u9XnR0dHav3//GTOzs7P185//3O5RAQCAoWxfQXn77be1atUqrV69Wtu3b1d+fr5+9atfKT8/v9V+Doej1ceWZbXZdtqcOXNUW1vre1RWVto9NgAAMIjtKygzZ87Uc889pwkTJkiS+vbtq/379ys7O1sZGRlyuVySTq2kxMTE+D6vurq6zarKaU6nU06n0+5RAQCAoWxfQTl+/Liuuqp1bEhIiO8244SEBLlcLhUVFfmeb2pqUklJiZKSkuweBwAABCHbV1BGjRqlefPmKS4uTr1799aOHTuUm5urSZMmSTp1aiczM1NZWVlKTExUYmKisrKyFBERofT0dLvHAQAAQcj2gvLGG2/oxRdf1NSpU1VdXS23263Jkyfr3/7t33z7zJo1Sw0NDZo6dapqamo0aNAgFRYWKjIy0u5xAABAELK9oERGRmrRokVatGjR9+7jcDjk8Xjk4d5wAABwBrwXDwAAMA4FBQAAGIeCAgAAjENBAQAAxqGgAAAA41BQAACAcSgoAADAOBQUAABgHAoKAAAwDgUFAAAYh4ICAACMQ0EBAADGoaAAAADjUFAAAIBxKCgAAMA4FBQAAGAcCgoAADAOBQUAABiHggIAAIxDQQEAAMahoAAAAONQUAAAgHEoKAAAwDgUFAAAYBwKCgAAMA4FBQAAGIeCAgAAjENBAQAAxgm91APAfMXF9uSk2BMDALgCsIICAACMQ0EBAADGoaAAAADjUFAAAIBxKCgAAMA4FBQAAGAcCgoAADAOBQUAABiHggIAAIxDQQEAAMahoAAAAONQUAAAgHEoKAAAwDgUFAAAYBwKCgAAMA4FBQAAGIeCAgAAjENBAQAAxqGgAAAA41BQAACAcSgoAADAOBQUAABgHAoKAAAwDgUFAAAYh4ICAACMQ0EBAADGoaAAAADjUFAAAIBxbC8o3bt3l8PhaPOYNm2aJMmyLHk8HrndboWHhyslJUXl5eV2jwEAAIKY7QWltLRUVVVVvkdRUZEk6cEHH5Qk5eTkKDc3V3l5eSotLZXL5dLw4cNVX19v9ygAACBI2V5QunTpIpfL5Xu8//776tGjh5KTk2VZlhYtWqS5c+cqLS1Nffr0UX5+vo4fP67Vq1d/b2ZjY6Pq6upaPQAAwOUroNegNDU1adWqVZo0aZIcDocqKirk9XqVmprq28fpdCo5OVmbNm363pzs7GxFRUX5HrGxsYEcGwAAXGIBLSjr1q3T119/rYkTJ0qSvF6vJCk6OrrVftHR0b7nzmTOnDmqra31PSorKwM2MwAAuPRCAxm+bNkyjRgxQm63u9V2h8PR6mPLstps+zan0ymn0xmQGQEAgHkCtoKyf/9+bdiwQU888YRvm8vlkqQ2qyXV1dVtVlUAAMCVK2AFZfny5eratatGjhzp25aQkCCXy+W7s0c6dZ1KSUmJkpKSAjUKAAAIMgE5xdPS0qLly5crIyNDoaHffAmHw6HMzExlZWUpMTFRiYmJysrKUkREhNLT0wMxCgAACEIBKSgbNmzQgQMHNGnSpDbPzZo1Sw0NDZo6dapqamo0aNAgFRYWKjIyMhCjAACAIBSQgpKamirLss74nMPhkMfjkcfjCcSXBgAAl4GA3sUDAKYqLrYvK8W+KAD/wJsFAgAA41BQAACAcSgoAADAOBQUAABgHAoKAAAwDgUFAAAYh4ICAACMQ0EBAADGoaAAAADjUFAAAIBxKCgAAMA4FBQAAGAcCgoAADAOBQUAABiHggIAAIxDQQEAAMahoAAAAONQUAAAgHEoKAAAwDgUFAAAYBwKCgAAMA4FBQAAGIeCAgAAjENBAQAAxqGgAAAA41BQAACAcSgoAADAOBQUAABgHAoKAAAwDgUFAAAYh4ICAACME3qpBwAAwETFxfbkpNgTc8VhBQUAABiHggIAAIxDQQEAAMahoAAAAONQUAAAgHEoKAAAwDgUFAAAYBwKCgAAMA4FBQAAGIeCAgAAjENBAQAAxqGgAAAA41BQAACAcSgoAADAOBQUAABgHAoKAAAwDgUFAAAYh4ICAACMQ0EBAADGoaAAAADjUFAAAIBxKCgAAMA4FBQAAGCcgBSUQ4cO6ZFHHlGnTp0UERGhW265Rdu2bfM9b1mWPB6P3G63wsPDlZKSovLy8kCMAgAAgpDtBaWmpkZDhgxRu3bt9OGHH+ovf/mLFi5cqB//+Me+fXJycpSbm6u8vDyVlpbK5XJp+PDhqq+vt3scAAAQhELtDlywYIFiY2O1fPly37bu3bv7/tuyLC1atEhz585VWlqaJCk/P1/R0dFavXq1Jk+e3CazsbFRjY2Nvo/r6ursHhsAABjE9hWU9evXa+DAgXrwwQfVtWtX9e/fX0uXLvU9X1FRIa/Xq9TUVN82p9Op5ORkbdq06YyZ2dnZioqK8j1iY2PtHhsAABjE9oKyb98+LV68WImJiSooKNCUKVP09NNPa8WKFZIkr9crSYqOjm71edHR0b7nvmvOnDmqra31PSorK+0eGwAAGMT2UzwtLS0aOHCgsrKyJEn9+/dXeXm5Fi9erMcee8y3n8PhaPV5lmW12Xaa0+mU0+m0e1QAAGAo21dQYmJidNNNN7XaduONN+rAgQOSJJfLJUltVkuqq6vbrKoAAIArk+0FZciQIdq9e3erbXv27FF8fLwkKSEhQS6XS0VFRb7nm5qaVFJSoqSkJLvHAQAAQcj2UzwzZsxQUlKSsrKyNG7cOG3ZskVLlizRkiVLJJ06tZOZmamsrCwlJiYqMTFRWVlZioiIUHp6ut3jAACAIGR7Qbntttu0du1azZkzRy+//LISEhK0aNEiPfzww759Zs2apYaGBk2dOlU1NTUaNGiQCgsLFRkZafc4AAAgCNleUCTpvvvu03333fe9zzscDnk8Hnk8nkB8eQAAEOR4Lx4AAGAcCgoAADAOBQUAABiHggIAAIxDQQEAAMahoAAAAONQUAAAgHEoKAAAwDgUFAAAYBwKCgAAMA4FBQAAGIeCAgAAjENBAQAAxqGgAAAA41BQAACAcSgoAADAOBQUAABgHAoKAAAwDgUFAAAYh4ICAACMQ0EBAADGoaAAAADjUFAAAIBxKCgAAMA4FBQAAGAcCgoAADAOBQUAABgn9FIPAAA/yOMxKwfARcEKCgAAMA4FBQAAGIeCAgAAjENBAQAAxqGgAAAA41BQAACAcSgoAADAOBQUAABgHAoKAAAwDgUFAAAYh4ICAACMQ0EBAADGoaAAAADjUFAAAIBxKCgAAMA4FBQAAGAcCgoAADAOBQUAABiHggIAAIxDQQEAAMahoAAAAONQUAAAgHEoKAAAwDgUFAAAYBwKCgAAMA4FBQAAGIeCAgAAjENBAQAAxrG9oHg8HjkcjlYPl8vle96yLHk8HrndboWHhyslJUXl5eV2jwEAAIJYQFZQevfuraqqKt+jrKzM91xOTo5yc3OVl5en0tJSuVwuDR8+XPX19YEYBQAABKGAFJTQ0FC5XC7fo0uXLpJOrZ4sWrRIc+fOVVpamvr06aP8/HwdP35cq1evDsQoAAAgCAWkoOzdu1dut1sJCQmaMGGC9u3bJ0mqqKiQ1+tVamqqb1+n06nk5GRt2rTpe/MaGxtVV1fX6gEAAC5ftheUQYMGacWKFSooKNDSpUvl9XqVlJSkI0eOyOv1SpKio6NbfU50dLTvuTPJzs5WVFSU7xEbG2v32AAAwCC2F5QRI0bogQceUN++fTVs2DB98MEHkqT8/HzfPg6Ho9XnWJbVZtu3zZkzR7W1tb5HZWWl3WMDAACDhAb6C3To0EF9+/bV3r17NXbsWEmS1+tVTEyMb5/q6uo2qyrf5nQ65XQ6Az0qAAMVF9uTk2JPDICLJOCvg9LY2Khdu3YpJiZGCQkJcrlcKioq8j3f1NSkkpISJSUlBXoUAAAQJGxfQXn22Wc1atQoxcXFqbq6Wr/85S9VV1enjIwMORwOZWZmKisrS4mJiUpMTFRWVpYiIiKUnp5u9ygAACBI2V5QDh48qIceekhfffWVunTpottvv12fffaZ4uPjJUmzZs1SQ0ODpk6dqpqaGg0aNEiFhYWKjIy0exQAABCkbC8oa9as+cHnHQ6HPB6PPB6P3V8aAABcJngvHgAAYBwKCgAAMA4FBQAAGIeCAgAAjENBAQAAxqGgAAAA41BQAACAcSgoAADAOBQUAABgHAoKAAAwDgUFAAAYh4ICAACMQ0EBAADGoaAAAADjUFAAAIBxKCgAAMA4FBQAAGAcCgoAADAOBQUAABiHggIAAIxDQQEAAMahoAAAAONQUAAAgHEoKAAAwDgUFAAAYJzQSz3AhbAsS5JUV1cXkPxjJxttyTnTfIHKtis3kNkX8/sRrNn8f+R7/UO5wZrN9/ryybYr8/Tv8R/isM5lL8McPHhQsbGxl3oMAABwASorK9WtW7cf3CcoC0pLS4sOHz6syMhIORyOi/716+rqFBsbq8rKSl199dVXfHYwzhys2cE4M9kXL5fsi5dL9oWxLEv19fVyu9266qofvsokKE/xXHXVVWdtXhfD1VdfHbD/ucGYHYwzB2t2MM5M9sXLJfvi5ZJ9/qKios5pPy6SBQAAxqGgAAAA41BQLoDT6dRLL70kp9NJdgBzyb54uWRf3OxgnDlYs4Nx5mDOtlNQXiQLAAAub6ygAAAA41BQAACAcSgoAADAOBQUAABgHAoKAAAwDgXlPL355ptKSEhQ+/btNWDAAH366ae25H7yyScaNWqU3G63HA6H1q1bZ0tudna2brvtNkVGRqpr164aO3asdu/ebUv24sWLdfPNN/tejXDw4MH68MMPbcn+tuzsbDkcDmVmZvqd5fF45HA4Wj1cLpf/Q/7DoUOH9Mgjj6hTp06KiIjQLbfcom3btvmd27179zZzOxwOTZs2ze/skydP6oUXXlBCQoLCw8N13XXX6eWXX1ZLS4vf2fX19crMzFR8fLzCw8OVlJSk0tLS88452/FhWZY8Ho/cbrfCw8OVkpKi8vJyW7Lfffdd3XPPPercubMcDod27txpy9wnTpzQ7Nmz1bdvX3Xo0EFut1uPPfaYDh8+bMvcHo9HvXr1UocOHXTNNddo2LBh2rx5sy3Z3zZ58mQ5HA4tWrTI79yJEye2+Rm//fbbbZt5165dGj16tKKiohQZGanbb79dBw4c8Dv7TMemw+HQK6+84nf20aNH9eSTT6pbt24KDw/XjTfeqMWLF/ud+9e//lUTJ06U2+1WRESE7r33Xu3du/esuRcTBeU8vP3228rMzNTcuXO1Y8cO/fM//7NGjBhxTj/gZ3Ps2DH169dPeXl5Nkz6jZKSEk2bNk2fffaZioqKdPLkSaWmpurYsWN+Z3fr1k3z58/X1q1btXXrVt11110aM2bMOf9iOBelpaVasmSJbr75Ztsye/furaqqKt+jrKzMltyamhoNGTJE7dq104cffqi//OUvWrhwoX784x/7nV1aWtpq5qKiIknSgw8+6Hf2ggUL9NZbbykvL0+7du1STk6OXnnlFb3xxht+Zz/xxBMqKirSypUrVVZWptTUVA0bNkyHDh06r5yzHR85OTnKzc1VXl6eSktL5XK5NHz4cNXX1/udfezYMQ0ZMkTz588/r5nPln38+HFt375dL774orZv3653331Xe/bs0ejRo/3OlqQbbrhBeXl5Kisr08aNG9W9e3elpqbq//7v//zOPm3dunXavHmz3G63LTNL0r333tvqZ/0Pf/iDLdn/8z//o6FDh6pXr14qLi7W559/rhdffFHt27f3O/vb81ZVVek3v/mNHA6HHnjgAb+zZ8yYoY8++kirVq3Srl27NGPGDD311FN67733LjjXsiyNHTtW+/bt03vvvacdO3YoPj5ew4YNs+V3g20snLN/+qd/sqZMmdJqW69evaznnnvO1q8jyVq7dq2tmadVV1dbkqySkpKA5F9zzTXWf/zHf9iSVV9fbyUmJlpFRUVWcnKyNX36dL8zX3rpJatfv35+55zJ7NmzraFDhwYk+7umT59u9ejRw2ppafE7a+TIkdakSZNabUtLS7MeeeQRv3KPHz9uhYSEWO+//36r7f369bPmzp17wbnfPT5aWlosl8tlzZ8/37ft73//uxUVFWW99dZbfmV/W0VFhSXJ2rFjxwVMfW7H9ZYtWyxJ1v79+23Prq2ttSRZGzZssCX74MGD1rXXXmt98cUXVnx8vPXqq6/6nZuRkWGNGTPmvHLONXv8+PF+/0x/X/Z3jRkzxrrrrrtsye7du7f18ssvt9p26623Wi+88MIF5+7evduSZH3xxRe+bSdPnrQ6duxoLV269LznDhRWUM5RU1OTtm3bptTU1FbbU1NTtWnTpks01fmrra2VJHXs2NHW3ObmZq1Zs0bHjh3T4MGDbcmcNm2aRo4cqWHDhtmSd9revXvldruVkJCgCRMmaN++fbbkrl+/XgMHDtSDDz6orl27qn///lq6dKkt2d/W1NSkVatWadKkSba8m/fQoUP1xz/+UXv27JEkff7559q4caN+8pOf+JV78uRJNTc3t/kXanh4uDZu3OhX9rdVVFTI6/W2OjadTqeSk5OD6tiUTh2fDofDllW3b2tqatKSJUsUFRWlfv36+Z3X0tKiRx99VDNnzlTv3r1tmPAbxcXF6tq1q2644Qb967/+q6qrq/3ObGlp0QcffKAbbrhB99xzj7p27apBgwbZdir92/7617/qgw8+0OOPP25L3tChQ7V+/XodOnRIlmXp448/1p49e3TPPfdccGZjY6MktTo2Q0JCFBYWZuux6S8Kyjn66quv1NzcrOjo6Fbbo6Oj5fV6L9FU58eyLD3zzDMaOnSo+vTpY0tmWVmZfvSjH8npdGrKlClau3atbrrpJr9z16xZo+3btys7O9uGKb8xaNAgrVixQgUFBVq6dKm8Xq+SkpJ05MgRv7P37dunxYsXKzExUQUFBZoyZYqefvpprVixwobJv7Fu3Tp9/fXXmjhxoi15s2fP1kMPPaRevXqpXbt26t+/vzIzM/XQQw/5lRsZGanBgwfrF7/4hQ4fPqzm5matWrVKmzdvVlVVlS2zS/Idf8F8bErS3//+dz333HNKT0+37R1m33//ff3oRz9S+/bt9eqrr6qoqEidO3f2O3fBggUKDQ3V008/bcOU3xgxYoT+8z//U3/605+0cOFClZaW6q677vL9Qr1Q1dXVOnr0qObPn697771XhYWFuv/++5WWlqaSkhKbpj8lPz9fkZGRSktLsyXv9ddf10033aRu3bopLCxM9957r958800NHTr0gjN79eql+Ph4zZkzRzU1NWpqatL8+fPl9XptPTb9FXqpBwg23/0Xq2VZtvwr9mJ48skn9ec//9nWhtyzZ0/t3LlTX3/9td555x1lZGSopKTEr5JSWVmp6dOnq7Cw8JzOD5+PESNG+P67b9++Gjx4sHr06KH8/Hw988wzfmW3tLRo4MCBysrKkiT1799f5eXlWrx4sR577DG/sr9t2bJlGjFixDmf9z+bt99+W6tWrdLq1avVu3dv7dy5U5mZmXK73crIyPAre+XKlZo0aZKuvfZahYSE6NZbb1V6erq2b99uy+zfFszH5okTJzRhwgS1tLTozTfftC33zjvv1M6dO/XVV19p6dKlGjdunDZv3qyuXbtecOa2bdv02muvafv27bZ/f8ePH+/77z59+mjgwIGKj4/XBx984Ncv/NMXfI8ZM0YzZsyQJN1yyy3atGmT3nrrLSUnJ/s3+Lf85je/0cMPP2zb312vv/66PvvsM61fv17x8fH65JNPNHXqVMXExFzw6nK7du30zjvv6PHHH1fHjh0VEhKiYcOGtfr70QSsoJyjzp07KyQkpM2/yKqrq9v8y81ETz31lNavX6+PP/5Y3bp1sy03LCxM119/vQYOHKjs7Gz169dPr732ml+Z27ZtU3V1tQYMGKDQ0FCFhoaqpKREr7/+ukJDQ9Xc3GzT9FKHDh3Ut29fW65ej4mJaVPMbrzxRlsuoj5t//792rBhg5544gnbMmfOnKnnnntOEyZMUN++ffXoo49qxowZtqxe9ejRQyUlJTp69KgqKyu1ZcsWnThxQgkJCTZMfsrpu7CC9dg8ceKExo0bp4qKChUVFdm2eiKd+vm+/vrrdfvtt2vZsmUKDQ3VsmXL/Mr89NNPVV1drbi4ON/xuX//fv3sZz9T9+7d7Rn8H2JiYhQfH+/38dm5c2eFhoYG/Pj89NNPtXv3btuOz4aGBj3//PPKzc3VqFGjdPPNN+vJJ5/U+PHj9atf/cqv7AEDBvj+cVlVVaWPPvpIR44csfXY9BcF5RyFhYVpwIABvrsnTisqKlJSUtIlmursLMvSk08+qXfffVd/+tOfAv7DZ1mW38uxd999t8rKyrRz507fY+DAgXr44Ye1c+dOhYSE2DTtqXOxu3btUkxMjN9ZQ4YMaXML9549exQfH+939mnLly9X165dNXLkSNsyjx8/rquuav1XQUhIiC23GZ/WoUMHxcTEqKamRgUFBRozZoxt2QkJCXK5XK2OzaamJpWUlBh9bErflJO9e/dqw4YN6tSpU0C/nh3H56OPPqo///nPrY5Pt9utmTNnqqCgwKZJTzly5IgqKyv9Pj7DwsJ02223Bfz4XLZsmQYMGGDLdT7SqZ+PEydOBPT4jIqKUpcuXbR3715t3brV1mPTX5ziOQ/PPPOMHn30UQ0cOFCDBw/WkiVLdODAAU2ZMsXv7KNHj+rLL7/0fVxRUaGdO3eqY8eOiouLu+DcadOmafXq1XrvvfcUGRnp+1dmVFSUwsPD/Zr5+eef14gRIxQbG6v6+nqtWbNGxcXF+uijj/zKjYyMbHONTIcOHdSpUye/r5159tlnNWrUKMXFxam6ulq//OUvVVdX5/epDOnU7YBJSUnKysrSuHHjtGXLFi1ZskRLlizxO1s6tUy9fPlyZWRkKDTUvkN31KhRmjdvnuLi4tS7d2/t2LFDubm5mjRpkt/ZBQUFsixLPXv21JdffqmZM2eqZ8+e+ulPf3peOWc7PjIzM5WVlaXExEQlJiYqKytLERERSk9P9zv7b3/7mw4cOOB7fZLTv+RcLtdZX0Pnh7Ldbrf+5V/+Rdu3b9f777+v5uZm3/HZsWNHhYWFXXB2p06dNG/ePI0ePVoxMTE6cuSI3nzzTR08ePCcbk0/2/fku0WqXbt2crlc6tmz5wXnduzYUR6PRw888IBiYmL0v//7v3r++efVuXNn3X///X7PPHPmTI0fP1533HGH7rzzTn300Uf6/e9/r+LiYr+zJamurk6/+93vtHDhwrPmnU92cnKyZs6cqfDwcMXHx6ukpEQrVqxQbm6uX7m/+93v1KVLF8XFxamsrEzTp0/X2LFj29wIcklduhuIgtOvf/1rKz4+3goLC7NuvfVW227X/fjjjy1JbR4ZGRl+5Z4pU5K1fPlyv2eeNGmS73vRpUsX6+6777YKCwv9zj0Tu24zHj9+vBUTE2O1a9fOcrvdVlpamlVeXu7/gP/w+9//3urTp4/ldDqtXr16WUuWLLEtu6CgwJJk7d6927ZMy7Ksuro6a/r06VZcXJzVvn1767rrrrPmzp1rNTY2+p399ttvW9ddd50VFhZmuVwua9q0adbXX3993jlnOz5aWlqsl156yXK5XJbT6bTuuOMOq6yszJbs5cuXn/H5l156ya/s07ctn+nx8ccf+5Xd0NBg3X///Zbb7bbCwsKsmJgYa/To0daWLVts+Z5817neZvxDucePH7dSU1OtLl26WO3atbPi4uKsjIwM68CBA7bNvGzZMuv666+32rdvb/Xr189at26dbdn//u//boWHh5/3z/fZsquqqqyJEydabrfbat++vdWzZ09r4cKFZ32JgbPlvvbaa1a3bt183+sXXnjBlmPeTg7LsqwLbjcAAAABwDUoAADAOBQUAABgHAoKAAAwDgUFAAAYh4ICAACMQ0EBAADGoaAAAADjUFAAAIBxKCgAAMA4FBQAAGAcCgoAADDO/wOb+PIbF5QsqgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "experiments = ['CHB_MIT_local_1','CHB_MIT_local_2',\n",
    "               'CHB_MIT_local_3','CHB_MIT_local_4','CHB_MIT_local_5'\n",
    "              ,'CHB_MIT_federated_1','CHB_MIT_federated_2','CHB_MIT_federated_3','CHB_MIT_federated_4','CHB_MIT_federated_5']\n",
    "labels = ['local 1','local 2','local 3','local 4','local 5','bandits 1','bandits 2','bandits 3','bandits 4','bandits 5']\n",
    "accuracies = []\n",
    "accuracies_per_client = np.zeros((10,20))\n",
    "for i,experiment in enumerate(experiments): \n",
    "    accuracies.append(np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt')))\n",
    "    accuracies_per_client[i,:] = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracies.txt'))\n",
    "print('accuracy local: ', np.mean(accuracies[:5]))\n",
    "print('accuracy mine: ',np.mean(accuracies[5:]))\n",
    "accuracy_local =  np.mean(accuracies_per_client[:5,:],axis=0) \n",
    "accuracy_mine =  np.mean(accuracies_per_client[5:,:],axis=0)\n",
    "print('accuracy local: ', accuracy_local)\n",
    "print('accuracy mine: ',accuracy_mine)\n",
    "ax = plt.gca()\n",
    "plt.bar([x for x in range(20)],accuracy_local,fc=(0, 0, 1, 0.5),tick_label=[str(x) for x in range(20)])\n",
    "plt.bar([x for x in range(20)],accuracy_mine,fc=(1,0,0,0.5),tick_label=[str(x) for x in range(20)])\n",
    "ax.set_ylim(45,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f7962",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1fe7312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages (1.5.1)\r\n"
     ]
    }
   ],
   "source": [
    "### We first load the dataset \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "import torch.nn.functional as F\n",
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e08164e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,) int64\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('blub.h5','w') as h5w:\n",
    "    l1 = [i for i in range(100)]\n",
    "    h5w.create_dataset('test1',data=l1)\n",
    "with h5py.File('blub.h5') as h5r:\n",
    "    print(h5r['test1'].shape, h5r['test1'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f269320c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 73 37 77 30  3 75 83  4 14 52 28  1 72 40 25 45 21 13 34 22 65 42 18\n",
      " 78 66 12 68 32 10 55 20 35 79 19 27 74 70 33 47 15 60  9 54 41 48 36  5\n",
      "  6 64 57 16 49 17 76  0 29 71 84 62]\n",
      "[2, 7, 11, 23, 24, 26, 31, 38, 39, 43, 44, 46, 50, 51, 53, 56, 58, 59, 61, 63, 67, 69, 80, 81, 82]\n"
     ]
    }
   ],
   "source": [
    "current_idx = [x for x in range(85)]\n",
    "train_idx = np.random.choice(current_idx,60,replace=False)\n",
    "val_idx = [x for x in range(85) if x not in train_idx]\n",
    "print(train_idx)\n",
    "print(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dda67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3d68fc7",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b7026e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 32, 2048]             192\n",
      "       BatchNorm1d-2             [-1, 32, 2048]              64\n",
      "              ReLU-3             [-1, 32, 2048]               0\n",
      "         MaxPool1d-4              [-1, 32, 410]               0\n",
      "            Conv1d-5              [-1, 64, 410]          10,304\n",
      "       BatchNorm1d-6              [-1, 64, 410]             128\n",
      "              ReLU-7              [-1, 64, 410]               0\n",
      "         MaxPool1d-8              [-1, 64, 137]               0\n",
      "            Conv1d-9             [-1, 128, 137]          41,088\n",
      "      BatchNorm1d-10             [-1, 128, 137]             256\n",
      "             ReLU-11             [-1, 128, 137]               0\n",
      "        MaxPool1d-12              [-1, 128, 46]               0\n",
      "           Conv1d-13               [-1, 64, 46]          41,024\n",
      "      BatchNorm1d-14               [-1, 64, 46]             128\n",
      "             ReLU-15               [-1, 64, 46]               0\n",
      "        MaxPool1d-16               [-1, 64, 15]               0\n",
      "           Linear-17                    [-1, 2]           1,922\n",
      "================================================================\n",
      "Total params: 95,106\n",
      "Trainable params: 95,106\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.79\n",
      "Params size (MB): 0.36\n",
      "Estimated Total Size (MB): 3.16\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# network \n",
    "# Convolutional neural network (two convolutional layers)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1,32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=5))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=3))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=3))\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv1d(128, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=3))\n",
    "\n",
    "        self.fc = nn.Linear(64*15, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "num_classes = 2\n",
    "model = ConvNet(num_classes).cuda()\n",
    "\n",
    "summary(model,(1,2*1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d6fb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 16, 2048]              96\n",
      "       BatchNorm1d-2             [-1, 16, 2048]              32\n",
      "              ReLU-3             [-1, 16, 2048]               0\n",
      "         MaxPool1d-4              [-1, 16, 410]               0\n",
      "            Conv1d-5              [-1, 32, 410]           2,592\n",
      "       BatchNorm1d-6              [-1, 32, 410]              64\n",
      "              ReLU-7              [-1, 32, 410]               0\n",
      "            Conv1d-8              [-1, 48, 410]           7,728\n",
      "       BatchNorm1d-9              [-1, 48, 410]              96\n",
      "             ReLU-10              [-1, 48, 410]               0\n",
      "        MaxPool1d-11              [-1, 48, 137]               0\n",
      "           Conv1d-12              [-1, 64, 137]          15,424\n",
      "      BatchNorm1d-13              [-1, 64, 137]             128\n",
      "             ReLU-14              [-1, 64, 137]               0\n",
      "           Conv1d-15              [-1, 96, 137]          30,816\n",
      "      BatchNorm1d-16              [-1, 96, 137]             192\n",
      "             ReLU-17              [-1, 96, 137]               0\n",
      "        MaxPool1d-18               [-1, 96, 46]               0\n",
      "           Conv1d-19              [-1, 128, 46]          61,568\n",
      "      BatchNorm1d-20              [-1, 128, 46]             256\n",
      "             ReLU-21              [-1, 128, 46]               0\n",
      "           Conv1d-22               [-1, 64, 46]          41,024\n",
      "      BatchNorm1d-23               [-1, 64, 46]             128\n",
      "             ReLU-24               [-1, 64, 46]               0\n",
      "        MaxPool1d-25               [-1, 64, 15]               0\n",
      "           Linear-26                    [-1, 2]           1,922\n",
      "================================================================\n",
      "Total params: 162,066\n",
      "Trainable params: 162,066\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.35\n",
      "Params size (MB): 0.62\n",
      "Estimated Total Size (MB): 2.97\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# network \n",
    "# Convolutional neural network (two convolutional layers)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1,16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=5))\n",
    "        \n",
    "        self.layer1b = nn.Sequential(\n",
    "            nn.Conv1d(16,32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU())\n",
    "            #nn.Dropout(0.2),\n",
    "            #nn.MaxPool1d(kernel_size=2, stride=5))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(32, 48, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(48),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=3))\n",
    "        \n",
    "        self.layer2b = nn.Sequential(\n",
    "            nn.Conv1d(48, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(64, 96, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(96),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=3))\n",
    "        \n",
    "        self.layer3b = nn.Sequential(\n",
    "            nn.Conv1d(96, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            )\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv1d(128, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=3))\n",
    "\n",
    "        self.fc = nn.Linear(64*15, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer1b(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer2b(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer3b(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "num_classes = 2\n",
    "model = ConvNet(num_classes).cuda()\n",
    "\n",
    "summary(model,(1,2*1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a266cc30",
   "metadata": {},
   "source": [
    "### Global training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8baff72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024])\n"
     ]
    }
   ],
   "source": [
    "# Split the seizures and allow to define the train ratio. \n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,filepath,i,iteration,partition='train'):\n",
    "        self.iteration = iteration\n",
    "        self.filepath = filepath \n",
    "        self.partition = partition \n",
    "        self.number = i \n",
    "        images, labels = self.load_data()\n",
    "        \n",
    "        images, self.labels = self.train_val_test(images,labels)\n",
    "        self.dataset = self.normalize(images)\n",
    "        self.size = len(self.labels)\n",
    "        \n",
    "    def load_data(self):\n",
    "        arrays = {}\n",
    "        filepath = self.filepath + 'chb'+self.create_digits(self.number)+'_4s_0s.mat'\n",
    "        f = h5py.File(filepath)\n",
    "        index = 0 \n",
    "        for k,v in f.items():\n",
    "            arrays[index] = np.array(v)\n",
    "            index = index +1 \n",
    "        all_electrodes = np.transpose(arrays[0])\n",
    "        labels = np.transpose(arrays[1])\n",
    "        image = np.reshape(all_electrodes, (np.shape(all_electrodes)[0],-1,1024))\n",
    "        selected_electrodes = [1,13]\n",
    "        image = image[:,selected_electrodes,:]\n",
    "        return image,labels\n",
    "\n",
    "    def train_val_test(self,images,labels):\n",
    "        \n",
    "        # find the begin, end and the number of seizures \n",
    "        begin = 0 \n",
    "        n_seizures = 0 \n",
    "        seizure_onset = []\n",
    "        seizure_end = []\n",
    "        seizures = []\n",
    "        non_seizures = []\n",
    "        for ii in range(len(labels)): \n",
    "            if labels[ii]==1 and begin ==0: # check where the seizure begins\n",
    "                n_seizures += 1 \n",
    "                seizure_onset.append(ii)\n",
    "            if labels[ii]==0 and begin ==1: # check where the seizure ends \n",
    "                seizure_end.append(ii-1)\n",
    "            if labels[ii]==1: \n",
    "                seizures.append(ii)\n",
    "                if ii == len(labels)-1:\n",
    "                    seizure_end.append(ii)\n",
    "            if labels[ii]==0: \n",
    "                non_seizures.append(ii)\n",
    "            begin = labels[ii]\n",
    "            \n",
    "        # if it is even, put half of them in the train,\n",
    "        # and half of them in the test dataset \n",
    "        \n",
    "        train_idx = []\n",
    "        test_idx = []\n",
    "        # if it is odd, split one of the seizures and divide the rest.\n",
    "        seizures_train = np.floor(n_seizures/2)\n",
    "         \n",
    "        for j in range(n_seizures):\n",
    "            if j < int(seizures_train): \n",
    "                train_idx.append([x for x in range(seizure_onset[j],seizure_end[j]+1)])\n",
    "            else: \n",
    "                if n_seizures % 2 == 0:\n",
    "                    test_idx.append([x for x in range(seizure_onset[j],seizure_end[j]+1)])\n",
    "                else: \n",
    "                    if j == int(seizures_train): #split seizure into 2 \n",
    "                        train_idx.append([x for x in range(seizure_onset[j],\n",
    "                                                           int(np.ceil(seizure_onset[j]+0.5*(seizure_end[j]-seizure_onset[j]))))])\n",
    "                        test_idx.append([x for x in range(int(np.ceil(seizure_onset[j]+0.5*(seizure_end[j]-seizure_onset[j]))),\n",
    "                                                         seizure_end[j]+1)])\n",
    "                    else: \n",
    "                        test_idx.append([x for x in range(seizure_onset[j],seizure_end[j]+1)])\n",
    "                        \n",
    "        train_idx= np.sort(np.hstack([np.hstack(train_idx),[x for idx,x in enumerate(non_seizures) if idx < int(len(non_seizures)/2)]]))  \n",
    "        test_idx= np.sort(np.hstack([np.hstack(test_idx),[x for idx,x in enumerate(non_seizures) if idx >= int(len(non_seizures)/2)]])) \n",
    "        \n",
    "        \n",
    "        #plt.plot(train_idx,labels[train_idx],'r.')\n",
    "        #plt.plot(test_idx,labels[test_idx],'b.')\n",
    "        \n",
    "        train_data = images[train_idx,:,:]\n",
    "        test_data = images[test_idx,:,:]\n",
    "        train_labels = labels[train_idx]\n",
    "        test_labels = labels[test_idx]\n",
    "        \n",
    "        \n",
    "        #train_data, test_data, train_labels, test_labels = train_test_split(images,labels,random_state=1)\n",
    "        train_data, val_data, train_labels, val_labels = train_test_split(train_data,train_labels,test_size=data_fraction,random_state=self.iteration)\n",
    "        \n",
    "        \n",
    "        if self.partition == 'train':\n",
    "            return train_data, train_labels\n",
    "            \n",
    "           # return images[:fraction_train,:,:], labels[:fraction_train]\n",
    "        if self.partition == 'val':\n",
    "            return val_data, val_labels\n",
    "            \n",
    "          #  return images[fraction_train:fraction_val,:,:],labels[fraction_train:fraction_val]\n",
    "        if self.partition == 'test': \n",
    "            return test_data, test_labels\n",
    "            \n",
    "          #  return images[fraction_val:,:,:],labels[fraction_val:]\n",
    "\n",
    "    def create_digits(self,number):\n",
    "        if number <10: \n",
    "            return '0'+str(number)\n",
    "        else: \n",
    "            return str(number)\n",
    "        \n",
    "    def normalize(self,data):\n",
    "        input_shape = np.shape(data)\n",
    "        data = np.reshape(data,(-1,1024))\n",
    "        var = np.mean(data,axis=0)\n",
    "        mean = np.mean(data,axis=0)\n",
    "        normalized = (data -mean)/var\n",
    "        normalized = np.reshape(data,(input_shape[0],2,1024))\n",
    "        return normalized \n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.from_numpy(self.dataset[index,:,:]),torch.from_numpy(self.labels[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        # You should change 0 to the total size of your dataset.\n",
    "        return len(self.labels)\n",
    "    \n",
    "filepath = '/mimer/NOBACKUP/groups/snic2022-22-122/arthur/'\n",
    "data_fraction = 1\n",
    "train_dataset = CustomDataset(filepath,12,0,'train')\n",
    "val_dataset = CustomDataset(filepath,3,0,'val')\n",
    "test_dataset = CustomDataset(filepath,3,0,'test')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=32, \n",
    "                                           shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=4, \n",
    "                                           shuffle=False)\n",
    "image, label = train_dataset.__getitem__(1)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0e24243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efda2d283a0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ratios = []\n",
    "val_ratios = []\n",
    "test_ratios = []\n",
    "for patient in range(1,24):\n",
    "    #print('patient: ',patient)\n",
    "    train_dataset = CustomDataset(filepath,patient,0,'train')\n",
    "    train_ratio = np.sum(train_dataset.labels)/len(train_dataset.labels)\n",
    "    train_ratios.append(train_ratio)\n",
    "    train_dataset = CustomDataset(filepath,patient,0,'val')\n",
    "    train_ratio = np.sum(train_dataset.labels)/len(train_dataset.labels)\n",
    "    val_ratios.append(train_ratio)\n",
    "    train_dataset = CustomDataset(filepath,patient,0,'test')\n",
    "    train_ratio = np.sum(train_dataset.labels)/len(train_dataset.labels)\n",
    "    test_ratios.append(train_ratio)\n",
    "    \n",
    "plt.plot(train_ratios,label='train')\n",
    "plt.plot(val_ratios,label='val')\n",
    "plt.plot(test_ratios,label='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c54a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rest of the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e7baf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2911\n",
      "1462\n",
      "2911\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 50\n",
    "num_classes = 2\n",
    "learning_rate = 0.005\n",
    "patient = 4\n",
    "\n",
    "model = ConvNet(num_classes).to(device).double()\n",
    "filepath = '/mimer/NOBACKUP/groups/snic2022-22-122/arthur/'\n",
    "\n",
    "train_size = 0 \n",
    "val_size = 0 \n",
    "test_size = 0 \n",
    "for patient in range(1,24):\n",
    "    train_dataset = CustomDataset(filepath,patient,0,'train')\n",
    "    val_dataset = CustomDataset(filepath,patient,0,'val')\n",
    "    test_dataset = CustomDataset(filepath,patient,0,'test')\n",
    "    if patient != 1: \n",
    "        train_dataset_coll = torch.utils.data.ConcatDataset([train_dataset,train_dataset_coll])\n",
    "        val_dataset_coll = torch.utils.data.ConcatDataset([val_dataset,val_dataset_coll])\n",
    "        test_dataset_coll = torch.utils.data.ConcatDataset([test_dataset,test_dataset_coll])\n",
    "    else: \n",
    "        train_dataset_coll = train_dataset\n",
    "        val_dataset_coll = val_dataset\n",
    "        test_dataset_coll = test_dataset\n",
    "    train_size += train_dataset.size\n",
    "    val_size += val_dataset.size\n",
    "    test_size += test_dataset.size \n",
    "    train_dataset = train_dataset_coll\n",
    "    val_dataset = val_dataset_coll\n",
    "    test_dataset = test_dataset_coll \n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(train_size)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=32, \n",
    "                                           shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=4, \n",
    "                                           shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                         batch_size = 4,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1283dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8174f2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70342a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "299ddbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(0.4937, device='cuda:0')\n",
      "tensor(0.5380, device='cuda:0')\n",
      "TP:  33\n",
      "TN:  434\n",
      "FP:  0\n",
      "FN:  401\n",
      "1\n",
      "tensor(0.7794, device='cuda:0')\n",
      "tensor(0.7224, device='cuda:0')\n",
      "TP:  211\n",
      "TN:  416\n",
      "FP:  18\n",
      "FN:  223\n",
      "2\n",
      "tensor(0.8183, device='cuda:0')\n",
      "tensor(0.7673, device='cuda:0')\n",
      "TP:  275\n",
      "TN:  391\n",
      "FP:  43\n",
      "FN:  159\n",
      "3\n",
      "tensor(0.7615, device='cuda:0')\n",
      "TP:  294\n",
      "TN:  367\n",
      "FP:  67\n",
      "FN:  140\n",
      "4\n",
      "tensor(0.7742, device='cuda:0')\n",
      "TP:  290\n",
      "TN:  382\n",
      "FP:  52\n",
      "FN:  144\n",
      "5\n",
      "tensor(0.7535, device='cuda:0')\n",
      "TP:  261\n",
      "TN:  393\n",
      "FP:  41\n",
      "FN:  173\n",
      "6\n",
      "tensor(0.7051, device='cuda:0')\n",
      "TP:  236\n",
      "TN:  376\n",
      "FP:  58\n",
      "FN:  198\n",
      "7\n",
      "tensor(0.7627, device='cuda:0')\n",
      "TP:  311\n",
      "TN:  351\n",
      "FP:  83\n",
      "FN:  123\n",
      "8\n",
      "tensor(0.7880, device='cuda:0')\n",
      "TP:  326\n",
      "TN:  358\n",
      "FP:  76\n",
      "FN:  108\n",
      "9\n",
      "tensor(0.7903, device='cuda:0')\n",
      "TP:  309\n",
      "TN:  377\n",
      "FP:  57\n",
      "FN:  125\n",
      "10\n",
      "tensor(0.7846, device='cuda:0')\n",
      "TP:  284\n",
      "TN:  397\n",
      "FP:  37\n",
      "FN:  150\n",
      "11\n",
      "tensor(0.7396, device='cuda:0')\n",
      "TP:  297\n",
      "TN:  345\n",
      "FP:  89\n",
      "FN:  137\n",
      "12\n",
      "tensor(0.7581, device='cuda:0')\n",
      "TP:  324\n",
      "TN:  334\n",
      "FP:  100\n",
      "FN:  110\n",
      "13\n",
      "tensor(0.7051, device='cuda:0')\n",
      "TP:  239\n",
      "TN:  373\n",
      "FP:  61\n",
      "FN:  195\n",
      "14\n",
      "tensor(0.7442, device='cuda:0')\n",
      "TP:  247\n",
      "TN:  399\n",
      "FP:  35\n",
      "FN:  187\n",
      "15\n",
      "tensor(0.7396, device='cuda:0')\n",
      "TP:  277\n",
      "TN:  365\n",
      "FP:  69\n",
      "FN:  157\n",
      "16\n",
      "tensor(0.7719, device='cuda:0')\n",
      "TP:  329\n",
      "TN:  341\n",
      "FP:  93\n",
      "FN:  105\n",
      "17\n",
      "tensor(0.7362, device='cuda:0')\n",
      "TP:  273\n",
      "TN:  366\n",
      "FP:  68\n",
      "FN:  161\n",
      "18\n",
      "tensor(0.7823, device='cuda:0')\n",
      "TP:  292\n",
      "TN:  387\n",
      "FP:  47\n",
      "FN:  142\n",
      "19\n",
      "tensor(0.7362, device='cuda:0')\n",
      "TP:  258\n",
      "TN:  381\n",
      "FP:  53\n",
      "FN:  176\n",
      "20\n",
      "tensor(0.7788, device='cuda:0')\n",
      "TP:  341\n",
      "TN:  335\n",
      "FP:  99\n",
      "FN:  93\n",
      "21\n",
      "tensor(0.7535, device='cuda:0')\n",
      "TP:  350\n",
      "TN:  304\n",
      "FP:  130\n",
      "FN:  84\n",
      "22\n",
      "tensor(0.7316, device='cuda:0')\n",
      "TP:  393\n",
      "TN:  242\n",
      "FP:  192\n",
      "FN:  41\n",
      "23\n",
      "tensor(0.7753, device='cuda:0')\n",
      "TP:  369\n",
      "TN:  304\n",
      "FP:  130\n",
      "FN:  65\n",
      "24\n",
      "tensor(0.7465, device='cuda:0')\n",
      "TP:  385\n",
      "TN:  263\n",
      "FP:  171\n",
      "FN:  49\n",
      "25\n",
      "tensor(0.7362, device='cuda:0')\n",
      "TP:  251\n",
      "TN:  388\n",
      "FP:  46\n",
      "FN:  183\n",
      "26\n",
      "tensor(0.7373, device='cuda:0')\n",
      "TP:  301\n",
      "TN:  339\n",
      "FP:  95\n",
      "FN:  133\n",
      "27\n",
      "tensor(0.7431, device='cuda:0')\n",
      "TP:  283\n",
      "TN:  362\n",
      "FP:  72\n",
      "FN:  151\n",
      "28\n",
      "tensor(0.7684, device='cuda:0')\n",
      "TP:  345\n",
      "TN:  322\n",
      "FP:  112\n",
      "FN:  89\n",
      "29\n",
      "tensor(0.7385, device='cuda:0')\n",
      "TP:  238\n",
      "TN:  403\n",
      "FP:  31\n",
      "FN:  196\n",
      "30\n",
      "tensor(0.7673, device='cuda:0')\n",
      "TP:  318\n",
      "TN:  348\n",
      "FP:  86\n",
      "FN:  116\n",
      "31\n",
      "tensor(0.7154, device='cuda:0')\n",
      "TP:  388\n",
      "TN:  233\n",
      "FP:  201\n",
      "FN:  46\n",
      "32\n",
      "tensor(0.7408, device='cuda:0')\n",
      "TP:  373\n",
      "TN:  270\n",
      "FP:  164\n",
      "FN:  61\n",
      "33\n",
      "tensor(0.7742, device='cuda:0')\n",
      "TP:  334\n",
      "TN:  338\n",
      "FP:  96\n",
      "FN:  100\n",
      "34\n",
      "tensor(0.7811, device='cuda:0')\n",
      "TP:  329\n",
      "TN:  349\n",
      "FP:  85\n",
      "FN:  105\n",
      "35\n",
      "tensor(0.7304, device='cuda:0')\n",
      "TP:  372\n",
      "TN:  262\n",
      "FP:  172\n",
      "FN:  62\n",
      "36\n",
      "tensor(0.7742, device='cuda:0')\n",
      "TP:  341\n",
      "TN:  331\n",
      "FP:  103\n",
      "FN:  93\n",
      "37\n",
      "tensor(0.7535, device='cuda:0')\n",
      "TP:  329\n",
      "TN:  325\n",
      "FP:  109\n",
      "FN:  105\n",
      "38\n",
      "tensor(0.7569, device='cuda:0')\n",
      "TP:  328\n",
      "TN:  329\n",
      "FP:  105\n",
      "FN:  106\n",
      "39\n",
      "tensor(0.7535, device='cuda:0')\n",
      "TP:  275\n",
      "TN:  379\n",
      "FP:  55\n",
      "FN:  159\n",
      "40\n",
      "tensor(0.7673, device='cuda:0')\n",
      "TP:  290\n",
      "TN:  376\n",
      "FP:  58\n",
      "FN:  144\n",
      "41\n",
      "tensor(0.7650, device='cuda:0')\n",
      "TP:  315\n",
      "TN:  349\n",
      "FP:  85\n",
      "FN:  119\n",
      "42\n",
      "tensor(0.7396, device='cuda:0')\n",
      "TP:  328\n",
      "TN:  314\n",
      "FP:  120\n",
      "FN:  106\n",
      "43\n",
      "tensor(0.7604, device='cuda:0')\n",
      "TP:  284\n",
      "TN:  376\n",
      "FP:  58\n",
      "FN:  150\n",
      "44\n",
      "tensor(0.7719, device='cuda:0')\n",
      "TP:  338\n",
      "TN:  332\n",
      "FP:  102\n",
      "FN:  96\n",
      "45\n",
      "tensor(0.7926, device='cuda:0')\n",
      "TP:  333\n",
      "TN:  355\n",
      "FP:  79\n",
      "FN:  101\n",
      "46\n",
      "tensor(0.8007, device='cuda:0')\n",
      "TP:  324\n",
      "TN:  371\n",
      "FP:  63\n",
      "FN:  110\n",
      "47\n",
      "tensor(0.7546, device='cuda:0')\n",
      "TP:  356\n",
      "TN:  299\n",
      "FP:  135\n",
      "FN:  78\n",
      "48\n",
      "tensor(0.7650, device='cuda:0')\n",
      "TP:  356\n",
      "TN:  308\n",
      "FP:  126\n",
      "FN:  78\n",
      "49\n",
      "tensor(0.7742, device='cuda:0')\n",
      "TP:  311\n",
      "TN:  361\n",
      "FP:  73\n",
      "FN:  123\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "losses_list = []\n",
    "losses_val_list = []\n",
    "accuracies = []\n",
    "accuracies_val = []\n",
    "best_val_accuracy = 0 \n",
    "accuracies_test = []\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    losses = 0 \n",
    "    losses_val = 0 \n",
    "\n",
    "    model.train()\n",
    "    accuracy = 0 \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.type(torch.LongTensor).squeeze(1).to(device)\n",
    "        # Forward pass\n",
    "        images = torch.reshape(images, (-1,1,2*1024))\n",
    "\n",
    "        output = model(images)\n",
    "        output = F.log_softmax(output,dim=1)\n",
    "\n",
    "        loss = F.nll_loss(output,labels) #.detach().cpu().numpy()\n",
    "        losses += torch.sum(loss).detach().cpu().numpy()\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        accuracy += sum(torch.argmax(output,1)==labels)\n",
    "    accuracy = accuracy / (train_size)\n",
    "    #if (i+1) % 100 == 0:\n",
    "    #accuracies.append(accuracy.detach().cpu().numpy())\n",
    "    losses_list.append(losses)\n",
    "    #print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "    #           .format(epoch+1, num_epochs, i+1, total_step, accuracy))\n",
    "\n",
    "    model.eval()\n",
    "    accuracy = 0 \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "\n",
    "        images = torch.reshape(images, (-1,1,2*1024))\n",
    "        labels = labels.type(torch.LongTensor).squeeze(1).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(images)\n",
    "        output = F.log_softmax(output,dim=1)\n",
    "        loss = F.nll_loss(output,labels) #.detach().cpu().numpy()\n",
    "        losses += torch.sum(loss).detach().cpu().numpy()\n",
    "\n",
    "        accuracy += sum(torch.argmax(output,1)==labels)\n",
    "    accuracy = accuracy / (train_size)\n",
    "    #if (i+1) % 100 == 0:\n",
    "    accuracies.append(accuracy.detach().cpu().numpy())\n",
    "    #losses_val_list.append(losses)\n",
    "    #print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "    #           .format(epoch+1, num_epochs, i+1, total_step, accuracy))\n",
    "\n",
    "    accuracy = 0 \n",
    "    for i, (images, labels) in enumerate(val_loader):\n",
    "        images = images.to(device)\n",
    "        images = torch.reshape(images, (-1,1,2*1024))\n",
    "        labels = labels.type(torch.LongTensor).squeeze(1).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(images)\n",
    "        output = F.log_softmax(output,dim=1)\n",
    "        loss = F.nll_loss(output,labels) #.detach().cpu().numpy()\n",
    "        losses += torch.sum(loss).detach().cpu().numpy()\n",
    "\n",
    "        accuracy += sum(torch.argmax(output,1)==labels)\n",
    "    accuracy = accuracy / (val_size)\n",
    "\n",
    "    if accuracy > best_val_accuracy: \n",
    "        print(accuracy)\n",
    "        best_val_accuracy = accuracy \n",
    "    test_accuracy = 0 \n",
    "    label_array = []\n",
    "    output_array = []\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        images = torch.reshape(images, (-1,1,2*1024))\n",
    "        labels = labels.type(torch.LongTensor).squeeze(1).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(images)\n",
    "        output = F.log_softmax(output,dim=1)\n",
    "        loss = F.nll_loss(output,labels) #.detach().cpu().numpy()\n",
    "        losses += torch.sum(loss).detach().cpu().numpy()\n",
    "        label_array.append(list(labels.detach().cpu().numpy()))\n",
    "        output_array.append(list(torch.argmax(output,1).detach().cpu().numpy()))\n",
    "        test_accuracy += sum(torch.argmax(output,1)==labels)\n",
    "    test_accuracy = test_accuracy / (test_size)\n",
    "    print(test_accuracy)\n",
    "    calc_table(label_array,output_array)\n",
    "\n",
    "    #if (i+1) % 100 == 0:\n",
    "    accuracies_val.append(accuracy.detach().cpu().numpy())\n",
    "    accuracies_test.append(test_accuracy.detach().cpu().numpy())\n",
    "    losses_val_list.append(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc832c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa0a049c520>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#accuracies_test_global = accuracies_test\n",
    "plt.plot(accuracies_test_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e5be9",
   "metadata": {},
   "source": [
    "### Local training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c5a8e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.ravel(output_array))\n",
    "def calc_table(label_array,output_array):\n",
    "    TP = 0 \n",
    "    TN = 0 \n",
    "    FP = 0 \n",
    "    FN = 0 \n",
    "    for i,ele in enumerate(output_array): \n",
    "        for j,ele2 in enumerate(ele): \n",
    "            if ele2 == 1 and label_array[i][j] == 1: \n",
    "                TP += 1 \n",
    "            if ele2 == 0 and label_array[i][j] ==0:\n",
    "                TN += 1\n",
    "            if ele2 == 1 and label_array[i][j] ==0: \n",
    "                FP += 1 \n",
    "            if ele2 ==0 and label_array[i][j] == 1: \n",
    "                FN += 1 \n",
    "\n",
    "    print('TP: ',TP)\n",
    "    print('TN: ',TN)\n",
    "    print('FP: ',FP)\n",
    "    print('FN: ',FN)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c3b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    num_zeros = 0 \n",
    "num_ones = 0 \n",
    "for i, (images, labels) in enumerate(test_loader):\n",
    "    num_ones += torch.sum(labels)\n",
    "    num_zeros += len(labels)-torch.sum(labels)\n",
    "print(num_zeros)\n",
    "print(num_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5a887cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor(0.5161, device='cuda:0')\n",
      "tensor(0.4324, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  16\n",
      "FP:  21\n",
      "FN:  0\n",
      "tensor(0.8065, device='cuda:0')\n",
      "tensor(0.7568, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  28\n",
      "FP:  9\n",
      "FN:  0\n",
      "tensor(0.9032, device='cuda:0')\n",
      "tensor(0.8919, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  33\n",
      "FP:  4\n",
      "FN:  0\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(0.9730, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  36\n",
      "FP:  1\n",
      "FN:  0\n",
      "2\n",
      "tensor(0.5185, device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  3\n",
      "FP:  13\n",
      "FN:  0\n",
      "tensor(0.5926, device='cuda:0')\n",
      "tensor(0.6250, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  10\n",
      "FP:  6\n",
      "FN:  0\n",
      "tensor(0.7037, device='cuda:0')\n",
      "tensor(0.6875, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  11\n",
      "FP:  5\n",
      "FN:  0\n",
      "tensor(0.7778, device='cuda:0')\n",
      "tensor(0.6875, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  11\n",
      "FP:  5\n",
      "FN:  0\n",
      "tensor(0.8148, device='cuda:0')\n",
      "tensor(0.9375, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  15\n",
      "FP:  1\n",
      "FN:  0\n",
      "tensor(0.8519, device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "TP:  0\n",
      "TN:  16\n",
      "FP:  0\n",
      "FN:  0\n",
      "tensor(0.8889, device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "TP:  0\n",
      "TN:  16\n",
      "FP:  0\n",
      "FN:  0\n",
      "tensor(0.9630, device='cuda:0')\n",
      "tensor(0.9375, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  15\n",
      "FP:  1\n",
      "FN:  0\n",
      "3\n",
      "tensor(0.4107, device='cuda:0')\n",
      "tensor(0.7576, device='cuda:0')\n",
      "TP:  25\n",
      "TN:  0\n",
      "FP:  8\n",
      "FN:  0\n",
      "tensor(0.6429, device='cuda:0')\n",
      "tensor(0.9091, device='cuda:0')\n",
      "TP:  25\n",
      "TN:  5\n",
      "FP:  3\n",
      "FN:  0\n",
      "tensor(0.8393, device='cuda:0')\n",
      "tensor(0.9697, device='cuda:0')\n",
      "TP:  24\n",
      "TN:  8\n",
      "FP:  0\n",
      "FN:  1\n",
      "tensor(0.9286, device='cuda:0')\n",
      "tensor(0.9394, device='cuda:0')\n",
      "TP:  23\n",
      "TN:  8\n",
      "FP:  0\n",
      "FN:  2\n",
      "4\n",
      "tensor(0.8302, device='cuda:0')\n",
      "tensor(0.2903, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  9\n",
      "FP:  22\n",
      "FN:  0\n",
      "tensor(0.9057, device='cuda:0')\n",
      "tensor(0.6129, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  19\n",
      "FP:  12\n",
      "FN:  0\n",
      "5\n",
      "tensor(0.5844, device='cuda:0')\n",
      "tensor(0.2609, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  12\n",
      "FP:  34\n",
      "FN:  0\n",
      "tensor(0.7922, device='cuda:0')\n",
      "tensor(0.7826, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  36\n",
      "FP:  10\n",
      "FN:  0\n",
      "tensor(0.8831, device='cuda:0')\n",
      "tensor(0.8913, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  41\n",
      "FP:  5\n",
      "FN:  0\n",
      "tensor(0.9610, device='cuda:0')\n",
      "tensor(0.9783, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  45\n",
      "FP:  1\n",
      "FN:  0\n",
      "6\n",
      "tensor(0.7500, device='cuda:0')\n",
      "tensor(0.4167, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  5\n",
      "FP:  0\n",
      "FN:  7\n",
      "tensor(0.8000, device='cuda:0')\n",
      "tensor(0.4167, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  5\n",
      "FP:  0\n",
      "FN:  7\n",
      "7\n",
      "tensor(0.7045, device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "TP:  26\n",
      "TN:  0\n",
      "FP:  0\n",
      "FN:  0\n",
      "tensor(0.7273, device='cuda:0')\n",
      "tensor(0.0769, device='cuda:0')\n",
      "TP:  2\n",
      "TN:  0\n",
      "FP:  0\n",
      "FN:  24\n",
      "tensor(0.8636, device='cuda:0')\n",
      "tensor(0.1923, device='cuda:0')\n",
      "TP:  5\n",
      "TN:  0\n",
      "FP:  0\n",
      "FN:  21\n",
      "tensor(0.9318, device='cuda:0')\n",
      "tensor(0.3462, device='cuda:0')\n",
      "TP:  9\n",
      "TN:  0\n",
      "FP:  0\n",
      "FN:  17\n",
      "tensor(0.9545, device='cuda:0')\n",
      "tensor(0.6154, device='cuda:0')\n",
      "TP:  16\n",
      "TN:  0\n",
      "FP:  0\n",
      "FN:  10\n",
      "tensor(0.9773, device='cuda:0')\n",
      "tensor(0.6538, device='cuda:0')\n",
      "TP:  17\n",
      "TN:  0\n",
      "FP:  0\n",
      "FN:  9\n",
      "8\n",
      "tensor(0.7009, device='cuda:0')\n",
      "tensor(0.2143, device='cuda:0')\n",
      "TP:  6\n",
      "TN:  9\n",
      "FP:  55\n",
      "FN:  0\n",
      "tensor(0.8120, device='cuda:0')\n",
      "tensor(0.5000, device='cuda:0')\n",
      "TP:  3\n",
      "TN:  32\n",
      "FP:  32\n",
      "FN:  3\n",
      "tensor(0.9060, device='cuda:0')\n",
      "tensor(0.8429, device='cuda:0')\n",
      "TP:  1\n",
      "TN:  58\n",
      "FP:  6\n",
      "FN:  5\n",
      "tensor(0.9231, device='cuda:0')\n",
      "tensor(0.9000, device='cuda:0')\n",
      "TP:  1\n",
      "TN:  62\n",
      "FP:  2\n",
      "FN:  5\n",
      "9\n",
      "tensor(0.1111, device='cuda:0')\n",
      "tensor(0.6818, device='cuda:0')\n",
      "TP:  14\n",
      "TN:  1\n",
      "FP:  6\n",
      "FN:  1\n",
      "tensor(0.8889, device='cuda:0')\n",
      "tensor(0.8636, device='cuda:0')\n",
      "TP:  14\n",
      "TN:  5\n",
      "FP:  2\n",
      "FN:  1\n",
      "tensor(0.9444, device='cuda:0')\n",
      "tensor(0.9091, device='cuda:0')\n",
      "TP:  14\n",
      "TN:  6\n",
      "FP:  1\n",
      "FN:  1\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(0.9091, device='cuda:0')\n",
      "TP:  13\n",
      "TN:  7\n",
      "FP:  0\n",
      "FN:  2\n",
      "10\n",
      "tensor(0.8475, device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "TP:  35\n",
      "TN:  0\n",
      "FP:  0\n",
      "FN:  0\n",
      "tensor(0.9322, device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "TP:  35\n",
      "TN:  0\n",
      "FP:  0\n",
      "FN:  0\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "TP:  35\n",
      "TN:  0\n",
      "FP:  0\n",
      "FN:  0\n",
      "11\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(0.9841, device='cuda:0')\n",
      "TP:  62\n",
      "TN:  0\n",
      "FP:  0\n",
      "FN:  1\n",
      "12\n",
      "tensor(0.8516, device='cuda:0')\n",
      "tensor(0.8165, device='cuda:0')\n",
      "TP:  27\n",
      "TN:  62\n",
      "FP:  10\n",
      "FN:  10\n",
      "13\n",
      "tensor(0.8286, device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "TP:  42\n",
      "TN:  0\n",
      "FP:  0\n",
      "FN:  0\n",
      "14\n",
      "tensor(0.8333, device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "TP:  0\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  0\n",
      "15\n",
      "tensor(0.5238, device='cuda:0')\n",
      "tensor(0.3709, device='cuda:0')\n",
      "TP:  16\n",
      "TN:  40\n",
      "FP:  0\n",
      "FN:  95\n",
      "tensor(0.7698, device='cuda:0')\n",
      "tensor(0.7417, device='cuda:0')\n",
      "TP:  78\n",
      "TN:  34\n",
      "FP:  6\n",
      "FN:  33\n",
      "tensor(0.9008, device='cuda:0')\n",
      "tensor(0.7947, device='cuda:0')\n",
      "TP:  81\n",
      "TN:  39\n",
      "FP:  1\n",
      "FN:  30\n",
      "tensor(0.9167, device='cuda:0')\n",
      "tensor(0.9139, device='cuda:0')\n",
      "TP:  100\n",
      "TN:  38\n",
      "FP:  2\n",
      "FN:  11\n",
      "tensor(0.9286, device='cuda:0')\n",
      "tensor(0.8874, device='cuda:0')\n",
      "TP:  95\n",
      "TN:  39\n",
      "FP:  1\n",
      "FN:  16\n",
      "16\n",
      "tensor(0.1818, device='cuda:0')\n",
      "tensor(0.3333, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  2\n",
      "FP:  0\n",
      "FN:  4\n",
      "17\n",
      "tensor(0.5750, device='cuda:0')\n",
      "tensor(0.2917, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  7\n",
      "FP:  17\n",
      "FN:  0\n",
      "tensor(0.8000, device='cuda:0')\n",
      "tensor(0.6250, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  15\n",
      "FP:  9\n",
      "FN:  0\n",
      "tensor(0.8500, device='cuda:0')\n",
      "tensor(0.6250, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  15\n",
      "FP:  9\n",
      "FN:  0\n",
      "tensor(0.9250, device='cuda:0')\n",
      "tensor(0.8333, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  20\n",
      "FP:  4\n",
      "FN:  0\n",
      "18\n",
      "tensor(0.2439, device='cuda:0')\n",
      "tensor(0.3200, device='cuda:0')\n",
      "TP:  8\n",
      "TN:  0\n",
      "FP:  0\n",
      "FN:  17\n",
      "tensor(0.5366, device='cuda:0')\n",
      "tensor(0.6000, device='cuda:0')\n",
      "TP:  15\n",
      "TN:  0\n",
      "FP:  0\n",
      "FN:  10\n",
      "19\n",
      "tensor(0.0286, device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "TP:  0\n",
      "TN:  0\n",
      "FP:  0\n",
      "FN:  20\n",
      "tensor(0.9714, device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "TP:  20\n",
      "TN:  0\n",
      "FP:  0\n",
      "FN:  0\n",
      "20\n",
      "tensor(0.4000, device='cuda:0')\n",
      "tensor(0.4167, device='cuda:0')\n",
      "TP:  9\n",
      "TN:  1\n",
      "FP:  14\n",
      "FN:  0\n",
      "tensor(0.4250, device='cuda:0')\n",
      "tensor(0.6250, device='cuda:0')\n",
      "TP:  9\n",
      "TN:  6\n",
      "FP:  9\n",
      "FN:  0\n",
      "tensor(0.8500, device='cuda:0')\n",
      "tensor(0.7500, device='cuda:0')\n",
      "TP:  9\n",
      "TN:  9\n",
      "FP:  6\n",
      "FN:  0\n",
      "tensor(0.8750, device='cuda:0')\n",
      "tensor(0.7917, device='cuda:0')\n",
      "TP:  6\n",
      "TN:  13\n",
      "FP:  2\n",
      "FN:  3\n",
      "tensor(0.9250, device='cuda:0')\n",
      "tensor(0.7917, device='cuda:0')\n",
      "TP:  4\n",
      "TN:  15\n",
      "FP:  0\n",
      "FN:  5\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3225984/1293631241.py:45: RuntimeWarning: divide by zero encountered in divide\n",
      "  normalized = (data -mean)/var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8077, device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "TP:  0\n",
      "TN:  0\n",
      "FP:  16\n",
      "FN:  0\n",
      "22\n",
      "tensor(0.3704, device='cuda:0')\n",
      "tensor(0.4000, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  6\n",
      "FP:  0\n",
      "FN:  9\n",
      "tensor(0.7037, device='cuda:0')\n",
      "tensor(0.6000, device='cuda:0')\n",
      "TP:  9\n",
      "TN:  0\n",
      "FP:  6\n",
      "FN:  0\n",
      "tensor(0.7407, device='cuda:0')\n",
      "tensor(0.6667, device='cuda:0')\n",
      "TP:  9\n",
      "TN:  1\n",
      "FP:  5\n",
      "FN:  0\n",
      "tensor(0.8519, device='cuda:0')\n",
      "tensor(0.7333, device='cuda:0')\n",
      "TP:  9\n",
      "TN:  2\n",
      "FP:  4\n",
      "FN:  0\n",
      "tensor(0.8889, device='cuda:0')\n",
      "tensor(0.7333, device='cuda:0')\n",
      "TP:  9\n",
      "TN:  2\n",
      "FP:  4\n",
      "FN:  0\n",
      "tensor(0.9259, device='cuda:0')\n",
      "tensor(0.7333, device='cuda:0')\n",
      "TP:  9\n",
      "TN:  2\n",
      "FP:  4\n",
      "FN:  0\n",
      "tensor(0.9630, device='cuda:0')\n",
      "tensor(0.8000, device='cuda:0')\n",
      "TP:  9\n",
      "TN:  3\n",
      "FP:  3\n",
      "FN:  0\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(0.8667, device='cuda:0')\n",
      "TP:  9\n",
      "TN:  4\n",
      "FP:  2\n",
      "FN:  0\n",
      "23\n",
      "tensor(0.0189, device='cuda:0')\n",
      "tensor(0.2258, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  7\n",
      "FP:  24\n",
      "FN:  0\n",
      "tensor(0.3019, device='cuda:0')\n",
      "tensor(0.6129, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  19\n",
      "FP:  12\n",
      "FN:  0\n",
      "tensor(0.6226, device='cuda:0')\n",
      "tensor(0.8387, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  26\n",
      "FP:  5\n",
      "FN:  0\n",
      "tensor(0.8302, device='cuda:0')\n",
      "tensor(0.9355, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  29\n",
      "FP:  2\n",
      "FN:  0\n",
      "tensor(0.8868, device='cuda:0')\n",
      "tensor(0.9355, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  29\n",
      "FP:  2\n",
      "FN:  0\n",
      "tensor(0.9057, device='cuda:0')\n",
      "tensor(0.9677, device='cuda:0')\n",
      "TP:  0\n",
      "TN:  30\n",
      "FP:  1\n",
      "FN:  0\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "accuracies_val1 = []\n",
    "accuracies_test1 = []\n",
    "network = ConvNet(num_classes).double().cuda()\n",
    "for patient in range(1,24): #,24):\n",
    "    print(patient)\n",
    "    # Hyper parameters\n",
    "    num_epochs = 10\n",
    "    num_classes = 2\n",
    "    learning_rate = 0.005\n",
    "    #patient = 4\n",
    "    \n",
    "    model = copy.deepcopy(network)\n",
    "\n",
    "    \n",
    "    filepath = '/mimer/NOBACKUP/groups/snic2022-22-122/arthur/'\n",
    "    train_dataset = CustomDataset(filepath,patient,'train')\n",
    "    val_dataset = CustomDataset(filepath,patient,'val')\n",
    "    test_dataset = CustomDataset(filepath,patient,'test')\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=32, \n",
    "                                               shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                               batch_size=32, \n",
    "                                               shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                             batch_size = 32,\n",
    "                                             shuffle=False)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    total_step = len(train_loader)\n",
    "    losses_list = []\n",
    "    losses_val_list = []\n",
    "    accuracies = []\n",
    "    accuracies_val = []\n",
    "    best_val_accuracy = 0 \n",
    "    for epoch in range(num_epochs):\n",
    "        #print(model.layer1[0].weight.detach().cpu().numpy())\n",
    "        losses = 0 \n",
    "        losses_val = 0 \n",
    "\n",
    "        model.train()\n",
    "        accuracy = 0 \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.type(torch.LongTensor).squeeze(1).to(device)\n",
    "            # Forward pass\n",
    "            images = torch.reshape(images, (-1,1,2*1024))\n",
    "\n",
    "            output = model(images)\n",
    "            output = F.log_softmax(output,dim=1)\n",
    "\n",
    "            loss = F.nll_loss(output,labels) #.detach().cpu().numpy()\n",
    "            losses += torch.sum(loss).detach().cpu().numpy()\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            accuracy += sum(torch.argmax(output,1)==labels)\n",
    "        accuracy = accuracy / (train_dataset.size)\n",
    "        #if (i+1) % 100 == 0:\n",
    "        #accuracies.append(accuracy.detach().cpu().numpy())\n",
    "        losses_list.append(losses)\n",
    "        #print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "        #           .format(epoch+1, num_epochs, i+1, total_step, accuracy))\n",
    "\n",
    "        model.eval()\n",
    "        accuracy = 0 \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "\n",
    "            images = torch.reshape(images, (-1,1,2*1024))\n",
    "            labels = labels.type(torch.LongTensor).squeeze(1).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(images)\n",
    "            output = F.log_softmax(output,dim=1)\n",
    "            loss = F.nll_loss(output,labels) #.detach().cpu().numpy()\n",
    "            losses += torch.sum(loss).detach().cpu().numpy()\n",
    "\n",
    "            accuracy += sum(torch.argmax(output,1)==labels)\n",
    "        accuracy = accuracy / (train_dataset.size)\n",
    "        #if (i+1) % 100 == 0:\n",
    "        accuracies.append(accuracy.detach().cpu().numpy())\n",
    "        #losses_val_list.append(losses)\n",
    "        #print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "        #           .format(epoch+1, num_epochs, i+1, total_step, accuracy))\n",
    "\n",
    "        accuracy = 0 \n",
    "        for i, (images, labels) in enumerate(val_loader):\n",
    "            images = images.to(device)\n",
    "            images = torch.reshape(images, (-1,1,2*1024))\n",
    "            labels = labels.type(torch.LongTensor).squeeze(1).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(images)\n",
    "            output = F.log_softmax(output,dim=1)\n",
    "            loss = F.nll_loss(output,labels) #.detach().cpu().numpy()\n",
    "            losses += torch.sum(loss).detach().cpu().numpy()\n",
    "\n",
    "            accuracy += sum(torch.argmax(output,1)==labels)\n",
    "        accuracy = accuracy / (val_dataset.size)\n",
    "\n",
    "        if accuracy > best_val_accuracy: \n",
    "            print(accuracy)\n",
    "            best_val_accuracy = accuracy \n",
    "            test_accuracy = 0 \n",
    "            label_array = []\n",
    "            output_array = []\n",
    "            for i, (images, labels) in enumerate(test_loader):\n",
    "                images = images.to(device)\n",
    "                images = torch.reshape(images, (-1,1,2*1024))\n",
    "                labels = labels.type(torch.LongTensor).squeeze(1).to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                output = model(images)\n",
    "                output = F.log_softmax(output,dim=1)\n",
    "                loss = F.nll_loss(output,labels) #.detach().cpu().numpy()\n",
    "                losses += torch.sum(loss).detach().cpu().numpy()\n",
    "                label_array.append(list(labels.detach().cpu().numpy()))\n",
    "                output_array.append(list(torch.argmax(output,1).detach().cpu().numpy()))\n",
    "                test_accuracy += sum(torch.argmax(output,1)==labels)\n",
    "            test_accuracy = test_accuracy / (test_dataset.size)\n",
    "            print(test_accuracy)\n",
    "            calc_table(label_array,output_array)\n",
    "            \n",
    "        else: \n",
    "            #print('not the best accuracy')\n",
    "            test_accuracy = 0 \n",
    "            label_array = []\n",
    "            output_array = []\n",
    "            for i, (images, labels) in enumerate(test_loader):\n",
    "                images = images.to(device)\n",
    "                images = torch.reshape(images, (-1,1,2*1024))\n",
    "                labels = labels.type(torch.LongTensor).squeeze(1).to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                output = model(images)\n",
    "                output = F.log_softmax(output,dim=1)\n",
    "                loss = F.nll_loss(output,labels) #.detach().cpu().numpy()\n",
    "                losses += torch.sum(loss).detach().cpu().numpy()\n",
    "                label_array.append(list(labels.detach().cpu().numpy()))\n",
    "                output_array.append(list(torch.argmax(output,1).detach().cpu().numpy()))\n",
    "                test_accuracy += sum(torch.argmax(output,1)==labels)\n",
    "            test_accuracy = test_accuracy / (test_dataset.size)\n",
    "            #print(test_accuracy)\n",
    "\n",
    "\n",
    "        #if (i+1) % 100 == 0:\n",
    "        accuracies_val.append(accuracy.detach().cpu().numpy())\n",
    "        \n",
    "        losses_val_list.append(losses)\n",
    "    accuracies_val1.append(best_val_accuracy) #.detach().cpu().numpy())\n",
    "    accuracies_test1.append(test_accuracy.detach().cpu().numpy())\n",
    "       # print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "        #           .format(epoch+1, num_epochs, i+1, total_step, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "bbd40b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(i)\n",
    "print(test_dataset.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "67cbc92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6692542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa090165880>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(accuracies_val1)\n",
    "#print(accuracies_test1)\n",
    "#print(np.mean(accuracies_val1))\n",
    "print(np.mean(accuracies_test1))\n",
    "# compare this to global training \n",
    "#plt.plot(accuracies_val1)\n",
    "plt.plot(accuracies_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3940f34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "868\n",
      "0.6854838757058992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3225984/1293631241.py:45: RuntimeWarning: divide by zero encountered in divide\n",
      "  normalized = (data -mean)/var\n"
     ]
    }
   ],
   "source": [
    "# calculate the real average accuracy, taking into account the difference in dataset sizes. \n",
    "#size_total = 0 \n",
    "accuracies_normalized = 0 \n",
    "for patient in range(1,24):\n",
    "    #print(patient)\n",
    "    test_dataset = CustomDataset(filepath,patient,'test')\n",
    "    #print(test_dataset.size)\n",
    "    #size_total += test_dataset.size \n",
    "    fraction = test_dataset.size / size_total \n",
    "    accuracies_normalized += accuracies_test1[patient-1]*fraction\n",
    "print(size_total)\n",
    "print(accuracies_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df7d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#62.24611708482676"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bce9d883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa090084c40>]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAinElEQVR4nO3dd3zV5d3/8deHhBU2SUDZQ4ZIUSEqDmSoCI5SrVbc4275eau9W21tbbW2Vm2t2l/V1kq5KWrrwIWKioCWpSJqUESGICAjDAlhJ5B53X9cQUII5AAnuc54Px8PHuXkHMib0+Ttle/3GuacQ0RE4l+d0AFERCQ6VOgiIglChS4ikiBU6CIiCUKFLiKSIFJDfeKMjAzXqVOnUJ9eRCQuzZ07d5NzLrOq54IVeqdOncjOzg716UVE4pKZrTrQc7rkIiKSIFToIiIJQoUuIpIgVOgiIglChS4ikiCqLXQzG2dmG81swQGeNzN7zMyWmdl8M+sb/ZgiIlKdSEboTwHDDvL8cKBb+a9RwBNHHktERA5VtfPQnXOzzKzTQV4yAviX8/vwzjGz5mZ2tHNufbRCSmzKLyxhVV4Bq/LyWbW5gILCktCRROJCVqeWnNm9yrVBRyQaC4vaAmsqPM4p/9h+hW5mo/CjeDp06BCFTy01bfvuYlZtKmBlXj6r8vJZWV7gK/MKyN1RuM9rzQKFFIkzNw7sGrOFXtW3cZWnZjjnxgBjALKysnSyRozYWlC0t6g37SnsfFblFZCXX7TPa1s3rU/H9EYM7pFJx/RGdEpvRMf0NDqmp9GkQd1A/wIRgegUeg7QvsLjdsC6KPy9EiXOOfLyiyoV9t7/3bar+NvXmkGbZg3pmJ7G0OOOolN6mi/ujDQ6tEwjrV6w3SJEpBrR+O6cCNxiZuOBU4Btun5e+5xzbNxRyMpNfmS9Z4S95393Vri+XcegXQs/qv7u8W3omJ5Gp/LSbtcijQZ1UwL+S0TkcFVb6Gb2PDAIyDCzHOC3QF0A59xoYBJwHrAMKACur6mwsq+ikjL+Nn0ZUxduYFVeAbuKS799LrWO0b5lGp3S0zipU0s/0s7wl0jaNm9IvVQtQRBJNJHMcrm8mucdcHPUEklElm3cwU/Gz2Phuu2ccUwGpx+TsffySHoj2jRvQGqKSlskmeiCaJxxzvHvOau4/63FNKqfypir+zH0uKNCxxKRGKBCjyMbd+zmFy/PZ8aSXAZ2z+ShS/vQqkmD0LFEJEao0OPE1IUbuGPCF+QXlvD7Ecdxdf+OmCZ+i0gFKvQYl19Ywn1vLeL5j9dwXJumPDryBI5p1SR0LBGJQSr0GPbZ6i3c+sI8Vm0u4L8HdeXWs7trdoqIHJAKPQaVlJbx+PTlPDbtK45q2oDxP+rPKV3SQ8cSkRinQo8xq/LyufWFeXy6eivfO6EN94zoTbOGWlIvItVToccI5xwvzc3hnokLqVPHeHTkCYw4oW3oWCISR1ToMWBLfhG/mvAFkxduoH+Xlvz5ByfQtnnD0LFEJM6o0AObtTSXn7/0OVsKivj1eT354RldqFNH0xFF5NCp0APZXVzKA29/yVOzV9KtVWOevP4kjmvTLHQsEYljKvQAFq3bzk9f+Iyl3+zkutM6ccfwntrhUESOmAq9FpWVOca+v4KHpyylWVpdnr7hZAbWwKklEsDubbBtLWxfB9tzoHgXnHAFNNBPXVJ7VOi1ZN3WXfzsxc/5cEUe5x7Xmj9e3IeWjeqFjiWRKNy5t6i3rYXta2FbTvnH1vqPFe3Y/8999ixc9TI00eZpUjtU6LVg4ufruOvVLygtczx4SR8u7ddO+7DEiuJdvpi35ewt5+3lZb3n97u37f/nGrWCZm0h/RjoPND/vmlbaNYOmraBjV/CS9fB2HPg6gmQ0a3W/2mSfFToNWjbrmJ++/oCXpu3jhM7NOeRy06gY3qj0LGSR0nhvqPoykW9bS3s2rz/n0tL9+XcoiN0PLVCUbf1Zd20DaTWP/jnbt4BrnsTnr0U/jkUrnwJ2mXVzL9TpJwKvYZ8tCKP2178nA3bd3Pr2d25eXBXHThRkwp3wldT4Mu3IG+5L+78jfu/rkHzveXcNqt8ZN1u7wi7aRuoG6U1AG37wn9NhWcuhqcvhEufgu7nRufvFqmCCj3KikrK+Mu7Sxk9czkdW6bx8o2ncmKHFqFjJaaiAl/iC1+FpVOhZBc0bg1HfQeO7rNvUe+5FFKvln9CSu8K//UOPHsJPH85fPcxOPGq2s0gSUOFHkUVj4W7/OT23HV+LxrV11scVcW74Kt3ykt8MhQXQKNMOPFKOO5i6NAf6sTYFNDGreC6t+CFq+D1m2HHBhjwM9B9FIkytU0U6Fi4Gla8G5b/x5f4krehaKe/zt3nMuh9MXQ8PfZKvLL6TeCKl+D1m2DavbDzGxj2QOznlriiQj9COhauhpQUwfJp5SU+CQq3Q8MWvsCPuxg6DYCUOPvyTa0HF43xl4U+/Jsv9YvGQF19vUh0xNl3RGzRsXBRVloMK2b4Ev/yTT9dsEEzOPa7cNxF0GUgpMT5VsJ16sC59/u56VPvgvw8uPw5LUCSqFChH4LSMscXa7cxc0kuM5Zu5LPVW3Us3JEqLYGVs2DBBF/iu7ZA/abQ8/zyEh/sR7aJ5rQf+5H6azfBk+fBlS9D06NDp5I4p0KvxsYdu3lv6SZmLs3lva9y2VJQjBkc3645dwzvyQ2nd9axcIeqtARWfQALJ8DiN6AgD+o1hh7n+UsqXYdUP887EfT5ATTKgBeuhn+eA1dNgMzuoVNJTSvYDK7M/38fZSr0SopLy/h01RZmLs1l5tJcFq7bDkBG4/oM6dmagT0yOeOYDC3bP1RlpbD6Qz8SXzwR8nOhbiPoMcxfEz/mrOjN/44nXYfsXYA0bqi/cdr+pNCpJNp2bfX3gha+6u8Nnf4TOOvuqH8aFTqwdusuZi7JZebSjXywLI+dhSWk1jH6dWzBL4b1YGD3TI49qqn2KT9UZWWw5iM/El/0ur8JmNrQL67pfTEccw7USwudMrw2J/oFSP+usACpx7DQqeRI7d7uZ2UtfNXP0iotgmYdoP9NfhBTA5Ky0HcXl/Lx15u/HYUv27gTgLbNG3Lh8W0Y2D2T045Jp2mDOL8BF0JZGazN9iPxRa/BjvWQ2gC6neO/iLufW/uLe+JByy57FyCNvwIufBT6Xh06lRyqwh2wtHyx21fvQGmhX9h28ij/9d+2b42uP0iKQnfO8fWm/G8LfM6KPHYXl1EvtQ6ndG7JyJPaM6hHJl0zG2uWyuHa+CV89m9Y+JrfJyWlnh+B9y4v8fq6aVytxpn+8suL18DEW2DnBhjwcy1AinVF+RVKfCqU7IYmR0PWDf7rv22Wn91UCxK20PMLS5i9PI+ZSzcyc2kuazbvAqBLRiNGntSBgT0y6d85nYb1tLDjiG1Y4G/qlRb7a+Fn3e0vGWgq3qGr3wQuf8GvKJ12n19VOvxBLUCKNUUFsGzPiuUpfsVy49bQ9xo/Em9/Sq2VeEUJU+jOOb7csMOPwpfkkr1qM8WljrR6KZzWNYNRZ3ZlYLdMOqTrmm1UFWz2lwjqN4UfTfN7p8iRSa0HF/3Dz1Wf/Zi/93DxWC1ACq14Nyx7198TWjIZivMhLQOOv9yPxDucGvw/vHFd6NsKinl/2aZvR+HfbC8EoOdRTbjh9M4M7JFJv44tqJ+q0U2NKC2Bl67118mvf1tlHk116sDQe32pT/m137Fx5HPQsHnoZMmlpNDPSlkwoXzbiR3QsCX0udSPxDueHlMrliNKYmbDgEeBFGCsc+6BSs83A54BOpT/nQ87556MclYAVuXl8/q8dcxcmstnq7dQ5qBpg1QGdMtkYPdMzuyeyVHNNJKpFe/8Br6eBSMe117fNeXUm/2P8q/eCE8Oh6te8btGSs0pKSpfsTzBb8dcuN1vu3zc9/xIvNOAmF2xXG2hm1kK8DhwDpADfGJmE51ziyq87GZgkXPuQjPLBJaY2bPOuaJoB/5yww7+8u5S+rRtxi2Dj2Fgj0yOb9dce43XtnnPw5y/wyk3ajvYmvadS/xmZC9ctfcEpMweoVMlltJi+HomLHgVvnzDbztRvxkce6EficfJthORjNBPBpY551YAmNl4YARQsdAd0MT8FJHGwGagJMpZARjYPZPsO88mvXESrCSMVTlz4Y2f+JHK0PtCp0kOXQfD9ZPgmUv8CUhXvAgdTgmdKr6VlsDK9/yNzcVv+NOr6jfdu2I5DrediKTQ2wJrKjzOASp/Jf0NmAisA5oAlznnyqKSsJIGdVNoUFfXxIPZ8Y0fKTZpDZc+HRejloRx9PF7T0D61wi49EnoMTx0qvhSVuq3ndizYvnbbSeG+5F41yFxffM5kkKvahKsq/T4XGAeMAToCrxjZu8557bv8xeZjQJGAXTo0OGQw0pgJYXw4tWwe6svlkbpoRMln5ad4Yap8NwP/OyiCx6BfteGThX7dm2F9/8C857zRxPWTYPuw8pXLJ+dMNtORFLoOUD7Co/b4UfiFV0PPOCcc8AyM/sa6Al8XPFFzrkxwBiArKysyv9RkFjmHEy63S/lv+RJf8ybhNE4E659wy9AeuN//LTGM2/XAqSqlBbD3Kdg+h/8Tp7HXgC9L4FuQxNy24lICv0ToJuZdQbWAiOBKyq9ZjVwFvCembUGegArohlUAsv+J3z6NJxxmx/VSFj1G8MVL8Drt8D0+/3U0fMeDj4POmY451dtTr0LNi2FzmfC0Pv9WbMJrNpCd86VmNktwBT8tMVxzrmFZnZj+fOjgXuBp8zsC/wlml865zbVYG6pTSs/gLd/6Uc1Q+4KnUb2SKkLF432c9U/eAR2boTvj02YyweHbcMCmHqnn3qYfgxcPt5fXkmCn2DMXyWpfVlZWS47OzvI55ZDsHUNjBnkF7T8aJqW88eqOU/A5Dugw2n+BKSGLUInqn07NvjtEj57xn+9DvqV308lwW7cm9lc51yVCz9iZ4mTxJ6iAnjhSr/t58jnVeaxrP9/Q6NMvwBpXPkCpGRZuVtUAB8+7m96lhb5xVhn/jwp/6OmQpeqOedvuK2f739k1Uk6se87l/hSH3/l3hOQWvUMnarmlJXBFy/Bf+6B7Wv92bPn3OO3Ik5SWl4pVZv9V//NMuROHbYQT7oM9AuQykpg3Lmwek7oRDVj1WwYOwReHQWNW/m9hC77d1KXOajQpSrL3oV3fwu9Rvj9uCW+HN3HrxNIS/f7vzx9IWSPg/wEmKeweYU/g/XJ4f4m8EVj4IfToONpoZPFBN0UlX3lLYf/HQxN2/lSqN84dCI5XPl58NETfml73jKwFD99r/fF0PMCSGsZOmHkdm2BWQ/DR//wh6cMuBX635yQc8mrc7Cboip02atwB4w92y9UGTUDWnQKnUiiwTn4ZoFf7r7wVdjyNdRJhS6D/HL3nufF7g3E0mL/08WMP/rVnn2vhsF3+qmaSUqFLtUrK/PL+pe87Xfz6zIodCKpCc7B+s/91rALX4Wtq6FOXb+HSe+L/Z4msTCbyTlYOtkvDMpbBp0Hwrn3a4UymrYokZj1IHz5Jgx7QGWeyMygzQn+19n3wLpPy0fur8FXU8rPgj3bj9x7DAtzFuz6+X5h0NezIKO731my29CkWBh0pFToAovf9D/SHn+F399ckoMZtO3nf51zL6ydWz5yfw2WTIKU+tCt/KDvbufW/P2U7eth+n3w2bP+EtB5D0O/6xJuYVBN0iWXZLdxsb9untkDrpsU11uHSpSUlUHOx37kvug1f08ltSF0H+pH7tHe2KooH2b/zW9fUFbiBxUDfqbj9g5A19Claru2wP8O8d9Qo2boaDPZX1mpn8u+cAIseh3yc6O39WxZGcx/Af7ze9ixDnp9D87+nd8iWA5I19Blf2Wl8PINfq+W695SmUvV6qRAp9P9r+EP7ns4xMIJ+x4OccxZkBrhSWIr3/eHX6//3F/yufRJ6NC/Zv8tSUCFnqze/Z0/zfzCx3SUmUSmTvk89s5n+uvbK9/zpb74Db+qOJLj2/KWwzt3+xvwTdvBxWOh9/ehjtY4RoMuuSSj+S/BhB/CST+E8/8cOo3Eu9JiWDHTT4Pcc8Byg2Z+8dKeA5YLd8Csh+Dj//Wj+AG3Qf+btNXvYdA1dNlr3Ty/x0fbfnDN65pBINFVUgQrppeX+1tQuN3PWHHO/77vNX5hUONWoZPGLV1DF29nrt+JLy1DBzxLzUitB93P9b9KCv1lvQUT/La2A38BrY8LnTChqdCTRWkxvHStP+X8hsn+XEqRmpRa398w7TE8dJKkoUJPFpPv8DMUvv9Pv0pQRBKObi0ng7lPwydj4bT/8YcgiEhCUqEnutUfwVs/g65n+UUbIpKwVOiJbNtaeOEqaN4eLvmnn0csIglL19ATVfFuX+bFBXDtxNjd71pEokaFnoicgzd/6rdGHfkctDo2dCIRqQW65JKI5jwBnz8Pg34NPc8PnUZEaokKPdGsmOFPeel5AZx5e+g0IlKLVOiJZPPX8NJ1/pSXi0ZrwyORJKPv+ERRuNMv63cOLn8uzNFhIhKUboomAufg9ZsgdzFc9Qq07BI6kYgEoEJPBO897E+TGXqfP71dRJKSLrnEu6VTYNr90OcyOPWW0GlEJCAVejwr3g1v3gate8OFj/pT3EUkaemSSzyb+yRsz4GLntDJLyIS2QjdzIaZ2RIzW2ZmdxzgNYPMbJ6ZLTSzmdGNKfsp3AmzHoYug/wZjyKS9KodoZtZCvA4cA6QA3xiZhOdc4sqvKY58HdgmHNutZnpfKma9tETULAJhtwdOomIxIhIRugnA8uccyucc0XAeGBEpddcAUxwzq0GcM5tjG5M2UfBZvjgr341aLt+odOISIyIpNDbAmsqPM4p/1hF3YEWZjbDzOaa2TVV/UVmNsrMss0sOzc39/ASC8x+zB+4O/jO0ElEJIZEUuhVTZ1wlR6nAv2A84Fzgd+YWff9/pBzY5xzWc65rMxMnWl5WHZ8A3NGQ58fQOteodOISAyJZJZLDtC+wuN2wLoqXrPJOZcP5JvZLOB4YGlUUspe7z0MZcUwqMp70yKSxCIZoX8CdDOzzmZWDxgJTKz0mteBAWaWamZpwCnA4uhGFbasguwnoe81Wt4vIvupdoTunCsxs1uAKUAKMM45t9DMbix/frRzbrGZTQbmA2XAWOfcgpoMnpRm/skfI6dtcUWkChEtLHLOTQImVfrY6EqPHwIeil402UfuEn9oxak3Q9M2odOISAzS0v94Mf1+qNsITr81dBIRiVEq9Hiw7jO/m+KpN0Oj9NBpRCRGqdDjwbT7oGELX+giIgegQo91Kz+AZe/CGbdBg6ah04hIDFOhxzLnYNq90ORoOPlHodOISIxToceyZe/C6g/9NEVtjysi1VChx6qyMvjP76FFJzjx6tBpRCQO6ICLWLX4ddgwHy4aA6n1QqcRkTigEXosKi3x54RmHgvfuSR0GhGJExqhx6L54yHvK7jsWb/UX0QkAhqhx5qSQpjxALTpCz3PD51GROKIRuixZu5TsG0NfPevYFVtRS8iUjWN0GNJUT7Megg6DfCHP4uIHAKN0GPJR6MhPxdGPqfRuYgcMo3QY8WuLfDBo9B9OLQ/OXQaEYlDKvRYMfuvsHsbDLkrdBIRiVMq9FiwcyPMeQJ6XwJH9Q6dRkTilAo9Frz3Zz9dcfCvQycRkTimQg9t6xrIHgcnXgXpXUOnEZE4pkIPbeafAIOBvwidRETinAo9pE1fwbzn4KQfQrN2odOISJxToYc0/Q9+n/MBt4VOIiIJQIUeyvr5sHAC9L8JGmWETiMiCUCFHsq0+6BBczjtltBJRCRBqNBDWD0HvpoCZ9wKDZqFTiMiCUKFXtuc80fLNW4NJ48KnUZEEogKvbYtnwarPvAHP9dLC51GRBKICr027RmdN+8Afa8NnUZEEowKvTYtfgPWz4NBv9LBzyISdSr02lJW6me2ZPSAPpeFTiMiCUgHXNSW+S/CpiXwg3/p4GcRqRERjdDNbJiZLTGzZWZ2x0Fed5KZlZrZJdGLmABKimDGH+DoE+DY74ZOIyIJqtpCN7MU4HFgONALuNzMeh3gdX8CpkQ7ZNz79GnYuhrO+o2OlhORGhPJCP1kYJlzboVzrggYD4yo4nU/Bl4BNkYxX/wrKvAHP3c8HbqeFTqNiCSwSAq9LbCmwuOc8o99y8zaAhcBow/2F5nZKDPLNrPs3NzcQ80anz4eAzu/gSEanYtIzYqk0KtqIVfp8SPAL51zpQf7i5xzY5xzWc65rMzMzAgjxrHd2+D9v0C3odDx1NBpRCTBRTLLJQdoX+FxO2BdpddkAePNj0AzgPPMrMQ591o0Qsat2X+D3Vt18LOI1IpICv0ToJuZdQbWAiOBKyq+wDnXec/vzewp4M2kL/OdufDh43DcRXD08aHTiEgSqLbQnXMlZnYLfvZKCjDOObfQzG4sf/6g182T1vt/gZJdMPjO0ElEJElEtLDIOTcJmFTpY1UWuXPuuiOPFee25cAnY+GEKyCjW+g0IpIktPS/Jsx8EHAw8Jehk4hIElGhR1vecvjsGci6we+qKCJSS1To0Tb9D5BaHwb8LHQSEUkyKvRo2vAFLHgZ+v83NG4VOo2IJBkVejRNu9+fEXraj0MnEZEkpEKPljUfw9K34fSfQMMWodOISBJSoUfDnqPlGmXCKTeGTiMiSUqFHg0rZsDK98oPfm4UOo2IJCkV+pFyDqbdC83aQ7/rQqcRkSSmQj9SSybB2rkw6A4/XVFEJBAV+pHYc/BzejfoMzJ0GhFJcjok+kgseAU2LoJLn4IUvZUiEpZG6IertBim3w9HfQeOrepEPhGR2qVh5eGa+xRsWQlXvAR19N9FEQlPTXQ4Cjb70XmnAdDtnNBpREQAFfrhmXYv7N4Owx/Uwc8iEjNU6Idq3TzIfhJOHgWte4VOIyLyLRX6oSgrg0m3Q6MMP+9cRCSG6KbooZj/AuR8DCP+Dg2bh04jIrIPjdAjtXsbvHM3tDsJjr88dBoRkf1ohB6pGX+C/Fy48kVNUxSRmKRmisTGxfDRaOh3LbQ5MXQaEZEqqdCr4xy8/Quo3wSG3B06jYjIAemSS3UWvQZfz4Lz/wyN0kOnERE5II3QD6YoH6bc6fdr6Xd96DQiIgelEfrBvPdn2L4WLhkHdVJCpxEROSiN0A8kbznM/qufotihf+g0IiLVUqEfyOQ7IKU+nH1P6CQiIhFRoVdlyWT4aqpf3t+kdeg0IiIRUaFXVrwbJv8SMnrAKf8vdBoRkYjppmhls//qD6645nVIqRs6jYhIxCIaoZvZMDNbYmbLzGy/bQbN7Eozm1/+a7aZHR/9qLVg62o/s6XX96DLoNBpREQOSbWFbmYpwOPAcKAXcLmZVd4I/GtgoHOuD3AvMCbaQWvFlDv9gRVD7wudRETkkEUyQj8ZWOacW+GcKwLGA/uciuycm+2c21L+cA7QLroxa8Hy6bB4Igy4DZq3D51GROSQRVLobYE1FR7nlH/sQP4LeLuqJ8xslJllm1l2bm5u5ClrWkmR36+lRWc49ceh04iIHJZICr2qQzNdlS80G4wv9F9W9bxzboxzLss5l5WZmRl5ypr28T9g01IY/ieo2yB0GhGRwxLJLJccoOI1iHbAusovMrM+wFhguHMuLzrxasGODTDjAeg+DLqfGzqNiMhhi2SE/gnQzcw6m1k9YCQwseILzKwDMAG42jm3NPoxa9A7d0NpEQz7Y+gkIiJHpNoRunOuxMxuAaYAKcA459xCM7ux/PnRwN1AOvB3MwMocc5l1VzsKFk1258TOuDn0LJL6DQiIkfEnKvycniNy8rKctnZ2UE+NwBlpfCPgbBrC9zyMdRrFC6LiEiEzGzugQbMybtSNHscfPMFXPq0ylxEEkJy7uWSvwmm3QudB0KvEdW/XkQkDiRnof/n9/40ouEP+pWhIiIJIPkKfe1c+PRfcMqN0Kpn6DQiIlGTXIVeVgaTbofGrWBglWufRETiVnLdFJ33rB+hX/QPaNA0dBoRkahKnhH6rq3w7u+gfX/oc1noNCIiUZc8hT7jj7BrM5z3kG6EikhCSo5C37AAPh4DWTfA0X1CpxERqRGJX+jO+a1xGzSHwXeGTiMiUmMS/6bogldg1QdwwSOQ1jJ0GhGRGpPYI/TCnTD1Ljj6BOh7Teg0IiI1KrFH6LMegh3r4Qf/hjopodOIiNSoxB2hb/oKPnwcTrgK2p8UOo2ISI1LzELfcyO0bhqc/dvQaUREakViFvqXb8HyaTD4136Zv4hIEki8Qi/eBZN/Ba16wUk/DJ1GRKTWJN5N0fcfgW2r4do3ISXx/nkiIgeSWCP0LSvhg0eg9/eh84DQaUREalViFfqUO8FS4Jx7QycREal1iVPoX70LX74JA2+HZm1DpxERqXWJUeglhX6aYvox0P+m0GlERIJIjLuGc/4Om5fDla9Aav3QaUREgoj/Efr2dTDzIehxPnQ7O3QaEZFg4r/Qp/4Gykpg2B9CJxERCSq+C33l+7DgZTjjVmjRKXQaEZGg4rfQS0tg0u3QvAOc8dPQaUREgovfm6KfjIWNi+CyZ6Buw9BpRESCi88R+s6NMP1+6DoEel4QOo2ISEyIz0J/9x6/CdfwB8EsdBoRkZgQf4Wekw3znoFTb4KMbqHTiIjEjPgrdMxfajnz9tBBRERiSkSFbmbDzGyJmS0zszuqeN7M7LHy5+ebWd/oRy3Xrh9c/SrUb1Jjn0JEJB5VW+hmlgI8DgwHegGXm1mvSi8bDnQr/zUKeCLKOUVEpBqRjNBPBpY551Y454qA8cCISq8ZAfzLeXOA5mZ2dJSziojIQURS6G2BNRUe55R/7FBfg5mNMrNsM8vOzc091KwiInIQkRR6VfMC3WG8BufcGOdclnMuKzMzM5J8IiISoUgKPQdoX+FxO2DdYbxGRERqUCSF/gnQzcw6m1k9YCQwsdJrJgLXlM926Q9sc86tj3JWERE5iGr3cnHOlZjZLcAUIAUY55xbaGY3lj8/GpgEnAcsAwqA62susoiIVCWizbmcc5PwpV3xY6Mr/N4BN0c3moiIHArzXRzgE5vlAqsO849nAJuiGCfe6f3Yl96PvfRe7CsR3o+OzrkqZ5UEK/QjYWbZzrms0Dlihd6Pfen92Evvxb4S/f2Iw71cRESkKip0EZEEEa+FPiZ0gBij92Nfej/20nuxr4R+P+LyGrqIiOwvXkfoIiJSiQpdRCRBxF2hV3fYRjIxs/ZmNt3MFpvZQjP7SehMoZlZipl9ZmZvhs4Smpk1N7OXzezL8q+RU0NnCsXMbi3/HllgZs+bWYPQmWpCXBV6hIdtJJMS4GfOuWOB/sDNSf5+APwEWBw6RIx4FJjsnOsJHE+Svi9m1hb4HyDLOdcbv4XJyLCpakZcFTqRHbaRNJxz651zn5b/fgf+G3a/feiThZm1A84HxobOEpqZNQXOBP4J4Jwrcs5tDRoqrFSgoZmlAmkk6G6w8VboER2kkYzMrBNwIvBR4CghPQL8AigLnCMWdAFygSfLL0GNNbNGoUOF4JxbCzwMrAbW43eDnRo2Vc2It0KP6CCNZGNmjYFXgJ8657aHzhOCmV0AbHTOzQ2dJUakAn2BJ5xzJwL5QFLeczKzFvif5DsDbYBGZnZV2FQ1I94KXQdpVGJmdfFl/qxzbkLoPAGdDnzXzFbiL8UNMbNnwkYKKgfIcc7t+YntZXzBJ6Ozga+dc7nOuWJgAnBa4Ew1It4KPZLDNpKGmRn+Guli59z/D50nJOfcr5xz7ZxznfBfF9Occwk5CouEc24DsMbMepR/6CxgUcBIIa0G+ptZWvn3zFkk6A3iiPZDjxUHOmwjcKyQTgeuBr4ws3nlH/t1+f71Ij8Gni0f/KwgSQ+ecc59ZGYvA5/iZ4Z9RoJuAaCl/yIiCSLeLrmIiMgBqNBFRBKECl1EJEGo0EVEEoQKXUQkQajQRUQShApdRCRB/B/hsMA4ALsy8AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracies)\n",
    "plt.plot(accuracies_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf293b78",
   "metadata": {},
   "source": [
    "### Bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b892a33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024])\n"
     ]
    }
   ],
   "source": [
    "# You should build your custom dataset as below.\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,filepath,i,iteration,partition='train'):\n",
    "        self.iteration = iteration\n",
    "        self.filepath = filepath \n",
    "        self.partition = partition \n",
    "        self.number = i \n",
    "        images, labels = self.load_data()\n",
    "        \n",
    "        images, self.labels = self.train_val_test(images,labels)\n",
    "        self.dataset = self.normalize(images)\n",
    "        #print(self.labels)\n",
    "        self.size = len(self.labels)\n",
    "        \n",
    "    def load_data(self):\n",
    "        arrays = {}\n",
    "        filepath = self.filepath + 'chb'+self.create_digits(self.number)+'_4s_0s.mat'\n",
    "        f = h5py.File(filepath)\n",
    "        index = 0 \n",
    "        for k,v in f.items():\n",
    "            arrays[index] = np.array(v)\n",
    "            index = index +1 \n",
    "        all_electrodes = np.transpose(arrays[0])\n",
    "        labels = np.transpose(arrays[1])\n",
    "        image = np.reshape(all_electrodes, (np.shape(all_electrodes)[0],-1,1024))\n",
    "        selected_electrodes = [1,13]\n",
    "        image = image[:,selected_electrodes,:]\n",
    "        return image,labels\n",
    "\n",
    "    def train_val_test(self,images,labels):\n",
    "        fraction_train = int(np.ceil(0.6*len(labels)))\n",
    "        fraction_val = int(np.ceil(0.75*len(labels)))\n",
    "        np.random.seed(self.iteration)\n",
    "        current_idx = [x for x in range(fraction_val)]\n",
    "        train_idx = np.random.choice(current_idx,fraction_train,replace=False)\n",
    "        val_idx = [x for x in range(fraction_val) if x not in train_idx]\n",
    "        \n",
    "        if self.partition == 'train':\n",
    "            #print(train_idx)\n",
    "            return images[train_idx,:,:], labels[train_idx]\n",
    "        if self.partition == 'val':\n",
    "            #print(val_idx)\n",
    "            return images[val_idx,:,:], labels[val_idx]\n",
    "            #return image[fraction_train:fraction_val,:,:],labels[fraction_train:fraction_val]\n",
    "        if self.partition == 'test': \n",
    "            #print(fraction_val)\n",
    "            return images[fraction_val:,:,:],labels[fraction_val:]\n",
    "\n",
    "    def create_digits(self,number):\n",
    "        if number <10: \n",
    "            return '0'+str(number)\n",
    "        else: \n",
    "            return str(number)\n",
    "        \n",
    "    def normalize(self,data):\n",
    "        input_shape = np.shape(data)\n",
    "        data = np.reshape(data,(-1,1024))\n",
    "        var = np.mean(data,axis=0)\n",
    "        mean = np.mean(data,axis=0)\n",
    "        normalized = (data -mean)/var\n",
    "        normalized = np.reshape(data,(input_shape[0],2,1024))\n",
    "        return normalized \n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.from_numpy(self.dataset[index,:,:]),torch.from_numpy(self.labels[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        # You should change 0 to the total size of your dataset.\n",
    "        return len(self.labels)\n",
    "    \n",
    "filepath = '/mimer/NOBACKUP/groups/snic2022-22-122/arthur/'\n",
    "\n",
    "train_dataset = CustomDataset(filepath,3,0,'train')\n",
    "val_dataset = CustomDataset(filepath,3,0,'val')\n",
    "test_dataset = CustomDataset(filepath,3,0,'test')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=32, \n",
    "                                           shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=4, \n",
    "                                           shuffle=False)\n",
    "image, label = train_dataset.__getitem__(1)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d45c3f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024])\n"
     ]
    }
   ],
   "source": [
    "# You should build your custom dataset as below.\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,filepath,i,iteration,partition='train'):\n",
    "        self.iteration = iteration\n",
    "        self.filepath = filepath \n",
    "        self.partition = partition \n",
    "        self.number = i \n",
    "        images, labels = self.load_data()\n",
    "        images, self.labels = self.train_val_test(images,labels)\n",
    "        self.dataset = self.normalize(images)\n",
    "        self.size = len(self.labels)\n",
    "        \n",
    "    def load_data(self):\n",
    "        arrays = {}\n",
    "        filepath = self.filepath + 'chb'+self.create_digits(self.number)+'_4s_0s.mat'\n",
    "        f = h5py.File(filepath)\n",
    "        index = 0 \n",
    "        for k,v in f.items():\n",
    "            arrays[index] = np.array(v)\n",
    "            index = index +1 \n",
    "        all_electrodes = np.transpose(arrays[0])\n",
    "        labels = np.transpose(arrays[1])\n",
    "        image = np.reshape(all_electrodes, (np.shape(all_electrodes)[0],-1,1024))\n",
    "        selected_electrodes = [1,13]\n",
    "        image = image[:,selected_electrodes,:]\n",
    "        return image,labels\n",
    "\n",
    "    def train_val_test(self,images,labels):\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(images,labels,random_state=1)\n",
    "        train_data, val_data, train_labels, val_labels = train_test_split(train_data,train_labels,test_size=0.333,random_state=self.iteration)\n",
    "        \n",
    "        fraction_train = int(np.ceil(0.6*len(labels)))\n",
    "        fraction_val = int(np.ceil(0.75*len(labels)))\n",
    "        if self.partition == 'train':\n",
    "            return train_data, train_labels\n",
    "            \n",
    "           # return images[:fraction_train,:,:], labels[:fraction_train]\n",
    "        if self.partition == 'val':\n",
    "            return val_data, val_labels\n",
    "            \n",
    "          #  return images[fraction_train:fraction_val,:,:],labels[fraction_train:fraction_val]\n",
    "        if self.partition == 'test': \n",
    "            return test_data, test_labels\n",
    "            \n",
    "          #  return images[fraction_val:,:,:],labels[fraction_val:]\n",
    "\n",
    "    def create_digits(self,number):\n",
    "        if number <10: \n",
    "            return '0'+str(number)\n",
    "        else: \n",
    "            return str(number)\n",
    "        \n",
    "    def normalize(self,data):\n",
    "        input_shape = np.shape(data)\n",
    "        data = np.reshape(data,(-1,1024))\n",
    "        var = np.mean(data,axis=0)\n",
    "        mean = np.mean(data,axis=0)\n",
    "        normalized = (data -mean)/var\n",
    "        normalized = np.reshape(data,(input_shape[0],2,1024))\n",
    "        return normalized \n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.from_numpy(self.dataset[index,:,:]),torch.from_numpy(self.labels[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        # You should change 0 to the total size of your dataset.\n",
    "        return len(self.labels)\n",
    "    \n",
    "filepath = '/mimer/NOBACKUP/groups/snic2022-22-122/arthur/'\n",
    "\n",
    "train_dataset = CustomDataset(filepath,3,0,'train')\n",
    "val_dataset = CustomDataset(filepath,3,0,'val')\n",
    "test_dataset = CustomDataset(filepath,3,0,'test')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=32, \n",
    "                                           shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=4, \n",
    "                                           shuffle=False)\n",
    "image, label = train_dataset.__getitem__(1)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a01f8ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient:  1\n",
      "0.45161290322580644\n",
      "0.45161290322580644\n",
      "0.3870967741935484\n",
      "patient:  2\n",
      "0.3148148148148148\n",
      "0.48148148148148145\n",
      "0.4444444444444444\n",
      "patient:  3\n",
      "0.42342342342342343\n",
      "0.4107142857142857\n",
      "0.5178571428571429\n",
      "patient:  4\n",
      "0.5\n",
      "0.39622641509433965\n",
      "0.37735849056603776\n",
      "patient:  5\n",
      "0.4675324675324675\n",
      "0.36363636363636365\n",
      "0.4935064935064935\n",
      "patient:  6\n",
      "0.55\n",
      "0.45\n",
      "0.25\n",
      "patient:  7\n",
      "0.4090909090909091\n",
      "0.5454545454545454\n",
      "0.45454545454545453\n",
      "patient:  8\n",
      "0.5042735042735043\n",
      "0.49572649572649574\n",
      "0.4444444444444444\n",
      "patient:  9\n",
      "0.4383561643835616\n",
      "0.4594594594594595\n",
      "0.4864864864864865\n",
      "patient:  10\n",
      "0.4700854700854701\n",
      "0.4745762711864407\n",
      "0.4406779661016949\n",
      "patient:  11\n",
      "0.4811320754716981\n",
      "0.41509433962264153\n",
      "0.514018691588785\n",
      "patient:  12\n",
      "0.4807692307692308\n",
      "0.46703296703296704\n",
      "0.5164835164835165\n",
      "patient:  13\n",
      "0.4857142857142857\n",
      "0.45714285714285713\n",
      "0.42857142857142855\n",
      "patient:  14\n",
      "0.4166666666666667\n",
      "0.4166666666666667\n",
      "0.4\n",
      "patient:  15\n",
      "0.498015873015873\n",
      "0.44047619047619047\n",
      "0.5019762845849802\n",
      "patient:  16\n",
      "0.4090909090909091\n",
      "0.2727272727272727\n",
      "0.5454545454545454\n",
      "patient:  17\n",
      "0.3875\n",
      "0.4634146341463415\n",
      "0.5365853658536586\n",
      "patient:  18\n",
      "0.46987951807228917\n",
      "0.40476190476190477\n",
      "0.5\n",
      "patient:  19\n",
      "0.43478260869565216\n",
      "0.5142857142857142\n",
      "0.2857142857142857\n",
      "patient:  20\n",
      "0.375\n",
      "0.425\n",
      "0.5365853658536586\n",
      "patient:  21\n",
      "0.4528301886792453\n",
      "0.4074074074074074\n",
      "0.5185185185185185\n",
      "patient:  22\n",
      "0.4807692307692308\n",
      "0.25925925925925924\n",
      "0.6666666666666666\n",
      "patient:  23\n",
      "0.4666666666666667\n",
      "0.5849056603773585\n",
      "0.4339622641509434\n"
     ]
    }
   ],
   "source": [
    "for patient in range(1,24):\n",
    "    print('patient: ',patient)\n",
    "    train_dataset = CustomDataset(filepath,patient,0,'train')\n",
    "    train_ratio = np.sum(train_dataset.labels)/len(train_dataset.labels)\n",
    "    print(train_ratio)\n",
    "    train_dataset = CustomDataset(filepath,patient,0,'val')\n",
    "    train_ratio = np.sum(train_dataset.labels)/len(train_dataset.labels)\n",
    "    print(train_ratio)\n",
    "    train_dataset = CustomDataset(filepath,patient,0,'test')\n",
    "    train_ratio = np.sum(train_dataset.labels)/len(train_dataset.labels)\n",
    "    print(train_ratio)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90d12ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.special import binom\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as tt\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.init as init\n",
    "\n",
    "from collections import Counter\n",
    "import operator\n",
    "import copy\n",
    "from itertools import product,combinations\n",
    "from time import time\n",
    "#from IPython.core.display import display\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "## code extracted from https://www.kaggle.com/code/graymant/breast-cancer-diagnosis-with-pytorch\n",
    "## SV code extracted from https://github.com/mburaksayici/ExplainableAI-Pure-Numpy/blob/main/KernelSHAP-Pure-Numpy.ipynb\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Combinatorial UCB\n",
    "import math\n",
    "\n",
    "def init():\n",
    "    with open('settings/train_settings_bandits.yaml', 'r') as file:\n",
    "        settings = yaml.safe_load(file)\n",
    "    if not os.path.isdir('checkpoints_bandits'):\n",
    "        os.mkdir('checkpoints_bandits')\n",
    "    if not os.path.isdir(os.path.join('checkpoints_bandits', settings['experiment_name'])):\n",
    "        os.mkdir(os.path.join('checkpoints_bandits', settings['experiment_name']))\n",
    "    save_dir = os.path.join('checkpoints_bandits', settings['experiment_name'])\n",
    "    if not os.path.isdir(os.path.join(save_dir, 'model')):\n",
    "        os.mkdir(os.path.join(save_dir, 'model'))\n",
    "    shutil.copyfile('settings/train_settings_bandits.yaml', save_dir + '/train_settings.yaml')\n",
    "    return settings,save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "195c623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class combinatorial_UCB(object):\n",
    "    def __init__(self, n_clients, n_clients_selected=10, algorithm='UCB1_tuned'):\n",
    "        self.n_clients = n_clients\n",
    "\n",
    "        # define variables for storage\n",
    "        # which clients we select\n",
    "        self.times_selected = np.zeros((n_clients, n_clients))  # to record how often each client got selected\n",
    "        self.reward_per_client = np.zeros((n_clients, n_clients))  # to record what reward we collected per client\n",
    "        self.reward2_per_client = np.zeros(\n",
    "            (n_clients, n_clients))  # to record the squared reward per client (needed for UCB1-tuned)\n",
    "        # how many clients we select\n",
    "        self.n_clients_selected_arr = []\n",
    "        self.reward3_per_client = np.zeros((n_clients, n_clients - 1))\n",
    "        self.times_selected2 = np.zeros((n_clients, n_clients - 1))\n",
    "\n",
    "        if n_clients_selected == None:\n",
    "            self.n_clients_selected = np.zeros((n_clients, 1))\n",
    "        else:\n",
    "            self.n_clients_selected = np.ones((n_clients, 1)) * n_clients_selected\n",
    "\n",
    "        self.algorithm = algorithm\n",
    "\n",
    "    def UCB(self, this_client, n):\n",
    "        # for this_client in range(self.n_clients):\n",
    "        other_clients = [x for x in range(self.n_clients) if x != this_client[0]]\n",
    "\n",
    "        upper_bound = np.zeros(self.n_clients)\n",
    "        for i, other_client in enumerate(other_clients):\n",
    "            if self.times_selected[this_client, other_client] == 0:  # make first iteration value high\n",
    "                upper_bound[other_client] = 1e500\n",
    "            else:\n",
    "                # We first calculate the average reward gained for this client\n",
    "                average_reward = self.reward_per_client[this_client, other_client] / self.times_selected[\n",
    "                    this_client, other_client]\n",
    "\n",
    "                # Then we compute the confidence interval [avg_reward - delta, avg_reward + delta]\n",
    "                if self.algorithm == 'UCB1':\n",
    "                    delta = math.sqrt(2 * math.log(n) / self.times_selected[this_client, other_client])\n",
    "\n",
    "                if self.algorithm == 'UCB1_tuned':\n",
    "                    variance_bound = self.reward2_per_client[this_client, other_client] / self.times_selected[\n",
    "                        this_client, other_client] - average_reward ** 2\n",
    "                    variance_bound += math.sqrt(2 * math.log(n) / self.times_selected[this_client, other_client])\n",
    "\n",
    "                    factor = np.min([variance_bound, 1 / 4])\n",
    "                    delta = math.sqrt(factor * math.log(n) / self.times_selected[this_client, other_client])\n",
    "\n",
    "                # upper bound\n",
    "                upper_bound[other_client] = average_reward + delta\n",
    "\n",
    "        if self.algorithm == 'random':\n",
    "            upper_bound = np.random.rand(self.n_clients)\n",
    "\n",
    "        # select the client with the highest upper bound\n",
    "        sorted_upper_bound = np.flip(np.argsort(upper_bound))\n",
    "\n",
    "        # if epoch == 0:\n",
    "        #     n_clients_selected = self.n_clients -2\n",
    "\n",
    "        # else:\n",
    "        n_clients_selected = self.n_clients_selected[i]-1\n",
    "\n",
    "        # Run UCB again to determine the number of clients\n",
    "        # upper_bound2 = np.zeros(self.n_clients-1)\n",
    "        # for ii in range(1,self.n_clients-1):\n",
    "        #    if self.times_selected2[this_client,ii]==0: # make first iteration value high\n",
    "        #        upper_bound2[ii] = 1e500\n",
    "        #        n_clients_selected = self.n_clients -2\n",
    "        #    else:\n",
    "        # predict the reward when selecting these clients\n",
    "        #        average_reward_n_clients = self.reward3_per_client[this_client,ii] / self.times_selected2[this_client,ii]\n",
    "        #        delta = math.sqrt(2*math.log(n)) / np.sum(self.times_selected2[this_client,ii])\n",
    "\n",
    "        #        upper_bound2[ii] = average_reward_n_clients + delta\n",
    "\n",
    "        #        n_clients_selected = np.argmax(upper_bound2)\n",
    "\n",
    "        # n_clients_selected_arr.append(n_clients_selected)\n",
    "        selected_clients = sorted_upper_bound[:int(n_clients_selected + 1)]\n",
    "\n",
    "        self.times_selected[this_client, selected_clients] += 1\n",
    "        return selected_clients\n",
    "\n",
    "    def collect_reward(self, this_client, selected_clients, observations):\n",
    "        # collect the reward\n",
    "        reward = observations[selected_clients]  # df.iloc[n,selected_client]\n",
    "        self.reward_per_client[this_client, selected_clients] += reward\n",
    "        self.reward2_per_client[this_client, selected_clients] += reward ** 2\n",
    "\n",
    "        # reward for numbers of clients selected\n",
    "        # n_clients_selected = len(selected_clients)-1\n",
    "        # self.times_selected2[this_client,n_clients_selected] += 1\n",
    "\n",
    "    # if epoch == 0:\n",
    "    #     self.n_clients_selected[this_client] = np.sum(observations)\n",
    "    # reward2 = np.abs(n_clients_selected - np.sum(observations))\n",
    "    # self.reward3_per_client[this_client,n_clients_selected] += 1 - reward2 / self.n_clients\n",
    "\n",
    "    def to_client(self, this_client, n):\n",
    "        self.selected_clients = self.UCB(this_client, n)\n",
    "        return self.selected_clients\n",
    "\n",
    "    def to_server(self, this_client, observation):\n",
    "        self.collect_reward(this_client, self.selected_clients, observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "fcca1402",
   "metadata": {},
   "outputs": [],
   "source": [
    "class P2P_AFPL():\n",
    "    def __init__(self, patients_left, n_clients_selected,test='local'):\n",
    "        self.selected_clients = patients_left\n",
    "        self.network = ConvNet(2).to(device).double()\n",
    "        self.best_test_loss = {}\n",
    "        self.best_test_loss_global = 1000000\n",
    "        self.current_test_loss = {}\n",
    "        self.current_train_loss = {}\n",
    "        self.test = test\n",
    "        self.total_clients = len(self.selected_clients)\n",
    "        self.patients_left = patients_left\n",
    "        self.client_models = {}\n",
    "        self.optimizers = {}\n",
    "        self.dataloaders = {}\n",
    "        self.len = {}\n",
    "        self.len_test = {}\n",
    "        self.len_really_test = {}\n",
    "        self.dataloaders_test = {}\n",
    "        self.dataloaders_really_test = {}\n",
    "        filepath = '/mimer/NOBACKUP/groups/snic2022-22-122/arthur/'\n",
    "        \n",
    "        if self.test == 'AFPL':\n",
    "            self.client_models_global = {}\n",
    "\n",
    "        if self.test == 'bandits':\n",
    "            self.comb_UCB = combinatorial_UCB(self.total_clients,n_clients_selected)\n",
    "\n",
    "        for idx, i in enumerate(self.patients_left):\n",
    "            self.client_models[str(idx)] = copy.deepcopy(self.network).double().cuda()\n",
    "            self.optimizers[str(idx)] = torch.optim.SGD(self.client_models[str(idx)].parameters(), lr=0.01,\n",
    "                                                        momentum=0.5)\n",
    "            dataset_train = CustomDataset(filepath,self.patients_left[idx],0,'train')\n",
    "            self.len[str(idx)] = len(dataset_train)\n",
    "            self.dataloaders[str(idx)] = DataLoader(dataset_train, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "            dataset_test = CustomDataset(filepath,self.patients_left[idx],0,'val')\n",
    "            self.len_test[str(idx)] = len(dataset_test)\n",
    "            self.dataloaders_test[str(idx)] = DataLoader(dataset_test, batch_size=32, shuffle=False)\n",
    "            self.best_test_loss[str(idx)] = 10000000\n",
    "            self.current_test_loss[str(idx)] = 100000\n",
    "            self.current_train_loss[str(idx)] = 1000000\n",
    "            if self.test == 'AFPL':\n",
    "                self.client_models_global[str(idx)] = copy.deepcopy(self.network).double().cuda()\n",
    "                self.shared_model = copy.deepcopy(self.network).double().cuda()\n",
    "\n",
    "            dataset_really_test = CustomDataset(filepath,self.patients_left[idx],0,'test')\n",
    "            self.len_really_test[str(idx)] = len(dataset_really_test)\n",
    "            self.dataloaders_really_test[str(idx)] = DataLoader(dataset_really_test, batch_size=32, shuffle=False)\n",
    "        self.dataset_train = dataset_train\n",
    "\n",
    "    def update_local_models(self, selected_clients):\n",
    "        self.dw = {}\n",
    "        loss_test = 0\n",
    "        loss_test2 = 0\n",
    "        losses = 0\n",
    "        losses2 = 0\n",
    "        loss_test3 = 0\n",
    "        losses3 = 0\n",
    "        losses4 = 0 \n",
    "\n",
    "        for idx, i in enumerate(selected_clients):\n",
    "            if self.iteration == 1000: \n",
    "                dataset_train = CustomDataset(filepath,i+1,self.iteration,'train')\n",
    "                self.dataloaders[str(i)] = DataLoader(dataset_train, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "                dataset_test = CustomDataset(filepath,i+1,self.iteration,'val')\n",
    "                self.dataloaders_test[str(i)] = DataLoader(dataset_test, batch_size=32, shuffle=False)\n",
    "\n",
    "            dataloader = self.dataloaders[str(i)]\n",
    "            optimizer = torch.optim.Adam(self.client_models[str(i)].parameters(), lr=0.005 * 0.95 ** self.iteration)\n",
    "            self.client_models[str(i)].train()\n",
    "\n",
    "            if self.test == 'AFPL':\n",
    "                self.client_models_global[str(i)] = copy.deepcopy(self.shared_model)\n",
    "                self.client_models_global[str(i)].train()\n",
    "                optimizer_global = torch.optim.Adam(self.client_models_global[str(i)].parameters(),\n",
    "                                                    lr=0.005 * 0.95 ** self.iteration)\n",
    "\n",
    "            for batch_idx, (data, target) in enumerate(dataloader):\n",
    "                data = data.cuda()\n",
    "                target = target.type(torch.LongTensor).squeeze(1).cuda()\n",
    "                # Forward pass\n",
    "                data = torch.reshape(data, (-1,1,2*1024))\n",
    "                output = self.client_models[str(i)](data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "                # data = data.double().cuda()\n",
    "                # target=target.long().cuda()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                # output = self.client_models[str(i)](data)\n",
    "                loss = F.nll_loss(output, target)\n",
    "\n",
    "                if self.test == 'AFPL':\n",
    "                    optimizer_global.zero_grad()\n",
    "                    output_global = self.client_models_global[str(i)](data)\n",
    "                    loss_global = F.nll_loss(output_global, target)\n",
    "                    loss_global.backward()\n",
    "                    optimizer_global.step()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            self.client_models[str(i)].eval()\n",
    "            dataloader_test = self.dataloaders_test[str(i)]\n",
    "            loss_test = 0\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (data, target) in enumerate(dataloader_test):\n",
    "                    data = data.cuda()\n",
    "                    target = target.type(torch.LongTensor).squeeze(1).cuda()\n",
    "                    # Forward pass\n",
    "                    data = torch.reshape(data, (-1,1,2*1024))\n",
    "                    output = self.client_models[str(i)](data)\n",
    "                    output = F.log_softmax(output, dim=-1)\n",
    "\n",
    "                    loss_test += F.nll_loss(output, target)\n",
    "                self.current_test_loss[str(i)] = loss_test / self.len_test[str(i)]\n",
    "                if self.current_test_loss[str(i)] < self.best_test_loss[str(i)]:\n",
    "                    torch.save(self.client_models[str(i)].state_dict(),\n",
    "                               os.path.join(save_dir, 'model', 'best_model' + str(i) + '.pt'))\n",
    "                    self.best_test_loss[str(i)] = self.current_test_loss[str(i)]\n",
    "\n",
    "            losses += loss_test / self.len_test[str(i)]\n",
    "            loss_test2 = 0\n",
    "            self.client_models[str(i)].eval()\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (data, target) in enumerate(dataloader):\n",
    "                    data = data.cuda()\n",
    "                    target = target.type(torch.LongTensor).squeeze(1).cuda()\n",
    "                    # Forward pass\n",
    "                    data = torch.reshape(data, (-1,1,2*1024))\n",
    "                    output = self.client_models[str(i)](data)\n",
    "                    output = F.log_softmax(output, dim=-1)\n",
    "\n",
    "                    loss_test2 += F.nll_loss(output, target)\n",
    "\n",
    "            losses2 += loss_test2 / self.len[str(i)]\n",
    "            self.current_train_loss[str(i)] = loss_test2 / self.len[str(i)]\n",
    "        print('losses before: ',losses4)\n",
    "        print('full train loss: ', losses2)\n",
    "        print('full loss: ', losses)\n",
    "\n",
    "        return losses2, losses\n",
    "\n",
    "    def combine_models(self, i, client_numbers, set_as=True):\n",
    "        zero_copy = copy.deepcopy(self.client_models[str(i)])  # This is used to collect the model in\n",
    "        j = 0\n",
    "        client_numbers_plus_client = np.concatenate((client_numbers, np.array([int(i)])))  # This is more efficient\n",
    "        #  alphas = zero_copy.alphas.detach()\n",
    "        # alphas[i] = 1 - torch.sum(\n",
    "        #     torch.tensor([iii for idx, iii in enumerate(alphas) if idx != i and idx in client_numbers]))\n",
    "        # It's not possible to set the value of self.alphas[i], so instead we determine it manually here\n",
    "        alphas = torch.ones(len(client_numbers_plus_client)).cuda() / (len(client_numbers_plus_client))\n",
    "        # print(alphas)\n",
    "        for ii in client_numbers_plus_client:\n",
    "            #  print(ii)\n",
    "            for (name, param), (name2, param2) in zip(zero_copy.named_parameters(), self.client_models[\n",
    "                str(ii)].named_parameters()):  # self.client_models[str(ii)].named_parameters()):\n",
    "\n",
    "                if name != 'alphas':\n",
    "                    if j == 0:\n",
    "                        param.data = torch.zeros(param.shape).cuda()\n",
    "\n",
    "                    param.data += alphas[j] * param2.data  # we add all participating client's models to the one here.\n",
    "\n",
    "            j += 1\n",
    "\n",
    "        # self.client_models[str(i)] = zero_copy.double()\n",
    "        if set_as == True:\n",
    "            for (name, param), (name2, param2) in zip(self.client_models[str(i)].named_parameters(),\n",
    "                                                      zero_copy.named_parameters()):\n",
    "                param.data = param2.data\n",
    "            self.client_models[str(i)].double()\n",
    "        else:\n",
    "            return zero_copy.double()\n",
    "\n",
    "    def federated_averaging(self):\n",
    "        self.shared_model = copy.deepcopy(self.network).double().cuda()\n",
    "        n_clients = len(self.selected_clients)\n",
    "        weight = [self.len[str(x)] for x in self.selected_clients]\n",
    "        weight = weight / np.sum(weight)\n",
    "\n",
    "        losses = 0\n",
    "        losses2 = 0\n",
    "        # print(\"weights \",weight)\n",
    "        for idx, i in enumerate(self.selected_clients):\n",
    "            for (name, param), (name2, param2) in zip(self.shared_model.named_parameters()\n",
    "                    , self.client_models[str(i)].named_parameters()):\n",
    "                if idx == 0:\n",
    "                    param.data = torch.zeros(param.shape).cuda().double()\n",
    "                param.data += weight[idx] * param2.data\n",
    "\n",
    "        self.shared_model = self.shared_model.double().eval()\n",
    "\n",
    "        for i in self.selected_clients:\n",
    "            self.client_models[str(i)] = copy.deepcopy(self.shared_model)  # copy global model to the clients\n",
    "            loss_test = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(i)]):\n",
    "                data = data.cuda()\n",
    "                target = target.type(torch.LongTensor).squeeze(1).cuda()\n",
    "                # Forward pass\n",
    "                data = torch.reshape(data, (-1,1,2*1024))\n",
    "                output = self.shared_model(data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "\n",
    "                loss_test += F.nll_loss(output, target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test = loss_test / self.len_test[str(i)]\n",
    "            losses += loss_test\n",
    "            if loss_test < self.best_test_loss[str(i)]:\n",
    "                torch.save(self.client_models[str(i)].state_dict(),\n",
    "                           os.path.join(save_dir, 'model', 'best_model' + str(i) + '.pt'))\n",
    "                self.best_test_loss[str(i)] = loss_test\n",
    "            self.client_models[str(i)].eval()\n",
    "            loss_test2 = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders[str(i)]):\n",
    "                data = data.cuda()\n",
    "                target = target.type(torch.LongTensor).squeeze(1).cuda()\n",
    "                # Forward pass\n",
    "                data = torch.reshape(data, (-1,1,2*1024))\n",
    "                output = self.shared_model(data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "\n",
    "                loss_test2 += F.nll_loss(output, target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test2 = loss_test2 / self.len[str(i)]\n",
    "            losses2 += loss_test2\n",
    "\n",
    "        return losses, losses2\n",
    "\n",
    "    def AFPL(self):  # use alpha = 0.25 = 0.75 global model + 0.25 local model\n",
    "        self.shared_model_old = copy.deepcopy(self.shared_model)\n",
    "        self.shared_model = copy.deepcopy(self.network).double().cuda()\n",
    "        n_clients = len(self.selected_clients)\n",
    "        weight = [self.len[str(x)] for x in self.selected_clients]\n",
    "        weight = weight / np.sum(weight)\n",
    "\n",
    "        losses = 0\n",
    "        losses2 = 0\n",
    "\n",
    "        # accumulate local weights\n",
    "        for idx, i in enumerate(self.selected_clients):\n",
    "            for (name, param), (name2, param2), (name3, param3), (name4, param4) in zip(\n",
    "                    self.shared_model.named_parameters()\n",
    "                    , self.client_models_global[str(i)].named_parameters(),\n",
    "                    self.shared_model_old.named_parameters(),\n",
    "                    self.client_models[str(i)].named_parameters()):\n",
    "                if idx == 0:\n",
    "                    param.data = torch.zeros(param.shape).cuda().double()\n",
    "                param.data += weight[idx] * param2.data  # accumulate local weights\n",
    "                param4.data = 0.25 * param4.data + 0.75 * param3.data  # do AFPL local model update: note that we take the previous global model\n",
    "            self.client_models[str(i)] = self.client_models[str(i)].double()\n",
    "            self.client_models[str(i)].eval()\n",
    "            loss_test = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(i)]):\n",
    "                data = data.cuda()\n",
    "                target = target.type(torch.LongTensor).squeeze(1).cuda()\n",
    "                # Forward pass\n",
    "                data = torch.reshape(data, (-1,1,2*1024))\n",
    "                output = self.client_models[str(i)](data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "\n",
    "                loss_test += F.nll_loss(output, target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test = loss_test / self.len_test[str(i)]\n",
    "            losses += loss_test\n",
    "            if loss_test < self.best_test_loss[str(i)]:\n",
    "                torch.save(self.client_models[str(i)].state_dict(),\n",
    "                           os.path.join(save_dir, 'model', 'best_model' + str(i) + '.pt'))\n",
    "                self.best_test_loss[str(i)] = loss_test\n",
    "            self.client_models[str(i)].eval()\n",
    "            loss_test2 = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders[str(i)]):\n",
    "                data = data.cuda()\n",
    "                target = target.type(torch.LongTensor).squeeze(1).cuda()\n",
    "                # Forward pass\n",
    "                data = torch.reshape(data, (-1,1,2*1024))\n",
    "                output = self.client_models[str(i)](data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "\n",
    "                loss_test2 += F.nll_loss(output, target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test2 = loss_test2 / self.len[str(i)]\n",
    "            losses2 += loss_test2\n",
    "\n",
    "        self.shared_model = self.shared_model.double()\n",
    "        return losses, losses2\n",
    "\n",
    "    def my_method2(self, client, k=30):\n",
    "\n",
    "        selected_clients = []\n",
    "        other_clients = [x for x in range(self.total_clients) if x is not client]\n",
    "        ey = np.zeros(len(other_clients))  # fix indices\n",
    "        current_test = np.zeros(len(other_clients))\n",
    "        collected_clients = []\n",
    "        list1 = np.arange(len(other_clients))\n",
    "        np.random.shuffle(list1)\n",
    "        for i in list1[:k]:\n",
    "            shared_model = self.combine_models(client, [other_clients[i]], set_as=False)\n",
    "\n",
    "            if len(collected_clients) > 0:\n",
    "                all_clients = collected_clients + [other_clients[i]]\n",
    "                shared_model2 = self.combine_models(client, all_clients, set_as=False)\n",
    "\n",
    "            shared_model.eval().cuda()\n",
    "            self.client_models[str(client)].eval().cuda()\n",
    "            loss_test = 0\n",
    "            loss_test2 = 0\n",
    "            loss_test3 = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(client)]):\n",
    "                data = data.cuda()\n",
    "                target = target.type(torch.LongTensor).squeeze(1).cuda()\n",
    "                # Forward pass\n",
    "                data = torch.reshape(data, (-1,1,2*1024))\n",
    "                output = shared_model(data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "                local_output = self.client_models[str(client)](data)\n",
    "                local_output = F.log_softmax(local_output, dim=-1)\n",
    "\n",
    "                loss_test += F.nll_loss(output, target).detach().cpu().numpy()\n",
    "                loss_test2 += F.nll_loss(local_output, target).detach().cpu().numpy()\n",
    "\n",
    "                if len(collected_clients) > 0:\n",
    "                    output2 = shared_model2(data)\n",
    "                    output2 = F.log_softmax(output2, dim=-1)\n",
    "                    loss_test3 += F.nll_loss(output2, target).detach().cpu().numpy()\n",
    "\n",
    "            ey[i] = loss_test / self.len_test[str(client)]\n",
    "            current_test[i] = loss_test2 / self.len_test[str(client)]\n",
    "            if ey[i] < current_test[i]:\n",
    "                if len(collected_clients) > 0:\n",
    "                    test2 = loss_test3 / self.len_test[str(client)]\n",
    "                    if test2 < current_test[i]:\n",
    "                        collected_clients.append(other_clients[i])\n",
    "                else:\n",
    "                    collected_clients.append(other_clients[i])\n",
    "        loss_test = current_test[i]\n",
    "        # print(client)\n",
    "        # print(loss_test)\n",
    "        # print(self.current_test_loss[str(client)])\n",
    "        # print(ey)\n",
    "\n",
    "        selected_clients = np.where(ey <= self.current_test_loss[str(client)].detach().cpu().numpy())[0]\n",
    "        selected_clients = [other_clients[x] for x in selected_clients]\n",
    "        # print(selected_clients)\n",
    "        selected_clients = collected_clients\n",
    "\n",
    "        if len(selected_clients) > 0:\n",
    "            self.combine_models(client, selected_clients, set_as=True)\n",
    "            loss_test = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(client)]):\n",
    "                data = data.cuda()\n",
    "                target = target.type(torch.LongTensor).squeeze(1).cuda()\n",
    "                # Forward pass\n",
    "                data = torch.reshape(data, (-1,1,2*1024))\n",
    "                output = self.client_models[str(client)](data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "\n",
    "                loss_test += F.nll_loss(output, target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test = loss_test / self.len_test[str(client)]\n",
    "            if loss_test < self.best_test_loss[str(client)]:\n",
    "                torch.save(self.client_models[str(client)].state_dict(),\n",
    "                           os.path.join(save_dir, 'model', 'best_model' + str(i) + '.pt'))\n",
    "                self.best_test_loss[str(client)] = loss_test\n",
    "            self.client_models[str(client)].eval()\n",
    "            loss_test2 = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders[str(client)]):\n",
    "                data = data.cuda()\n",
    "                target = target.type(torch.LongTensor).squeeze(1).cuda()\n",
    "                # Forward pass\n",
    "                data = torch.reshape(data, (-1,1,2*1024))\n",
    "                output = self.client_models[str(client)](data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "                loss_test2 += F.nll_loss(output, target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test2 = loss_test2 / self.len[str(client)]\n",
    "        return loss_test, loss_test2, selected_clients\n",
    "\n",
    "    def bandits(self, client, n,length):\n",
    "\n",
    "        selected_clients = []\n",
    "        other_clients = [x for x in range(self.total_clients) if x != client]\n",
    "        # print(other_clients)\n",
    "        ey = np.zeros(self.total_clients)  # fix indices\n",
    "        current_test = np.zeros(self.total_clients)\n",
    "        collected_clients = []\n",
    "        #print('START OF UCB CLIENT: ',client)\n",
    "        selected_clients_UCB = self.comb_UCB.to_client([client], n)\n",
    "        if client == 0:\n",
    "            print('selected clients UCB: ', selected_clients_UCB)\n",
    "        old_accuracy = 0 \n",
    "        for i in selected_clients_UCB:\n",
    "            shared_model = self.combine_models(client, [i], set_as=False)\n",
    "\n",
    "            if len(collected_clients) > 0:\n",
    "                all_clients = collected_clients + [i]\n",
    "                shared_model2 = self.combine_models(client, all_clients, set_as=False)\n",
    "\n",
    "            shared_model.eval().cuda()\n",
    "            self.client_models[str(client)].eval().cuda()\n",
    "            loss_test = 0\n",
    "            loss_test2 = 0\n",
    "            loss_test3 = 0\n",
    "            \n",
    "            accuracy_shared = 0 \n",
    "            accuracy_local = 0 \n",
    "            \n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(client)]):\n",
    "                data = data.cuda()\n",
    "                target = target.type(torch.LongTensor).squeeze(1).cuda()\n",
    "                # Forward pass\n",
    "                data = torch.reshape(data, (-1,1,2*1024))\n",
    "                output = shared_model(data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "                output2 = self.client_models[str(client)](data)\n",
    "                output2 = F.log_softmax(output2, dim=-1)\n",
    "                loss_test += F.nll_loss(output, target).detach().cpu().numpy()\n",
    "                loss_test2 += F.nll_loss(output2, target).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "                if len(collected_clients) > 0:\n",
    "                    output = shared_model2(data)\n",
    "                    output = F.log_softmax(output, dim=-1)\n",
    "                    loss_test3 += F.nll_loss(output, target).detach().cpu().numpy()\n",
    "                    old_accuracy = accuracy_shareds\n",
    "                    \n",
    "                # calculate accuracy \n",
    "                output_array = output.detach().cpu().numpy()\n",
    "                output_class = np.argmax(output_array, axis=-1)\n",
    "                target_array = target.detach().cpu().numpy()\n",
    "                accuracy_shared += np.sum(output_class == target_array)\n",
    "                \n",
    "                output_array2 = output2.detach().cpu().numpy()\n",
    "                output_class2 = np.argmax(output_array2, axis=-1)\n",
    "                accuracy_local += np.sum(output_class2 == target_array)\n",
    "                    \n",
    "            accuracy_locals = accuracy_local / length[str(client)] * 100 \n",
    "            accuracy_shareds = accuracy_shared / length[str(client)] *100 \n",
    "            #print('CLIENT: ',i)\n",
    "          #  print(accuracy_locals)\n",
    "           # print(accuracy_shareds)\n",
    "            \n",
    "            # ACCURACY-based client selection \n",
    "            if accuracy_shareds > accuracy_locals and accuracy_shareds > old_accuracy: \n",
    "                collected_clients.append(i)\n",
    "\n",
    "                # LOSS-BASED client selection: \n",
    "         #   ey[i] = loss_test / self.len_test[str(client)]\n",
    "         #   current_test[i] = loss_test2 / self.len_test[str(client)]\n",
    "         #   if ey[i] < current_test[i]:\n",
    "        #        if len(collected_clients) > 0:\n",
    "        #            test2 = loss_test3 / self.len_test[str(client)]\n",
    "        #            if test2 < current_test[i]:\n",
    "         #               collected_clients.append(i)\n",
    "        #        else:\n",
    "         #           collected_clients.append(i)\n",
    "        \n",
    "        loss_test = current_test[i]\n",
    "        #selected_clients = np.where(ey <= self.current_test_loss[str(client)].detach().cpu().numpy())[0]\n",
    "        \n",
    "        selected_clients = collected_clients\n",
    "\n",
    "        observation = np.zeros(self.total_clients)\n",
    "        observation[selected_clients] = 1\n",
    "        if client == 0:\n",
    "            print(observation)\n",
    "\n",
    "        self.comb_UCB.to_server(client, observation)\n",
    "\n",
    "        if len(selected_clients) > 0:\n",
    "            self.combine_models(client, selected_clients, set_as=True)\n",
    "            loss_test = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(client)]):\n",
    "                data = data.cuda()\n",
    "                target = target.type(torch.LongTensor).squeeze(1).cuda()\n",
    "                # Forward pass\n",
    "                data = torch.reshape(data, (-1,1,2*1024))\n",
    "                output2 = self.client_models[str(client)](data)\n",
    "                output2 = F.log_softmax(output2, dim=-1)\n",
    "\n",
    "                loss_test += F.nll_loss(output2, target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test = loss_test / self.len_test[str(client)]\n",
    "            if loss_test < self.best_test_loss[str(client)]:\n",
    "                torch.save(self.client_models[str(client)].state_dict(),\n",
    "                           os.path.join(save_dir, 'model', 'best_model' + str(i) + '.pt'))\n",
    "                self.best_test_loss[str(client)] = loss_test\n",
    "            self.client_models[str(client)].eval()\n",
    "            loss_test2 = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders[str(client)]):\n",
    "                data = data.cuda()\n",
    "                target = target.type(torch.LongTensor).squeeze(1).cuda()\n",
    "                # Forward pass\n",
    "                data = torch.reshape(data, (-1,1,2*1024))\n",
    "                output2 = self.client_models[str(client)](data)\n",
    "                output2 = F.log_softmax(output2, dim=-1)\n",
    "\n",
    "                loss_test2 += F.nll_loss(output2, target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test2 = loss_test2 / self.len[str(client)]\n",
    "        return loss_test, loss_test2, selected_clients, selected_clients_UCB\n",
    "\n",
    "    def calc_accuracy(self,dataloaders,length):\n",
    "        accuracies = np.zeros(len(self.selected_clients))\n",
    "        total = 0\n",
    "        for i in self.selected_clients:\n",
    "            #dataloader = self.dataloaders_really_test[str(i)]\n",
    "            dataloader = dataloaders[str(i)]\n",
    "            intermediate_accuracy = 0\n",
    "            self.client_models[str(i)].eval()\n",
    "            y_pred = []\n",
    "            y_true = []\n",
    "            for batch_idx, (data, target) in enumerate(dataloader):\n",
    "                data = data.cuda()\n",
    "                target = target.type(torch.LongTensor).squeeze(1).cuda()\n",
    "                # Forward pass\n",
    "                data = torch.reshape(data, (-1,1,2*1024))\n",
    "                output = self.client_models[str(i)](data)\n",
    "                output = F.log_softmax(output, dim=-1)\n",
    "                output_array = output.detach().cpu().numpy()\n",
    "                output_class = np.argmax(output_array, axis=-1)\n",
    "                target_array = target.detach().cpu().numpy()\n",
    "                intermediate_accuracy += np.sum(output_class == target_array)\n",
    "                y_pred.append(list(output_class))\n",
    "                y_true.append(list(target_array))\n",
    "\n",
    "            #accuracy = intermediate_accuracy / p2p.len_really_test[str(i)] * 100\n",
    "            # print(i)\n",
    "            accuracy = intermediate_accuracy / length[str(i)] * 100 \n",
    "            if self.iteration % 5 == 0: \n",
    "                print('client accuracy : ',str(i))\n",
    "                print(accuracy)\n",
    "\n",
    "            pred = np.array([j for sub in y_pred for j in sub])\n",
    "            true = np.array([j for sub in y_true for j in sub])\n",
    "            C = confusion_matrix(true, pred).ravel()\n",
    "            if len(C) == 4:\n",
    "                df = pandas.DataFrame([[C[3], C[1]], [C[2], C[0]]], columns=['Positive', 'Negative'],\n",
    "                                      index=['Predicted Positive', 'Predicted Negative'])\n",
    "\n",
    "            total += length[str(i)]\n",
    "            accuracies[i] = intermediate_accuracy\n",
    "        overall_accuracy = np.sum(accuracies) / total * 100\n",
    "       \n",
    "        return overall_accuracy\n",
    "    \n",
    "    def loop(self, epochs, p2p, experiment_name):\n",
    "\n",
    "        loss_tests = []\n",
    "        loss_trains = []\n",
    "        loss_tests2 = []\n",
    "        loss_trains2 = []\n",
    "        accuracies = []\n",
    "        accuracies_train = []\n",
    "        self.p2p = p2p\n",
    "        self.phis = np.zeros((self.total_clients, self.total_clients))\n",
    "        self.phisUCB = np.zeros((self.total_clients, self.total_clients))\n",
    "        self.selected_clients_arr = np.zeros((epochs, self.total_clients, self.total_clients))\n",
    "\n",
    "        for i in range(epochs):\n",
    "            print(i)\n",
    "            #print(self.client_models[str(1)].layer1[0].weight.detach().cpu().numpy())\n",
    "            self.iteration = i\n",
    "            list1 = []\n",
    "            self.selected_clients = [x for x in range(self.total_clients)]\n",
    "            loss_train, loss_test = self.update_local_models(self.selected_clients)\n",
    "            loss_tests.append(loss_test.detach().cpu().numpy())\n",
    "            loss_trains.append(loss_train.detach().cpu().numpy())\n",
    "            #print(self.client_models[str(1)].layer1[0].weight.detach().cpu().numpy())\n",
    "            accuracy_val = self.calc_accuracy(self.dataloaders_test,self.len_test)\n",
    "            print('val accuracy before bandits: ',accuracy_val)\n",
    "            if self.test == 'AFPL':\n",
    "                losses2, losses3 = self.AFPL()\n",
    "\n",
    "            if self.test == 'local':\n",
    "                print('we are done')\n",
    "\n",
    "            if self.test == 'federated':\n",
    "                losses2, losses3 = self.federated_averaging()\n",
    "\n",
    "            if self.test == 'bandits':\n",
    "                losses2 = 0\n",
    "                losses3 = 0\n",
    "                for client in range(self.total_clients):\n",
    "                    loss_test2, loss_train2, selected_clients2,selected_clients_UCB = self.bandits(client, i,self.len_test)\n",
    "                    losses2 += loss_test2\n",
    "                    if len(selected_clients2) < 1:\n",
    "                        losses3 += self.current_train_loss[str(client)].detach().cpu().numpy()\n",
    "                    else:\n",
    "                        losses3 += loss_train2\n",
    "                    self.phis[client, selected_clients2] += 1\n",
    "                    self.phisUCB[client,selected_clients_UCB] += 1\n",
    "                    self.selected_clients_arr[i, client, selected_clients2] += 1\n",
    "                fname = os.path.join('checkpoints_bandits', experiment_name, 'phi' + str(i) + '.txt')\n",
    "                np.savetxt(fname, self.phis)\n",
    "                fname = os.path.join('checkpoints_bandits', experiment_name, 'phi_UCB' + str(i) + '.txt')\n",
    "                np.savetxt(fname, self.phisUCB)\n",
    "\n",
    "            if self.test == 'mine':\n",
    "                losses2 = 0\n",
    "                losses3 = 0\n",
    "                for client in range(self.total_clients):\n",
    "                    loss_test2, loss_train2, selected_clients2 = self.my_method2(client)\n",
    "                    losses2 += loss_test2\n",
    "                    if len(selected_clients2) < 1:\n",
    "                        losses3 += self.current_train_loss[str(client)].detach().cpu().numpy()\n",
    "\n",
    "                    else:\n",
    "                        losses3 += loss_train2\n",
    "                    self.phis[client, selected_clients2] += 1\n",
    "                    # print(selected_clients2)\n",
    "                fname = os.path.join('checkpoints_bandits', experiment_name, 'phi' + str(i) + '.txt')\n",
    "                np.savetxt(fname, self.phis)\n",
    "\n",
    "            if self.test == 'optimal':\n",
    "                losses2, losses3 = self.optimal_fedavg()\n",
    "                losses2 = losses2.detach().cpu().numpy()\n",
    "                losses3 = losses3.detach().cpu().numpy()\n",
    "\n",
    "            if self.test != 'local':\n",
    "                print('loss after my code: ', losses2)\n",
    "                print('train loss after my code: ', losses3)\n",
    "                loss_tests2.append(losses2)\n",
    "                loss_trains2.append(losses3)\n",
    "                fname = os.path.join('checkpoints_bandits', experiment_name, 'losses_test.txt')\n",
    "                np.savetxt(fname, loss_tests2)\n",
    "                fname = os.path.join('checkpoints_bandits', experiment_name, 'losses_train.txt')\n",
    "                np.savetxt(fname, loss_trains2)\n",
    "\n",
    "\n",
    "            else:\n",
    "                fname = os.path.join('checkpoints_bandits', experiment_name, 'losses_test.txt')\n",
    "                np.savetxt(fname, loss_tests)\n",
    "                fname = os.path.join('checkpoints_bandits', experiment_name, 'losses_train.txt')\n",
    "                np.savetxt(fname, loss_trains)\n",
    "\n",
    "            accuracy_val = self.calc_accuracy(self.dataloaders_test,self.len_test)\n",
    "            print('val accuracy: ',accuracy_val)\n",
    "            accuracy = self.calc_accuracy(self.dataloaders_really_test,self.len_really_test)\n",
    "            print('test accuracy: ',accuracy)\n",
    "            accuracies.append(accuracy)\n",
    "            # accuracy_train = self.calc_accuracy(test=False)\n",
    "            # print(accuracy_train)\n",
    "            # accuracies_train.append(accuracy_train)\n",
    "        # print(self.phis)\n",
    "        fname = os.path.join('checkpoints_bandits', experiment_name, 'accuracies.txt')\n",
    "        np.savetxt(fname, accuracies)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_trains, label='train loss before')\n",
    "        plt.plot(loss_tests, label='test loss before')\n",
    "        plt.plot(loss_trains2, label='train loss after')\n",
    "        plt.plot(loss_tests2, label='test loss after')\n",
    "        plt.title('loss curve')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.savefig(os.path.join('checkpoints_bandits', experiment_name, 'loss_curve.png'))\n",
    "        plt.clf()\n",
    "        plt.plot(accuracies, label='test')\n",
    "        # plt.plot(accuracies_train,label='train')\n",
    "        plt.title('accuracy progression')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join('checkpoints_bandits', experiment_name, 'accuracy_progression.png'))\n",
    "        return accuracies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b973f487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23]\n",
      "0\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.6906, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.7919, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "79.03225806451613\n",
      "client accuracy :  1\n",
      "77.77777777777779\n",
      "client accuracy :  2\n",
      "80.35714285714286\n",
      "client accuracy :  3\n",
      "60.37735849056604\n",
      "client accuracy :  4\n",
      "90.9090909090909\n",
      "client accuracy :  5\n",
      "79.54545454545455\n",
      "client accuracy :  6\n",
      "68.37606837606837\n",
      "client accuracy :  7\n",
      "89.1891891891892\n",
      "client accuracy :  8\n",
      "71.1864406779661\n",
      "client accuracy :  9\n",
      "97.16981132075472\n",
      "client accuracy :  10\n",
      "58.791208791208796\n",
      "client accuracy :  11\n",
      "75.71428571428571\n",
      "client accuracy :  12\n",
      "66.26984126984127\n",
      "client accuracy :  13\n",
      "78.04878048780488\n",
      "client accuracy :  14\n",
      "83.33333333333334\n",
      "client accuracy :  15\n",
      "88.57142857142857\n",
      "client accuracy :  16\n",
      "85.0\n",
      "client accuracy :  17\n",
      "55.55555555555556\n",
      "client accuracy :  18\n",
      "33.33333333333333\n",
      "client accuracy :  19\n",
      "88.67924528301887\n",
      "val accuracy before bandits:  73.91613361762616\n",
      "loss after my code:  30.147911474012712\n",
      "train loss after my code:  26.47929471316313\n",
      "client accuracy :  0\n",
      "45.16129032258064\n",
      "client accuracy :  1\n",
      "48.148148148148145\n",
      "client accuracy :  2\n",
      "41.07142857142857\n",
      "client accuracy :  3\n",
      "39.62264150943396\n",
      "client accuracy :  4\n",
      "36.36363636363637\n",
      "client accuracy :  5\n",
      "54.54545454545454\n",
      "client accuracy :  6\n",
      "49.572649572649574\n",
      "client accuracy :  7\n",
      "45.94594594594595\n",
      "client accuracy :  8\n",
      "47.45762711864407\n",
      "client accuracy :  9\n",
      "41.509433962264154\n",
      "client accuracy :  10\n",
      "46.7032967032967\n",
      "client accuracy :  11\n",
      "45.714285714285715\n",
      "client accuracy :  12\n",
      "44.047619047619044\n",
      "client accuracy :  13\n",
      "46.34146341463415\n",
      "client accuracy :  14\n",
      "40.476190476190474\n",
      "client accuracy :  15\n",
      "51.42857142857142\n",
      "client accuracy :  16\n",
      "42.5\n",
      "client accuracy :  17\n",
      "40.74074074074074\n",
      "client accuracy :  18\n",
      "25.925925925925924\n",
      "client accuracy :  19\n",
      "58.490566037735846\n",
      "val accuracy:  44.9182658137882\n",
      "client accuracy :  0\n",
      "38.70967741935484\n",
      "client accuracy :  1\n",
      "44.44444444444444\n",
      "client accuracy :  2\n",
      "51.78571428571429\n",
      "client accuracy :  3\n",
      "37.735849056603776\n",
      "client accuracy :  4\n",
      "49.35064935064935\n",
      "client accuracy :  5\n",
      "45.45454545454545\n",
      "client accuracy :  6\n",
      "44.44444444444444\n",
      "client accuracy :  7\n",
      "48.64864864864865\n",
      "client accuracy :  8\n",
      "44.06779661016949\n",
      "client accuracy :  9\n",
      "51.4018691588785\n",
      "client accuracy :  10\n",
      "51.64835164835166\n",
      "client accuracy :  11\n",
      "42.857142857142854\n",
      "client accuracy :  12\n",
      "50.19762845849802\n",
      "client accuracy :  13\n",
      "53.65853658536586\n",
      "client accuracy :  14\n",
      "50.0\n",
      "client accuracy :  15\n",
      "28.57142857142857\n",
      "client accuracy :  16\n",
      "53.65853658536586\n",
      "client accuracy :  17\n",
      "51.85185185185185\n",
      "client accuracy :  18\n",
      "66.66666666666666\n",
      "client accuracy :  19\n",
      "43.39622641509434\n",
      "test accuracy:  47.87234042553192\n",
      "1\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.0699, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.1498, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  71.78393745557925\n",
      "loss after my code:  23.56968148051789\n",
      "train loss after my code:  21.007768676505602\n",
      "val accuracy:  44.9182658137882\n",
      "test accuracy:  47.801418439716315\n",
      "2\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.3503, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.7493, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  73.20540156361052\n",
      "loss after my code:  77.28169373946409\n",
      "train loss after my code:  66.96200153366371\n",
      "val accuracy:  44.9182658137882\n",
      "test accuracy:  47.87234042553192\n",
      "3\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.2611, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.4646, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  69.7228144989339\n",
      "loss after my code:  75.56729024840658\n",
      "train loss after my code:  65.12332905888695\n",
      "val accuracy:  44.9182658137882\n",
      "test accuracy:  47.87234042553192\n",
      "4\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.7743, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.0268, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  73.98720682302772\n",
      "loss after my code:  59.738943764337336\n",
      "train loss after my code:  53.44757193096766\n",
      "val accuracy:  44.9182658137882\n",
      "test accuracy:  47.87234042553192\n",
      "5\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.9571, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.1512, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "66.12903225806451\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "83.92857142857143\n",
      "client accuracy :  3\n",
      "71.69811320754717\n",
      "client accuracy :  4\n",
      "63.63636363636363\n",
      "client accuracy :  5\n",
      "79.54545454545455\n",
      "client accuracy :  6\n",
      "64.1025641025641\n",
      "client accuracy :  7\n",
      "86.48648648648648\n",
      "client accuracy :  8\n",
      "77.96610169491525\n",
      "client accuracy :  9\n",
      "71.69811320754717\n",
      "client accuracy :  10\n",
      "79.12087912087912\n",
      "client accuracy :  11\n",
      "88.57142857142857\n",
      "client accuracy :  12\n",
      "85.31746031746032\n",
      "client accuracy :  13\n",
      "68.29268292682927\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "82.85714285714286\n",
      "client accuracy :  16\n",
      "42.5\n",
      "client accuracy :  17\n",
      "48.148148148148145\n",
      "client accuracy :  18\n",
      "37.03703703703704\n",
      "client accuracy :  19\n",
      "92.45283018867924\n",
      "val accuracy before bandits:  75.33759772565742\n",
      "loss after my code:  170.6073255286975\n",
      "train loss after my code:  146.4204649587293\n",
      "client accuracy :  0\n",
      "45.16129032258064\n",
      "client accuracy :  1\n",
      "48.148148148148145\n",
      "client accuracy :  2\n",
      "41.07142857142857\n",
      "client accuracy :  3\n",
      "39.62264150943396\n",
      "client accuracy :  4\n",
      "36.36363636363637\n",
      "client accuracy :  5\n",
      "54.54545454545454\n",
      "client accuracy :  6\n",
      "49.572649572649574\n",
      "client accuracy :  7\n",
      "45.94594594594595\n",
      "client accuracy :  8\n",
      "47.45762711864407\n",
      "client accuracy :  9\n",
      "41.509433962264154\n",
      "client accuracy :  10\n",
      "46.7032967032967\n",
      "client accuracy :  11\n",
      "45.714285714285715\n",
      "client accuracy :  12\n",
      "44.047619047619044\n",
      "client accuracy :  13\n",
      "46.34146341463415\n",
      "client accuracy :  14\n",
      "40.476190476190474\n",
      "client accuracy :  15\n",
      "51.42857142857142\n",
      "client accuracy :  16\n",
      "42.5\n",
      "client accuracy :  17\n",
      "40.74074074074074\n",
      "client accuracy :  18\n",
      "25.925925925925924\n",
      "client accuracy :  19\n",
      "58.490566037735846\n",
      "val accuracy:  44.9182658137882\n",
      "client accuracy :  0\n",
      "38.70967741935484\n",
      "client accuracy :  1\n",
      "44.44444444444444\n",
      "client accuracy :  2\n",
      "51.78571428571429\n",
      "client accuracy :  3\n",
      "37.735849056603776\n",
      "client accuracy :  4\n",
      "49.35064935064935\n",
      "client accuracy :  5\n",
      "45.45454545454545\n",
      "client accuracy :  6\n",
      "44.44444444444444\n",
      "client accuracy :  7\n",
      "48.64864864864865\n",
      "client accuracy :  8\n",
      "44.06779661016949\n",
      "client accuracy :  9\n",
      "51.4018691588785\n",
      "client accuracy :  10\n",
      "51.64835164835166\n",
      "client accuracy :  11\n",
      "42.857142857142854\n",
      "client accuracy :  12\n",
      "50.19762845849802\n",
      "client accuracy :  13\n",
      "53.65853658536586\n",
      "client accuracy :  14\n",
      "50.0\n",
      "client accuracy :  15\n",
      "28.57142857142857\n",
      "client accuracy :  16\n",
      "53.65853658536586\n",
      "client accuracy :  17\n",
      "51.85185185185185\n",
      "client accuracy :  18\n",
      "66.66666666666666\n",
      "client accuracy :  19\n",
      "43.39622641509434\n",
      "test accuracy:  47.87234042553192\n",
      "6\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.8079, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.9862, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  74.27149964463398\n",
      "loss after my code:  62.245247848223514\n",
      "train loss after my code:  51.99367751750098\n",
      "val accuracy:  45.06041222459133\n",
      "test accuracy:  47.87234042553192\n",
      "7\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.9242, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.2225, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  76.83013503909027\n",
      "loss after my code:  77.16876961729486\n",
      "train loss after my code:  67.20887405431948\n",
      "val accuracy:  44.9182658137882\n",
      "test accuracy:  47.87234042553192\n",
      "8\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.9617, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.0957, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  78.3226723525231\n",
      "loss after my code:  163.7164975572198\n",
      "train loss after my code:  141.0464879750836\n",
      "val accuracy:  44.9182658137882\n",
      "test accuracy:  47.87234042553192\n",
      "9\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.8708, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.0571, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  76.04832977967307\n",
      "loss after my code:  76.49373806023908\n",
      "train loss after my code:  66.23411758078477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy:  45.06041222459133\n",
      "test accuracy:  47.801418439716315\n",
      "10\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.7343, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.8453, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "88.70967741935483\n",
      "client accuracy :  1\n",
      "55.55555555555556\n",
      "client accuracy :  2\n",
      "85.71428571428571\n",
      "client accuracy :  3\n",
      "60.37735849056604\n",
      "client accuracy :  4\n",
      "81.81818181818183\n",
      "client accuracy :  5\n",
      "81.81818181818183\n",
      "client accuracy :  6\n",
      "87.17948717948718\n",
      "client accuracy :  7\n",
      "81.08108108108108\n",
      "client accuracy :  8\n",
      "94.91525423728814\n",
      "client accuracy :  9\n",
      "95.28301886792453\n",
      "client accuracy :  10\n",
      "73.62637362637363\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "87.3015873015873\n",
      "client accuracy :  13\n",
      "68.29268292682927\n",
      "client accuracy :  14\n",
      "78.57142857142857\n",
      "client accuracy :  15\n",
      "82.85714285714286\n",
      "client accuracy :  16\n",
      "42.5\n",
      "client accuracy :  17\n",
      "40.74074074074074\n",
      "client accuracy :  18\n",
      "74.07407407407408\n",
      "client accuracy :  19\n",
      "79.24528301886792\n",
      "val accuracy before bandits:  80.66808813077469\n",
      "loss after my code:  84.50428134333654\n",
      "train loss after my code:  71.42232777457421\n",
      "client accuracy :  0\n",
      "45.16129032258064\n",
      "client accuracy :  1\n",
      "48.148148148148145\n",
      "client accuracy :  2\n",
      "41.07142857142857\n",
      "client accuracy :  3\n",
      "41.509433962264154\n",
      "client accuracy :  4\n",
      "36.36363636363637\n",
      "client accuracy :  5\n",
      "54.54545454545454\n",
      "client accuracy :  6\n",
      "49.572649572649574\n",
      "client accuracy :  7\n",
      "45.94594594594595\n",
      "client accuracy :  8\n",
      "47.45762711864407\n",
      "client accuracy :  9\n",
      "41.509433962264154\n",
      "client accuracy :  10\n",
      "46.7032967032967\n",
      "client accuracy :  11\n",
      "45.714285714285715\n",
      "client accuracy :  12\n",
      "44.047619047619044\n",
      "client accuracy :  13\n",
      "46.34146341463415\n",
      "client accuracy :  14\n",
      "40.476190476190474\n",
      "client accuracy :  15\n",
      "51.42857142857142\n",
      "client accuracy :  16\n",
      "42.5\n",
      "client accuracy :  17\n",
      "40.74074074074074\n",
      "client accuracy :  18\n",
      "25.925925925925924\n",
      "client accuracy :  19\n",
      "58.490566037735846\n",
      "val accuracy:  44.989339019189764\n",
      "client accuracy :  0\n",
      "38.70967741935484\n",
      "client accuracy :  1\n",
      "44.44444444444444\n",
      "client accuracy :  2\n",
      "51.78571428571429\n",
      "client accuracy :  3\n",
      "37.735849056603776\n",
      "client accuracy :  4\n",
      "49.35064935064935\n",
      "client accuracy :  5\n",
      "45.45454545454545\n",
      "client accuracy :  6\n",
      "44.44444444444444\n",
      "client accuracy :  7\n",
      "48.64864864864865\n",
      "client accuracy :  8\n",
      "44.06779661016949\n",
      "client accuracy :  9\n",
      "51.4018691588785\n",
      "client accuracy :  10\n",
      "51.64835164835166\n",
      "client accuracy :  11\n",
      "42.857142857142854\n",
      "client accuracy :  12\n",
      "50.19762845849802\n",
      "client accuracy :  13\n",
      "53.65853658536586\n",
      "client accuracy :  14\n",
      "50.0\n",
      "client accuracy :  15\n",
      "28.57142857142857\n",
      "client accuracy :  16\n",
      "53.65853658536586\n",
      "client accuracy :  17\n",
      "51.85185185185185\n",
      "client accuracy :  18\n",
      "66.66666666666666\n",
      "client accuracy :  19\n",
      "43.39622641509434\n",
      "test accuracy:  47.87234042553192\n",
      "11\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.5566, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.6445, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  81.80525941719972\n",
      "loss after my code:  122.6763361827593\n",
      "train loss after my code:  105.07281724823363\n",
      "val accuracy:  44.989339019189764\n",
      "test accuracy:  47.87234042553192\n",
      "12\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.6581, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.8040, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  81.09452736318407\n",
      "loss after my code:  144.19320060292716\n",
      "train loss after my code:  126.41802159555235\n",
      "val accuracy:  44.989339019189764\n",
      "test accuracy:  47.87234042553192\n",
      "13\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.4772, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.6032, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  82.8002842928216\n",
      "loss after my code:  119.44004502072389\n",
      "train loss after my code:  103.12124927499669\n",
      "val accuracy:  45.06041222459133\n",
      "test accuracy:  47.87234042553192\n",
      "14\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.5085, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.6873, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  80.95238095238095\n",
      "loss after my code:  44.32284632603642\n",
      "train loss after my code:  37.371249290655236\n",
      "val accuracy:  45.62899786780384\n",
      "test accuracy:  48.58156028368794\n",
      "15\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.5064, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.7041, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "95.16129032258065\n",
      "client accuracy :  1\n",
      "48.148148148148145\n",
      "client accuracy :  2\n",
      "87.5\n",
      "client accuracy :  3\n",
      "60.37735849056604\n",
      "client accuracy :  4\n",
      "83.11688311688312\n",
      "client accuracy :  5\n",
      "84.0909090909091\n",
      "client accuracy :  6\n",
      "77.77777777777779\n",
      "client accuracy :  7\n",
      "91.8918918918919\n",
      "client accuracy :  8\n",
      "86.4406779661017\n",
      "client accuracy :  9\n",
      "97.16981132075472\n",
      "client accuracy :  10\n",
      "71.97802197802197\n",
      "client accuracy :  11\n",
      "84.28571428571429\n",
      "client accuracy :  12\n",
      "86.5079365079365\n",
      "client accuracy :  13\n",
      "95.1219512195122\n",
      "client accuracy :  14\n",
      "88.09523809523809\n",
      "client accuracy :  15\n",
      "85.71428571428571\n",
      "client accuracy :  16\n",
      "45.0\n",
      "client accuracy :  17\n",
      "51.85185185185185\n",
      "client accuracy :  18\n",
      "37.03703703703704\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  81.09452736318407\n",
      "loss after my code:  84.24421024884032\n",
      "train loss after my code:  72.53298091867914\n",
      "client accuracy :  0\n",
      "45.16129032258064\n",
      "client accuracy :  1\n",
      "48.148148148148145\n",
      "client accuracy :  2\n",
      "42.857142857142854\n",
      "client accuracy :  3\n",
      "41.509433962264154\n",
      "client accuracy :  4\n",
      "36.36363636363637\n",
      "client accuracy :  5\n",
      "54.54545454545454\n",
      "client accuracy :  6\n",
      "49.572649572649574\n",
      "client accuracy :  7\n",
      "45.94594594594595\n",
      "client accuracy :  8\n",
      "47.45762711864407\n",
      "client accuracy :  9\n",
      "41.509433962264154\n",
      "client accuracy :  10\n",
      "46.7032967032967\n",
      "client accuracy :  11\n",
      "45.714285714285715\n",
      "client accuracy :  12\n",
      "44.44444444444444\n",
      "client accuracy :  13\n",
      "46.34146341463415\n",
      "client accuracy :  14\n",
      "42.857142857142854\n",
      "client accuracy :  15\n",
      "51.42857142857142\n",
      "client accuracy :  16\n",
      "42.5\n",
      "client accuracy :  17\n",
      "40.74074074074074\n",
      "client accuracy :  18\n",
      "25.925925925925924\n",
      "client accuracy :  19\n",
      "58.490566037735846\n",
      "val accuracy:  45.20255863539446\n",
      "client accuracy :  0\n",
      "38.70967741935484\n",
      "client accuracy :  1\n",
      "44.44444444444444\n",
      "client accuracy :  2\n",
      "51.78571428571429\n",
      "client accuracy :  3\n",
      "37.735849056603776\n",
      "client accuracy :  4\n",
      "49.35064935064935\n",
      "client accuracy :  5\n",
      "45.45454545454545\n",
      "client accuracy :  6\n",
      "44.44444444444444\n",
      "client accuracy :  7\n",
      "48.64864864864865\n",
      "client accuracy :  8\n",
      "44.06779661016949\n",
      "client accuracy :  9\n",
      "51.4018691588785\n",
      "client accuracy :  10\n",
      "51.64835164835166\n",
      "client accuracy :  11\n",
      "42.857142857142854\n",
      "client accuracy :  12\n",
      "50.19762845849802\n",
      "client accuracy :  13\n",
      "53.65853658536586\n",
      "client accuracy :  14\n",
      "50.0\n",
      "client accuracy :  15\n",
      "28.57142857142857\n",
      "client accuracy :  16\n",
      "53.65853658536586\n",
      "client accuracy :  17\n",
      "51.85185185185185\n",
      "client accuracy :  18\n",
      "66.66666666666666\n",
      "client accuracy :  19\n",
      "43.39622641509434\n",
      "test accuracy:  47.87234042553192\n",
      "16\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.3956, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5130, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  82.4449182658138\n",
      "loss after my code:  31.07240120970676\n",
      "train loss after my code:  26.93756631987204\n",
      "val accuracy:  45.91329068941009\n",
      "test accuracy:  48.51063829787234\n",
      "17\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.4899, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.6489, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  81.52096659559346\n",
      "loss after my code:  61.147207952508545\n",
      "train loss after my code:  53.472435615951014\n",
      "val accuracy:  45.20255863539446\n",
      "test accuracy:  47.87234042553192\n",
      "18\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.3701, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4479, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  84.36389481165601\n",
      "loss after my code:  65.60417352356899\n",
      "train loss after my code:  55.60300198629367\n",
      "val accuracy:  45.20255863539446\n",
      "test accuracy:  47.87234042553192\n",
      "19\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.3913, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5252, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  84.15067519545131\n",
      "loss after my code:  26.154589757662965\n",
      "train loss after my code:  22.20037147547389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy:  46.41080312722104\n",
      "test accuracy:  48.723404255319146\n",
      "20\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.4155, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5046, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "95.16129032258065\n",
      "client accuracy :  1\n",
      "62.96296296296296\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "60.37735849056604\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "84.0909090909091\n",
      "client accuracy :  6\n",
      "88.03418803418803\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "94.91525423728814\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "67.58241758241759\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "88.88888888888889\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "88.09523809523809\n",
      "client accuracy :  15\n",
      "74.28571428571429\n",
      "client accuracy :  16\n",
      "50.0\n",
      "client accuracy :  17\n",
      "66.66666666666666\n",
      "client accuracy :  18\n",
      "55.55555555555556\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  84.5771144278607\n",
      "loss after my code:  32.30995316071294\n",
      "train loss after my code:  28.249798240129884\n",
      "client accuracy :  0\n",
      "45.16129032258064\n",
      "client accuracy :  1\n",
      "48.148148148148145\n",
      "client accuracy :  2\n",
      "44.642857142857146\n",
      "client accuracy :  3\n",
      "43.39622641509434\n",
      "client accuracy :  4\n",
      "36.36363636363637\n",
      "client accuracy :  5\n",
      "56.81818181818182\n",
      "client accuracy :  6\n",
      "48.717948717948715\n",
      "client accuracy :  7\n",
      "48.64864864864865\n",
      "client accuracy :  8\n",
      "47.45762711864407\n",
      "client accuracy :  9\n",
      "41.509433962264154\n",
      "client accuracy :  10\n",
      "46.15384615384615\n",
      "client accuracy :  11\n",
      "47.14285714285714\n",
      "client accuracy :  12\n",
      "44.84126984126984\n",
      "client accuracy :  13\n",
      "51.21951219512195\n",
      "client accuracy :  14\n",
      "40.476190476190474\n",
      "client accuracy :  15\n",
      "48.57142857142857\n",
      "client accuracy :  16\n",
      "42.5\n",
      "client accuracy :  17\n",
      "40.74074074074074\n",
      "client accuracy :  18\n",
      "25.925925925925924\n",
      "client accuracy :  19\n",
      "56.60377358490566\n",
      "val accuracy:  45.41577825159915\n",
      "client accuracy :  0\n",
      "38.70967741935484\n",
      "client accuracy :  1\n",
      "44.44444444444444\n",
      "client accuracy :  2\n",
      "50.0\n",
      "client accuracy :  3\n",
      "39.62264150943396\n",
      "client accuracy :  4\n",
      "50.649350649350644\n",
      "client accuracy :  5\n",
      "47.72727272727273\n",
      "client accuracy :  6\n",
      "44.44444444444444\n",
      "client accuracy :  7\n",
      "48.64864864864865\n",
      "client accuracy :  8\n",
      "44.06779661016949\n",
      "client accuracy :  9\n",
      "51.4018691588785\n",
      "client accuracy :  10\n",
      "52.197802197802204\n",
      "client accuracy :  11\n",
      "44.285714285714285\n",
      "client accuracy :  12\n",
      "50.19762845849802\n",
      "client accuracy :  13\n",
      "53.65853658536586\n",
      "client accuracy :  14\n",
      "50.0\n",
      "client accuracy :  15\n",
      "28.57142857142857\n",
      "client accuracy :  16\n",
      "48.78048780487805\n",
      "client accuracy :  17\n",
      "48.148148148148145\n",
      "client accuracy :  18\n",
      "66.66666666666666\n",
      "client accuracy :  19\n",
      "47.16981132075472\n",
      "test accuracy:  48.08510638297872\n",
      "21\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.3875, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5549, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  81.52096659559346\n",
      "loss after my code:  34.45548113881712\n",
      "train loss after my code:  29.86631280199798\n",
      "val accuracy:  45.41577825159915\n",
      "test accuracy:  48.01418439716312\n",
      "22\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.3903, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4881, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  81.80525941719972\n",
      "loss after my code:  21.788118510296073\n",
      "train loss after my code:  18.75186686347014\n",
      "val accuracy:  45.62899786780384\n",
      "test accuracy:  48.51063829787234\n",
      "23\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.3268, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4330, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  82.87135749822318\n",
      "loss after my code:  10.375956741238502\n",
      "train loss after my code:  8.894313461639204\n",
      "val accuracy:  48.685145700071075\n",
      "test accuracy:  51.34751773049645\n",
      "24\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.3588, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4904, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  82.08955223880598\n",
      "loss after my code:  8.080943082061994\n",
      "train loss after my code:  6.942446814807225\n",
      "val accuracy:  48.8272921108742\n",
      "test accuracy:  50.99290780141844\n",
      "25\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.3330, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4473, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "77.77777777777779\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "64.15094339622641\n",
      "client accuracy :  4\n",
      "93.5064935064935\n",
      "client accuracy :  5\n",
      "72.72727272727273\n",
      "client accuracy :  6\n",
      "87.17948717948718\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "58.24175824175825\n",
      "client accuracy :  11\n",
      "82.85714285714286\n",
      "client accuracy :  12\n",
      "88.4920634920635\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "80.0\n",
      "client accuracy :  16\n",
      "57.49999999999999\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "66.66666666666666\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "val accuracy before bandits:  83.93745557924662\n",
      "loss after my code:  8.620936233483256\n",
      "train loss after my code:  7.26119196102312\n",
      "client accuracy :  0\n",
      "46.774193548387096\n",
      "client accuracy :  1\n",
      "48.148148148148145\n",
      "client accuracy :  2\n",
      "48.214285714285715\n",
      "client accuracy :  3\n",
      "49.056603773584904\n",
      "client accuracy :  4\n",
      "36.36363636363637\n",
      "client accuracy :  5\n",
      "59.09090909090909\n",
      "client accuracy :  6\n",
      "47.008547008547005\n",
      "client accuracy :  7\n",
      "48.64864864864865\n",
      "client accuracy :  8\n",
      "47.45762711864407\n",
      "client accuracy :  9\n",
      "46.22641509433962\n",
      "client accuracy :  10\n",
      "50.0\n",
      "client accuracy :  11\n",
      "50.0\n",
      "client accuracy :  12\n",
      "47.22222222222222\n",
      "client accuracy :  13\n",
      "58.536585365853654\n",
      "client accuracy :  14\n",
      "45.23809523809524\n",
      "client accuracy :  15\n",
      "54.285714285714285\n",
      "client accuracy :  16\n",
      "35.0\n",
      "client accuracy :  17\n",
      "51.85185185185185\n",
      "client accuracy :  18\n",
      "29.629629629629626\n",
      "client accuracy :  19\n",
      "56.60377358490566\n",
      "val accuracy:  47.76119402985074\n",
      "client accuracy :  0\n",
      "50.0\n",
      "client accuracy :  1\n",
      "44.44444444444444\n",
      "client accuracy :  2\n",
      "55.35714285714286\n",
      "client accuracy :  3\n",
      "45.28301886792453\n",
      "client accuracy :  4\n",
      "50.649350649350644\n",
      "client accuracy :  5\n",
      "59.09090909090909\n",
      "client accuracy :  6\n",
      "41.88034188034188\n",
      "client accuracy :  7\n",
      "48.64864864864865\n",
      "client accuracy :  8\n",
      "45.76271186440678\n",
      "client accuracy :  9\n",
      "51.4018691588785\n",
      "client accuracy :  10\n",
      "56.59340659340659\n",
      "client accuracy :  11\n",
      "47.14285714285714\n",
      "client accuracy :  12\n",
      "50.59288537549407\n",
      "client accuracy :  13\n",
      "58.536585365853654\n",
      "client accuracy :  14\n",
      "42.857142857142854\n",
      "client accuracy :  15\n",
      "34.285714285714285\n",
      "client accuracy :  16\n",
      "48.78048780487805\n",
      "client accuracy :  17\n",
      "48.148148148148145\n",
      "client accuracy :  18\n",
      "70.37037037037037\n",
      "client accuracy :  19\n",
      "50.943396226415096\n",
      "test accuracy:  50.283687943262414\n",
      "26\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.4232, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5317, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  81.37882018479033\n",
      "loss after my code:  4.978061941024087\n",
      "train loss after my code:  4.60578568369624\n",
      "val accuracy:  53.233830845771145\n",
      "test accuracy:  53.262411347517734\n",
      "27\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.4752, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5942, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  81.16560056858563\n",
      "loss after my code:  4.751029710719134\n",
      "train loss after my code:  4.353085159299269\n",
      "val accuracy:  52.30987917555082\n",
      "test accuracy:  53.12056737588653\n",
      "28\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.3442, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4195, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  82.72921108742004\n",
      "loss after my code:  5.013550156514659\n",
      "train loss after my code:  4.4522965193717186\n",
      "val accuracy:  51.243781094527364\n",
      "test accuracy:  52.76595744680851\n",
      "29\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.4363, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5180, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  81.09452736318407\n",
      "loss after my code:  4.300034559065\n",
      "train loss after my code:  4.034890421093522\n",
      "val accuracy:  53.66027007818053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  53.04964539007092\n",
      "30\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.4357, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5629, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "81.48148148148148\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "66.0377358490566\n",
      "client accuracy :  4\n",
      "93.5064935064935\n",
      "client accuracy :  5\n",
      "77.27272727272727\n",
      "client accuracy :  6\n",
      "76.06837606837607\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "95.28301886792453\n",
      "client accuracy :  10\n",
      "56.043956043956044\n",
      "client accuracy :  11\n",
      "77.14285714285715\n",
      "client accuracy :  12\n",
      "83.33333333333334\n",
      "client accuracy :  13\n",
      "95.1219512195122\n",
      "client accuracy :  14\n",
      "90.47619047619048\n",
      "client accuracy :  15\n",
      "62.857142857142854\n",
      "client accuracy :  16\n",
      "72.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "77.77777777777779\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "val accuracy before bandits:  81.73418621179816\n",
      "loss after my code:  5.835561952991456\n",
      "train loss after my code:  5.444324894694944\n",
      "client accuracy :  0\n",
      "50.0\n",
      "client accuracy :  1\n",
      "44.44444444444444\n",
      "client accuracy :  2\n",
      "58.92857142857143\n",
      "client accuracy :  3\n",
      "52.83018867924528\n",
      "client accuracy :  4\n",
      "35.064935064935064\n",
      "client accuracy :  5\n",
      "56.81818181818182\n",
      "client accuracy :  6\n",
      "50.427350427350426\n",
      "client accuracy :  7\n",
      "56.75675675675676\n",
      "client accuracy :  8\n",
      "66.10169491525424\n",
      "client accuracy :  9\n",
      "65.09433962264151\n",
      "client accuracy :  10\n",
      "54.395604395604394\n",
      "client accuracy :  11\n",
      "74.28571428571429\n",
      "client accuracy :  12\n",
      "59.12698412698413\n",
      "client accuracy :  13\n",
      "58.536585365853654\n",
      "client accuracy :  14\n",
      "52.38095238095239\n",
      "client accuracy :  15\n",
      "62.857142857142854\n",
      "client accuracy :  16\n",
      "55.00000000000001\n",
      "client accuracy :  17\n",
      "55.55555555555556\n",
      "client accuracy :  18\n",
      "74.07407407407408\n",
      "client accuracy :  19\n",
      "52.83018867924528\n",
      "val accuracy:  56.6453447050462\n",
      "client accuracy :  0\n",
      "58.06451612903226\n",
      "client accuracy :  1\n",
      "48.148148148148145\n",
      "client accuracy :  2\n",
      "53.57142857142857\n",
      "client accuracy :  3\n",
      "50.943396226415096\n",
      "client accuracy :  4\n",
      "41.55844155844156\n",
      "client accuracy :  5\n",
      "63.63636363636363\n",
      "client accuracy :  6\n",
      "49.572649572649574\n",
      "client accuracy :  7\n",
      "54.054054054054056\n",
      "client accuracy :  8\n",
      "57.6271186440678\n",
      "client accuracy :  9\n",
      "64.48598130841121\n",
      "client accuracy :  10\n",
      "54.395604395604394\n",
      "client accuracy :  11\n",
      "60.0\n",
      "client accuracy :  12\n",
      "49.40711462450593\n",
      "client accuracy :  13\n",
      "43.90243902439025\n",
      "client accuracy :  14\n",
      "42.857142857142854\n",
      "client accuracy :  15\n",
      "51.42857142857142\n",
      "client accuracy :  16\n",
      "34.146341463414636\n",
      "client accuracy :  17\n",
      "59.25925925925925\n",
      "client accuracy :  18\n",
      "59.25925925925925\n",
      "client accuracy :  19\n",
      "58.490566037735846\n",
      "test accuracy:  52.76595744680851\n",
      "31\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.5010, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5876, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  80.81023454157783\n",
      "loss after my code:  4.428207180297958\n",
      "train loss after my code:  4.167451022484113\n",
      "val accuracy:  55.65031982942431\n",
      "test accuracy:  52.90780141843972\n",
      "32\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.4786, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5756, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  79.67306325515281\n",
      "loss after my code:  5.960571167911501\n",
      "train loss after my code:  5.930276781117874\n",
      "val accuracy:  56.07675906183369\n",
      "test accuracy:  52.4113475177305\n",
      "33\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.4953, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.6118, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  80.52594171997157\n",
      "loss after my code:  6.648902794889734\n",
      "train loss after my code:  6.133536754683562\n",
      "val accuracy:  55.366027007818055\n",
      "test accuracy:  52.76595744680851\n",
      "34\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.5630, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.7291, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  77.82515991471215\n",
      "loss after my code:  9.741123987758268\n",
      "train loss after my code:  9.130873819501257\n",
      "val accuracy:  54.37100213219617\n",
      "test accuracy:  51.34751773049645\n",
      "35\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.5193, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.6557, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "95.16129032258065\n",
      "client accuracy :  1\n",
      "77.77777777777779\n",
      "client accuracy :  2\n",
      "89.28571428571429\n",
      "client accuracy :  3\n",
      "66.0377358490566\n",
      "client accuracy :  4\n",
      "92.20779220779221\n",
      "client accuracy :  5\n",
      "79.54545454545455\n",
      "client accuracy :  6\n",
      "80.34188034188034\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "87.73584905660378\n",
      "client accuracy :  10\n",
      "53.84615384615385\n",
      "client accuracy :  11\n",
      "75.71428571428571\n",
      "client accuracy :  12\n",
      "78.57142857142857\n",
      "client accuracy :  13\n",
      "85.36585365853658\n",
      "client accuracy :  14\n",
      "83.33333333333334\n",
      "client accuracy :  15\n",
      "71.42857142857143\n",
      "client accuracy :  16\n",
      "77.5\n",
      "client accuracy :  17\n",
      "77.77777777777779\n",
      "client accuracy :  18\n",
      "88.88888888888889\n",
      "client accuracy :  19\n",
      "88.67924528301887\n",
      "val accuracy before bandits:  79.53091684434968\n",
      "loss after my code:  9.302792795713046\n",
      "train loss after my code:  8.68585567782022\n",
      "client accuracy :  0\n",
      "56.451612903225815\n",
      "client accuracy :  1\n",
      "48.148148148148145\n",
      "client accuracy :  2\n",
      "58.92857142857143\n",
      "client accuracy :  3\n",
      "54.71698113207547\n",
      "client accuracy :  4\n",
      "53.246753246753244\n",
      "client accuracy :  5\n",
      "47.72727272727273\n",
      "client accuracy :  6\n",
      "48.717948717948715\n",
      "client accuracy :  7\n",
      "48.64864864864865\n",
      "client accuracy :  8\n",
      "54.23728813559322\n",
      "client accuracy :  9\n",
      "54.71698113207547\n",
      "client accuracy :  10\n",
      "53.2967032967033\n",
      "client accuracy :  11\n",
      "61.42857142857143\n",
      "client accuracy :  12\n",
      "57.14285714285714\n",
      "client accuracy :  13\n",
      "56.09756097560976\n",
      "client accuracy :  14\n",
      "57.14285714285714\n",
      "client accuracy :  15\n",
      "51.42857142857142\n",
      "client accuracy :  16\n",
      "60.0\n",
      "client accuracy :  17\n",
      "51.85185185185185\n",
      "client accuracy :  18\n",
      "66.66666666666666\n",
      "client accuracy :  19\n",
      "43.39622641509434\n",
      "val accuracy:  54.37100213219617\n",
      "client accuracy :  0\n",
      "58.06451612903226\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "46.42857142857143\n",
      "client accuracy :  3\n",
      "56.60377358490566\n",
      "client accuracy :  4\n",
      "46.75324675324675\n",
      "client accuracy :  5\n",
      "56.81818181818182\n",
      "client accuracy :  6\n",
      "55.55555555555556\n",
      "client accuracy :  7\n",
      "48.64864864864865\n",
      "client accuracy :  8\n",
      "54.23728813559322\n",
      "client accuracy :  9\n",
      "51.4018691588785\n",
      "client accuracy :  10\n",
      "50.0\n",
      "client accuracy :  11\n",
      "54.285714285714285\n",
      "client accuracy :  12\n",
      "49.80237154150198\n",
      "client accuracy :  13\n",
      "46.34146341463415\n",
      "client accuracy :  14\n",
      "47.61904761904761\n",
      "client accuracy :  15\n",
      "65.71428571428571\n",
      "client accuracy :  16\n",
      "46.34146341463415\n",
      "client accuracy :  17\n",
      "55.55555555555556\n",
      "client accuracy :  18\n",
      "48.148148148148145\n",
      "client accuracy :  19\n",
      "47.16981132075472\n",
      "test accuracy:  51.48936170212765\n",
      "36\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.6583, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.7832, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  78.03837953091684\n",
      "loss after my code:  12.594502449786702\n",
      "train loss after my code:  11.693482691972374\n",
      "val accuracy:  55.15280739161336\n",
      "test accuracy:  51.48936170212765\n",
      "37\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.7002, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.8146, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  76.97228144989339\n",
      "loss after my code:  12.439008558895742\n",
      "train loss after my code:  11.491781674573321\n",
      "val accuracy:  54.79744136460555\n",
      "test accuracy:  51.56028368794326\n",
      "38\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.7439, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.8784, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  74.27149964463398\n",
      "loss after my code:  11.148930088022404\n",
      "train loss after my code:  10.577230499437137\n",
      "val accuracy:  54.86851457000711\n",
      "test accuracy:  51.34751773049645\n",
      "39\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.7158, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.9113, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  78.53589196872778\n",
      "loss after my code:  11.001503695696407\n",
      "train loss after my code:  10.077968110499649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy:  54.65529495380241\n",
      "test accuracy:  51.13475177304964\n",
      "40\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.8028, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.9680, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "91.93548387096774\n",
      "client accuracy :  1\n",
      "88.88888888888889\n",
      "client accuracy :  2\n",
      "87.5\n",
      "client accuracy :  3\n",
      "66.0377358490566\n",
      "client accuracy :  4\n",
      "89.6103896103896\n",
      "client accuracy :  5\n",
      "77.27272727272727\n",
      "client accuracy :  6\n",
      "62.39316239316239\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "80.18867924528303\n",
      "client accuracy :  10\n",
      "53.2967032967033\n",
      "client accuracy :  11\n",
      "70.0\n",
      "client accuracy :  12\n",
      "78.96825396825396\n",
      "client accuracy :  13\n",
      "85.36585365853658\n",
      "client accuracy :  14\n",
      "80.95238095238095\n",
      "client accuracy :  15\n",
      "71.42857142857143\n",
      "client accuracy :  16\n",
      "75.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "88.88888888888889\n",
      "client accuracy :  19\n",
      "83.01886792452831\n",
      "val accuracy before bandits:  76.61691542288557\n",
      "loss after my code:  10.609341426260123\n",
      "train loss after my code:  9.83254443006574\n",
      "client accuracy :  0\n",
      "54.83870967741935\n",
      "client accuracy :  1\n",
      "48.148148148148145\n",
      "client accuracy :  2\n",
      "57.14285714285714\n",
      "client accuracy :  3\n",
      "58.490566037735846\n",
      "client accuracy :  4\n",
      "61.038961038961034\n",
      "client accuracy :  5\n",
      "45.45454545454545\n",
      "client accuracy :  6\n",
      "49.572649572649574\n",
      "client accuracy :  7\n",
      "48.64864864864865\n",
      "client accuracy :  8\n",
      "52.54237288135594\n",
      "client accuracy :  9\n",
      "58.490566037735846\n",
      "client accuracy :  10\n",
      "53.2967032967033\n",
      "client accuracy :  11\n",
      "58.57142857142858\n",
      "client accuracy :  12\n",
      "55.55555555555556\n",
      "client accuracy :  13\n",
      "56.09756097560976\n",
      "client accuracy :  14\n",
      "59.523809523809526\n",
      "client accuracy :  15\n",
      "48.57142857142857\n",
      "client accuracy :  16\n",
      "62.5\n",
      "client accuracy :  17\n",
      "55.55555555555556\n",
      "client accuracy :  18\n",
      "74.07407407407408\n",
      "client accuracy :  19\n",
      "43.39622641509434\n",
      "val accuracy:  54.86851457000711\n",
      "client accuracy :  0\n",
      "59.67741935483871\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "48.214285714285715\n",
      "client accuracy :  3\n",
      "58.490566037735846\n",
      "client accuracy :  4\n",
      "49.35064935064935\n",
      "client accuracy :  5\n",
      "56.81818181818182\n",
      "client accuracy :  6\n",
      "54.700854700854705\n",
      "client accuracy :  7\n",
      "51.35135135135135\n",
      "client accuracy :  8\n",
      "55.932203389830505\n",
      "client accuracy :  9\n",
      "46.728971962616825\n",
      "client accuracy :  10\n",
      "48.35164835164835\n",
      "client accuracy :  11\n",
      "55.714285714285715\n",
      "client accuracy :  12\n",
      "50.988142292490124\n",
      "client accuracy :  13\n",
      "43.90243902439025\n",
      "client accuracy :  14\n",
      "45.23809523809524\n",
      "client accuracy :  15\n",
      "68.57142857142857\n",
      "client accuracy :  16\n",
      "48.78048780487805\n",
      "client accuracy :  17\n",
      "55.55555555555556\n",
      "client accuracy :  18\n",
      "29.629629629629626\n",
      "client accuracy :  19\n",
      "50.943396226415096\n",
      "test accuracy:  51.41843971631206\n",
      "41\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.7848, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.9594, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  76.11940298507463\n",
      "loss after my code:  12.851825212947748\n",
      "train loss after my code:  11.980442203719686\n",
      "val accuracy:  54.72636815920397\n",
      "test accuracy:  51.77304964539007\n",
      "42\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.9174, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.1042, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  75.33759772565742\n",
      "loss after my code:  10.311457977268518\n",
      "train loss after my code:  9.533299179242535\n",
      "val accuracy:  54.93958777540867\n",
      "test accuracy:  51.34751773049645\n",
      "43\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.9402, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.1445, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  75.26652452025586\n",
      "loss after my code:  12.26206154393439\n",
      "train loss after my code:  11.000912231100553\n",
      "val accuracy:  54.72636815920397\n",
      "test accuracy:  51.77304964539007\n",
      "44\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.0264, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.2159, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  73.98720682302772\n",
      "loss after my code:  12.99299453458777\n",
      "train loss after my code:  11.775998021889093\n",
      "val accuracy:  54.72636815920397\n",
      "test accuracy:  51.843971631205676\n",
      "45\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.0069, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.2359, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "82.25806451612904\n",
      "client accuracy :  1\n",
      "88.88888888888889\n",
      "client accuracy :  2\n",
      "83.92857142857143\n",
      "client accuracy :  3\n",
      "64.15094339622641\n",
      "client accuracy :  4\n",
      "88.31168831168831\n",
      "client accuracy :  5\n",
      "77.27272727272727\n",
      "client accuracy :  6\n",
      "64.95726495726495\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "96.61016949152543\n",
      "client accuracy :  9\n",
      "82.0754716981132\n",
      "client accuracy :  10\n",
      "52.74725274725275\n",
      "client accuracy :  11\n",
      "65.71428571428571\n",
      "client accuracy :  12\n",
      "74.60317460317461\n",
      "client accuracy :  13\n",
      "85.36585365853658\n",
      "client accuracy :  14\n",
      "76.19047619047619\n",
      "client accuracy :  15\n",
      "68.57142857142857\n",
      "client accuracy :  16\n",
      "72.5\n",
      "client accuracy :  17\n",
      "66.66666666666666\n",
      "client accuracy :  18\n",
      "92.5925925925926\n",
      "client accuracy :  19\n",
      "83.01886792452831\n",
      "val accuracy before bandits:  74.6268656716418\n",
      "loss after my code:  13.731327368902225\n",
      "train loss after my code:  12.035589226111645\n",
      "client accuracy :  0\n",
      "54.83870967741935\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "57.14285714285714\n",
      "client accuracy :  3\n",
      "58.490566037735846\n",
      "client accuracy :  4\n",
      "63.63636363636363\n",
      "client accuracy :  5\n",
      "45.45454545454545\n",
      "client accuracy :  6\n",
      "50.427350427350426\n",
      "client accuracy :  7\n",
      "48.64864864864865\n",
      "client accuracy :  8\n",
      "52.54237288135594\n",
      "client accuracy :  9\n",
      "58.490566037735846\n",
      "client accuracy :  10\n",
      "53.2967032967033\n",
      "client accuracy :  11\n",
      "54.285714285714285\n",
      "client accuracy :  12\n",
      "56.74603174603175\n",
      "client accuracy :  13\n",
      "53.65853658536586\n",
      "client accuracy :  14\n",
      "59.523809523809526\n",
      "client accuracy :  15\n",
      "48.57142857142857\n",
      "client accuracy :  16\n",
      "57.49999999999999\n",
      "client accuracy :  17\n",
      "59.25925925925925\n",
      "client accuracy :  18\n",
      "70.37037037037037\n",
      "client accuracy :  19\n",
      "41.509433962264154\n",
      "val accuracy:  54.86851457000711\n",
      "client accuracy :  0\n",
      "61.29032258064516\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "48.214285714285715\n",
      "client accuracy :  3\n",
      "64.15094339622641\n",
      "client accuracy :  4\n",
      "49.35064935064935\n",
      "client accuracy :  5\n",
      "54.54545454545454\n",
      "client accuracy :  6\n",
      "55.55555555555556\n",
      "client accuracy :  7\n",
      "51.35135135135135\n",
      "client accuracy :  8\n",
      "57.6271186440678\n",
      "client accuracy :  9\n",
      "48.598130841121495\n",
      "client accuracy :  10\n",
      "48.35164835164835\n",
      "client accuracy :  11\n",
      "57.14285714285714\n",
      "client accuracy :  12\n",
      "50.19762845849802\n",
      "client accuracy :  13\n",
      "43.90243902439025\n",
      "client accuracy :  14\n",
      "47.61904761904761\n",
      "client accuracy :  15\n",
      "68.57142857142857\n",
      "client accuracy :  16\n",
      "46.34146341463415\n",
      "client accuracy :  17\n",
      "55.55555555555556\n",
      "client accuracy :  18\n",
      "33.33333333333333\n",
      "client accuracy :  19\n",
      "52.83018867924528\n",
      "test accuracy:  51.98581560283688\n",
      "46\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.1141, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.3280, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  74.27149964463398\n",
      "loss after my code:  15.618421626390985\n",
      "train loss after my code:  13.824240143127716\n",
      "val accuracy:  55.010660980810236\n",
      "test accuracy:  51.77304964539007\n",
      "47\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.1977, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.4108, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  71.92608386638237\n",
      "loss after my code:  15.705508765191555\n",
      "train loss after my code:  14.442160226437522\n",
      "val accuracy:  55.15280739161336\n",
      "test accuracy:  51.77304964539007\n",
      "48\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.2694, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.4575, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  72.49466950959487\n",
      "loss after my code:  15.57172346644349\n",
      "train loss after my code:  13.609372652959637\n",
      "val accuracy:  55.15280739161336\n",
      "test accuracy:  51.91489361702127\n",
      "49\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.4687, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.7026, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  71.21535181236673\n",
      "loss after my code:  15.55983335649845\n",
      "train loss after my code:  14.566183629540209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy:  55.15280739161336\n",
      "test accuracy:  51.843971631205676\n",
      "50\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.4903, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.7302, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "82.25806451612904\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "80.35714285714286\n",
      "client accuracy :  3\n",
      "62.264150943396224\n",
      "client accuracy :  4\n",
      "89.6103896103896\n",
      "client accuracy :  5\n",
      "77.27272727272727\n",
      "client accuracy :  6\n",
      "61.53846153846154\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "96.61016949152543\n",
      "client accuracy :  9\n",
      "77.35849056603774\n",
      "client accuracy :  10\n",
      "52.74725274725275\n",
      "client accuracy :  11\n",
      "62.857142857142854\n",
      "client accuracy :  12\n",
      "70.23809523809523\n",
      "client accuracy :  13\n",
      "78.04878048780488\n",
      "client accuracy :  14\n",
      "61.904761904761905\n",
      "client accuracy :  15\n",
      "68.57142857142857\n",
      "client accuracy :  16\n",
      "75.0\n",
      "client accuracy :  17\n",
      "59.25925925925925\n",
      "client accuracy :  18\n",
      "92.5925925925926\n",
      "client accuracy :  19\n",
      "64.15094339622641\n",
      "val accuracy before bandits:  71.64179104477611\n",
      "loss after my code:  15.892560198114088\n",
      "train loss after my code:  14.396581777517428\n",
      "client accuracy :  0\n",
      "54.83870967741935\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "57.14285714285714\n",
      "client accuracy :  3\n",
      "60.37735849056604\n",
      "client accuracy :  4\n",
      "63.63636363636363\n",
      "client accuracy :  5\n",
      "45.45454545454545\n",
      "client accuracy :  6\n",
      "50.427350427350426\n",
      "client accuracy :  7\n",
      "54.054054054054056\n",
      "client accuracy :  8\n",
      "52.54237288135594\n",
      "client accuracy :  9\n",
      "58.490566037735846\n",
      "client accuracy :  10\n",
      "53.2967032967033\n",
      "client accuracy :  11\n",
      "54.285714285714285\n",
      "client accuracy :  12\n",
      "56.74603174603175\n",
      "client accuracy :  13\n",
      "53.65853658536586\n",
      "client accuracy :  14\n",
      "59.523809523809526\n",
      "client accuracy :  15\n",
      "48.57142857142857\n",
      "client accuracy :  16\n",
      "57.49999999999999\n",
      "client accuracy :  17\n",
      "59.25925925925925\n",
      "client accuracy :  18\n",
      "74.07407407407408\n",
      "client accuracy :  19\n",
      "41.509433962264154\n",
      "val accuracy:  55.15280739161336\n",
      "client accuracy :  0\n",
      "61.29032258064516\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "46.42857142857143\n",
      "client accuracy :  3\n",
      "62.264150943396224\n",
      "client accuracy :  4\n",
      "50.649350649350644\n",
      "client accuracy :  5\n",
      "54.54545454545454\n",
      "client accuracy :  6\n",
      "55.55555555555556\n",
      "client accuracy :  7\n",
      "51.35135135135135\n",
      "client accuracy :  8\n",
      "57.6271186440678\n",
      "client accuracy :  9\n",
      "48.598130841121495\n",
      "client accuracy :  10\n",
      "48.35164835164835\n",
      "client accuracy :  11\n",
      "57.14285714285714\n",
      "client accuracy :  12\n",
      "50.19762845849802\n",
      "client accuracy :  13\n",
      "46.34146341463415\n",
      "client accuracy :  14\n",
      "47.61904761904761\n",
      "client accuracy :  15\n",
      "71.42857142857143\n",
      "client accuracy :  16\n",
      "46.34146341463415\n",
      "client accuracy :  17\n",
      "48.148148148148145\n",
      "client accuracy :  18\n",
      "33.33333333333333\n",
      "client accuracy :  19\n",
      "52.83018867924528\n",
      "test accuracy:  51.91489361702127\n",
      "51\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.4101, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.6866, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  72.35252309879175\n",
      "loss after my code:  15.810201889854316\n",
      "train loss after my code:  14.107862807712968\n",
      "val accuracy:  55.15280739161336\n",
      "test accuracy:  51.91489361702127\n",
      "52\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.4579, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.7503, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  71.49964463397299\n",
      "loss after my code:  17.088410835200314\n",
      "train loss after my code:  14.980706285066036\n",
      "val accuracy:  55.15280739161336\n",
      "test accuracy:  51.70212765957447\n",
      "53\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.5495, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.8080, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  70.57569296375267\n",
      "loss after my code:  17.974217047760757\n",
      "train loss after my code:  16.241564241946765\n",
      "val accuracy:  55.010660980810236\n",
      "test accuracy:  51.70212765957447\n",
      "54\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.5284, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.8152, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  71.71286425017769\n",
      "loss after my code:  19.245130494461822\n",
      "train loss after my code:  17.1145085415076\n",
      "val accuracy:  54.93958777540867\n",
      "test accuracy:  52.05673758865248\n",
      "55\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.5757, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.8658, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "72.58064516129032\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "69.64285714285714\n",
      "client accuracy :  3\n",
      "66.0377358490566\n",
      "client accuracy :  4\n",
      "88.31168831168831\n",
      "client accuracy :  5\n",
      "75.0\n",
      "client accuracy :  6\n",
      "63.24786324786324\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "96.61016949152543\n",
      "client accuracy :  9\n",
      "80.18867924528303\n",
      "client accuracy :  10\n",
      "52.74725274725275\n",
      "client accuracy :  11\n",
      "65.71428571428571\n",
      "client accuracy :  12\n",
      "69.04761904761905\n",
      "client accuracy :  13\n",
      "70.73170731707317\n",
      "client accuracy :  14\n",
      "61.904761904761905\n",
      "client accuracy :  15\n",
      "68.57142857142857\n",
      "client accuracy :  16\n",
      "75.0\n",
      "client accuracy :  17\n",
      "59.25925925925925\n",
      "client accuracy :  18\n",
      "85.18518518518519\n",
      "client accuracy :  19\n",
      "62.264150943396224\n",
      "val accuracy before bandits:  70.64676616915423\n",
      "loss after my code:  16.055171800845383\n",
      "train loss after my code:  14.528900197554554\n",
      "client accuracy :  0\n",
      "54.83870967741935\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "57.14285714285714\n",
      "client accuracy :  3\n",
      "60.37735849056604\n",
      "client accuracy :  4\n",
      "63.63636363636363\n",
      "client accuracy :  5\n",
      "45.45454545454545\n",
      "client accuracy :  6\n",
      "50.427350427350426\n",
      "client accuracy :  7\n",
      "54.054054054054056\n",
      "client accuracy :  8\n",
      "52.54237288135594\n",
      "client accuracy :  9\n",
      "58.490566037735846\n",
      "client accuracy :  10\n",
      "52.74725274725275\n",
      "client accuracy :  11\n",
      "54.285714285714285\n",
      "client accuracy :  12\n",
      "56.34920634920635\n",
      "client accuracy :  13\n",
      "53.65853658536586\n",
      "client accuracy :  14\n",
      "59.523809523809526\n",
      "client accuracy :  15\n",
      "48.57142857142857\n",
      "client accuracy :  16\n",
      "57.49999999999999\n",
      "client accuracy :  17\n",
      "59.25925925925925\n",
      "client accuracy :  18\n",
      "74.07407407407408\n",
      "client accuracy :  19\n",
      "41.509433962264154\n",
      "val accuracy:  55.010660980810236\n",
      "client accuracy :  0\n",
      "61.29032258064516\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "46.42857142857143\n",
      "client accuracy :  3\n",
      "62.264150943396224\n",
      "client accuracy :  4\n",
      "50.649350649350644\n",
      "client accuracy :  5\n",
      "54.54545454545454\n",
      "client accuracy :  6\n",
      "55.55555555555556\n",
      "client accuracy :  7\n",
      "51.35135135135135\n",
      "client accuracy :  8\n",
      "57.6271186440678\n",
      "client accuracy :  9\n",
      "48.598130841121495\n",
      "client accuracy :  10\n",
      "48.35164835164835\n",
      "client accuracy :  11\n",
      "57.14285714285714\n",
      "client accuracy :  12\n",
      "49.40711462450593\n",
      "client accuracy :  13\n",
      "46.34146341463415\n",
      "client accuracy :  14\n",
      "47.61904761904761\n",
      "client accuracy :  15\n",
      "71.42857142857143\n",
      "client accuracy :  16\n",
      "46.34146341463415\n",
      "client accuracy :  17\n",
      "48.148148148148145\n",
      "client accuracy :  18\n",
      "33.33333333333333\n",
      "client accuracy :  19\n",
      "52.83018867924528\n",
      "test accuracy:  51.77304964539007\n",
      "56\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.5786, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.8680, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  71.57071783937455\n",
      "loss after my code:  18.002215616625282\n",
      "train loss after my code:  15.88365149048231\n",
      "val accuracy:  54.93958777540867\n",
      "test accuracy:  51.98581560283688\n",
      "57\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.7149, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.0079, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  70.93105899076049\n",
      "loss after my code:  18.27414153142651\n",
      "train loss after my code:  15.748452553790251\n",
      "val accuracy:  54.93958777540867\n",
      "test accuracy:  52.05673758865248\n",
      "58\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.8025, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.0793, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  70.85998578535892\n",
      "loss after my code:  18.581495404418693\n",
      "train loss after my code:  16.878446154498572\n",
      "val accuracy:  54.93958777540867\n",
      "test accuracy:  52.05673758865248\n",
      "59\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.8818, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.1668, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  69.79388770433546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after my code:  18.14365255928803\n",
      "train loss after my code:  16.48644864137799\n",
      "val accuracy:  54.93958777540867\n",
      "test accuracy:  52.05673758865248\n",
      "60\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.9211, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.2742, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "74.19354838709677\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "82.14285714285714\n",
      "client accuracy :  3\n",
      "66.0377358490566\n",
      "client accuracy :  4\n",
      "88.31168831168831\n",
      "client accuracy :  5\n",
      "77.27272727272727\n",
      "client accuracy :  6\n",
      "61.53846153846154\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "91.52542372881356\n",
      "client accuracy :  9\n",
      "76.41509433962264\n",
      "client accuracy :  10\n",
      "53.2967032967033\n",
      "client accuracy :  11\n",
      "60.0\n",
      "client accuracy :  12\n",
      "69.44444444444444\n",
      "client accuracy :  13\n",
      "70.73170731707317\n",
      "client accuracy :  14\n",
      "61.904761904761905\n",
      "client accuracy :  15\n",
      "68.57142857142857\n",
      "client accuracy :  16\n",
      "65.0\n",
      "client accuracy :  17\n",
      "59.25925925925925\n",
      "client accuracy :  18\n",
      "85.18518518518519\n",
      "client accuracy :  19\n",
      "56.60377358490566\n",
      "val accuracy before bandits:  69.9360341151386\n",
      "loss after my code:  17.829467416342027\n",
      "train loss after my code:  15.721609215334755\n",
      "client accuracy :  0\n",
      "54.83870967741935\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "57.14285714285714\n",
      "client accuracy :  3\n",
      "60.37735849056604\n",
      "client accuracy :  4\n",
      "63.63636363636363\n",
      "client accuracy :  5\n",
      "45.45454545454545\n",
      "client accuracy :  6\n",
      "50.427350427350426\n",
      "client accuracy :  7\n",
      "54.054054054054056\n",
      "client accuracy :  8\n",
      "52.54237288135594\n",
      "client accuracy :  9\n",
      "58.490566037735846\n",
      "client accuracy :  10\n",
      "52.74725274725275\n",
      "client accuracy :  11\n",
      "54.285714285714285\n",
      "client accuracy :  12\n",
      "55.952380952380956\n",
      "client accuracy :  13\n",
      "53.65853658536586\n",
      "client accuracy :  14\n",
      "59.523809523809526\n",
      "client accuracy :  15\n",
      "48.57142857142857\n",
      "client accuracy :  16\n",
      "57.49999999999999\n",
      "client accuracy :  17\n",
      "59.25925925925925\n",
      "client accuracy :  18\n",
      "74.07407407407408\n",
      "client accuracy :  19\n",
      "41.509433962264154\n",
      "val accuracy:  54.93958777540867\n",
      "client accuracy :  0\n",
      "61.29032258064516\n",
      "client accuracy :  1\n",
      "55.55555555555556\n",
      "client accuracy :  2\n",
      "48.214285714285715\n",
      "client accuracy :  3\n",
      "62.264150943396224\n",
      "client accuracy :  4\n",
      "50.649350649350644\n",
      "client accuracy :  5\n",
      "54.54545454545454\n",
      "client accuracy :  6\n",
      "55.55555555555556\n",
      "client accuracy :  7\n",
      "51.35135135135135\n",
      "client accuracy :  8\n",
      "55.932203389830505\n",
      "client accuracy :  9\n",
      "48.598130841121495\n",
      "client accuracy :  10\n",
      "48.35164835164835\n",
      "client accuracy :  11\n",
      "57.14285714285714\n",
      "client accuracy :  12\n",
      "49.40711462450593\n",
      "client accuracy :  13\n",
      "46.34146341463415\n",
      "client accuracy :  14\n",
      "50.0\n",
      "client accuracy :  15\n",
      "71.42857142857143\n",
      "client accuracy :  16\n",
      "46.34146341463415\n",
      "client accuracy :  17\n",
      "48.148148148148145\n",
      "client accuracy :  18\n",
      "33.33333333333333\n",
      "client accuracy :  19\n",
      "56.60377358490566\n",
      "test accuracy:  52.05673758865248\n",
      "61\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.9295, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.1948, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  70.57569296375267\n",
      "loss after my code:  17.68660389838519\n",
      "train loss after my code:  15.91323827873226\n",
      "val accuracy:  54.93958777540867\n",
      "test accuracy:  52.05673758865248\n",
      "62\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.8419, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.2263, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  70.22032693674485\n",
      "loss after my code:  17.686689326684043\n",
      "train loss after my code:  16.393900624982972\n",
      "val accuracy:  54.93958777540867\n",
      "test accuracy:  52.05673758865248\n",
      "63\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.9886, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.2837, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  68.727789623312\n",
      "loss after my code:  17.963055005608016\n",
      "train loss after my code:  16.469545783432107\n",
      "val accuracy:  54.93958777540867\n",
      "test accuracy:  52.05673758865248\n",
      "64\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.1686, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.4039, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  68.23027718550107\n",
      "loss after my code:  17.54979166735523\n",
      "train loss after my code:  15.686254512986858\n",
      "val accuracy:  54.93958777540867\n",
      "test accuracy:  52.05673758865248\n",
      "65\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.1788, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.5180, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "67.74193548387096\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "69.64285714285714\n",
      "client accuracy :  3\n",
      "66.0377358490566\n",
      "client accuracy :  4\n",
      "88.31168831168831\n",
      "client accuracy :  5\n",
      "77.27272727272727\n",
      "client accuracy :  6\n",
      "62.39316239316239\n",
      "client accuracy :  7\n",
      "91.8918918918919\n",
      "client accuracy :  8\n",
      "89.83050847457628\n",
      "client accuracy :  9\n",
      "69.81132075471697\n",
      "client accuracy :  10\n",
      "53.2967032967033\n",
      "client accuracy :  11\n",
      "60.0\n",
      "client accuracy :  12\n",
      "65.47619047619048\n",
      "client accuracy :  13\n",
      "73.17073170731707\n",
      "client accuracy :  14\n",
      "61.904761904761905\n",
      "client accuracy :  15\n",
      "68.57142857142857\n",
      "client accuracy :  16\n",
      "62.5\n",
      "client accuracy :  17\n",
      "66.66666666666666\n",
      "client accuracy :  18\n",
      "85.18518518518519\n",
      "client accuracy :  19\n",
      "54.71698113207547\n",
      "val accuracy before bandits:  67.94598436389481\n",
      "loss after my code:  17.951018517818415\n",
      "train loss after my code:  15.825495059065974\n",
      "client accuracy :  0\n",
      "54.83870967741935\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "58.92857142857143\n",
      "client accuracy :  3\n",
      "60.37735849056604\n",
      "client accuracy :  4\n",
      "63.63636363636363\n",
      "client accuracy :  5\n",
      "45.45454545454545\n",
      "client accuracy :  6\n",
      "50.427350427350426\n",
      "client accuracy :  7\n",
      "54.054054054054056\n",
      "client accuracy :  8\n",
      "52.54237288135594\n",
      "client accuracy :  9\n",
      "58.490566037735846\n",
      "client accuracy :  10\n",
      "52.74725274725275\n",
      "client accuracy :  11\n",
      "54.285714285714285\n",
      "client accuracy :  12\n",
      "55.952380952380956\n",
      "client accuracy :  13\n",
      "53.65853658536586\n",
      "client accuracy :  14\n",
      "59.523809523809526\n",
      "client accuracy :  15\n",
      "48.57142857142857\n",
      "client accuracy :  16\n",
      "57.49999999999999\n",
      "client accuracy :  17\n",
      "59.25925925925925\n",
      "client accuracy :  18\n",
      "74.07407407407408\n",
      "client accuracy :  19\n",
      "41.509433962264154\n",
      "val accuracy:  55.010660980810236\n",
      "client accuracy :  0\n",
      "61.29032258064516\n",
      "client accuracy :  1\n",
      "55.55555555555556\n",
      "client accuracy :  2\n",
      "48.214285714285715\n",
      "client accuracy :  3\n",
      "62.264150943396224\n",
      "client accuracy :  4\n",
      "50.649350649350644\n",
      "client accuracy :  5\n",
      "54.54545454545454\n",
      "client accuracy :  6\n",
      "55.55555555555556\n",
      "client accuracy :  7\n",
      "51.35135135135135\n",
      "client accuracy :  8\n",
      "55.932203389830505\n",
      "client accuracy :  9\n",
      "48.598130841121495\n",
      "client accuracy :  10\n",
      "48.35164835164835\n",
      "client accuracy :  11\n",
      "57.14285714285714\n",
      "client accuracy :  12\n",
      "49.40711462450593\n",
      "client accuracy :  13\n",
      "46.34146341463415\n",
      "client accuracy :  14\n",
      "50.0\n",
      "client accuracy :  15\n",
      "71.42857142857143\n",
      "client accuracy :  16\n",
      "46.34146341463415\n",
      "client accuracy :  17\n",
      "48.148148148148145\n",
      "client accuracy :  18\n",
      "33.33333333333333\n",
      "client accuracy :  19\n",
      "56.60377358490566\n",
      "test accuracy:  52.05673758865248\n",
      "66\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.2028, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.5066, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  68.37242359630419\n",
      "loss after my code:  17.692440212173825\n",
      "train loss after my code:  16.016955163788207\n",
      "val accuracy:  54.93958777540867\n",
      "test accuracy:  52.05673758865248\n",
      "67\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.1481, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.4056, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  68.58564321250888\n",
      "loss after my code:  18.559246354793537\n",
      "train loss after my code:  17.408409896790953\n",
      "val accuracy:  55.010660980810236\n",
      "test accuracy:  52.05673758865248\n",
      "68\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.2505, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.5854, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  67.51954513148543\n",
      "loss after my code:  18.91700687610955\n",
      "train loss after my code:  16.956543833877845\n",
      "val accuracy:  55.010660980810236\n",
      "test accuracy:  52.05673758865248\n",
      "69\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.2310, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.5890, device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy before bandits:  67.30632551528075\n",
      "loss after my code:  18.44849242820364\n",
      "train loss after my code:  16.240812699449506\n",
      "val accuracy:  55.010660980810236\n",
      "test accuracy:  52.05673758865248\n",
      "70\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.3102, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.6860, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "67.74193548387096\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "64.28571428571429\n",
      "client accuracy :  3\n",
      "66.0377358490566\n",
      "client accuracy :  4\n",
      "87.01298701298701\n",
      "client accuracy :  5\n",
      "77.27272727272727\n",
      "client accuracy :  6\n",
      "61.53846153846154\n",
      "client accuracy :  7\n",
      "91.8918918918919\n",
      "client accuracy :  8\n",
      "91.52542372881356\n",
      "client accuracy :  9\n",
      "71.69811320754717\n",
      "client accuracy :  10\n",
      "52.74725274725275\n",
      "client accuracy :  11\n",
      "58.57142857142858\n",
      "client accuracy :  12\n",
      "65.87301587301587\n",
      "client accuracy :  13\n",
      "73.17073170731707\n",
      "client accuracy :  14\n",
      "61.904761904761905\n",
      "client accuracy :  15\n",
      "65.71428571428571\n",
      "client accuracy :  16\n",
      "62.5\n",
      "client accuracy :  17\n",
      "66.66666666666666\n",
      "client accuracy :  18\n",
      "88.88888888888889\n",
      "client accuracy :  19\n",
      "52.83018867924528\n",
      "val accuracy before bandits:  67.66169154228857\n",
      "loss after my code:  18.099619167913087\n",
      "train loss after my code:  16.432179158164914\n",
      "client accuracy :  0\n",
      "54.83870967741935\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "58.92857142857143\n",
      "client accuracy :  3\n",
      "60.37735849056604\n",
      "client accuracy :  4\n",
      "63.63636363636363\n",
      "client accuracy :  5\n",
      "45.45454545454545\n",
      "client accuracy :  6\n",
      "50.427350427350426\n",
      "client accuracy :  7\n",
      "54.054054054054056\n",
      "client accuracy :  8\n",
      "52.54237288135594\n",
      "client accuracy :  9\n",
      "58.490566037735846\n",
      "client accuracy :  10\n",
      "52.74725274725275\n",
      "client accuracy :  11\n",
      "54.285714285714285\n",
      "client accuracy :  12\n",
      "55.952380952380956\n",
      "client accuracy :  13\n",
      "53.65853658536586\n",
      "client accuracy :  14\n",
      "59.523809523809526\n",
      "client accuracy :  15\n",
      "48.57142857142857\n",
      "client accuracy :  16\n",
      "57.49999999999999\n",
      "client accuracy :  17\n",
      "59.25925925925925\n",
      "client accuracy :  18\n",
      "74.07407407407408\n",
      "client accuracy :  19\n",
      "41.509433962264154\n",
      "val accuracy:  55.010660980810236\n",
      "client accuracy :  0\n",
      "61.29032258064516\n",
      "client accuracy :  1\n",
      "55.55555555555556\n",
      "client accuracy :  2\n",
      "48.214285714285715\n",
      "client accuracy :  3\n",
      "62.264150943396224\n",
      "client accuracy :  4\n",
      "50.649350649350644\n",
      "client accuracy :  5\n",
      "54.54545454545454\n",
      "client accuracy :  6\n",
      "55.55555555555556\n",
      "client accuracy :  7\n",
      "51.35135135135135\n",
      "client accuracy :  8\n",
      "55.932203389830505\n",
      "client accuracy :  9\n",
      "48.598130841121495\n",
      "client accuracy :  10\n",
      "48.35164835164835\n",
      "client accuracy :  11\n",
      "57.14285714285714\n",
      "client accuracy :  12\n",
      "49.40711462450593\n",
      "client accuracy :  13\n",
      "46.34146341463415\n",
      "client accuracy :  14\n",
      "50.0\n",
      "client accuracy :  15\n",
      "71.42857142857143\n",
      "client accuracy :  16\n",
      "46.34146341463415\n",
      "client accuracy :  17\n",
      "48.148148148148145\n",
      "client accuracy :  18\n",
      "33.33333333333333\n",
      "client accuracy :  19\n",
      "56.60377358490566\n",
      "test accuracy:  52.05673758865248\n",
      "71\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.3533, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.6874, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  66.95095948827291\n",
      "loss after my code:  17.929893778675837\n",
      "train loss after my code:  16.16514609129236\n",
      "val accuracy:  55.010660980810236\n",
      "test accuracy:  52.05673758865248\n",
      "72\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.4110, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.8163, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  66.73773987206823\n",
      "loss after my code:  17.912955346736755\n",
      "train loss after my code:  16.113865843289553\n",
      "val accuracy:  55.010660980810236\n",
      "test accuracy:  52.05673758865248\n",
      "73\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.2639, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.6914, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  68.1592039800995\n",
      "loss after my code:  18.459270620382956\n",
      "train loss after my code:  16.29370292558659\n",
      "val accuracy:  55.010660980810236\n",
      "test accuracy:  52.05673758865248\n",
      "74\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.3075, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.7048, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  67.80383795309169\n",
      "loss after my code:  19.093677500642382\n",
      "train loss after my code:  17.11875030400118\n",
      "val accuracy:  55.010660980810236\n",
      "test accuracy:  52.05673758865248\n",
      "75\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.4334, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.7695, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "67.74193548387096\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "64.28571428571429\n",
      "client accuracy :  3\n",
      "62.264150943396224\n",
      "client accuracy :  4\n",
      "88.31168831168831\n",
      "client accuracy :  5\n",
      "72.72727272727273\n",
      "client accuracy :  6\n",
      "60.68376068376068\n",
      "client accuracy :  7\n",
      "91.8918918918919\n",
      "client accuracy :  8\n",
      "91.52542372881356\n",
      "client accuracy :  9\n",
      "71.69811320754717\n",
      "client accuracy :  10\n",
      "52.74725274725275\n",
      "client accuracy :  11\n",
      "60.0\n",
      "client accuracy :  12\n",
      "65.87301587301587\n",
      "client accuracy :  13\n",
      "70.73170731707317\n",
      "client accuracy :  14\n",
      "61.904761904761905\n",
      "client accuracy :  15\n",
      "68.57142857142857\n",
      "client accuracy :  16\n",
      "62.5\n",
      "client accuracy :  17\n",
      "66.66666666666666\n",
      "client accuracy :  18\n",
      "88.88888888888889\n",
      "client accuracy :  19\n",
      "54.71698113207547\n",
      "val accuracy before bandits:  67.51954513148543\n",
      "loss after my code:  18.95520378539907\n",
      "train loss after my code:  17.47831251110215\n",
      "client accuracy :  0\n",
      "54.83870967741935\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "58.92857142857143\n",
      "client accuracy :  3\n",
      "60.37735849056604\n",
      "client accuracy :  4\n",
      "63.63636363636363\n",
      "client accuracy :  5\n",
      "45.45454545454545\n",
      "client accuracy :  6\n",
      "50.427350427350426\n",
      "client accuracy :  7\n",
      "54.054054054054056\n",
      "client accuracy :  8\n",
      "52.54237288135594\n",
      "client accuracy :  9\n",
      "58.490566037735846\n",
      "client accuracy :  10\n",
      "52.74725274725275\n",
      "client accuracy :  11\n",
      "54.285714285714285\n",
      "client accuracy :  12\n",
      "55.952380952380956\n",
      "client accuracy :  13\n",
      "53.65853658536586\n",
      "client accuracy :  14\n",
      "59.523809523809526\n",
      "client accuracy :  15\n",
      "48.57142857142857\n",
      "client accuracy :  16\n",
      "57.49999999999999\n",
      "client accuracy :  17\n",
      "59.25925925925925\n",
      "client accuracy :  18\n",
      "74.07407407407408\n",
      "client accuracy :  19\n",
      "41.509433962264154\n",
      "val accuracy:  55.010660980810236\n",
      "client accuracy :  0\n",
      "61.29032258064516\n",
      "client accuracy :  1\n",
      "55.55555555555556\n",
      "client accuracy :  2\n",
      "48.214285714285715\n",
      "client accuracy :  3\n",
      "62.264150943396224\n",
      "client accuracy :  4\n",
      "50.649350649350644\n",
      "client accuracy :  5\n",
      "54.54545454545454\n",
      "client accuracy :  6\n",
      "55.55555555555556\n",
      "client accuracy :  7\n",
      "51.35135135135135\n",
      "client accuracy :  8\n",
      "55.932203389830505\n",
      "client accuracy :  9\n",
      "48.598130841121495\n",
      "client accuracy :  10\n",
      "48.35164835164835\n",
      "client accuracy :  11\n",
      "57.14285714285714\n",
      "client accuracy :  12\n",
      "49.40711462450593\n",
      "client accuracy :  13\n",
      "46.34146341463415\n",
      "client accuracy :  14\n",
      "50.0\n",
      "client accuracy :  15\n",
      "71.42857142857143\n",
      "client accuracy :  16\n",
      "46.34146341463415\n",
      "client accuracy :  17\n",
      "48.148148148148145\n",
      "client accuracy :  18\n",
      "33.33333333333333\n",
      "client accuracy :  19\n",
      "56.60377358490566\n",
      "test accuracy:  52.05673758865248\n",
      "76\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.3883, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.7322, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  67.37739872068231\n",
      "loss after my code:  19.29010336315095\n",
      "train loss after my code:  17.466674393039938\n",
      "val accuracy:  55.010660980810236\n",
      "test accuracy:  52.05673758865248\n",
      "77\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.4792, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.7616, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  67.23525230987917\n",
      "loss after my code:  19.42022820088305\n",
      "train loss after my code:  17.386680662152752\n",
      "val accuracy:  55.010660980810236\n",
      "test accuracy:  52.05673758865248\n",
      "78\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.4328, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.8449, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  67.02203269367448\n",
      "loss after my code:  20.04328808111366\n",
      "train loss after my code:  18.295382680394543\n",
      "val accuracy:  55.0817341862118\n",
      "test accuracy:  52.05673758865248\n",
      "79\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.4339, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.8117, device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy before bandits:  67.16417910447761\n",
      "loss after my code:  19.86885159234056\n",
      "train loss after my code:  17.910301277727655\n",
      "val accuracy:  55.0817341862118\n",
      "test accuracy:  52.05673758865248\n",
      "80\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.5382, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.8923, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "66.12903225806451\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "64.28571428571429\n",
      "client accuracy :  3\n",
      "64.15094339622641\n",
      "client accuracy :  4\n",
      "87.01298701298701\n",
      "client accuracy :  5\n",
      "77.27272727272727\n",
      "client accuracy :  6\n",
      "60.68376068376068\n",
      "client accuracy :  7\n",
      "91.8918918918919\n",
      "client accuracy :  8\n",
      "89.83050847457628\n",
      "client accuracy :  9\n",
      "71.69811320754717\n",
      "client accuracy :  10\n",
      "52.74725274725275\n",
      "client accuracy :  11\n",
      "60.0\n",
      "client accuracy :  12\n",
      "63.888888888888886\n",
      "client accuracy :  13\n",
      "70.73170731707317\n",
      "client accuracy :  14\n",
      "61.904761904761905\n",
      "client accuracy :  15\n",
      "65.71428571428571\n",
      "client accuracy :  16\n",
      "62.5\n",
      "client accuracy :  17\n",
      "62.96296296296296\n",
      "client accuracy :  18\n",
      "88.88888888888889\n",
      "client accuracy :  19\n",
      "47.16981132075472\n",
      "val accuracy before bandits:  66.73773987206823\n",
      "loss after my code:  20.02212159842953\n",
      "train loss after my code:  18.499031306161378\n",
      "client accuracy :  0\n",
      "54.83870967741935\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "58.92857142857143\n",
      "client accuracy :  3\n",
      "60.37735849056604\n",
      "client accuracy :  4\n",
      "63.63636363636363\n",
      "client accuracy :  5\n",
      "45.45454545454545\n",
      "client accuracy :  6\n",
      "50.427350427350426\n",
      "client accuracy :  7\n",
      "54.054054054054056\n",
      "client accuracy :  8\n",
      "52.54237288135594\n",
      "client accuracy :  9\n",
      "58.490566037735846\n",
      "client accuracy :  10\n",
      "53.2967032967033\n",
      "client accuracy :  11\n",
      "54.285714285714285\n",
      "client accuracy :  12\n",
      "55.952380952380956\n",
      "client accuracy :  13\n",
      "53.65853658536586\n",
      "client accuracy :  14\n",
      "59.523809523809526\n",
      "client accuracy :  15\n",
      "48.57142857142857\n",
      "client accuracy :  16\n",
      "57.49999999999999\n",
      "client accuracy :  17\n",
      "59.25925925925925\n",
      "client accuracy :  18\n",
      "74.07407407407408\n",
      "client accuracy :  19\n",
      "41.509433962264154\n",
      "val accuracy:  55.0817341862118\n",
      "client accuracy :  0\n",
      "61.29032258064516\n",
      "client accuracy :  1\n",
      "55.55555555555556\n",
      "client accuracy :  2\n",
      "48.214285714285715\n",
      "client accuracy :  3\n",
      "62.264150943396224\n",
      "client accuracy :  4\n",
      "50.649350649350644\n",
      "client accuracy :  5\n",
      "54.54545454545454\n",
      "client accuracy :  6\n",
      "55.55555555555556\n",
      "client accuracy :  7\n",
      "51.35135135135135\n",
      "client accuracy :  8\n",
      "55.932203389830505\n",
      "client accuracy :  9\n",
      "48.598130841121495\n",
      "client accuracy :  10\n",
      "48.35164835164835\n",
      "client accuracy :  11\n",
      "57.14285714285714\n",
      "client accuracy :  12\n",
      "49.40711462450593\n",
      "client accuracy :  13\n",
      "46.34146341463415\n",
      "client accuracy :  14\n",
      "50.0\n",
      "client accuracy :  15\n",
      "71.42857142857143\n",
      "client accuracy :  16\n",
      "46.34146341463415\n",
      "client accuracy :  17\n",
      "48.148148148148145\n",
      "client accuracy :  18\n",
      "33.33333333333333\n",
      "client accuracy :  19\n",
      "56.60377358490566\n",
      "test accuracy:  52.05673758865248\n",
      "81\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.5858, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.9345, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  66.8088130774698\n",
      "loss after my code:  19.737903706646982\n",
      "train loss after my code:  17.916433796241893\n",
      "val accuracy:  55.0817341862118\n",
      "test accuracy:  52.05673758865248\n",
      "82\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.4801, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.9264, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  67.02203269367448\n",
      "loss after my code:  20.19464419703733\n",
      "train loss after my code:  17.858413254199203\n",
      "val accuracy:  55.0817341862118\n",
      "test accuracy:  52.05673758865248\n",
      "83\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.4925, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.9848, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  66.95095948827291\n",
      "loss after my code:  20.243179943615207\n",
      "train loss after my code:  18.92073946030298\n",
      "val accuracy:  55.0817341862118\n",
      "test accuracy:  52.05673758865248\n",
      "84\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.6074, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(3.0531, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  66.45344705046197\n",
      "loss after my code:  20.111359975760944\n",
      "train loss after my code:  17.756061593016792\n",
      "val accuracy:  55.0817341862118\n",
      "test accuracy:  52.05673758865248\n",
      "85\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.5908, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(3.0268, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "67.74193548387096\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "64.28571428571429\n",
      "client accuracy :  3\n",
      "64.15094339622641\n",
      "client accuracy :  4\n",
      "87.01298701298701\n",
      "client accuracy :  5\n",
      "70.45454545454545\n",
      "client accuracy :  6\n",
      "60.68376068376068\n",
      "client accuracy :  7\n",
      "91.8918918918919\n",
      "client accuracy :  8\n",
      "89.83050847457628\n",
      "client accuracy :  9\n",
      "71.69811320754717\n",
      "client accuracy :  10\n",
      "52.74725274725275\n",
      "client accuracy :  11\n",
      "60.0\n",
      "client accuracy :  12\n",
      "64.28571428571429\n",
      "client accuracy :  13\n",
      "73.17073170731707\n",
      "client accuracy :  14\n",
      "61.904761904761905\n",
      "client accuracy :  15\n",
      "62.857142857142854\n",
      "client accuracy :  16\n",
      "62.5\n",
      "client accuracy :  17\n",
      "62.96296296296296\n",
      "client accuracy :  18\n",
      "85.18518518518519\n",
      "client accuracy :  19\n",
      "47.16981132075472\n",
      "val accuracy before bandits:  66.5955934612651\n",
      "loss after my code:  20.19221219581279\n",
      "train loss after my code:  18.45344261746742\n",
      "client accuracy :  0\n",
      "54.83870967741935\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "58.92857142857143\n",
      "client accuracy :  3\n",
      "60.37735849056604\n",
      "client accuracy :  4\n",
      "63.63636363636363\n",
      "client accuracy :  5\n",
      "45.45454545454545\n",
      "client accuracy :  6\n",
      "50.427350427350426\n",
      "client accuracy :  7\n",
      "54.054054054054056\n",
      "client accuracy :  8\n",
      "52.54237288135594\n",
      "client accuracy :  9\n",
      "58.490566037735846\n",
      "client accuracy :  10\n",
      "53.2967032967033\n",
      "client accuracy :  11\n",
      "54.285714285714285\n",
      "client accuracy :  12\n",
      "55.952380952380956\n",
      "client accuracy :  13\n",
      "53.65853658536586\n",
      "client accuracy :  14\n",
      "59.523809523809526\n",
      "client accuracy :  15\n",
      "48.57142857142857\n",
      "client accuracy :  16\n",
      "57.49999999999999\n",
      "client accuracy :  17\n",
      "59.25925925925925\n",
      "client accuracy :  18\n",
      "74.07407407407408\n",
      "client accuracy :  19\n",
      "41.509433962264154\n",
      "val accuracy:  55.0817341862118\n",
      "client accuracy :  0\n",
      "61.29032258064516\n",
      "client accuracy :  1\n",
      "55.55555555555556\n",
      "client accuracy :  2\n",
      "48.214285714285715\n",
      "client accuracy :  3\n",
      "62.264150943396224\n",
      "client accuracy :  4\n",
      "50.649350649350644\n",
      "client accuracy :  5\n",
      "54.54545454545454\n",
      "client accuracy :  6\n",
      "55.55555555555556\n",
      "client accuracy :  7\n",
      "51.35135135135135\n",
      "client accuracy :  8\n",
      "55.932203389830505\n",
      "client accuracy :  9\n",
      "48.598130841121495\n",
      "client accuracy :  10\n",
      "48.35164835164835\n",
      "client accuracy :  11\n",
      "57.14285714285714\n",
      "client accuracy :  12\n",
      "49.40711462450593\n",
      "client accuracy :  13\n",
      "46.34146341463415\n",
      "client accuracy :  14\n",
      "50.0\n",
      "client accuracy :  15\n",
      "71.42857142857143\n",
      "client accuracy :  16\n",
      "46.34146341463415\n",
      "client accuracy :  17\n",
      "48.148148148148145\n",
      "client accuracy :  18\n",
      "33.33333333333333\n",
      "client accuracy :  19\n",
      "56.60377358490566\n",
      "test accuracy:  52.05673758865248\n",
      "86\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.6197, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(3.0337, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  66.31130063965884\n",
      "loss after my code:  20.474513106111612\n",
      "train loss after my code:  18.185986987015088\n",
      "val accuracy:  55.0817341862118\n",
      "test accuracy:  52.05673758865248\n",
      "87\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.5397, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.9612, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  67.09310589907605\n",
      "loss after my code:  20.72481961788883\n",
      "train loss after my code:  19.281419800537154\n",
      "val accuracy:  55.0817341862118\n",
      "test accuracy:  52.05673758865248\n",
      "88\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.7267, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(3.0808, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  66.66666666666666\n",
      "loss after my code:  20.676215096383423\n",
      "train loss after my code:  18.462252236685263\n",
      "val accuracy:  55.0817341862118\n",
      "test accuracy:  52.05673758865248\n",
      "89\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.5870, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(3.0037, device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy before bandits:  66.5955934612651\n",
      "loss after my code:  20.864467719863633\n",
      "train loss after my code:  19.55061521582392\n",
      "val accuracy:  55.0817341862118\n",
      "test accuracy:  52.05673758865248\n",
      "90\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.5745, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(3.0423, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "64.51612903225806\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "64.28571428571429\n",
      "client accuracy :  3\n",
      "64.15094339622641\n",
      "client accuracy :  4\n",
      "85.71428571428571\n",
      "client accuracy :  5\n",
      "72.72727272727273\n",
      "client accuracy :  6\n",
      "60.68376068376068\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "89.83050847457628\n",
      "client accuracy :  9\n",
      "71.69811320754717\n",
      "client accuracy :  10\n",
      "52.74725274725275\n",
      "client accuracy :  11\n",
      "60.0\n",
      "client accuracy :  12\n",
      "65.07936507936508\n",
      "client accuracy :  13\n",
      "70.73170731707317\n",
      "client accuracy :  14\n",
      "61.904761904761905\n",
      "client accuracy :  15\n",
      "68.57142857142857\n",
      "client accuracy :  16\n",
      "62.5\n",
      "client accuracy :  17\n",
      "62.96296296296296\n",
      "client accuracy :  18\n",
      "85.18518518518519\n",
      "client accuracy :  19\n",
      "47.16981132075472\n",
      "val accuracy before bandits:  66.73773987206823\n",
      "loss after my code:  20.933011699038094\n",
      "train loss after my code:  18.922082558711033\n",
      "client accuracy :  0\n",
      "54.83870967741935\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "58.92857142857143\n",
      "client accuracy :  3\n",
      "60.37735849056604\n",
      "client accuracy :  4\n",
      "63.63636363636363\n",
      "client accuracy :  5\n",
      "45.45454545454545\n",
      "client accuracy :  6\n",
      "50.427350427350426\n",
      "client accuracy :  7\n",
      "54.054054054054056\n",
      "client accuracy :  8\n",
      "52.54237288135594\n",
      "client accuracy :  9\n",
      "58.490566037735846\n",
      "client accuracy :  10\n",
      "53.2967032967033\n",
      "client accuracy :  11\n",
      "54.285714285714285\n",
      "client accuracy :  12\n",
      "55.952380952380956\n",
      "client accuracy :  13\n",
      "53.65853658536586\n",
      "client accuracy :  14\n",
      "59.523809523809526\n",
      "client accuracy :  15\n",
      "48.57142857142857\n",
      "client accuracy :  16\n",
      "57.49999999999999\n",
      "client accuracy :  17\n",
      "59.25925925925925\n",
      "client accuracy :  18\n",
      "74.07407407407408\n",
      "client accuracy :  19\n",
      "41.509433962264154\n",
      "val accuracy:  55.0817341862118\n",
      "client accuracy :  0\n",
      "61.29032258064516\n",
      "client accuracy :  1\n",
      "55.55555555555556\n",
      "client accuracy :  2\n",
      "48.214285714285715\n",
      "client accuracy :  3\n",
      "62.264150943396224\n",
      "client accuracy :  4\n",
      "50.649350649350644\n",
      "client accuracy :  5\n",
      "54.54545454545454\n",
      "client accuracy :  6\n",
      "55.55555555555556\n",
      "client accuracy :  7\n",
      "51.35135135135135\n",
      "client accuracy :  8\n",
      "55.932203389830505\n",
      "client accuracy :  9\n",
      "48.598130841121495\n",
      "client accuracy :  10\n",
      "48.35164835164835\n",
      "client accuracy :  11\n",
      "57.14285714285714\n",
      "client accuracy :  12\n",
      "49.40711462450593\n",
      "client accuracy :  13\n",
      "46.34146341463415\n",
      "client accuracy :  14\n",
      "50.0\n",
      "client accuracy :  15\n",
      "71.42857142857143\n",
      "client accuracy :  16\n",
      "46.34146341463415\n",
      "client accuracy :  17\n",
      "48.148148148148145\n",
      "client accuracy :  18\n",
      "33.33333333333333\n",
      "client accuracy :  19\n",
      "56.60377358490566\n",
      "test accuracy:  52.05673758865248\n",
      "91\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.6627, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(3.1465, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  66.09808102345416\n",
      "loss after my code:  20.91711437578397\n",
      "train loss after my code:  17.97192578056754\n",
      "val accuracy:  55.0817341862118\n",
      "test accuracy:  52.05673758865248\n",
      "92\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.7748, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(3.1274, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  66.38237384506041\n",
      "loss after my code:  20.89006227583829\n",
      "train loss after my code:  18.988730737234555\n",
      "val accuracy:  55.0817341862118\n",
      "test accuracy:  52.05673758865248\n",
      "93\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.6780, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(3.0950, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  66.45344705046197\n",
      "loss after my code:  20.833742304980998\n",
      "train loss after my code:  18.592084833569874\n",
      "val accuracy:  55.0817341862118\n",
      "test accuracy:  52.05673758865248\n",
      "94\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.8127, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(3.1834, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  66.16915422885572\n",
      "loss after my code:  20.524780747314566\n",
      "train loss after my code:  18.59848806718887\n",
      "val accuracy:  55.0817341862118\n",
      "test accuracy:  52.05673758865248\n",
      "95\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.6661, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(3.1332, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "64.51612903225806\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "64.28571428571429\n",
      "client accuracy :  3\n",
      "64.15094339622641\n",
      "client accuracy :  4\n",
      "85.71428571428571\n",
      "client accuracy :  5\n",
      "72.72727272727273\n",
      "client accuracy :  6\n",
      "60.68376068376068\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "88.13559322033898\n",
      "client accuracy :  9\n",
      "71.69811320754717\n",
      "client accuracy :  10\n",
      "52.74725274725275\n",
      "client accuracy :  11\n",
      "58.57142857142858\n",
      "client accuracy :  12\n",
      "63.888888888888886\n",
      "client accuracy :  13\n",
      "73.17073170731707\n",
      "client accuracy :  14\n",
      "61.904761904761905\n",
      "client accuracy :  15\n",
      "68.57142857142857\n",
      "client accuracy :  16\n",
      "62.5\n",
      "client accuracy :  17\n",
      "62.96296296296296\n",
      "client accuracy :  18\n",
      "85.18518518518519\n",
      "client accuracy :  19\n",
      "47.16981132075472\n",
      "val accuracy before bandits:  66.45344705046197\n",
      "loss after my code:  20.683260538491737\n",
      "train loss after my code:  18.08497577778972\n",
      "client accuracy :  0\n",
      "54.83870967741935\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "58.92857142857143\n",
      "client accuracy :  3\n",
      "60.37735849056604\n",
      "client accuracy :  4\n",
      "63.63636363636363\n",
      "client accuracy :  5\n",
      "45.45454545454545\n",
      "client accuracy :  6\n",
      "50.427350427350426\n",
      "client accuracy :  7\n",
      "54.054054054054056\n",
      "client accuracy :  8\n",
      "52.54237288135594\n",
      "client accuracy :  9\n",
      "58.490566037735846\n",
      "client accuracy :  10\n",
      "53.2967032967033\n",
      "client accuracy :  11\n",
      "54.285714285714285\n",
      "client accuracy :  12\n",
      "55.952380952380956\n",
      "client accuracy :  13\n",
      "53.65853658536586\n",
      "client accuracy :  14\n",
      "59.523809523809526\n",
      "client accuracy :  15\n",
      "48.57142857142857\n",
      "client accuracy :  16\n",
      "57.49999999999999\n",
      "client accuracy :  17\n",
      "59.25925925925925\n",
      "client accuracy :  18\n",
      "74.07407407407408\n",
      "client accuracy :  19\n",
      "41.509433962264154\n",
      "val accuracy:  55.0817341862118\n",
      "client accuracy :  0\n",
      "61.29032258064516\n",
      "client accuracy :  1\n",
      "55.55555555555556\n",
      "client accuracy :  2\n",
      "48.214285714285715\n",
      "client accuracy :  3\n",
      "62.264150943396224\n",
      "client accuracy :  4\n",
      "50.649350649350644\n",
      "client accuracy :  5\n",
      "54.54545454545454\n",
      "client accuracy :  6\n",
      "55.55555555555556\n",
      "client accuracy :  7\n",
      "51.35135135135135\n",
      "client accuracy :  8\n",
      "55.932203389830505\n",
      "client accuracy :  9\n",
      "48.598130841121495\n",
      "client accuracy :  10\n",
      "48.35164835164835\n",
      "client accuracy :  11\n",
      "57.14285714285714\n",
      "client accuracy :  12\n",
      "49.40711462450593\n",
      "client accuracy :  13\n",
      "46.34146341463415\n",
      "client accuracy :  14\n",
      "50.0\n",
      "client accuracy :  15\n",
      "71.42857142857143\n",
      "client accuracy :  16\n",
      "46.34146341463415\n",
      "client accuracy :  17\n",
      "48.148148148148145\n",
      "client accuracy :  18\n",
      "33.33333333333333\n",
      "client accuracy :  19\n",
      "56.60377358490566\n",
      "test accuracy:  52.05673758865248\n",
      "96\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.7775, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(3.1814, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  66.31130063965884\n",
      "loss after my code:  20.669627168318286\n",
      "train loss after my code:  18.18185791853425\n",
      "val accuracy:  55.0817341862118\n",
      "test accuracy:  52.05673758865248\n",
      "97\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.7554, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(3.1806, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  65.95593461265103\n",
      "loss after my code:  20.435245686368162\n",
      "train loss after my code:  18.300051315474263\n",
      "val accuracy:  55.0817341862118\n",
      "test accuracy:  52.05673758865248\n",
      "98\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.7603, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(3.2242, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  66.0270078180526\n",
      "loss after my code:  20.285198572411524\n",
      "train loss after my code:  18.679986527388415\n",
      "val accuracy:  55.0817341862118\n",
      "test accuracy:  52.05673758865248\n",
      "99\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.7259, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(3.1747, device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy before bandits:  66.31130063965884\n",
      "loss after my code:  20.223053929369648\n",
      "train loss after my code:  17.636452934540646\n",
      "val accuracy:  55.0817341862118\n",
      "test accuracy:  52.05673758865248\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "settings, save_dir = init()\n",
    "import collections\n",
    "from time import time\n",
    "import random\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pandas\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "experiment_name = settings['experiment_name']\n",
    "test ='federated'\n",
    "n_epochs = 100 #settings['n_epochs']\n",
    "patients_removed = [6, 14, 16]\n",
    "patients_left = [x for x in range(1,24) if x not in patients_removed]\n",
    "print(patients_left)\n",
    "p2p = P2P_AFPL(patients_left,19, test)\n",
    "accuracies_fed = p2p.loop(n_epochs, p2p, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d326ef21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23]\n",
      "0\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.6906, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.7919, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "79.03225806451613\n",
      "client accuracy :  1\n",
      "77.77777777777779\n",
      "client accuracy :  2\n",
      "80.35714285714286\n",
      "client accuracy :  3\n",
      "60.37735849056604\n",
      "client accuracy :  4\n",
      "90.9090909090909\n",
      "client accuracy :  5\n",
      "79.54545454545455\n",
      "client accuracy :  6\n",
      "68.37606837606837\n",
      "client accuracy :  7\n",
      "89.1891891891892\n",
      "client accuracy :  8\n",
      "71.1864406779661\n",
      "client accuracy :  9\n",
      "97.16981132075472\n",
      "client accuracy :  10\n",
      "58.791208791208796\n",
      "client accuracy :  11\n",
      "75.71428571428571\n",
      "client accuracy :  12\n",
      "66.26984126984127\n",
      "client accuracy :  13\n",
      "78.04878048780488\n",
      "client accuracy :  14\n",
      "83.33333333333334\n",
      "client accuracy :  15\n",
      "88.57142857142857\n",
      "client accuracy :  16\n",
      "85.0\n",
      "client accuracy :  17\n",
      "55.55555555555556\n",
      "client accuracy :  18\n",
      "33.33333333333333\n",
      "client accuracy :  19\n",
      "88.67924528301887\n",
      "val accuracy before bandits:  73.91613361762616\n",
      "selected clients UCB:  [19 18  1  2  3  4  5  6  7  8]\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "loss after my code:  0.3591438965319887\n",
      "train loss after my code:  0.41663981317971466\n",
      "client accuracy :  0\n",
      "95.16129032258065\n",
      "client accuracy :  1\n",
      "81.48148148148148\n",
      "client accuracy :  2\n",
      "91.07142857142857\n",
      "client accuracy :  3\n",
      "67.9245283018868\n",
      "client accuracy :  4\n",
      "92.20779220779221\n",
      "client accuracy :  5\n",
      "81.81818181818183\n",
      "client accuracy :  6\n",
      "73.50427350427351\n",
      "client accuracy :  7\n",
      "91.8918918918919\n",
      "client accuracy :  8\n",
      "94.91525423728814\n",
      "client accuracy :  9\n",
      "97.16981132075472\n",
      "client accuracy :  10\n",
      "58.791208791208796\n",
      "client accuracy :  11\n",
      "75.71428571428571\n",
      "client accuracy :  12\n",
      "68.25396825396825\n",
      "client accuracy :  13\n",
      "82.92682926829268\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "88.57142857142857\n",
      "client accuracy :  16\n",
      "87.5\n",
      "client accuracy :  17\n",
      "59.25925925925925\n",
      "client accuracy :  18\n",
      "51.85185185185185\n",
      "client accuracy :  19\n",
      "94.33962264150944\n",
      "val accuracy:  78.60696517412936\n",
      "client accuracy :  0\n",
      "93.54838709677419\n",
      "client accuracy :  1\n",
      "88.88888888888889\n",
      "client accuracy :  2\n",
      "92.85714285714286\n",
      "client accuracy :  3\n",
      "67.9245283018868\n",
      "client accuracy :  4\n",
      "83.11688311688312\n",
      "client accuracy :  5\n",
      "95.45454545454545\n",
      "client accuracy :  6\n",
      "75.21367521367522\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "94.91525423728814\n",
      "client accuracy :  9\n",
      "91.58878504672897\n",
      "client accuracy :  10\n",
      "54.94505494505495\n",
      "client accuracy :  11\n",
      "62.857142857142854\n",
      "client accuracy :  12\n",
      "70.35573122529645\n",
      "client accuracy :  13\n",
      "82.92682926829268\n",
      "client accuracy :  14\n",
      "88.09523809523809\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "80.48780487804879\n",
      "client accuracy :  17\n",
      "55.55555555555556\n",
      "client accuracy :  18\n",
      "88.88888888888889\n",
      "client accuracy :  19\n",
      "86.79245283018868\n",
      "test accuracy:  77.80141843971631\n",
      "1\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.7490, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.8989, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  73.41862117981522\n",
      "selected clients UCB:  [ 9 17 16 15 14 13 12 11 10  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "loss after my code:  0.25566550095414564\n",
      "train loss after my code:  0.27663757078558704\n",
      "val accuracy:  78.89125799573561\n",
      "test accuracy:  76.52482269503547\n",
      "2\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.7385, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.1443, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  76.19047619047619\n",
      "selected clients UCB:  [19 10  2  8 18  9 15  7 13 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      "loss after my code:  0.30158617767605855\n",
      "train loss after my code:  0.3818211887564561\n",
      "val accuracy:  82.2316986496091\n",
      "test accuracy:  80.42553191489363\n",
      "3\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.5439, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.8351, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  81.4498933901919\n",
      "selected clients UCB:  [19  8 10 12  2 18  9 15  7 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "loss after my code:  0.2240554382902728\n",
      "train loss after my code:  0.23526550718205677\n",
      "val accuracy:  87.63326226012794\n",
      "test accuracy:  85.60283687943262\n",
      "4\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.5008, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.6320, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  83.72423596304193\n",
      "selected clients UCB:  [19 10  8 18  7 12  2  9 15 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "loss after my code:  0.25158781613594583\n",
      "train loss after my code:  0.1984328020679704\n",
      "val accuracy:  88.55721393034825\n",
      "test accuracy:  87.09219858156028\n",
      "5\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.5218, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.8498, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "85.48387096774194\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "91.07142857142857\n",
      "client accuracy :  3\n",
      "77.35849056603774\n",
      "client accuracy :  4\n",
      "76.62337662337663\n",
      "client accuracy :  5\n",
      "86.36363636363636\n",
      "client accuracy :  6\n",
      "72.64957264957265\n",
      "client accuracy :  7\n",
      "89.1891891891892\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "91.50943396226415\n",
      "client accuracy :  10\n",
      "80.76923076923077\n",
      "client accuracy :  11\n",
      "84.28571428571429\n",
      "client accuracy :  12\n",
      "70.23809523809523\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "59.523809523809526\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "57.49999999999999\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "88.88888888888889\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  80.24164889836531\n",
      "selected clients UCB:  [19 10 18 15  8  7  5 17 16  1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "loss after my code:  0.17765498281198025\n",
      "train loss after my code:  0.22103046820151132\n",
      "client accuracy :  0\n",
      "96.7741935483871\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "81.13207547169812\n",
      "client accuracy :  4\n",
      "96.1038961038961\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "74.35897435897436\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "80.76923076923077\n",
      "client accuracy :  11\n",
      "84.28571428571429\n",
      "client accuracy :  12\n",
      "83.33333333333334\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "88.09523809523809\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "80.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "92.5925925925926\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  87.91755508173419\n",
      "client accuracy :  0\n",
      "95.16129032258065\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "73.50427350427351\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "84.61538461538461\n",
      "client accuracy :  11\n",
      "72.85714285714285\n",
      "client accuracy :  12\n",
      "83.399209486166\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "90.47619047619048\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "75.60975609756098\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "94.33962264150944\n",
      "test accuracy:  88.01418439716312\n",
      "6\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.5162, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.6150, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  86.9225302061123\n",
      "selected clients UCB:  [19 10 18 15  7  8  3  4  6  2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.1966216107154098\n",
      "train loss after my code:  0.19381607237001136\n",
      "val accuracy:  91.11584932480456\n",
      "test accuracy:  89.71631205673759\n",
      "7\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.2501, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4188, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  83.51101634683724\n",
      "selected clients UCB:  [19 10 15 18  7  8 12  9  2 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "loss after my code:  0.24069700135658656\n",
      "train loss after my code:  0.2044367864631785\n",
      "val accuracy:  88.77043354655295\n",
      "test accuracy:  88.79432624113474\n",
      "8\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.3567, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5203, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  86.4960909737029\n",
      "selected clients UCB:  [19 10 15  8 18  7  2  9 12 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "loss after my code:  0.22161906137467222\n",
      "train loss after my code:  0.2919895226732785\n",
      "val accuracy:  90.26297085998578\n",
      "test accuracy:  89.00709219858156\n",
      "9\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.8041, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.9996, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  82.51599147121536\n",
      "selected clients UCB:  [19 10 15 18  8  7  2  4 17 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.3195483681112414\n",
      "train loss after my code:  0.21100993846006166\n",
      "val accuracy:  89.05472636815921\n",
      "test accuracy:  89.29078014184397\n",
      "10\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1226, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3546, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "95.16129032258065\n",
      "client accuracy :  1\n",
      "88.88888888888889\n",
      "client accuracy :  2\n",
      "91.07142857142857\n",
      "client accuracy :  3\n",
      "77.35849056603774\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "86.36363636363636\n",
      "client accuracy :  6\n",
      "88.03418803418803\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "97.16981132075472\n",
      "client accuracy :  10\n",
      "73.07692307692307\n",
      "client accuracy :  11\n",
      "88.57142857142857\n",
      "client accuracy :  12\n",
      "90.47619047619048\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "71.42857142857143\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "75.0\n",
      "client accuracy :  17\n",
      "77.77777777777779\n",
      "client accuracy :  18\n",
      "85.18518518518519\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  88.05970149253731\n",
      "selected clients UCB:  [19 10 15 18  8  7  1 14  3  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "loss after my code:  0.17756069715729567\n",
      "train loss after my code:  0.14541446445143075\n",
      "client accuracy :  0\n",
      "96.7741935483871\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "86.36363636363636\n",
      "client accuracy :  6\n",
      "88.03418803418803\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "73.07692307692307\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "90.47619047619048\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "77.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "92.5925925925926\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  90.12082444918266\n",
      "client accuracy :  0\n",
      "91.93548387096774\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "92.85714285714286\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "96.61016949152543\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "78.02197802197803\n",
      "client accuracy :  11\n",
      "84.28571428571429\n",
      "client accuracy :  12\n",
      "87.74703557312253\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "80.48780487804879\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "94.33962264150944\n",
      "test accuracy:  90.0\n",
      "11\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.2099, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4720, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  88.55721393034825\n",
      "selected clients UCB:  [19 14 10 15 18  7  6  8  2  9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.24577230044491696\n",
      "train loss after my code:  0.1860552570356889\n",
      "val accuracy:  91.82658137882018\n",
      "test accuracy:  91.56028368794327\n",
      "12\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.2195, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4228, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  87.20682302771856\n",
      "selected clients UCB:  [19 10  7 14 15 18  8 12  2 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "loss after my code:  0.18067654355556728\n",
      "train loss after my code:  0.1805643863419558\n",
      "val accuracy:  91.54228855721394\n",
      "test accuracy:  90.99290780141844\n",
      "13\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1777, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3490, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  89.62331201137171\n",
      "selected clients UCB:  [19 10 17  7 15 18 14  8  4  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "loss after my code:  0.21438068547328396\n",
      "train loss after my code:  0.1628726037850231\n",
      "val accuracy:  92.03980099502488\n",
      "test accuracy:  91.41843971631207\n",
      "14\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0680, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2585, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  89.97867803837953\n",
      "selected clients UCB:  [19 10 14  5  7 17 15 18  3 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0.]\n",
      "loss after my code:  0.15828044550642542\n",
      "train loss after my code:  0.1523952868753656\n",
      "val accuracy:  91.4001421464108\n",
      "test accuracy:  90.92198581560284\n",
      "15\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1849, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4006, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "59.25925925925925\n",
      "client accuracy :  2\n",
      "92.85714285714286\n",
      "client accuracy :  3\n",
      "73.58490566037736\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "81.81818181818183\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "94.91525423728814\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "82.96703296703298\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "84.52380952380952\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "68.57142857142857\n",
      "client accuracy :  16\n",
      "67.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "94.33962264150944\n",
      "val accuracy before bandits:  88.05970149253731\n",
      "selected clients UCB:  [19 14 17 16 10  7  5 15 18 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.18863086420525374\n",
      "train loss after my code:  0.12217946968347555\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "82.96703296703298\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "84.52380952380952\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "82.5\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "val accuracy:  90.97370291400142\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "95.45454545454545\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "96.61016949152543\n",
      "client accuracy :  9\n",
      "95.32710280373831\n",
      "client accuracy :  10\n",
      "84.06593406593407\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "79.44664031620553\n",
      "client accuracy :  13\n",
      "80.48780487804879\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "82.92682926829268\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "92.45283018867924\n",
      "test accuracy:  90.1418439716312\n",
      "16\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1983, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4256, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  85.9275053304904\n",
      "selected clients UCB:  [19 14 10 17  7 16  5 15 18  1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "loss after my code:  0.17630657997186489\n",
      "train loss after my code:  0.1312494042018857\n",
      "val accuracy:  91.25799573560768\n",
      "test accuracy:  91.91489361702128\n",
      "17\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1091, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2934, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  88.27292110874201\n",
      "selected clients UCB:  [19 17 14 10  7 16  6 11  2  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.164273297783675\n",
      "train loss after my code:  0.1488803809900588\n",
      "val accuracy:  90.76048329779674\n",
      "test accuracy:  91.98581560283688\n",
      "18\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1403, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4209, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  85.99857853589197\n",
      "selected clients UCB:  [19 17 14 10  7 12  5  9 16 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.18639593203129093\n",
      "train loss after my code:  0.17230929752825813\n",
      "val accuracy:  89.62331201137171\n",
      "test accuracy:  90.1418439716312\n",
      "19\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0900, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2675, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  89.05472636815921\n",
      "selected clients UCB:  [19 17 10 14  7 15  8 18  2  4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "loss after my code:  0.11763320557579456\n",
      "train loss after my code:  0.10943324212151376\n",
      "val accuracy:  91.32906894100924\n",
      "test accuracy:  91.70212765957447\n",
      "20\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1352, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3544, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "87.5\n",
      "client accuracy :  3\n",
      "69.81132075471697\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "79.54545454545455\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "70.27027027027027\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "81.31868131868131\n",
      "client accuracy :  11\n",
      "77.14285714285715\n",
      "client accuracy :  12\n",
      "79.36507936507937\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "100.0\n",
      "client accuracy :  15\n",
      "88.57142857142857\n",
      "client accuracy :  16\n",
      "87.5\n",
      "client accuracy :  17\n",
      "92.5925925925926\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "88.67924528301887\n",
      "val accuracy before bandits:  87.34896943852168\n",
      "selected clients UCB:  [19 14 17 10  2  7 15  6  1 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.1374964882899961\n",
      "train loss after my code:  0.10346191679641353\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "81.13207547169812\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "81.81818181818183\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "81.31868131868131\n",
      "client accuracy :  11\n",
      "82.85714285714286\n",
      "client accuracy :  12\n",
      "87.3015873015873\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "100.0\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "87.5\n",
      "client accuracy :  17\n",
      "92.5925925925926\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "92.45283018867924\n",
      "val accuracy:  90.97370291400142\n",
      "client accuracy :  0\n",
      "96.7741935483871\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "96.1038961038961\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "96.61016949152543\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "86.81318681318682\n",
      "client accuracy :  11\n",
      "78.57142857142857\n",
      "client accuracy :  12\n",
      "91.30434782608695\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "85.36585365853658\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "90.56603773584906\n",
      "test accuracy:  92.05673758865248\n",
      "21\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0839, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2837, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  89.62331201137171\n",
      "selected clients UCB:  [19 14 17 10  7  2  3 11  5  9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "loss after my code:  0.18547539934921445\n",
      "train loss after my code:  0.09474929064803049\n",
      "val accuracy:  91.68443496801706\n",
      "test accuracy:  91.98581560283688\n",
      "22\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1756, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4712, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  85.71428571428571\n",
      "selected clients UCB:  [19 14  5  7 10 17  2 16 12 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.2178892548418135\n",
      "train loss after my code:  0.16755205853108468\n",
      "val accuracy:  89.69438521677327\n",
      "test accuracy:  91.34751773049645\n",
      "23\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1842, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3480, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  87.06467661691542\n",
      "selected clients UCB:  [19 14  7  5 10 17 18  2  8 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.13933856256323635\n",
      "train loss after my code:  0.16687462513797996\n",
      "val accuracy:  89.33901918976545\n",
      "test accuracy:  90.56737588652483\n",
      "24\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1055, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3658, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  88.55721393034825\n",
      "selected clients UCB:  [19  7 14  5 10 17 18  2  8  9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "loss after my code:  0.13075517582621665\n",
      "train loss after my code:  0.14825621298638308\n",
      "val accuracy:  90.8315565031983\n",
      "test accuracy:  90.92198581560284\n",
      "25\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1338, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3345, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "81.81818181818183\n",
      "client accuracy :  6\n",
      "90.5982905982906\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "97.16981132075472\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "82.53968253968253\n",
      "client accuracy :  13\n",
      "78.04878048780488\n",
      "client accuracy :  14\n",
      "88.09523809523809\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "62.5\n",
      "client accuracy :  17\n",
      "74.07407407407408\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  89.26794598436389\n",
      "selected clients UCB:  [19  9 17  7 14 10  5 12 16  1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.140725660680888\n",
      "train loss after my code:  0.13625029260230756\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "81.81818181818183\n",
      "client accuracy :  6\n",
      "90.5982905982906\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "84.92063492063492\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "80.0\n",
      "client accuracy :  17\n",
      "77.77777777777779\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  91.4001421464108\n",
      "client accuracy :  0\n",
      "95.16129032258065\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "91.45299145299145\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "96.61016949152543\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "86.56126482213439\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "82.92682926829268\n",
      "client accuracy :  17\n",
      "77.77777777777779\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "test accuracy:  92.05673758865248\n",
      "26\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0645, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2990, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.11584932480456\n",
      "selected clients UCB:  [19 17  9  7 14 10  5  3 13 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.19842682149529595\n",
      "train loss after my code:  0.11489070841246765\n",
      "val accuracy:  92.03980099502488\n",
      "test accuracy:  91.70212765957447\n",
      "27\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1341, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3988, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  89.55223880597015\n",
      "selected clients UCB:  [19 17  7  9 14 10  6  4 15 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "loss after my code:  0.09595689339026092\n",
      "train loss after my code:  0.10083817637120673\n",
      "val accuracy:  92.25302061122956\n",
      "test accuracy:  91.63120567375887\n",
      "28\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1481, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4433, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  89.33901918976545\n",
      "selected clients UCB:  [19 15  7 17  9 14 10  8  2 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "loss after my code:  0.11229814788564124\n",
      "train loss after my code:  0.08815326072861829\n",
      "val accuracy:  91.75550817341862\n",
      "test accuracy:  93.40425531914893\n",
      "29\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0875, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3144, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  90.76048329779674\n",
      "selected clients UCB:  [19  2 15  7 17 14 16 12  5  9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.15792027768418482\n",
      "train loss after my code:  0.12416988288627685\n",
      "val accuracy:  92.96375266524521\n",
      "test accuracy:  92.97872340425532\n",
      "30\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1069, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3558, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "85.18518518518519\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "77.35849056603774\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "90.5982905982906\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "97.16981132075472\n",
      "client accuracy :  10\n",
      "84.06593406593407\n",
      "client accuracy :  11\n",
      "78.57142857142857\n",
      "client accuracy :  12\n",
      "90.07936507936508\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "85.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "86.79245283018868\n",
      "val accuracy before bandits:  90.47619047619048\n",
      "selected clients UCB:  [19  2 15  7 17 10  8 14 18  4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.10955559111630903\n",
      "train loss after my code:  0.09705122769641863\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "90.5982905982906\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "84.06593406593407\n",
      "client accuracy :  11\n",
      "82.85714285714286\n",
      "client accuracy :  12\n",
      "90.07936507936508\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "100.0\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "85.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.03980099502488\n",
      "client accuracy :  0\n",
      "100.0\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "84.61538461538461\n",
      "client accuracy :  11\n",
      "80.0\n",
      "client accuracy :  12\n",
      "86.95652173913044\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "85.36585365853658\n",
      "client accuracy :  17\n",
      "77.77777777777779\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "test accuracy:  91.70212765957447\n",
      "31\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0702, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3179, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.03980099502488\n",
      "selected clients UCB:  [19  2 15  7 17 10  1 13  3 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "loss after my code:  0.15525663433456371\n",
      "train loss after my code:  0.09984553711183859\n",
      "val accuracy:  93.10589907604833\n",
      "test accuracy:  92.05673758865248\n",
      "32\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1229, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4130, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  89.62331201137171\n",
      "selected clients UCB:  [19 11  1  2 15  7  6  5  9 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.12731707756769992\n",
      "train loss after my code:  0.12728849722943192\n",
      "val accuracy:  91.75550817341862\n",
      "test accuracy:  92.2695035460993\n",
      "33\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1445, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4312, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  90.68941009239516\n",
      "selected clients UCB:  [19  1 11  2  5 15  7 16  8 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.15291518169633297\n",
      "train loss after my code:  0.12093885342231374\n",
      "val accuracy:  92.181947405828\n",
      "test accuracy:  91.98581560283688\n",
      "34\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0587, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3432, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.03980099502488\n",
      "selected clients UCB:  [19  1 11  2  5 17 14 18  7 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.15111911773455025\n",
      "train loss after my code:  0.10865203251792856\n",
      "val accuracy:  93.17697228144989\n",
      "test accuracy:  93.61702127659575\n",
      "35\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0942, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3349, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "92.85714285714286\n",
      "client accuracy :  3\n",
      "81.13207547169812\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "84.0909090909091\n",
      "client accuracy :  6\n",
      "90.5982905982906\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "82.96703296703298\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "94.44444444444444\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "90.47619047619048\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "82.5\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.11087420042644\n",
      "selected clients UCB:  [19  2 11  1  5 10  8  9  7 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.15893991241874092\n",
      "train loss after my code:  0.11132578209843284\n",
      "client accuracy :  0\n",
      "100.0\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "86.36363636363636\n",
      "client accuracy :  6\n",
      "90.5982905982906\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "82.96703296703298\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "94.44444444444444\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "100.0\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "85.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  93.24804548685147\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "83.51648351648352\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "91.699604743083\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "85.36585365853658\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  92.62411347517731\n",
      "36\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0771, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4078, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.03980099502488\n",
      "selected clients UCB:  [19  1  2  9 11  5 14 17 13  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "loss after my code:  0.11295513455847425\n",
      "train loss after my code:  0.08104058816030761\n",
      "val accuracy:  93.24804548685147\n",
      "test accuracy:  92.19858156028369\n",
      "37\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1767, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5247, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  90.54726368159204\n",
      "selected clients UCB:  [19  2  1  9 17  5  4  3 15 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.24191818619175834\n",
      "train loss after my code:  0.14062817673037112\n",
      "val accuracy:  92.75053304904051\n",
      "test accuracy:  92.62411347517731\n",
      "38\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0550, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3476, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.89765458422174\n",
      "selected clients UCB:  [19  2  1 17  9 11 16 10  7  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.11153912949588614\n",
      "train loss after my code:  0.07393464768171562\n",
      "val accuracy:  92.32409381663112\n",
      "test accuracy:  92.12765957446808\n",
      "39\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0441, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3629, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.96872778962332\n",
      "selected clients UCB:  [19  2  1 17  9  5 14 18 15 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "loss after my code:  0.13525561789633142\n",
      "train loss after my code:  0.08652514751120476\n",
      "val accuracy:  92.53731343283582\n",
      "test accuracy:  92.2695035460993\n",
      "40\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0492, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3762, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "79.24528301886792\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "84.0909090909091\n",
      "client accuracy :  6\n",
      "91.45299145299145\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "84.06593406593407\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "87.6984126984127\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "82.5\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  91.47121535181236\n",
      "selected clients UCB:  [19  2  1 18 17  9  7 12 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.2516119930691079\n",
      "train loss after my code:  0.141545330434314\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "86.36363636363636\n",
      "client accuracy :  6\n",
      "91.45299145299145\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "84.06593406593407\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "87.6984126984127\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "100.0\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "85.0\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.181947405828\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "100.0\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "95.45454545454545\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "84.61538461538461\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "90.11857707509881\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "85.36585365853658\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  92.97872340425532\n",
      "41\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0987, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4681, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.181947405828\n",
      "selected clients UCB:  [19  2 18  1 17 14 15  5  8  9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "loss after my code:  0.18023849100713343\n",
      "train loss after my code:  0.10075635695638313\n",
      "val accuracy:  92.96375266524521\n",
      "test accuracy:  92.8368794326241\n",
      "42\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0594, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4510, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.46624022743426\n",
      "selected clients UCB:  [19  2  9 15 18  1 17 10  3 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "loss after my code:  0.016262393774103448\n",
      "train loss after my code:  0.05903791903005073\n",
      "val accuracy:  93.31911869225303\n",
      "test accuracy:  93.19148936170212\n",
      "43\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1090, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5034, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.03980099502488\n",
      "selected clients UCB:  [19  2 13 15 17  9 18  6  4  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "loss after my code:  0.08919121354039732\n",
      "train loss after my code:  0.09862578303454661\n",
      "val accuracy:  93.10589907604833\n",
      "test accuracy:  92.8368794326241\n",
      "44\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0467, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3793, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.82658137882018\n",
      "selected clients UCB:  [19  2 15 13 18  7 17  9  1 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.08326797889467101\n",
      "train loss after my code:  0.08051628185168853\n",
      "val accuracy:  92.53731343283582\n",
      "test accuracy:  92.48226950354609\n",
      "45\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0518, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3728, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "92.85714285714286\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "93.18181818181817\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.71428571428571\n",
      "client accuracy :  11\n",
      "87.14285714285714\n",
      "client accuracy :  12\n",
      "92.06349206349206\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "87.5\n",
      "client accuracy :  17\n",
      "77.77777777777779\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "selected clients UCB:  [19  2 15 13 18  7 17  9 14  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "loss after my code:  0.0917375119295485\n",
      "train loss after my code:  0.1358207743100084\n",
      "client accuracy :  0\n",
      "100.0\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "93.18181818181817\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.71428571428571\n",
      "client accuracy :  11\n",
      "87.14285714285714\n",
      "client accuracy :  12\n",
      "92.06349206349206\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "100.0\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "87.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  93.24804548685147\n",
      "client accuracy :  0\n",
      "96.7741935483871\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "94.33962264150944\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "84.61538461538461\n",
      "client accuracy :  11\n",
      "88.57142857142857\n",
      "client accuracy :  12\n",
      "90.51383399209486\n",
      "client accuracy :  13\n",
      "95.1219512195122\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "85.36585365853658\n",
      "client accuracy :  17\n",
      "74.07407407407408\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "test accuracy:  92.62411347517731\n",
      "46\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0840, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4228, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.60838663823738\n",
      "selected clients UCB:  [19  2 15 13 18  7 17  9  5 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "loss after my code:  0.08566738170494975\n",
      "train loss after my code:  0.12224233515348894\n",
      "val accuracy:  93.31911869225303\n",
      "test accuracy:  92.8368794326241\n",
      "47\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0458, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3570, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "selected clients UCB:  [19 15  2 18 13  7 17 16 12  1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.16624160168495933\n",
      "train loss after my code:  0.0967295713872128\n",
      "val accuracy:  93.46126510305615\n",
      "test accuracy:  93.12056737588652\n",
      "48\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1020, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4491, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.32409381663112\n",
      "selected clients UCB:  [19  2 15 18  7 13 10 17  9 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.]\n",
      "loss after my code:  0.2163623446201184\n",
      "train loss after my code:  0.1387631605198295\n",
      "val accuracy:  93.03482587064677\n",
      "test accuracy:  93.04964539007092\n",
      "49\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0870, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4623, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.60838663823738\n",
      "selected clients UCB:  [19 15  2 17 18  7  3  6  4  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.09155527235904541\n",
      "train loss after my code:  0.09171354420440563\n",
      "val accuracy:  93.17697228144989\n",
      "test accuracy:  93.19148936170212\n",
      "50\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0737, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4589, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "88.88888888888889\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "81.13207547169812\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "84.0909090909091\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "92.85714285714286\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "88.57142857142857\n",
      "client accuracy :  16\n",
      "80.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.32409381663112\n",
      "selected clients UCB:  [19 15  2 17 18  5  7 10 16 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.14293222688385662\n",
      "train loss after my code:  0.10614221019948408\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "84.0909090909091\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "92.85714285714286\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "80.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.75053304904051\n",
      "client accuracy :  0\n",
      "100.0\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "100.0\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "95.45454545454545\n",
      "client accuracy :  6\n",
      "91.45299145299145\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "91.30434782608695\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "90.2439024390244\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  93.61702127659575\n",
      "51\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0520, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3848, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.17697228144989\n",
      "selected clients UCB:  [19 15  2 17 18 12 11  9 14  1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.18171210862771242\n",
      "train loss after my code:  0.08996153135940717\n",
      "val accuracy:  93.60341151385929\n",
      "test accuracy:  93.04964539007092\n",
      "52\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0914, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4672, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "selected clients UCB:  [19 15  2 17  7 10 18  5  8  9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.09149495066746029\n",
      "train loss after my code:  0.11703567317929502\n",
      "val accuracy:  93.03482587064677\n",
      "test accuracy:  92.41134751773049\n",
      "53\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0713, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4495, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.60838663823738\n",
      "selected clients UCB:  [19 15  2 17  7 14  6  4  3 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.12039844157582055\n",
      "train loss after my code:  0.14182340127841198\n",
      "val accuracy:  93.17697228144989\n",
      "test accuracy:  92.90780141843972\n",
      "54\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0834, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4310, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "selected clients UCB:  [19 15  2 17 10  1 16 13 12 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.12138002506688217\n",
      "train loss after my code:  0.12192873487438186\n",
      "val accuracy:  93.39019189765459\n",
      "test accuracy:  93.04964539007092\n",
      "55\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0809, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4093, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "81.13207547169812\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "93.18181818181817\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "92.06349206349206\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "88.57142857142857\n",
      "client accuracy :  16\n",
      "82.5\n",
      "client accuracy :  17\n",
      "77.77777777777779\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "val accuracy before bandits:  92.46624022743426\n",
      "selected clients UCB:  [19 15  2 17  8  5  7  9 14 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.19125506378670845\n",
      "train loss after my code:  0.1305257785654784\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "93.18181818181817\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "92.06349206349206\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "88.57142857142857\n",
      "client accuracy :  16\n",
      "82.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.96375266524521\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "91.30434782608695\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "78.04878048780488\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  92.97872340425532\n",
      "56\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0817, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4524, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.10589907604833\n",
      "selected clients UCB:  [19 15  2 17 18  7  1  5  8 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.09637734602951861\n",
      "train loss after my code:  0.10931900546831498\n",
      "val accuracy:  93.53233830845771\n",
      "test accuracy:  92.8368794326241\n",
      "57\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0741, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4234, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "selected clients UCB:  [19 15  2 17 18  3  4  6  9 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.09606406522639879\n",
      "train loss after my code:  0.10543972222604306\n",
      "val accuracy:  93.10589907604833\n",
      "test accuracy:  93.19148936170212\n",
      "58\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0703, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3953, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.17697228144989\n",
      "selected clients UCB:  [19 15  2 16 13 12 11  7 17 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.13217582947742157\n",
      "train loss after my code:  0.094028930173624\n",
      "val accuracy:  93.46126510305615\n",
      "test accuracy:  93.47517730496455\n",
      "59\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0724, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4361, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.03482587064677\n",
      "selected clients UCB:  [19 15  2 18  7  5  8  1  9 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.03638402309995164\n",
      "train loss after my code:  0.10265061058318824\n",
      "val accuracy:  93.39019189765459\n",
      "test accuracy:  93.26241134751773\n",
      "60\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0890, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4295, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "81.13207547169812\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "93.18181818181817\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "93.65079365079364\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "87.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  93.24804548685147\n",
      "selected clients UCB:  [19 15  2 17  7 16 13 12 11 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.07100148958733661\n",
      "train loss after my code:  0.08942849224781443\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "93.18181818181817\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "93.65079365079364\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "100.0\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "87.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  93.53233830845771\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "90.5982905982906\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.51383399209486\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "95.1219512195122\n",
      "client accuracy :  17\n",
      "92.5925925925926\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "test accuracy:  93.47517730496455\n",
      "61\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0863, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4562, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.89267945984363\n",
      "selected clients UCB:  [19 15  2 18  3  4  6 17  5  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.18606294228773498\n",
      "train loss after my code:  0.09907685011891339\n",
      "val accuracy:  93.31911869225303\n",
      "test accuracy:  93.40425531914893\n",
      "62\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0974, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4676, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.89267945984363\n",
      "selected clients UCB:  [19 15  2 14  9  1  7 10 18 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.023002517707666717\n",
      "train loss after my code:  0.11595070180700938\n",
      "val accuracy:  93.24804548685147\n",
      "test accuracy:  93.61702127659575\n",
      "63\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0892, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4428, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.89267945984363\n",
      "selected clients UCB:  [19 15  2  7 14  9 13 12 11 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.11801836137712471\n",
      "train loss after my code:  0.1181987268859866\n",
      "val accuracy:  93.24804548685147\n",
      "test accuracy:  93.97163120567376\n",
      "64\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1013, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4444, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.10589907604833\n",
      "selected clients UCB:  [19 15  2  5  8 10 18 17  1  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.1270127998208771\n",
      "train loss after my code:  0.1384151811953245\n",
      "val accuracy:  93.39019189765459\n",
      "test accuracy:  93.90070921985816\n",
      "65\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0969, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4552, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "94.04761904761905\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  93.24804548685147\n",
      "selected clients UCB:  [19 15  2  6  3  4  9 14 10 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.09160388600134496\n",
      "train loss after my code:  0.13815480842931677\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "94.04761904761905\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  93.60341151385929\n",
      "client accuracy :  0\n",
      "100.0\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "100.0\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "85.71428571428571\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "92.09486166007905\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "92.6829268292683\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "test accuracy:  93.82978723404256\n",
      "66\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1276, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4936, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.24804548685147\n",
      "selected clients UCB:  [19 15  2  5  8 17  7 16 13 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.019744470135138366\n",
      "train loss after my code:  0.13109012442315443\n",
      "val accuracy:  93.53233830845771\n",
      "test accuracy:  93.82978723404256\n",
      "67\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1016, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4330, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.31911869225303\n",
      "selected clients UCB:  [19 15  2 11  1 18 10 17  9 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.16524304971198567\n",
      "train loss after my code:  0.29699269709384435\n",
      "val accuracy:  93.67448471926085\n",
      "test accuracy:  93.19148936170212\n",
      "68\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1848, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4348, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.46126510305615\n",
      "selected clients UCB:  [19 15  2  7  5  8  3  4  6 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.23218736764979364\n",
      "train loss after my code:  0.1808104114088121\n",
      "val accuracy:  93.81663113006397\n",
      "test accuracy:  93.47517730496455\n",
      "69\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1439, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4821, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.46126510305615\n",
      "selected clients UCB:  [19 15  2 18 17  7  9 14 12 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.11293330636899203\n",
      "train loss after my code:  0.15709947420923834\n",
      "val accuracy:  93.60341151385929\n",
      "test accuracy:  93.47517730496455\n",
      "70\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1547, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4536, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "81.13207547169812\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "93.25396825396825\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  93.31911869225303\n",
      "selected clients UCB:  [19 15  2 16 13  1  5  8 17  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.09326081437806365\n",
      "train loss after my code:  0.16977101229105296\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "93.25396825396825\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "100.0\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  93.53233830845771\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "100.0\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "91.699604743083\n",
      "client accuracy :  13\n",
      "82.92682926829268\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "95.1219512195122\n",
      "client accuracy :  17\n",
      "92.5925925925926\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "test accuracy:  93.33333333333333\n",
      "71\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1276, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4473, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.60341151385929\n",
      "selected clients UCB:  [19 15  2 10 18  9 14  7  6  4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.22187624910698206\n",
      "train loss after my code:  0.19503701914548868\n",
      "val accuracy:  93.7455579246624\n",
      "test accuracy:  93.54609929078013\n",
      "72\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1620, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5114, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.46126510305615\n",
      "selected clients UCB:  [19 15  2  3  1 17 10 18 16 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.09882861155976479\n",
      "train loss after my code:  0.1604352504903932\n",
      "val accuracy:  93.67448471926085\n",
      "test accuracy:  93.26241134751773\n",
      "73\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1195, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4759, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.10589907604833\n",
      "selected clients UCB:  [19 15  2 12 11  5  8  9 14  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.12400805327447807\n",
      "train loss after my code:  0.1303379910162851\n",
      "val accuracy:  93.24804548685147\n",
      "test accuracy:  93.40425531914893\n",
      "74\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1120, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4770, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.53233830845771\n",
      "selected clients UCB:  [19 15  2 17 10 18  1  5  8  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.010965986498663698\n",
      "train loss after my code:  0.13558083172252638\n",
      "val accuracy:  93.7455579246624\n",
      "test accuracy:  93.75886524822695\n",
      "75\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1018, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4866, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "81.13207547169812\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "93.65079365079364\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "val accuracy before bandits:  93.24804548685147\n",
      "selected clients UCB:  [19 15  2 17 11 16 13 12  9 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.08932073788280415\n",
      "train loss after my code:  0.11107157925833555\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "93.65079365079364\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "val accuracy:  93.31911869225303\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "85.71428571428571\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "91.30434782608695\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "95.1219512195122\n",
      "client accuracy :  17\n",
      "92.5925925925926\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "test accuracy:  93.47517730496455\n",
      "76\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1043, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4789, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.03482587064677\n",
      "selected clients UCB:  [19 15  2  6  3  4 10 18  7 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.09755046085278558\n",
      "train loss after my code:  0.10533920660758019\n",
      "val accuracy:  93.10589907604833\n",
      "test accuracy:  93.61702127659575\n",
      "77\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1165, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4880, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.31911869225303\n",
      "selected clients UCB:  [19 15  2  5  8  1 10 18  9 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.15300031054544347\n",
      "train loss after my code:  0.12982553111788853\n",
      "val accuracy:  93.60341151385929\n",
      "test accuracy:  93.61702127659575\n",
      "78\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1488, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4881, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.89267945984363\n",
      "selected clients UCB:  [19 15  2  7 16 13 12 11 17 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.04215612545697179\n",
      "train loss after my code:  0.16103538521620897\n",
      "val accuracy:  93.03482587064677\n",
      "test accuracy:  93.47517730496455\n",
      "79\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1606, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4841, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.96375266524521\n",
      "selected clients UCB:  [19 15  2  3  4  6 18  5  8  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.15218246922047743\n",
      "train loss after my code:  0.17356763610141707\n",
      "val accuracy:  93.17697228144989\n",
      "test accuracy:  93.40425531914893\n",
      "80\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1501, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5225, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "81.13207547169812\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "93.25396825396825\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  93.03482587064677\n",
      "selected clients UCB:  [19 15  2 14  9  1 17 10 18  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.03691419639294977\n",
      "train loss after my code:  0.15480055863867156\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "81.13207547169812\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "93.25396825396825\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  93.24804548685147\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "90.5982905982906\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "85.71428571428571\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "90.9090909090909\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "95.1219512195122\n",
      "client accuracy :  17\n",
      "92.5925925925926\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  93.26241134751773\n",
      "81\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1470, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5020, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "selected clients UCB:  [19 15  2 16 13 12 11  8  5 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.23533813571433515\n",
      "train loss after my code:  0.24462977219384485\n",
      "val accuracy:  93.24804548685147\n",
      "test accuracy:  92.90780141843972\n",
      "82\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1790, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5238, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.03482587064677\n",
      "selected clients UCB:  [19 15  2 14  9  1  7 10 18  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.10671349145615046\n",
      "train loss after my code:  0.1798650383238058\n",
      "val accuracy:  93.17697228144989\n",
      "test accuracy:  92.90780141843972\n",
      "83\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1688, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5226, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.96375266524521\n",
      "selected clients UCB:  [19 15  2  4  3 17  9 14  8  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.10161083197274484\n",
      "train loss after my code:  0.18238699954693813\n",
      "val accuracy:  93.10589907604833\n",
      "test accuracy:  93.12056737588652\n",
      "84\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1520, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5078, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.89267945984363\n",
      "selected clients UCB:  [19 15  2  7 16 13 12 11 10 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "loss after my code:  0.10056646229336902\n",
      "train loss after my code:  0.18345458846887033\n",
      "val accuracy:  93.10589907604833\n",
      "test accuracy:  93.04964539007092\n",
      "85\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1468, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4906, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "79.24528301886792\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "84.61538461538461\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "92.85714285714286\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "selected clients UCB:  [19 15 18  2  1 17  7  9 14 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.11042249957202949\n",
      "train loss after my code:  0.17213713197313799\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "81.13207547169812\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "84.61538461538461\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "92.85714285714286\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "100.0\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.96375266524521\n",
      "client accuracy :  0\n",
      "100.0\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "90.5982905982906\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "85.71428571428571\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "91.30434782608695\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "95.1219512195122\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "test accuracy:  93.47517730496455\n",
      "86\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1572, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5046, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "selected clients UCB:  [19 15 18  2  4  6  3  8  5 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.1593918846338293\n",
      "train loss after my code:  0.16770845428128522\n",
      "val accuracy:  92.96375266524521\n",
      "test accuracy:  93.47517730496455\n",
      "87\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1575, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5138, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.89267945984363\n",
      "selected clients UCB:  [19 15 18  2  7 16 13 12 11  1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.0015231744896767045\n",
      "train loss after my code:  0.16443535781766874\n",
      "val accuracy:  92.96375266524521\n",
      "test accuracy:  93.40425531914893\n",
      "88\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1652, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5085, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.89267945984363\n",
      "selected clients UCB:  [19 15  2 18 10  9 14 17  8  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.0\n",
      "train loss after my code:  0.16523664755711864\n",
      "val accuracy:  92.89267945984363\n",
      "test accuracy:  93.47517730496455\n",
      "89\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1351, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5088, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.89267945984363\n",
      "selected clients UCB:  [19 15  2 18  7  3  4  6 10 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.043149531851657597\n",
      "train loss after my code:  0.13644618268466138\n",
      "val accuracy:  92.96375266524521\n",
      "test accuracy:  93.47517730496455\n",
      "90\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1302, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5100, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "81.13207547169812\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "92.85714285714286\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.96375266524521\n",
      "selected clients UCB:  [19 15  2 18  1  9 14 13 12 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.0\n",
      "train loss after my code:  0.13020417981427723\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "81.13207547169812\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "92.85714285714286\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.96375266524521\n",
      "client accuracy :  0\n",
      "100.0\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "90.5982905982906\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "91.699604743083\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "95.1219512195122\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  93.61702127659575\n",
      "91\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1382, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5102, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.89267945984363\n",
      "selected clients UCB:  [19 15  2 18 16  7  5  8 10 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.11677448478302388\n",
      "train loss after my code:  0.18194462034571748\n",
      "val accuracy:  92.96375266524521\n",
      "test accuracy:  93.40425531914893\n",
      "92\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1386, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5205, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "selected clients UCB:  [19 15  2 18  7  9 14  1  6  4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.0978623846273645\n",
      "train loss after my code:  0.13041425934007217\n",
      "val accuracy:  92.89267945984363\n",
      "test accuracy:  93.33333333333333\n",
      "93\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1350, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5073, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.96375266524521\n",
      "selected clients UCB:  [19 15  2 18  3 16 13 12 11  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.0\n",
      "train loss after my code:  0.13497467162157462\n",
      "val accuracy:  92.96375266524521\n",
      "test accuracy:  93.47517730496455\n",
      "94\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1425, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5112, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "selected clients UCB:  [19 15  2 18  8 17 10  7  9 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.10577258553092633\n",
      "train loss after my code:  0.13417828020281614\n",
      "val accuracy:  92.89267945984363\n",
      "test accuracy:  93.40425531914893\n",
      "95\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1190, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5153, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "81.13207547169812\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "91.45299145299145\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "84.61538461538461\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "92.85714285714286\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "selected clients UCB:  [19 15  2 18 17  7 10  1  5  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.09291777305427998\n",
      "train loss after my code:  0.11250582936359371\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "91.45299145299145\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "84.61538461538461\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "92.85714285714286\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.82160625444207\n",
      "client accuracy :  0\n",
      "100.0\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "90.5982905982906\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "85.71428571428571\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.9090909090909\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "95.1219512195122\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  93.47517730496455\n",
      "96\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1150, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5085, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.89267945984363\n",
      "selected clients UCB:  [19 15  2 18 11 16 13 12  9 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.03411197711325568\n",
      "train loss after my code:  0.12623729005906603\n",
      "val accuracy:  92.96375266524521\n",
      "test accuracy:  93.47517730496455\n",
      "97\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1244, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5123, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "selected clients UCB:  [19 15  2  6  3  4  7 17 18 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.03920586099700245\n",
      "train loss after my code:  0.13414847689640097\n",
      "val accuracy:  92.96375266524521\n",
      "test accuracy:  93.40425531914893\n",
      "98\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1187, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5073, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.89267945984363\n",
      "selected clients UCB:  [19 15  2  1  5  8  7 18 17  9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.004347109894128797\n",
      "train loss after my code:  0.11983810990751911\n",
      "val accuracy:  92.96375266524521\n",
      "test accuracy:  93.40425531914893\n",
      "99\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1137, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5077, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.89267945984363\n",
      "selected clients UCB:  [19 15  2 14 10 16 13 12 11  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.036544893926354745\n",
      "train loss after my code:  0.11802103032379936\n",
      "val accuracy:  92.96375266524521\n",
      "test accuracy:  93.61702127659575\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "settings, save_dir = init()\n",
    "import collections\n",
    "from time import time\n",
    "import random\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pandas\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "experiment_name = settings['experiment_name']\n",
    "test ='bandits'\n",
    "n_epochs = 100 #settings['n_epochs']\n",
    "patients_removed = [6, 14, 16]\n",
    "patients_left = [x for x in range(1,24) if x not in patients_removed]\n",
    "print(patients_left)\n",
    "p2p = P2P_AFPL(patients_left,10, test)\n",
    "accuracies_local3 = p2p.loop(n_epochs, p2p, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a630dc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23]\n",
      "0\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.6906, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.7919, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "79.03225806451613\n",
      "client accuracy :  1\n",
      "77.77777777777779\n",
      "client accuracy :  2\n",
      "80.35714285714286\n",
      "client accuracy :  3\n",
      "60.37735849056604\n",
      "client accuracy :  4\n",
      "90.9090909090909\n",
      "client accuracy :  5\n",
      "79.54545454545455\n",
      "client accuracy :  6\n",
      "68.37606837606837\n",
      "client accuracy :  7\n",
      "89.1891891891892\n",
      "client accuracy :  8\n",
      "71.1864406779661\n",
      "client accuracy :  9\n",
      "97.16981132075472\n",
      "client accuracy :  10\n",
      "58.791208791208796\n",
      "client accuracy :  11\n",
      "75.71428571428571\n",
      "client accuracy :  12\n",
      "66.26984126984127\n",
      "client accuracy :  13\n",
      "78.04878048780488\n",
      "client accuracy :  14\n",
      "83.33333333333334\n",
      "client accuracy :  15\n",
      "88.57142857142857\n",
      "client accuracy :  16\n",
      "85.0\n",
      "client accuracy :  17\n",
      "55.55555555555556\n",
      "client accuracy :  18\n",
      "33.33333333333333\n",
      "client accuracy :  19\n",
      "88.67924528301887\n",
      "val accuracy before bandits:  73.91613361762616\n",
      "selected clients UCB:  [19 18  1  2  3]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "loss after my code:  0.3387539979898869\n",
      "train loss after my code:  0.4227191480560735\n",
      "client accuracy :  0\n",
      "95.16129032258065\n",
      "client accuracy :  1\n",
      "81.48148148148148\n",
      "client accuracy :  2\n",
      "91.07142857142857\n",
      "client accuracy :  3\n",
      "67.9245283018868\n",
      "client accuracy :  4\n",
      "90.9090909090909\n",
      "client accuracy :  5\n",
      "81.81818181818183\n",
      "client accuracy :  6\n",
      "72.64957264957265\n",
      "client accuracy :  7\n",
      "91.8918918918919\n",
      "client accuracy :  8\n",
      "93.22033898305084\n",
      "client accuracy :  9\n",
      "97.16981132075472\n",
      "client accuracy :  10\n",
      "58.791208791208796\n",
      "client accuracy :  11\n",
      "75.71428571428571\n",
      "client accuracy :  12\n",
      "68.25396825396825\n",
      "client accuracy :  13\n",
      "82.92682926829268\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "88.57142857142857\n",
      "client accuracy :  16\n",
      "87.5\n",
      "client accuracy :  17\n",
      "70.37037037037037\n",
      "client accuracy :  18\n",
      "48.148148148148145\n",
      "client accuracy :  19\n",
      "90.56603773584906\n",
      "val accuracy:  78.39374555792466\n",
      "client accuracy :  0\n",
      "91.93548387096774\n",
      "client accuracy :  1\n",
      "85.18518518518519\n",
      "client accuracy :  2\n",
      "91.07142857142857\n",
      "client accuracy :  3\n",
      "67.9245283018868\n",
      "client accuracy :  4\n",
      "88.31168831168831\n",
      "client accuracy :  5\n",
      "95.45454545454545\n",
      "client accuracy :  6\n",
      "72.64957264957265\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "91.52542372881356\n",
      "client accuracy :  9\n",
      "91.58878504672897\n",
      "client accuracy :  10\n",
      "54.94505494505495\n",
      "client accuracy :  11\n",
      "62.857142857142854\n",
      "client accuracy :  12\n",
      "70.35573122529645\n",
      "client accuracy :  13\n",
      "80.48780487804879\n",
      "client accuracy :  14\n",
      "88.09523809523809\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "78.04878048780488\n",
      "client accuracy :  17\n",
      "62.96296296296296\n",
      "client accuracy :  18\n",
      "88.88888888888889\n",
      "client accuracy :  19\n",
      "86.79245283018868\n",
      "test accuracy:  77.4468085106383\n",
      "1\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.8493, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.1458, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  72.70788912579957\n",
      "selected clients UCB:  [ 9  4 17 16 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "loss after my code:  0.22733208211471165\n",
      "train loss after my code:  0.49692704675726884\n",
      "val accuracy:  80.31272210376687\n",
      "test accuracy:  79.57446808510639\n",
      "2\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.8304, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.0068, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  75.55081734186211\n",
      "selected clients UCB:  [ 8  5  6 14 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.1950738593265896\n",
      "train loss after my code:  0.27690223685500026\n",
      "val accuracy:  82.87135749822318\n",
      "test accuracy:  82.12765957446808\n",
      "3\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.6631, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.9132, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  81.2366737739872\n",
      "selected clients UCB:  [10  7 12 11 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.24133503691183714\n",
      "train loss after my code:  0.2587206642477187\n",
      "val accuracy:  87.13574982231698\n",
      "test accuracy:  86.52482269503547\n",
      "4\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.4239, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.7716, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  83.15565031982942\n",
      "selected clients UCB:  [ 9 11  2  6 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "loss after my code:  0.23285811194232928\n",
      "train loss after my code:  0.22997207702046235\n",
      "val accuracy:  88.69936034115139\n",
      "test accuracy:  88.01418439716312\n",
      "5\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.3828, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.7094, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "80.64516129032258\n",
      "client accuracy :  1\n",
      "81.48148148148148\n",
      "client accuracy :  2\n",
      "92.85714285714286\n",
      "client accuracy :  3\n",
      "73.58490566037736\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "84.0909090909091\n",
      "client accuracy :  6\n",
      "85.47008547008546\n",
      "client accuracy :  7\n",
      "89.1891891891892\n",
      "client accuracy :  8\n",
      "89.83050847457628\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "83.51648351648352\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "71.42857142857143\n",
      "client accuracy :  13\n",
      "85.36585365853658\n",
      "client accuracy :  14\n",
      "78.57142857142857\n",
      "client accuracy :  15\n",
      "77.14285714285715\n",
      "client accuracy :  16\n",
      "60.0\n",
      "client accuracy :  17\n",
      "74.07407407407408\n",
      "client accuracy :  18\n",
      "62.96296296296296\n",
      "client accuracy :  19\n",
      "94.33962264150944\n",
      "val accuracy before bandits:  82.94243070362474\n",
      "selected clients UCB:  [ 7  8 18 11 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "loss after my code:  0.19522567885392708\n",
      "train loss after my code:  0.3466853030320434\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "92.85714285714286\n",
      "client accuracy :  3\n",
      "77.35849056603774\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "85.47008547008546\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "96.61016949152543\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "85.71428571428571\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "88.57142857142857\n",
      "client accuracy :  16\n",
      "60.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "96.29629629629629\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  89.76545842217483\n",
      "client accuracy :  0\n",
      "93.54838709677419\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "81.13207547169812\n",
      "client accuracy :  4\n",
      "96.1038961038961\n",
      "client accuracy :  5\n",
      "95.45454545454545\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "91.52542372881356\n",
      "client accuracy :  9\n",
      "94.39252336448598\n",
      "client accuracy :  10\n",
      "82.41758241758241\n",
      "client accuracy :  11\n",
      "87.14285714285714\n",
      "client accuracy :  12\n",
      "88.53754940711462\n",
      "client accuracy :  13\n",
      "73.17073170731707\n",
      "client accuracy :  14\n",
      "90.47619047619048\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "65.85365853658537\n",
      "client accuracy :  17\n",
      "77.77777777777779\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  89.29078014184397\n",
      "6\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.4333, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.6545, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  84.86140724946695\n",
      "selected clients UCB:  [ 7 18 11 15 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.2240538984299596\n",
      "train loss after my code:  0.23229845191906787\n",
      "val accuracy:  89.76545842217483\n",
      "test accuracy:  87.2340425531915\n",
      "7\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1981, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3390, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  87.63326226012794\n",
      "selected clients UCB:  [ 7 11 15 18  9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "loss after my code:  0.0809905005388997\n",
      "train loss after my code:  0.15329497287339267\n",
      "val accuracy:  90.90262970859986\n",
      "test accuracy:  89.21985815602837\n",
      "8\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.2743, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5033, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  85.85643212508884\n",
      "selected clients UCB:  [ 7 11 15  2  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.21407993673961137\n",
      "train loss after my code:  0.19445126007621935\n",
      "val accuracy:  88.62828713574982\n",
      "test accuracy:  87.58865248226951\n",
      "9\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.4659, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.6685, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  87.20682302771856\n",
      "selected clients UCB:  [ 7  8 11 15 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "loss after my code:  0.20685434373734832\n",
      "train loss after my code:  0.14960345578697634\n",
      "val accuracy:  91.68443496801706\n",
      "test accuracy:  90.70921985815603\n",
      "10\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.3137, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5378, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "95.16129032258065\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "85.71428571428571\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "84.0909090909091\n",
      "client accuracy :  6\n",
      "87.17948717948718\n",
      "client accuracy :  7\n",
      "91.8918918918919\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "64.83516483516483\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "80.55555555555556\n",
      "client accuracy :  13\n",
      "53.65853658536586\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "87.5\n",
      "client accuracy :  17\n",
      "70.37037037037037\n",
      "client accuracy :  18\n",
      "92.5925925925926\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  85.28784648187633\n",
      "selected clients UCB:  [ 7  8 15 11 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.221664353215042\n",
      "train loss after my code:  0.21049341630701265\n",
      "client accuracy :  0\n",
      "96.7741935483871\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "87.17948717948718\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "82.41758241758241\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "87.6984126984127\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "100.0\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "87.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  91.25799573560768\n",
      "client accuracy :  0\n",
      "93.54838709677419\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "96.1038961038961\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "91.45299145299145\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "96.61016949152543\n",
      "client accuracy :  9\n",
      "95.32710280373831\n",
      "client accuracy :  10\n",
      "86.81318681318682\n",
      "client accuracy :  11\n",
      "87.14285714285714\n",
      "client accuracy :  12\n",
      "88.14229249011858\n",
      "client accuracy :  13\n",
      "80.48780487804879\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "78.04878048780488\n",
      "client accuracy :  17\n",
      "77.77777777777779\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "94.33962264150944\n",
      "test accuracy:  91.27659574468086\n",
      "11\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.2745, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4493, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  86.42501776830134\n",
      "selected clients UCB:  [ 7 15  8  9  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.15714353734429512\n",
      "train loss after my code:  0.1126941879906121\n",
      "val accuracy:  88.55721393034825\n",
      "test accuracy:  87.44680851063829\n",
      "12\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.5266, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.7536, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  85.28784648187633\n",
      "selected clients UCB:  [ 7 15  2  3  1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "loss after my code:  0.12766063745373069\n",
      "train loss after my code:  0.13012225487835874\n",
      "val accuracy:  90.19189765458422\n",
      "test accuracy:  89.00709219858156\n",
      "13\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1390, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4001, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  88.41506751954513\n",
      "selected clients UCB:  [ 7  3 15 17 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "loss after my code:  0.11456787820493448\n",
      "train loss after my code:  0.12212790795850142\n",
      "val accuracy:  91.54228855721394\n",
      "test accuracy:  91.27659574468086\n",
      "14\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.3241, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4685, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  89.62331201137171\n",
      "selected clients UCB:  [ 7  3 17  4 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.2163598996569191\n",
      "train loss after my code:  0.17068954142716355\n",
      "val accuracy:  92.03980099502488\n",
      "test accuracy:  91.91489361702128\n",
      "15\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.2959, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.7488, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "81.48148148148148\n",
      "client accuracy :  2\n",
      "82.14285714285714\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "90.9090909090909\n",
      "client accuracy :  5\n",
      "77.27272727272727\n",
      "client accuracy :  6\n",
      "87.17948717948718\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "84.06593406593407\n",
      "client accuracy :  11\n",
      "87.14285714285714\n",
      "client accuracy :  12\n",
      "86.11111111111111\n",
      "client accuracy :  13\n",
      "82.92682926829268\n",
      "client accuracy :  14\n",
      "85.71428571428571\n",
      "client accuracy :  15\n",
      "71.42857142857143\n",
      "client accuracy :  16\n",
      "77.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "48.148148148148145\n",
      "client accuracy :  19\n",
      "86.79245283018868\n",
      "val accuracy before bandits:  86.56716417910447\n",
      "selected clients UCB:  [ 7 14  3  5 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.24886263823657748\n",
      "train loss after my code:  0.18402927399051622\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "93.5064935064935\n",
      "client accuracy :  5\n",
      "81.81818181818183\n",
      "client accuracy :  6\n",
      "87.17948717948718\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "84.06593406593407\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "88.88888888888889\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "88.57142857142857\n",
      "client accuracy :  16\n",
      "80.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "88.88888888888889\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "val accuracy:  90.68941009239516\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "85.18518518518519\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "79.24528301886792\n",
      "client accuracy :  4\n",
      "92.20779220779221\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "94.91525423728814\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "86.81318681318682\n",
      "client accuracy :  11\n",
      "85.71428571428571\n",
      "client accuracy :  12\n",
      "90.11857707509881\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "75.60975609756098\n",
      "client accuracy :  17\n",
      "92.5925925925926\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "92.45283018867924\n",
      "test accuracy:  91.27659574468086\n",
      "16\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1542, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3604, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  88.98365316275763\n",
      "selected clients UCB:  [ 7 12 10 17 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.11216005276149366\n",
      "train loss after my code:  0.10043897953779207\n",
      "val accuracy:  90.97370291400142\n",
      "test accuracy:  91.77304964539007\n",
      "17\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1694, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4668, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  87.13574982231698\n",
      "selected clients UCB:  [ 7 15 11 18  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.18351033637387693\n",
      "train loss after my code:  0.11709620283417523\n",
      "val accuracy:  91.75550817341862\n",
      "test accuracy:  90.42553191489363\n",
      "18\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1884, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4044, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  87.7043354655295\n",
      "selected clients UCB:  [ 7 11  8 15 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "loss after my code:  0.13012331817097428\n",
      "train loss after my code:  0.09943044136126532\n",
      "val accuracy:  91.18692253020612\n",
      "test accuracy:  90.2127659574468\n",
      "19\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1662, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4696, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  89.19687277896233\n",
      "selected clients UCB:  [ 7 11 18 15  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.18841873059281272\n",
      "train loss after my code:  0.14403248137356175\n",
      "val accuracy:  90.76048329779674\n",
      "test accuracy:  88.86524822695036\n",
      "20\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1116, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3526, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "92.85714285714286\n",
      "client accuracy :  3\n",
      "60.37735849056604\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "84.0909090909091\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "82.41758241758241\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "89.28571428571429\n",
      "client accuracy :  13\n",
      "85.36585365853658\n",
      "client accuracy :  14\n",
      "100.0\n",
      "client accuracy :  15\n",
      "88.57142857142857\n",
      "client accuracy :  16\n",
      "82.5\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  90.6183368869936\n",
      "selected clients UCB:  [ 7 11  8 19  2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.17120490626185084\n",
      "train loss after my code:  0.07559973490733457\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "86.36363636363636\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "82.41758241758241\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "91.26984126984127\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "100.0\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "85.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.60838663823738\n",
      "client accuracy :  0\n",
      "96.7741935483871\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "96.1038961038961\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "94.87179487179486\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "96.61016949152543\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "82.96703296703298\n",
      "client accuracy :  11\n",
      "88.57142857142857\n",
      "client accuracy :  12\n",
      "90.51383399209486\n",
      "client accuracy :  13\n",
      "82.92682926829268\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "78.04878048780488\n",
      "client accuracy :  17\n",
      "74.07407407407408\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "94.33962264150944\n",
      "test accuracy:  91.70212765957447\n",
      "21\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1258, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4049, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  89.26794598436389\n",
      "selected clients UCB:  [ 7 11 14  6  9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.1213004190149249\n",
      "train loss after my code:  0.09671793009103516\n",
      "val accuracy:  91.54228855721394\n",
      "test accuracy:  91.13475177304964\n",
      "22\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1874, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5462, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  88.84150675195451\n",
      "selected clients UCB:  [ 7 11 17 18 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.09956298210128807\n",
      "train loss after my code:  0.09267167030076588\n",
      "val accuracy:  91.82658137882018\n",
      "test accuracy:  90.99290780141844\n",
      "23\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1795, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5523, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  89.90760483297797\n",
      "selected clients UCB:  [ 7 11 15 18  4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "loss after my code:  0.17492365729186984\n",
      "train loss after my code:  0.06713239319928128\n",
      "val accuracy:  92.46624022743426\n",
      "test accuracy:  91.77304964539007\n",
      "24\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0472, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3372, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  90.40511727078892\n",
      "selected clients UCB:  [ 7 15  5  1 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.1899554277664922\n",
      "train loss after my code:  0.07020176117921953\n",
      "val accuracy:  92.181947405828\n",
      "test accuracy:  91.70212765957447\n",
      "25\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1035, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4246, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "75.47169811320755\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "77.27272727272727\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "94.33962264150944\n",
      "client accuracy :  10\n",
      "84.06593406593407\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "88.09523809523809\n",
      "client accuracy :  13\n",
      "85.36585365853658\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "82.5\n",
      "client accuracy :  17\n",
      "74.07407407407408\n",
      "client accuracy :  18\n",
      "96.29629629629629\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  90.47619047619048\n",
      "selected clients UCB:  [ 7 13 12 10 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.18306407522561222\n",
      "train loss after my code:  0.10512061192008049\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "79.54545454545455\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "84.06593406593407\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "89.28571428571429\n",
      "client accuracy :  13\n",
      "85.36585365853658\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "82.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  91.96872778962332\n",
      "client accuracy :  0\n",
      "96.7741935483871\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "92.85714285714286\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "100.0\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "81.86813186813187\n",
      "client accuracy :  11\n",
      "88.57142857142857\n",
      "client accuracy :  12\n",
      "91.699604743083\n",
      "client accuracy :  13\n",
      "75.60975609756098\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "82.92682926829268\n",
      "client accuracy :  17\n",
      "74.07407407407408\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  91.70212765957447\n",
      "26\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0923, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4551, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  88.62828713574982\n",
      "selected clients UCB:  [ 7 15  8  3 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.2143054644599633\n",
      "train loss after my code:  0.1539747153811673\n",
      "val accuracy:  92.11087420042644\n",
      "test accuracy:  91.20567375886525\n",
      "27\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1236, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4293, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  90.33404406538736\n",
      "selected clients UCB:  [ 7  9 17  2 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.29093860466412136\n",
      "train loss after my code:  0.1396138978036944\n",
      "val accuracy:  92.46624022743426\n",
      "test accuracy:  90.85106382978724\n",
      "28\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0831, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4119, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.181947405828\n",
      "selected clients UCB:  [ 7  6 15 11 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.16999339092551188\n",
      "train loss after my code:  0.08194611752865501\n",
      "val accuracy:  93.24804548685147\n",
      "test accuracy:  91.48936170212765\n",
      "29\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0696, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3715, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.75550817341862\n",
      "selected clients UCB:  [ 7 15 11  3  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.1492190831998888\n",
      "train loss after my code:  0.07947690868177597\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  92.48226950354609\n",
      "30\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1578, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4892, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "84.0909090909091\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "84.61538461538461\n",
      "client accuracy :  11\n",
      "97.14285714285714\n",
      "client accuracy :  12\n",
      "87.6984126984127\n",
      "client accuracy :  13\n",
      "85.36585365853658\n",
      "client accuracy :  14\n",
      "100.0\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "62.5\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  91.11584932480456\n",
      "selected clients UCB:  [ 7 15 18 11 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.24364979199481418\n",
      "train loss after my code:  0.18217432334424016\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "86.36363636363636\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "84.61538461538461\n",
      "client accuracy :  11\n",
      "97.14285714285714\n",
      "client accuracy :  12\n",
      "91.26984126984127\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "100.0\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "67.5\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.3951670220327\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "92.85714285714286\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "96.1038961038961\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "95.72649572649573\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "96.61016949152543\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "82.41758241758241\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "92.09486166007905\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "75.60975609756098\n",
      "client accuracy :  17\n",
      "77.77777777777779\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  92.48226950354609\n",
      "31\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1963, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5817, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.11584932480456\n",
      "selected clients UCB:  [ 7  9 14  6  2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.3696963571190188\n",
      "train loss after my code:  0.2672717996528074\n",
      "val accuracy:  93.03482587064677\n",
      "test accuracy:  91.34751773049645\n",
      "32\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1777, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5242, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.18692253020612\n",
      "selected clients UCB:  [ 7 17 16  1 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "loss after my code:  0.2072981024717508\n",
      "train loss after my code:  0.18499163786554093\n",
      "val accuracy:  92.53731343283582\n",
      "test accuracy:  91.20567375886525\n",
      "33\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1861, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5389, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.25799573560768\n",
      "selected clients UCB:  [16  7  5  4 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.29178388587258314\n",
      "train loss after my code:  0.15914391395296382\n",
      "val accuracy:  92.89267945984363\n",
      "test accuracy:  91.98581560283688\n",
      "34\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0882, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4276, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.96375266524521\n",
      "selected clients UCB:  [16  7 10 15  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "loss after my code:  0.33542498134406884\n",
      "train loss after my code:  0.1709586879420946\n",
      "val accuracy:  93.60341151385929\n",
      "test accuracy:  91.77304964539007\n",
      "35\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1296, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5381, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "81.13207547169812\n",
      "client accuracy :  4\n",
      "93.5064935064935\n",
      "client accuracy :  5\n",
      "81.81818181818183\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "90.87301587301587\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "65.0\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.11087420042644\n",
      "selected clients UCB:  [ 8  7 15 16  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.2888073229859392\n",
      "train loss after my code:  0.12516762218382654\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "86.36363636363636\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "90.87301587301587\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "72.5\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.89267945984363\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "94.8051948051948\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "80.21978021978022\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "84.98023715415019\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "85.36585365853658\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  90.85106382978724\n",
      "36\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0771, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4246, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.25302061122956\n",
      "selected clients UCB:  [ 7  8 15 11 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.04271682351649046\n",
      "train loss after my code:  0.09082908328082472\n",
      "val accuracy:  92.46624022743426\n",
      "test accuracy:  91.56028368794327\n",
      "37\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.2216, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.7138, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.4001421464108\n",
      "selected clients UCB:  [ 7 15  8 11 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.47920151554451146\n",
      "train loss after my code:  0.3108429042139711\n",
      "val accuracy:  92.67945984363894\n",
      "test accuracy:  91.56028368794327\n",
      "38\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.2357, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.6948, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.96872778962332\n",
      "selected clients UCB:  [ 7 15  9 14  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.4089573967073561\n",
      "train loss after my code:  0.19866778913912317\n",
      "val accuracy:  93.46126510305615\n",
      "test accuracy:  92.05673758865248\n",
      "39\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1658, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5889, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.11087420042644\n",
      "selected clients UCB:  [ 7 17 16  2  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.34149413853009253\n",
      "train loss after my code:  0.22438252293853886\n",
      "val accuracy:  93.03482587064677\n",
      "test accuracy:  91.70212765957447\n",
      "40\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0970, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5034, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "97.14285714285714\n",
      "client accuracy :  12\n",
      "90.47619047619048\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  93.03482587064677\n",
      "selected clients UCB:  [ 2  7 18  8 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.035384547603372105\n",
      "train loss after my code:  0.19960880531464287\n",
      "client accuracy :  0\n",
      "100.0\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "97.14285714285714\n",
      "client accuracy :  12\n",
      "90.47619047619048\n",
      "client accuracy :  13\n",
      "95.1219512195122\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  93.46126510305615\n",
      "client accuracy :  0\n",
      "96.7741935483871\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "92.45283018867924\n",
      "client accuracy :  4\n",
      "94.8051948051948\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "82.41758241758241\n",
      "client accuracy :  11\n",
      "88.57142857142857\n",
      "client accuracy :  12\n",
      "91.30434782608695\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "80.48780487804879\n",
      "client accuracy :  17\n",
      "77.77777777777779\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  92.12765957446808\n",
      "41\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0801, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4743, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.96375266524521\n",
      "selected clients UCB:  [ 2  7 11  5  1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.08946867448275514\n",
      "train loss after my code:  0.1697806411800792\n",
      "val accuracy:  93.60341151385929\n",
      "test accuracy:  92.41134751773049\n",
      "42\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0696, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4158, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.67945984363894\n",
      "selected clients UCB:  [ 2  7  4 13 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.13525921504526725\n",
      "train loss after my code:  0.16805943024427153\n",
      "val accuracy:  93.53233830845771\n",
      "test accuracy:  92.12765957446808\n",
      "43\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1007, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4183, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.3951670220327\n",
      "selected clients UCB:  [ 2  4  7 10 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.37211599368929454\n",
      "train loss after my code:  0.2808429596129892\n",
      "val accuracy:  93.39019189765459\n",
      "test accuracy:  91.27659574468086\n",
      "44\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1590, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4981, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.25302061122956\n",
      "selected clients UCB:  [ 2  4 11  7  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.2498296021028552\n",
      "train loss after my code:  0.3141733384422265\n",
      "val accuracy:  92.96375266524521\n",
      "test accuracy:  92.2695035460993\n",
      "45\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1534, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4013, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "100.0\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "91.45299145299145\n",
      "client accuracy :  7\n",
      "89.1891891891892\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "93.25396825396825\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "85.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  93.17697228144989\n",
      "selected clients UCB:  [ 2  4 18  8 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.03428451628481762\n",
      "train loss after my code:  0.15954843907088317\n",
      "client accuracy :  0\n",
      "100.0\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "91.45299145299145\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "97.14285714285714\n",
      "client accuracy :  12\n",
      "93.25396825396825\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "85.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "100.0\n",
      "val accuracy:  93.60341151385929\n",
      "client accuracy :  0\n",
      "96.7741935483871\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "92.45283018867924\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "94.87179487179486\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "82.96703296703298\n",
      "client accuracy :  11\n",
      "87.14285714285714\n",
      "client accuracy :  12\n",
      "90.11857707509881\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "78.04878048780488\n",
      "client accuracy :  17\n",
      "92.5925925925926\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "test accuracy:  92.48226950354609\n",
      "46\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0853, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3733, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.31911869225303\n",
      "selected clients UCB:  [ 2 19 14  4  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.09104288223182133\n",
      "train loss after my code:  0.09741539677692086\n",
      "val accuracy:  93.60341151385929\n",
      "test accuracy:  91.98581560283688\n",
      "47\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0647, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3583, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.60838663823738\n",
      "selected clients UCB:  [ 2  9 17 16  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.1042918940057204\n",
      "train loss after my code:  0.0867227834439456\n",
      "val accuracy:  93.10589907604833\n",
      "test accuracy:  92.62411347517731\n",
      "48\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0508, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3353, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.24804548685147\n",
      "selected clients UCB:  [ 2  9 11  7 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.054553113615403014\n",
      "train loss after my code:  0.06495033320067535\n",
      "val accuracy:  93.46126510305615\n",
      "test accuracy:  91.91489361702128\n",
      "49\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0645, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3920, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.181947405828\n",
      "selected clients UCB:  [ 2  9 18  8  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.12804616644744063\n",
      "train loss after my code:  0.09579406214531035\n",
      "val accuracy:  92.67945984363894\n",
      "test accuracy:  92.34042553191489\n",
      "50\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0779, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4406, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "90.5982905982906\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "92.85714285714286\n",
      "client accuracy :  13\n",
      "85.36585365853658\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "72.5\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "100.0\n",
      "val accuracy before bandits:  92.67945984363894\n",
      "selected clients UCB:  [ 2  9  3 11 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.08240794281775149\n",
      "train loss after my code:  0.09461225191540111\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "90.5982905982906\n",
      "client accuracy :  7\n",
      "94.5945945945946\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "92.85714285714286\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "75.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "100.0\n",
      "val accuracy:  92.89267945984363\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "92.45283018867924\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "83.51648351648352\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "90.9090909090909\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "82.92682926829268\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  92.6950354609929\n",
      "51\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1152, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5018, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.3951670220327\n",
      "selected clients UCB:  [2 9 7 1 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.15803663147427477\n",
      "train loss after my code:  0.09527624926552326\n",
      "val accuracy:  93.95877754086709\n",
      "test accuracy:  92.34042553191489\n",
      "52\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0639, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4357, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.24804548685147\n",
      "selected clients UCB:  [ 9  2 12 10 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.03870749822443126\n",
      "train loss after my code:  0.056912866184940486\n",
      "val accuracy:  93.81663113006397\n",
      "test accuracy:  92.34042553191489\n",
      "53\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0584, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4428, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.60838663823738\n",
      "selected clients UCB:  [ 9  2 14  4  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.1024385884475274\n",
      "train loss after my code:  0.06289900257662337\n",
      "val accuracy:  93.03482587064677\n",
      "test accuracy:  92.62411347517731\n",
      "54\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0535, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4507, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.67945984363894\n",
      "selected clients UCB:  [ 9 16 19 17  2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.08804485976003446\n",
      "train loss after my code:  0.08712284377605958\n",
      "val accuracy:  93.24804548685147\n",
      "test accuracy:  92.5531914893617\n",
      "55\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0416, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4142, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "79.24528301886792\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "84.61538461538461\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "93.25396825396825\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "87.5\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "100.0\n",
      "val accuracy before bandits:  93.17697228144989\n",
      "selected clients UCB:  [ 9 11  7 15 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.14268581093878221\n",
      "train loss after my code:  0.09743505986097573\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "81.13207547169812\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "84.61538461538461\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "93.25396825396825\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "87.5\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "100.0\n",
      "val accuracy:  93.31911869225303\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "84.06593406593407\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "91.30434782608695\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "82.92682926829268\n",
      "client accuracy :  17\n",
      "92.5925925925926\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  92.8368794326241\n",
      "56\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1025, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4840, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.03482587064677\n",
      "selected clients UCB:  [ 9  8  3  7 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.12845845927528413\n",
      "train loss after my code:  0.10480065637542277\n",
      "val accuracy:  93.60341151385929\n",
      "test accuracy:  92.12765957446808\n",
      "57\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0745, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4441, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.03482587064677\n",
      "selected clients UCB:  [ 3  9 15  2  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.11753425545701235\n",
      "train loss after my code:  0.07889931356721362\n",
      "val accuracy:  93.60341151385929\n",
      "test accuracy:  92.2695035460993\n",
      "58\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0958, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4296, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.31911869225303\n",
      "selected clients UCB:  [ 3  9 18  8  4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.11545746789580144\n",
      "train loss after my code:  0.2336159636056876\n",
      "val accuracy:  93.81663113006397\n",
      "test accuracy:  93.04964539007092\n",
      "59\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1205, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4033, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.39019189765459\n",
      "selected clients UCB:  [ 3  9 14  6 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.17731691040449704\n",
      "train loss after my code:  0.1679397310533967\n",
      "val accuracy:  93.7455579246624\n",
      "test accuracy:  93.12056737588652\n",
      "60\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0943, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4038, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.71428571428571\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "92.46031746031747\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "100.0\n",
      "val accuracy before bandits:  93.39019189765459\n",
      "selected clients UCB:  [ 3 17 16 15 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.029263591674292926\n",
      "train loss after my code:  0.11136968507861425\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.71428571428571\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "92.46031746031747\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "100.0\n",
      "val accuracy:  93.46126510305615\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "82.96703296703298\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "91.30434782608695\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "87.8048780487805\n",
      "client accuracy :  17\n",
      "92.5925925925926\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  93.04964539007092\n",
      "61\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0535, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4110, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.88770433546553\n",
      "selected clients UCB:  [ 7  2  5  1 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.09864265814999576\n",
      "train loss after my code:  0.07866982718963694\n",
      "val accuracy:  94.02985074626866\n",
      "test accuracy:  93.12056737588652\n",
      "62\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0473, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4047, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.60341151385929\n",
      "selected clients UCB:  [12 10  9  7 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.13231366304237946\n",
      "train loss after my code:  0.08273067155070302\n",
      "val accuracy:  93.95877754086709\n",
      "test accuracy:  93.04964539007092\n",
      "63\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0583, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4171, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.46126510305615\n",
      "selected clients UCB:  [11 18  3  8  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.11544294518410997\n",
      "train loss after my code:  0.0656626929540801\n",
      "val accuracy:  93.81663113006397\n",
      "test accuracy:  92.90780141843972\n",
      "64\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0550, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4012, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.67448471926085\n",
      "selected clients UCB:  [ 2 15  9  6  4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.09103562421709369\n",
      "train loss after my code:  0.05845729105150683\n",
      "val accuracy:  93.88770433546553\n",
      "test accuracy:  93.19148936170212\n",
      "65\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0477, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4036, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "97.16981132075472\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "92.46031746031747\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "100.0\n",
      "val accuracy before bandits:  93.46126510305615\n",
      "selected clients UCB:  [ 9 16 14 19 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.034011454492946014\n",
      "train loss after my code:  0.05550616517450876\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "92.46031746031747\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "100.0\n",
      "val accuracy:  93.7455579246624\n",
      "client accuracy :  0\n",
      "96.7741935483871\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "84.06593406593407\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "90.9090909090909\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "95.23809523809523\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "92.6829268292683\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  93.19148936170212\n",
      "66\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0428, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4027, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.60341151385929\n",
      "selected clients UCB:  [ 9  7 11  2 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.09938724778811531\n",
      "train loss after my code:  0.06956648289504375\n",
      "val accuracy:  93.88770433546553\n",
      "test accuracy:  93.12056737588652\n",
      "67\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0562, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4048, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.46126510305615\n",
      "selected clients UCB:  [ 9  3 18  8  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.035768030659065454\n",
      "train loss after my code:  0.05035239660369351\n",
      "val accuracy:  93.7455579246624\n",
      "test accuracy:  93.04964539007092\n",
      "68\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0456, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3856, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.53233830845771\n",
      "selected clients UCB:  [ 9  1 13 12 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.056495241062876025\n",
      "train loss after my code:  0.06264567251027711\n",
      "val accuracy:  93.88770433546553\n",
      "test accuracy:  92.97872340425532\n",
      "69\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0369, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3684, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.60341151385929\n",
      "selected clients UCB:  [13  5 11  7 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.04473961079681273\n",
      "train loss after my code:  0.04264467018840567\n",
      "val accuracy:  93.95877754086709\n",
      "test accuracy:  93.12056737588652\n",
      "70\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0297, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3678, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "94.04761904761905\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "100.0\n",
      "val accuracy before bandits:  93.95877754086709\n",
      "selected clients UCB:  [13  9  2  7  4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.017738139052498228\n",
      "train loss after my code:  0.04514044991639558\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "94.04761904761905\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "100.0\n",
      "val accuracy:  94.10092395167023\n",
      "client accuracy :  0\n",
      "96.7741935483871\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "84.06593406593407\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "90.9090909090909\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "95.1219512195122\n",
      "client accuracy :  17\n",
      "92.5925925925926\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  93.19148936170212\n",
      "71\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0291, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3690, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.88770433546553\n",
      "selected clients UCB:  [13 19  6 17 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.031223994129258786\n",
      "train loss after my code:  0.046635433367306446\n",
      "val accuracy:  93.95877754086709\n",
      "test accuracy:  92.8368794326241\n",
      "72\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0308, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3897, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.67448471926085\n",
      "selected clients UCB:  [13 14 18  8  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.06430821149233164\n",
      "train loss after my code:  0.04626087111442944\n",
      "val accuracy:  93.88770433546553\n",
      "test accuracy:  93.33333333333333\n",
      "73\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0347, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4050, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.60341151385929\n",
      "selected clients UCB:  [13 11 15  7  9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.036817449291108736\n",
      "train loss after my code:  0.03795390766100853\n",
      "val accuracy:  93.7455579246624\n",
      "test accuracy:  92.97872340425532\n",
      "74\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0260, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3829, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.7455579246624\n",
      "selected clients UCB:  [ 2 15 11  7  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.005505546437156393\n",
      "train loss after my code:  0.028478725479559194\n",
      "val accuracy:  93.81663113006397\n",
      "test accuracy:  93.12056737588652\n",
      "75\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0252, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3883, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "93.25396825396825\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  93.60341151385929\n",
      "selected clients UCB:  [ 8 18  1  5 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.07258497906272658\n",
      "train loss after my code:  0.035822393623850465\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "93.25396825396825\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "100.0\n",
      "val accuracy:  93.88770433546553\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "84.06593406593407\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "90.9090909090909\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "95.1219512195122\n",
      "client accuracy :  17\n",
      "92.5925925925926\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  93.26241134751773\n",
      "76\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0348, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3837, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.81663113006397\n",
      "selected clients UCB:  [10  7  9  2  4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.06301086248185118\n",
      "train loss after my code:  0.03943141216625242\n",
      "val accuracy:  93.95877754086709\n",
      "test accuracy:  93.40425531914893\n",
      "77\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0492, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3855, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.81663113006397\n",
      "selected clients UCB:  [19  6 17 16 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.06686568291530653\n",
      "train loss after my code:  0.041616125555674434\n",
      "val accuracy:  93.95877754086709\n",
      "test accuracy:  93.47517730496455\n",
      "78\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0576, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3774, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.7455579246624\n",
      "selected clients UCB:  [13 15 11  7  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.05463108629811614\n",
      "train loss after my code:  0.05670372790439266\n",
      "val accuracy:  93.88770433546553\n",
      "test accuracy:  93.26241134751773\n",
      "79\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0412, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3731, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.95877754086709\n",
      "selected clients UCB:  [18  3 15  9  2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.0038576743316124976\n",
      "train loss after my code:  0.041368523703639276\n",
      "val accuracy:  94.02985074626866\n",
      "test accuracy:  93.19148936170212\n",
      "80\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0407, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3821, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "93.25396825396825\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  93.81663113006397\n",
      "selected clients UCB:  [ 7 11 15 19 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.004632502161756808\n",
      "train loss after my code:  0.04095903312286212\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "93.25396825396825\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "100.0\n",
      "val accuracy:  93.95877754086709\n",
      "client accuracy :  0\n",
      "100.0\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "83.51648351648352\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "90.9090909090909\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "95.1219512195122\n",
      "client accuracy :  17\n",
      "92.5925925925926\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  93.33333333333333\n",
      "81\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0315, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3790, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  94.10092395167023\n",
      "selected clients UCB:  [ 7 16  4 14 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.021927465700031304\n",
      "train loss after my code:  0.031474727131408524\n",
      "val accuracy:  94.17199715707179\n",
      "test accuracy:  93.47517730496455\n",
      "82\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0257, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3760, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.81663113006397\n",
      "selected clients UCB:  [ 6  5  1 12 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.018511526208665523\n",
      "train loss after my code:  0.025919587351742695\n",
      "val accuracy:  93.95877754086709\n",
      "test accuracy:  93.04964539007092\n",
      "83\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0230, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3704, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.7455579246624\n",
      "selected clients UCB:  [ 9  2 18  3  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.04499728743825647\n",
      "train loss after my code:  0.025908877969754666\n",
      "val accuracy:  93.88770433546553\n",
      "test accuracy:  93.26241134751773\n",
      "84\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0338, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3696, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.88770433546553\n",
      "selected clients UCB:  [11  7 15  9  2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.03996822377706923\n",
      "train loss after my code:  0.028073660515264085\n",
      "val accuracy:  94.02985074626866\n",
      "test accuracy:  93.26241134751773\n",
      "85\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0350, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3612, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.71428571428571\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "93.25396825396825\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  93.7455579246624\n",
      "selected clients UCB:  [ 7 11 15  3 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.05918014156599843\n",
      "train loss after my code:  0.044175593509087514\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "85.71428571428571\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "93.25396825396825\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "100.0\n",
      "val accuracy:  93.95877754086709\n",
      "client accuracy :  0\n",
      "100.0\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "85.16483516483517\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "90.9090909090909\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "95.1219512195122\n",
      "client accuracy :  17\n",
      "92.5925925925926\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  93.19148936170212\n",
      "86\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0503, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3889, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  94.17199715707179\n",
      "selected clients UCB:  [ 8  7 19 17 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.039940219697907176\n",
      "train loss after my code:  0.048943841640393816\n",
      "val accuracy:  94.24307036247335\n",
      "test accuracy:  93.12056737588652\n",
      "87\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0345, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3836, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.88770433546553\n",
      "selected clients UCB:  [14 13  6  4 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.011800102121998684\n",
      "train loss after my code:  0.03454171703288575\n",
      "val accuracy:  93.95877754086709\n",
      "test accuracy:  93.19148936170212\n",
      "88\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0434, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3804, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.81663113006397\n",
      "selected clients UCB:  [ 9  2 15  7  5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.0769162257841198\n",
      "train loss after my code:  0.04353391277564121\n",
      "val accuracy:  93.95877754086709\n",
      "test accuracy:  93.19148936170212\n",
      "89\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0421, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3652, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  94.10092395167023\n",
      "selected clients UCB:  [ 1 12 10  3 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.00035946422891320717\n",
      "train loss after my code:  0.04212744401711605\n",
      "val accuracy:  94.17199715707179\n",
      "test accuracy:  92.97872340425532\n",
      "90\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0340, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3735, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "86.81318681318682\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "93.25396825396825\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  93.88770433546553\n",
      "selected clients UCB:  [ 8  7 15 11  9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.04146832147868905\n",
      "train loss after my code:  0.04104152863138957\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "86.81318681318682\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "93.25396825396825\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "100.0\n",
      "val accuracy:  94.02985074626866\n",
      "client accuracy :  0\n",
      "96.7741935483871\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "84.06593406593407\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "91.699604743083\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "95.1219512195122\n",
      "client accuracy :  17\n",
      "92.5925925925926\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  93.04964539007092\n",
      "91\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0479, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3792, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.88770433546553\n",
      "selected clients UCB:  [ 2 19  4 17 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.03570591003771362\n",
      "train loss after my code:  0.05114724818835534\n",
      "val accuracy:  93.95877754086709\n",
      "test accuracy:  93.12056737588652\n",
      "92\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0422, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3757, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.88770433546553\n",
      "selected clients UCB:  [14 13  6  7 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.04449374111407945\n",
      "train loss after my code:  0.05764564089124094\n",
      "val accuracy:  93.95877754086709\n",
      "test accuracy:  93.04964539007092\n",
      "93\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0484, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3734, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.95877754086709\n",
      "selected clients UCB:  [11  3 18  8  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.0\n",
      "train loss after my code:  0.0484206330130025\n",
      "val accuracy:  93.95877754086709\n",
      "test accuracy:  93.12056737588652\n",
      "94\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0467, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3687, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  94.02985074626866\n",
      "selected clients UCB:  [ 9  2  1  5 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.0\n",
      "train loss after my code:  0.04674430196341333\n",
      "val accuracy:  94.02985074626866\n",
      "test accuracy:  93.04964539007092\n",
      "95\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0352, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3654, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "86.81318681318682\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "93.25396825396825\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "100.0\n",
      "val accuracy before bandits:  93.95877754086709\n",
      "selected clients UCB:  [10 15  7 11 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.005665040205237974\n",
      "train loss after my code:  0.03663083153672598\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "100.0\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "86.81318681318682\n",
      "client accuracy :  11\n",
      "95.71428571428572\n",
      "client accuracy :  12\n",
      "93.25396825396825\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "97.61904761904762\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "100.0\n",
      "val accuracy:  94.02985074626866\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "98.21428571428571\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "97.40259740259741\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "92.3076923076923\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "83.51648351648352\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "91.699604743083\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "90.47619047619048\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "95.1219512195122\n",
      "client accuracy :  17\n",
      "92.5925925925926\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  93.04964539007092\n",
      "96\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0443, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3712, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  94.02985074626866\n",
      "selected clients UCB:  [17 16  4 14 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.03820524602450507\n",
      "train loss after my code:  0.037988316072370285\n",
      "val accuracy:  94.10092395167023\n",
      "test accuracy:  92.97872340425532\n",
      "97\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0351, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3641, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  94.10092395167023\n",
      "selected clients UCB:  [6 7 9 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.0\n",
      "train loss after my code:  0.035098993043174605\n",
      "val accuracy:  94.10092395167023\n",
      "test accuracy:  93.12056737588652\n",
      "98\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0281, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3687, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.88770433546553\n",
      "selected clients UCB:  [18  8 15  7 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.02778985860506557\n",
      "train loss after my code:  0.04318365831170585\n",
      "val accuracy:  93.95877754086709\n",
      "test accuracy:  92.76595744680851\n",
      "99\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0361, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3608, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  94.02985074626866\n",
      "selected clients UCB:  [15  9  2  7  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.0\n",
      "train loss after my code:  0.036101651321933735\n",
      "val accuracy:  94.02985074626866\n",
      "test accuracy:  93.04964539007092\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA42ElEQVR4nO3dd3yb5bn/8c/lvbedxM5wNhmQgRNCIIQVViGMQgktpxR6mO2PUeAUTguUng7WKbSFwkmhQMsmpEALhVBIwswekO1MxyO2vKdsy7p/fzyPHNmWbSWx40i63q+XX7alR9L9OM5Xt6/nHmKMQSmlVOAJG+gGKKWUOjwa4EopFaA0wJVSKkBpgCulVIDSAFdKqQClAa6UUgFKA1ypACciz4jIfQPdDnX0iY4DV0qpwKQ9cHVMEMsx9/soIhHH8vOp0HbM/YdRA0dE7hGRXSJSJyJbROTSTvdfLyJbve6fbt8+TEQWi4hDRCpE5En79l+IyEtej88VEeMJMRFZJiK/FpEvgEZglIhc6/Uau0Xkxk5tuFhENohIrd3W80TkChFZ2+m4O0Xk7W7Oc5mI/FZEVolIjYi8IyJpndr4QxEpAD4RkTAR+bmI7BORMhH5q4gkez3f9+37KkTkPhHZKyJne/0MFonISyJSC/xARJJF5DkRKRGRIhH5lYiE28ePEZHldrvKReR1+3YRkcft168Rka9FZLJ93wsi8qtO/047RaRSRN4VkWyv+4yI3CQi+SJSJSJPiYj49Quijj3GGP3QD4wxAFcA2Vhv7FcCDcAQr/uKgBmAAGOAEUA4sBF4HIgHYoBT7cf8AnjJ6/lzAQNE2N8vAwqASUAEEAl8Cxhtv8ZcrGCfbh8/E6gB5tltzAGOA6KBSmCC12utB77dzXkus89lst3mtzzt9GrjX+37YoHrgJ3AKCABWAz8zT5+IlAPnApEAY8BrcDZXj+DVuASu82xwNvA/9nPnwWsAm60j38V+Jl9rPfP8lxgLZBi/2wmeP3bvAD8yv76TKAcmG7/XP4IfOp17gb4p/08wwEHcN5A/+7px2H+nx3oBujHsfsBbAAutr/+ELjNxzEn2yEQ4eM+fwL8l7204W3P69qh93g3xz0N/Nr+ehJQBUR3c+wy4CGv7ycCLVhvRp42jvK6/2PgFq/vx9uhHAHcD7zqdV+c/VzeAe4doIOAZiDW67argKX2138FFgJDO7X5TGAHMAsI63Sfd4A/BzzidV+C3dZc+3vjeVOwv38DuGegf9f04/A+tISi2tmlgA0iUi0i1Vg91Az77mHALh8PGwbsM8a4DvNl93dqw/kissL+878auMCPNgC8CHzXLgf8B/CGMabZz9fdh9X7z+jm/mz7GO/jI7DCONv7WGNMI1DRw2uNsF+rxOvn/H9YPXGA/8LqYa8Skc0icp39vJ8ATwJPAaUislBEknycV4e2GmPq7fbkeB1zwOvrRqyQVwFIA1wBICIjgD8DPwbSjTEpwCasMAErhEb7eOh+YHg3F+casHqkHoN9HNM+DEpEorHKGY8Bg+w2vO9HGzDGrMDq+c4Bvgv8zddxXoZ5fT0cq5da7qtdQDFW8Hof7wJKgRJgqNc5xALpnZvn9fV+rB54hjEmxf5IMsZMss/jgDHmemNMNnAj8CcRGWPf9wdjzIlYf2GMA+72cV4d2ioi8XZ7inz+FFRA0wBXHvFYQeMAEJFrsXrgHs8Cd4nIifYFtTF26K/CCrGHRCReRGJE5BT7MRuA00RkuH3R795e2hCFVbd1AC4ROR84x+v+54BrReQs+8Jijogc53X/X7F6qS5jzOe9vNbVIjJRROKAXwKLjDFt3Rz7KnCHiIwUkQTgN8Dr9l8di4CLRGS2iEQBD3LwDacLY0wJsAT4XxFJss9jtIjMBbAvyHreEKqw/k3aRGSGiJwkIpFYb4xOwFd7X7F/RlPtN8TfACuNMXt7+XmoAKQBrgAwxmwB/hf4CqtneTzwhdf9bwK/xgqIOqzadJodehdhXdQsAAqxLoBijPkIeB34GusC3D97aUMdcCtWXbYKqyf9rtf9q4BrsS6Y1gDL6dgz/hvWm05vvW/PsS9glRNi7Nftzl/s4z8F9mCF5/+z27TZ/vo1rDeyOqAMq5fdne9jvVltsc9zETDEvm8GsFJE6rHO/TZjzB4gCesvpCqsEkkF1l8qHRhjPgbuw/pLpgTrL5YFPbRFBTCdyKOChl2+KMMatZLfw3HLsC6uPtsPbUgAqoGxdvAq1W+0B66Cyc3A6p7Cuz+IyEUiEmfXmx8DvgH2Hs02qNCks8JUUBCRvVi150sG4OUvxiqxCLAGWGD0T1t1FGgJRSmlApSWUJRSKkAd1RJKRkaGyc3NPZovqZRSAW/t2rXlxpjMzrf7FeAichtwPVaN78/GmCe87rsLeBTINMaU+34GS25uLmvWrDmUdiulVMgTkX2+bu+1hGKveHY91kJCU4ALRWSsfd8wrIWFCvquqUoppfzhTw18ArDCGNNozzxbDniWGX0ca+0GvRKqlFJHmT8BvglrOnS6Pe34AmCYiMwHiowxG3t6sIjcICJrRGSNw+HogyYrpZQCP2rgxpitIvIw8BHWuscbsRby+Rkd16no7vELsZbHJC8vr0tPvbW1lcLCQpxO5yE2/dgWExPD0KFDiYyMHOimKKWClF8XMY0xz2EtJISI/AZrrYzvARvtzTyGAutEZKYx5kC3T+RDYWEhiYmJ5ObmEiwbgxhjqKiooLCwkJEjRw50c5RSQcqvceAikmV/Hg5cBvzVGJNljMk1xuRiLWA0/VDDG8DpdJKenh404Q0gIqSnpwfdXxVKqWOLv+PA3xKRdKw1k39kjKnqy0YEU3h7BOM5KaWOLf6WUOb0cn9un7RGKRXw9pY38MWuciZnJzNlWIpfj1m7r5Ky2mbOP35I7werdiG/mFV1dTWvvPIKt9xyyyE/9oknnuCGG24gLi6u94OVCmLVjS08s3w3H2wqYW9FIwARYcJvLzueK/KGdfu4/ZWNPPTBNt77ugSAxbfMZvrw1KPS5mAQ8muhVFdX86c//emwHvvEE0/Q2NjYxy1SauA56pq5+82NFFT0/Pvd2ubmhS/2MPfRZSz8dBe5GfE8OH8S7986h1mj0rl70dc8+uE23O6OA9Dqm1088sE2zvrdcj7eWsqtZ45hUFI0v3h3c5djVfdCvgd+zz33sGvXLqZOncq8efPIysrijTfeoLm5mUsvvZQHH3yQhoYGvvOd71BYWEhbWxv33XcfpaWlFBcXc8YZZ5CRkcHSpUsH+lRUCLF2JT/4vUjfXnd58pN83lxbSH5ZPYtuOpmI8I59PWMMy7Y7+NV7W9jlaODUMRn8/MIJHDf44D7Lz187g/vf2cRTS3fxeX458yYO4vTxWWwpruWRD7dTXt/MpdNy+K/zxjMkOZZRmQnc/voGFq0t5DszrF77KysLeGb5LlxtbgCiI8OZmZvG6eMzOWVsBkkxXYfpdv7ZhIUF7/WoYyrAH/zHZrYU1/bpc07MTuKBiyZ1e/9DDz3Epk2b2LBhA0uWLGHRokWsWrUKYwzz58/n008/xeFwkJ2dzXvvvQdATU0NycnJ/O53v2Pp0qVkZGR0+/xK+WKMobKhhbT4qC7BW9XQQlJsJOHdBE+ds5UfPL+atfsOjiXISoxm7rhMTh+fxaljM0iO7X7+gdttWL+/muXby1i2w0FRVROv3ziLMVmJAJTUNPHqqv0cNziRDfureXLpTm4/e1z743eU1vGr97by6Q4HozLiefb7eZw1IavLeUSGh/GbS49nck4yr64q4LElO3hsyQ4Apg9P4dlr8pjqVSO/eGo2f1uxj4c/2MY5kwbx5Cc7efbzPZw4IpVRGfEAVDe18v43Jby+Zj8RYcL0EamcPj6TvBFpbCqqYdkOByt3V9DssgI/TOCa2bn87IIJXd6EPOqbXUSECTGR4R1ud7a24XIbEqL9i0ljDA0tbX4f3xeOqQAfaEuWLGHJkiVMmzYNgPr6evLz85kzZw533XUXP/3pT7nwwguZM6fHa7pKdeuzfAdLNpeybEcZ+yubGJRkBe9JI9PZUVrHsu0OtpfWkRwbyZyxGZw+PotzJw0i0e5ptra5ueXldWzYX82Nc0cRFxmBwZBfWs8Hmw/w5tpCwsOE6cNTOH18FnPHZTIpO6k9XNfuq+SX/9jCxsIawgSmDU/FbQy3v76BxTefQlREGE8v24XbGP78/Twe/2gHf/xkJ6eNyyQ3PZ7HP9rBK6sKiI8K574LJ/Ifs0YQFdF9JVZE+N5JI/jeSSNw1DXzWb6DhOgI5k0c1CXwRYQH50/ioic/Z97jn+Koa+YHs3P5+bc6hm9rm5t1+6pYtsPBsu0OHvlge/t9ozLiWTBjGGnx0QDsq2zg+S/2sre8gT9+dzoJ0REYY9hcXMvyHQ6Wb3ewtqCK8DDhpJFpnD4+CwGW73CwYncFLrdh+vAU5o7LZMqwFMLtNifGRDIxO6n9TXZzcQ3/888trN1XxavXzyIvN629TcYYPtx8gHMmDu7zvwaO6oYOeXl5pvNqhFu3bmXChAlHrQ2d7d27lwsvvJBNmzZx5513Mm7cOG688cYux1VWVvL+++/zzDPPcM4553D//fe3r67YXQ98oM9NHVuWbi/j2udXExsZzilj0pk2PJXNxTV8ll9OndNFZLiQNyKN2aPT2VvRyPIdDsrrm8lIiOLOc8ZzxYlDuXfxN7y5tpBHvn1Ce5nBw9XmZv3+apZtL2PZdgeb7b9mMxOjOW1sJs7WNt77poRBSdHccfY4zps8mJS4KD7cfIAb/7aWW04fzdWzRnD6o8v49ok5/PayE6h1tnL+E5/R5jY0tLhobGnj6pOGc9vZ40iLj+qXn9N///0bXltVwP0XTuQHp/Q+Ea601sn6gmomDklieHrXAQUvr9zH/e9sZmxWApNzklm+w4GjztpzelJ2EnPHZeJsdbNsRxm7HQ2A9UYwd3wmcVHhLN/hYFNR18pAalwkc8ZmEhEu/H19ESmxkURHhBMZIbx/65z2N92nlu7k0Q+384erpjF/SvZh/UxEZK0xJq/L7aEe4BUVFUyfPp19+/axZMkS7rvvPj7++GMSEhIoKioiMjISl8tFWloaMTExvP3227zwwgu8/fbbHH/88bz77rvdzrYc6HNTx5afvLGBj7eWsfK/z+rw57qrzc320jpGpMd3+PPb7TasK6ji4Q+2sXpvFYOSoimtbebWs8byk3njfL1EB2V1Tj7dUc6y7WV8ll9Os6uNG04bzU1zRxEX1fGP73ve+prX1+xnZm4aa/dVsfSu0xmWZoXhqj2VXP3sSk4enc7PvzWBsYMS++gn4purzc2BWidDU/tudNenOxz8+JV1iAhzxmYwd1wmc8dlkpUU0+G4/ZXWRVvPuXuU1TnZY4c7wIFaJ8u3O/g030FNUys/mJ3Lj88cy86yOq545isumz6Ux66Ywt/XF3LH6xu5dFoOv/vOlMO+TqEB3oPvfve7fP3115x//vkMHTqUZ5+1NitPSEjgpZdeYufOndx9992EhYURGRnJ008/TV5eHn/84x956qmnGDJkiM+LmMfCuamjY1NRDSv3VHLdKb6XhGhtc3Pi/3zEvImD+d/vTDmk5zbG8P43B3hsyXZmj07nV5dMPuQgaHMbWtvcXeq8Hg3NLi74w2fsq2jkqpnD+e1lx3e4v6mljdgo348NFK1tbgS6rYUfDrfb0Oxyd/jZ/G7Jdv7wyU6unzOSF77cy4zcNF64dmaPpabeaIAPgGA+N3XQzrJ6vv30l9Q0tfL+rXOYmJ3U5ZjP8h38x3Or+PP385g3cdAAtLJ3XxdW8+iH23n42yeQnRI70M0JWK1tbi5/+ks2FtYwflAib958ss/RMoeiuwAP+XHgSoHVQ7311fU8s3zXIT2urM7JD55fRUSYEBEmvLOxyOdxH2w6QFxUOHPGHrsjlk4YmsLffniShvcRigwP4w9XTePyE4fy/LUzjji8e6IBroJeZUMLpzz0CR9u7n6ttaeX7eTdjcU8/ME2vtzpe2dAT8hP/5+PuPXV9by1tpAfvrCGivoW/vKDGcwdl8k/NhR3mYjidhuWbCnl9PGZ3ZYwVHAZkR7PY1dM6fc3w2MiwI9mGedoCbRzanG5WbG7gi92lvPFznI2FdUMdJMOmTGG3Y76LrcvXldIUXUTL63wua0gG/dX88S/8zl/8mBGZsTzkzc2UtPY2uW4X7+3lXc3FjMpO4kvd5Vz55sb2Vxcw5PfncaUYSnMn5pNcY2T1XsrOzxu/f4qHHXNnDtpcN+cqFK2AR8HHhMTQ0VFRVAtKetZDzwmJqb3g48RL63Yxy//uaXDbR/fOZfRmQkD1CKoqG9mT3lDhzG13Wl2tXHvW9+weH0Rv18wlYun5gDWv8Xrq/cD8MXOchx1zWQmRrc/rrHFxR2vbyAzMZqHLjuBfZUNXPanL/nvt7/hyaumtf9OPvvZbv7yxR6uO2Uk9180EbfbGkvc6na3r90xb+IgYiPDeWdjMSeNSm9/jQ82HSAqPIwzj8vqs5+NUnAMBPjQoUMpLCwk2LZb8+zIEyg+31nOiPQ4Hr18Co66Zn70yjpW76kcsACvbmzhyoUr2FlW3+v42aqGFm7821pW7a0kNS6S3/87n28dP4SI8DDWFVSTX1bPf546kmc/38N7Xxd3GFv86/e2sqeigZf/8ySS4yI5IS6FO+aN49EPt5MUE0FGQjR1ThcvfrWX8ycP5uffsi5Kh4UJxw9N7tCOuKgIzpk0iPe/KeEXF00iKiIMYwwfbD7AKWPS28cFK9VXBjzAIyMjddeaAeZqc7NqTyXzp2Yzc2QaxhhS4iJZX1DNgpnDj3p7nK1t3PDXtRRUNDJxSBJ3vbGRrMRoZnn1aj0cdc1c8cyXFNc4+cNV04gKD+Oml9by7sZiLps+lNdXFxAXFc7t88bx5a4K3tl4MMDXFVTx8soCfnjqSGaPPnhx8aa5o1lfUNXecwc4dUwGj185tdeZdBdPzeadDcV8lu/grAmD+HirNePyx2eM6aOfjlIH+RXgInIbcD0gwJ+NMU+IyKPARUALsAu41hhT3V8NVf1nc3Et9c0uTrYDUkSYNiyF9fv7dN8Ov7jdhjvf3MiqvZX84appnDY2g28//SU3/HUNb908u8skkn9+XczeikZeu2EWs0al43YbJgxJ4g8f53PWcYP4x8YS5k/JJiE6gounZvPbf22joKKRoamx/OLdzQxKiu4yKSY8THj2mhmH1f45YzNJjYvkxa/28da6Qt7/5gBDU2O1/q36Ra8XMUVkMlZ4zwSmABeKyFisTY4nG2NOAHYA9/ZnQ1X/WbG7AoCTRh2sNU8bnkp+WT21zq4X8/pCdxd5//jJTt77uoR7zj+O+VOySYmL4oVrZxIdGc61L6ymxV6kyOOrXRUMT4tr752HhQm3nz2WvRWN3PzyWppa27hypjXl/CK7DPPuxiIWrS3k68Ia7j1/AvF9uPhQZHgYFxw/hE93OFi6zcFP5o3jozvmkhLXP9POVWjz5zd3ArDCGNMIICLLgUuNMY94HbMCuLwf2qeOgq92VzA6M56sxIMXXacNT8EYa4TGnLGZPh/nbG077GFxt762gVaXmz99b3p7WWJfRQNPLd3JRVOyufG0Ue3HDkuL45fzJ3Hzy+tYvbeSU8ZY5Q6327ByTyXnTuo4MeaciYOYOCSJL3dVMG5QAtPsFe+yU2KZOTKNRWsLqW92ceKIVC6eenhrU/TkljPGkB4fxXdPGsHg5MC5kK0Cjz/DCDcBp4lIuojEARcAnbfYuA74l68Hi8gNIrJGRNYE24VKX5pa2trXUwgErjY3q/dUcvLojvXlKcNSEIH1BdU+H1dY1ci0X37EnW9spNnVdkivuXpvJf/YWMwHmw/w3Od72m//1XtbiQgXfv6tCV1GJJ02LpOo8DA+2VbWftu2A3XUNLV2qY2LWL1wgCtnDO/wXPOnZLO3opGKhhYenD+pX0Y+5aTE8pNzxmt4q37Xa4AbY7YCD2OVTD4ANgIuz/0i8jP7+5e7efxCY0yeMSYvM9N3Ty6Y/Oq9LZz3xKf9Vnroa5uKa2loaesSgkkxkYzNSmB9ge86+L++OUBTaxtvrSvkP55bRXVji9+v+cS/d5CREMWZx2Xx6Ifb2VpiLe350ZZS/t+ZYxmU1DX44qMjOGlUGku9AtxT+vF1cXPexEG88p8n8f2TR3S4/YLjhxATGcZVM4czOSe5y+OUCiR+TeQxxjxnjJlujDkNqATyAUTkGuBC4Hsm0Gau9IOGZhdvry+ioaWNdzcUd7ivsqGF11YV9PkEn0+2lfLW2sL25TEPVXv9e2TXEJw2LJX1+6t9tvmDzQeYlJ3EE1dOZUNBNZf+6UuKq5t6fb1Veyr5YmcFN80dzaOXn0ByXCS3v7aBX/5jM7npcVx3am63jz3zuCx2lzewt9xaFe6r3RWMSI/zOdtNRJg9JoPITgsXpcVH8e+fzOXB+d1v8qFUoPArwEUky/48HLgMeFVEzgN+Csz31MdD3Xtfl9DQ0kZqXGSHIWgAv31/K/cs/oYdpV1nCvpijOF3H+3osRzT1NLGLS+v4843NzLj1//mwj9+xm2vred2++OttYW9vs5XuyoYm5XQYXKLx7ThKVQ3trKnvKHD7WW1Ttbuq+K8SYO5ZFoOL19/EkVVTTz/xZ4uz9GZ1fuO5nsnjSA9IZpHLz+B7aV17HI0cP9FE4mO6L6m7pkI88m2Mtxuw6o9lczy8cbTm6GpcV2CXalA5O9v8VsisgX4B/AjY0wV8CSQCHwkIhtE5Jn+amSgeG11AWOyErj97HF8U1TTPh19X0UDi9dbixxtLfFvy7j9lU384eN8Hluyvdtjlu9w4Gx18z8XT+Luc8cTFxnBhv3VrN9fzaf55fz337+hrNbZ7eNb29ys2VvpswQB1kgU6FoHX7KlFIDzJltD42bkpnHiiFQ+y/e9hojHyt0VfLmrgpvmjmpffvP08Vncfe54fjA7lzOP63mVvhHp8YzOjGfp9jK2Hqilpqm1S+1eqVDi1/gpY0yXPcSMMTozwcuO0jrWFVTz829N4JKpOfzm/a28vno/k3OS+eMnO4kIE8JF2FJSyyXTcnp9Pke9VRJ57+sS7j1/gs8LYh9uPkBKXCQLZg4nMjyMH3lNFimoaOSM/13G08t3dbsn6KaiGp/1b4+xWQkkRkewfn8V3z7x4KzSDzcfYFRmPGOyDs7SnDMug0c+2N5hqroxhpteWsvG/dYbWZ2zlczEaK6e1bEu/aNDmORy5nFZvPjlPj7ZatXCvYc+KhVq9O/IPvL66v1EhguXTsshOS6S8ycP5u0NRWw7UMvf1xfxvZNGMHZQgt898Ao7wF1uw1+/2tvl/haXm4+3lnL2hEE+ywHD0+P49vQcXl5ZQGk3vfDP7R5zdyEYFiZMGZbSoQde3djCV7sqOHfS4A4jOOaMsS5Qf+G1kt+2A3V8uLmUMVkJzB2XyYUnZPPYFVOOaEW+M47LoqXNzZ8/201uehxDknXpUxW6NMD7QLOrjcXrCjln4mDSE6ze55UzhlPndHHd86uJCBNuOn0UE4ck+R3g5fXWqI4pw1J4ZVUBTS0dh+qt2F1BrdPFeT3M8PvxGWNxuw1PL+u6xrUxhrfWFTIzN42MhK71b49pw1PYdqCOxhZr4NHHW8twuU2X152UnURqXGSHMso7G4oJDxN+v2AqD19+Ag9ffgJzxx3ZSKQZuWkkRkdQ63R1+5eDUqFCA7wX2w7UUtTL6IqPtpRS1djKlV6bzM4alUZuehzFNU6unjWCrMQYJgxJory+hbK67uvSHp4e+N3njKe6sZXF6ztekPxgs7VBwKk9bBBg9cKH8sqqAg7UdHzNlXsq2VvRyIKZnYf0dzRrVDptbsOChStYs7eSDzcfYEhyDCd0WsgpLMwa9fFZvgNjDG634R8bi5kzNqP9Ta0vRIaHMWecdc5a/1ahTgO8B40tLq78vxU89K9tPR73ydYyMhKi2mcIgjWM7ZrZuSTFRHDjXGtW4YQh1lZbW4p774WX1zeTGBPBKWPSOT4nmb98vqd9o4A2t2HJ5lLOGJ/Vaznix2eOsXvhOzvc/vrq/STGRHD+5CE9Pv6UMRk8fuUUymqbufyZr/j31tIu5ROPOWMyKKtrJr+snrUFVRRVN/XLTMf5U7KJiwrXAFchTwO8B2+tK6KmqbW9N9yd4pomctPjCe+0Ut0PZuey6mdnt09Rn2gH+NaSul5fu7yhhcyEaESE607NZZejgddW78cYa6fy8vpmzp3c+wJJw9LiuHLGMF5aWcDafdaknJrGVt7/poRLpub4tVHtpdOG8sldc7ntrLEMTorh8hN9L5Pr+Wvgs/xy3tlQRExkGPMm9v0iTudNHsL6++d1mPqvVCjSAO+G22143p7m3dusygM1ToZ0M5nEu4ecHBdJTkqsX3Xw8rpm0hOsBZC+dXw2JwxN5r///g0LFq7guc/2EBUexhnj/asn33P+cQxJjuEnb2ygvtnFOxuLaHa5O5R8ehMXFcEd88bx5b1ndTuDcWhqHKMy4lm2vYz3vznA2RMGkdCHC0V562m8uFKhQgO8G8t3ONhd3kBSTAQ1Td0HuDGGkhonQ/xc92LCkES2+BHgFQ0t7RcXoyLCWHzzbH51yWTyy+oPeYOAxJhIfvedqeyvbOSX/9jMq6v2MzknqV+mkp86NoPP8supbGhp3xVHKdU/NMC78Zcv9jAoKZoLp2T73B/Ro7qxlWaXm8E+1u/wZeKQJHY76nG29rwAVHn9wR44QER4GFfPGsHSu07np+cdx13njvfvRGwzR6Zx8+mjeWNNIVtLarlyRv9s1HCqfR0gOTbyiEecKKV6pgHuw/YDdXyWX873T84lIz6KumZXl53GPYprrBEq/vfAk3Aba+JPd1rb3FQ3tvoc3pccG8nNp49mUvah955vO2sck3OSiI0M73GLsiNx8uh0ouw1saMi9NdLqf404FuqHYue/2IPMZFhfHfmcN5aV4gxUNfsIjm2a8nCMzzP36VDvUeinDA0xecxlQ3WGPCexmcfjqiIMF7+z1k46pw+z6UvJMZEsviW2QxLi+uX51dKHaQB7sOHmw9wweQhpMZHkWQHXW1Tq8/QK7ED3N8ZgcPT4oiPCu/xQma5PeolI6Hvd3FJjo3st/D20GValTo69G/cTlxtbqoaWxmebvUgPWHX3YXMAzVOwsPE52p+voSFCccNSepxKKFnFmZf98CVUsFFA7yTKvuCZVq81ftN9uqB+1JS42RQYnSXMeA98Uyp725tcM+4876cwaiUCj4a4J1U2TvLeAI8KaaXHnht0yFvnTVhSBJ1za5ul1/tzxKKUip4aIB3UmGXL9LsXcST4+weeDeTeawx4Ie2It55kwczOjOeH764mkU+Nl2oqG8hKiKs3ybBKKWCgwZ4J+098ISOJRRfPXBjDAdqnIfcA0+Lj2LxLacwc2Qad725kcc+3N6hnOKob26fRq+UUt3xd0u120Rkk4hsFpHb7dvSROQjEcm3P6f2a0uPEs8QPk8PPD4qnPAw8RngtU0uGlva/B4D7i05NpIXrp3Jd/KG8uTSnXxl700JVg88XcsnSqle9BrgIjIZuB6YCUwBLhSRscA9wMfGmLHAx/b3Ac8T4Cl2gIsISTER1Da5uhxbUmtN4jnUHrhHZHgY954/AYCvC2vaby+vb9YRKEqpXvnTA58ArDDGNBpjXMBy4FLgYuBF+5gXgUv6pYVHWWVDC4kxER1mESbHRvrsgR8cA374q+KlxkcxJDmmw7jwivoW0uO1B66U6pk/Ab4JOE1E0kUkDrgAGAYMMsaUANifs3w9WERuEJE1IrLG4XD0Vbv7TWVDS/sIFI+kbgL84CzMI9vWy3unHmMMFQ3NZPg5rlwpFbp6DXBjzFbgYeAj4ANgI9C1ntD94xcaY/KMMXmZmcf+4kZVjV0DPDk20ucolJIaJ2ECWUcYthOGJLHL0YCztY3aJhetbUZ74EqpXvl1EdMY85wxZrox5jSgEsgHSkVkCID9uaz/mnn0VNS3tF/A9Oi+B95EZmK0z02FD8WEIUm0uQ35pfXtu9H7O7NTKRW6/B2FkmV/Hg5cBrwKvAtcYx9yDfBOfzTwaPPVA0+KifQ5E7OkxnnE5ROAidmenXpqD87CjNcAV0r1zN+ZIm+JSDrQCvzIGFMlIg8Bb4jID4EC4Ir+auTRYtWfuymhNLkwxnQYm11S42RMZsIRv+6ItDjiosLZUlJLvD15JyNRSyhKqZ75FeDGmDk+bqsAzurzFg2gxpY2WlxunwHe0ubG2erusIfkgRpn+wYGRyIsTBg/2NqpZ1RmPKA9cKVU73QmphfPGPDULqNQrPc57zp4nbOV+mbXEQ0h9OYZieKoa0aELm8iSinVmQa4l86zMD3aVyT0GolyqBs59GbCkCTqnC42FtaQFhd1SKsbKqVCU9AHeFmdk4uf+oJ9FQ29HlvZaR0UD1/roRzqRg698VzIXLWnQmdhKqX8EvQB/tWuCjbur2bVnsoOtztb2zjtkaUs2Xyg/bbKet898PYlZRu79sD7qoRy3OBERMDZ6tZ1UJRSfgn6AN9UZK0xUlTd1OH2gspGCiob+XLXwUWkOq9E6OGrhOLpgQ/yczf63sRFRZCbbl3A1B64UsofIRDg1hT1oqqOAV5Y1QjA7vKDpZWKhhYiw4XETutw+y6hNJGREN2nO69PtDc81h64UsofQR3gxhg2FfvugRfagb7bUd9+W1VDC6lxUV3W4U6M6ToKpai6ieyUvul9e0wYkghoD1wp5Z+gDvD9lU3UOV2Eh0m3AV5U3YSztQ3wvZAVQES4tTuO95KyO8vqGd0Hk3i8TbB74LqVmlLKH0Ed4J7e96xRaZRUO3G7D+564ymhGAN77REq3QU4dFxStr7ZZc3CzOrbAJ8xMo3TxmVy0sj0Pn1epVRwCu4AL6ohIkw4Y3wWLW3u9oWiwOqBe0oVu8rsAG9s6TKJxyMxJqI9wHeVWWWXvu6BJ8VE8tfrZpKbEd+nz6uUCk5BHeDfFNUwblBie9AWel3ILKxqYs5Yaxq8pw5e2dB1JUIP7yVld9oB3tc9cKWUOhRBG+DGGDYX1zI5J4mcVGuyjacO3tDsorKhhbGDEshOjmF3eQOuNjc1Ta09llA8KxLudNQTESaMSI87OiejlFI+BG2Al9Q4qWxoYXJOMjkpdoDbPXBPT3xYahyjMhPY7ainuqkVY7pfg8R7TfCdZfXkZsQf8TrgSil1JII2gTwTeCZlJxMfHUFKXCRF1daFS88FzKGpsYzKjGe3o+HgOih+9MB3Oer7ZBlZpZQ6EsEb4MW1hMnBsdU5KbFdeuBDU+MYlRFPXbOL7QfqgJ4DvKGljaaWNvZVNGr9Wyk14II2wDcX1TA6M4G4KGsSTk5KbHsNvLCqkeiIMDISohhl96TX7LXWSum2hGJP5vm6sJo2t2F0lo4UUUoNLH+3VLtDRDaLyCYReVVEYkRkqoisEJEN9q7zM/u7sYdiU3ENk3OS27/PSbV64MYYCquaGJoai4i0b6CwZl8V0EMPPM6aTr+2wDpuTGZifzZfKaV61WuAi0gOcCuQZ4yZDIQDC4BHgAeNMVOB++3vjwlldU5Ka5uZZC/RClYPvKGljerGVjvArREk2cmxxESGsbXEWjMlxQ7qzjzroazbVw2gPXCl1IDzt4QSAcSKSAQQBxQDBvAkZLJ92zFhS7EVxpOyD/bAh3oNJSysamz/PixMGJmRgNtAYnQE0RHhXZ+Qg0vKriuoIicltr00o5RSA6XXFDLGFInIY1gbFzcBS4wxS0RkP/ChfV8YMNvX40XkBuAGgOHDh/dZw3uyo9S6IHnc4INljpyUuPb7qhpb23vgAKMy49laUtvtLEw42AOvbGjhtHGZ/dFspZQ6JP6UUFKBi4GRQDYQLyJXAzcDdxhjhgF3AM/5erwxZqExJs8Yk5eZeXSCL7+0noyE6A6B7JnMs3K3dbFyWNrBnXRG21PXe9qH0hPggA4hVEodE/wpoZwN7DHGOIwxrcBirN72NfbXAG8Cx8xFzB1l9Ywb1DFkU+MiiY0MZ+UeawOHjj1w69ieAjzJO8B1CKFS6hjgT4AXALNEJE6shbLPArZi1bzn2secCeT3TxMPjTGGnaV1jBvUcZSIiJCTGsveioOTeDw8I1F6CvCYyPD2zRs0wJVSxwJ/auArRWQRsA5wAeuBhfbn39sXNp3Yde6BVlTdRENLG2MHdQ3ZnJRYdpbVExMZRrpXWPvTAwerjOKoa9YAV0odE/waSmGMeQB4oNPNnwMn9nmLjlB+qbVSYOceOBysgw9Njeuw605CdAQPf/t4ZvayDndSTARtbtNr0Cul1NEQdGPh8susEShjffSSPYtaeZdPPK6c0fsImUFJMQzuo13olVLqSAVdgO8orSczMZoUH+t6D03tPsD98dgVU+i0XaZSSg2YoAvw/NK6LiNQPA72wA9vHe/slMMLfqWU6g9BtZiV223IL6tnbJbvdUrGDU5k3KAEZo3SPSeVUoEvqHrgRdVNNLa0+byACdZ0+CV3zPV5n1JKBZqg6oF7LmB2V0JRSqlgElwBbg8h7K6EopRSwSSoAnxHaT1ZidHta3crpVQwC6oAzy/rOoVeKaWCVdAEuNttyC+t9zmFXimlglHQBHhRdRNNrd2PQFFKqWATNAGuI1CUUqEmaAK8tLYZgCHJOltSKRUagibA65ytACTGBNXcJKWU6lbQBHi904UIxOtmw0qpEOFXgIvIHSKyWUQ2icirIhJj3/7/RGS7fd8j/dvUntU6XSRERRAWpssFKqVCQ6/dVRHJAW4FJhpjmkTkDWCBiOzD2uz4BGNMs4hk9XNbe1Tf7NLyiVIqpPhbQokAYu3t0+Kw9sO8GXjIGNMMYIwp658m+qfO2UqCBrhSKoT0GuDGmCLgMazNjUuAGmPMEmAcMEdEVorIchGZ4evxInKDiKwRkTUOh6Mv296B1QPXKfRKqdDRa4CLSCpWqWQkkA3Ei8jVWL3yVGAWcDfwhkjX/WqMMQuNMXnGmLzMzMw+bby3OqeLhGjtgSulQoc/JZSzgT3GGIcxphVYDMwGCoHFxrIKcAMZ/dfUntU7tQaulAot/gR4ATBLROLsHvZZwFbgbeBMABEZB0QB5f3Uzl7VaoArpUJMr4lnjFkpIouAdYALWA8sBAzwFxHZBLQA1xhjTH82tif1za1aA1dKhRS/uqzGmAeAB3zcdXXfNufwtLa5cba6tQaulAopQTETs97pAnQavVIqtARFgNfZAa49cKVUKAmOAG/2LGSlNXClVOgIjgDXEopSKgQFRYBrDVwpFYqCIsA9JRStgSulQklQBPjBHrjWwJVSoSMoArxWSyhKqRAUFAFe3+wiMlyIjgiK01FKKb8EReLVOVtJiI7Ax2KISikVtIIiwK2VCLX+rZQKLUER4LoWuFIqFAVHgOt+mEqpEBQcAa5rgSulQlBQBLiuBa6UCkVBEeBaA1dKhSK/AlxE7hCRzSKySUReFZEYr/vuEhEjIgOyH6YxRvfDVEqFJH92pc8BbgXyjDGTgXBggX3fMGAe1r6ZA8LZ6sblNiRogCulQoy/JZQIIFZEIoA4oNi+/XHgv7D2xxwQuha4UipU9Rrgxpgi4DGsXnYJUGOMWSIi84EiY8zGnh4vIjeIyBoRWeNwOPqk0d7a1wLXGrhSKsT4U0JJBS4GRgLZQLyIfB/4GXB/b483xiw0xuQZY/IyMzOPtL1d6FrgSqlQ5U8J5WxgjzHGYYxpBRYD12IF+kYR2QsMBdaJyOB+a2k3dD9MpVSo8if1CoBZIhIHNAFnAYuNMWd4DrBDPM8YU94vrexBvdbAlVIhyp8a+EpgEbAO+MZ+zMJ+bpffdC1wpVSo8iv1jDEPAA/0cH9uXzXoUGkNXCkVqgJ+JqanBh6vNXClVIgJ+ACvb24lNjKcyPCAPxWllDokAZ96dU6XzsJUSoWkwA9wXQtcKRWiAj/AnS6dhamUCkkBH+D1Tl0LXCkVmgI+wHUtcKVUqAr4AK/XGrhSKkQFfIDrKBSlVKgK6AB3u43dA9cauFIq9AR0gNe36FrgSqnQFdgBruugKKVCWEAHePta4BrgSqkQFNABrmuBK6VCWUAHeK3uxqOUCmEBHeCeGniSllCUUiHIrwAXkTtEZLOIbBKRV0UkRkQeFZFtIvK1iPxdRFL6ua1daA1cKRXK/NmVPge4FWvPy8lAOLAA+AiYbIw5AdgB3NufDfWluqkFgORYrYErpUKPvyWUCCBWRCKAOKDYGLPEGOOy71+BtTP9UVVW20xCdARxUdoDV0qFHn82NS4CHsPanb4EqDHGLOl02HXAv3w9XkRuEJE1IrLG4XAcaXs7cNQ1k5UY3afPqZRSgcKfEkoqcDEwEsgG4kXkaq/7fwa4gJd9Pd4Ys9AYk2eMycvMzOybVtvK6pxkaoArpUKUPyWUs4E9xhiHMaYVWAzMBhCRa4ALge8ZY0z/NdO3srpmspJijvbLKqXUMcGfAC8AZolInIgIcBawVUTOA34KzDfGNPZnI30xxlBWqyUUpVTo6vXqnzFmpYgsAtZhlUrWAwuBzUA08JGV66wwxtzUj23toL7ZRVNrmwa4Uipk+TV8wxjzAPBAp5vH9H1z/FdW1wxAVpIGuFIqNAXsTMyyWjvAE7UGrpQKTYEb4HVOAC2hKKVCVsAGuKNOe+BKqdAWsAFeVtdMVEQYSbE6C1MpFZoCN8BrnWQlRmOPgFFKqZATuAGu0+iVUiEuwANc699KqdAVuAFe69Qx4EqpkBaQAe5sbaPW6dISilIqpAVkgOsQQqWUCtAA90ziydQSilIqhAVmgLdPo9cAV0qFrsAMcC2hKKVUoAa4k/AwIT0+aqCbopRSAyYwA7y2mYyEKMLCdBamUip0+RXgInKHiGwWkU0i8qqIxIhImoh8JCL59ufU/m6sR1ldM4N0KzWlVIjzZ1PjHOBWIM8YMxkIBxYA9wAfG2PGAh/b3x8VOo1eKaX8L6FEALEiEgHEAcVYO9W/aN//InBJn7euG446J5l6AVMpFeJ6DXBjTBHwGNbmxiVAjTFmCTDIGFNiH1MCZPl6vIjcICJrRGSNw+E44ga3trmpaGjRHrhSKuT5U0JJxeptjwSygXgRudrfFzDGLDTG5Blj8jIzMw+/pbby+maM0b0wlVLKnxLK2cAeY4zDGNMKLAZmA6UiMgTA/lzWf808SPfCVEopiz8BXgDMEpE4sXZPOAvYCrwLXGMfcw3wTv80saODk3i0B66UCm297kdmjFkpIouAdYALWA8sBBKAN0Tkh1ghf0V/NtSjfTNjLaEopUKcXxtKGmMeAB7odHMzVm/8qPKUUDISNMCVUqEt4GZiltQ0kZUYTWR4wDVdKaX6VMClYHG1k+yU2IFuhlJKDbgADPAmcjTAlVIqsALcGENRdRPZKTqEUCmlAirAKxtaaHa5tYSilFIEWIAXV1tDCDXAlVIq0AK8pglAa+BKKUWgBXi1FeDaA1dKqQAM8JjIMFLjIge6KUopNeACLMCtMeDWkixKKRXaAirAi3QMuFJKtQuoAC+ubiI7WQNcKaUggAK82dVGWV2zXsBUSilbwAR4aY21CqHOwlRKKUvABHhRtY4BV0opbwET4DoGXCmlOvJnU+PxIrLB66NWRG4XkakissK+bY2IzOzPhnoCfHCyllCUUgr821JtOzAVQETCgSLg78CfgQeNMf8SkQuAR4DT+6uhxTVNZCREExMZ3l8voZRSAeVQSyhnAbuMMfsAAyTZtycDxX3ZsM6Kqp3k6AVMpZRq59eemF4WAK/aX98OfCgij2G9Ecz29QARuQG4AWD48OGH10qsEsrYrITDfrxSSgUbv3vgIhIFzAfetG+6GbjDGDMMuAN4ztfjjDELjTF5xpi8zMzMw2qkMcaaxKMXMJVSqt2hlFDOB9YZY0rt768BFttfvwn020XMmqZWGlvaNMCVUsrLoQT4VRwsn4BV855rf30mkN9Xjers4BhwrYErpZSHXzVwEYkD5gE3et18PfB7EYkAnNh17v6gO/EopVRXfgW4MaYRSO902+fAif3RqM50Eo9SSnUVEDMxi6ubiIoIIz0+aqCbopRSx4yACPCRGfFcMjVbN3JQSikvhzoOfEAsmDmcBTMPfwy5UkoFo4DogSullOpKA1wppQKUBrhSSgUoDXCllApQGuBKKRWgNMCVUipAaYArpVSA0gBXSqkAJcaYo/diIg5g32E+PAMo78PmBIpQPO9QPGcIzfMOxXOGQz/vEcaYLhsqHNUAPxIissYYkzfQ7TjaQvG8Q/GcITTPOxTPGfruvLWEopRSAUoDXCmlAlQgBfjCgW7AAAnF8w7Fc4bQPO9QPGfoo/MOmBq4UkqpjgKpB66UUsqLBrhSSgWogAhwETlPRLaLyE4RuWeg29MfRGSYiCwVka0isllEbrNvTxORj0Qk3/6cOtBt7WsiEi4i60Xkn/b3oXDOKSKySES22f/mJwf7eYvIHfbv9iYReVVEYoLxnEXkLyJSJiKbvG7r9jxF5F4727aLyLmH8lrHfICLSDjwFHA+MBG4SkQmDmyr+oULuNMYMwGYBfzIPs97gI+NMWOBj+3vg81twFav70PhnH8PfGCMOQ6YgnX+QXveIpID3ArkGWMmA+HAAoLznF8Azut0m8/ztP+PLwAm2Y/5k515fjnmAxyYCew0xuw2xrQArwEXD3Cb+pwxpsQYs87+ug7rP3QO1rm+aB/2InDJgDSwn4jIUOBbwLNeNwf7OScBpwHPARhjWowx1QT5eWNt4RgrIhFAHFBMEJ6zMeZToLLTzd2d58XAa8aYZmPMHmAnVub5JRACPAfY7/V9oX1b0BKRXGAasBIYZIwpASvkgawBbFp/eAL4L8DtdVuwn/MowAE8b5eOnhWReIL4vI0xRcBjQAFQAtQYY5YQxOfcSXfneUT5FggB7msr+qAd+ygiCcBbwO3GmNqBbk9/EpELgTJjzNqBbstRFgFMB542xkwDGgiO0kG37JrvxcBIIBuIF5GrB7ZVx4QjyrdACPBCYJjX90Ox/vQKOiISiRXeLxtjFts3l4rIEPv+IUDZQLWvH5wCzBeRvVilsTNF5CWC+5zB+p0uNMastL9fhBXowXzeZwN7jDEOY0wrsBiYTXCfs7fuzvOI8i0QAnw1MFZERopIFFbB/90BblOfExHBqoluNcb8zuuud4Fr7K+vAd452m3rL8aYe40xQ40xuVj/rp8YY64miM8ZwBhzANgvIuPtm84CthDc510AzBKROPt3/Sys6zzBfM7eujvPd4EFIhItIiOBscAqv5/VGHPMfwAXADuAXcDPBro9/XSOp2L96fQ1sMH+uABIx7pqnW9/ThvotvbT+Z8O/NP+OujPGZgKrLH/vd8GUoP9vIEHgW3AJuBvQHQwnjPwKladvxWrh/3Dns4T+JmdbduB8w/ltXQqvVJKBahAKKEopZTyQQNcKaUClAa4UkoFKA1wpZQKUBrgSikVoDTAlVIqQGmAK6VUgPr/DHKC2tCgT+sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "settings, save_dir = init()\n",
    "import collections\n",
    "from time import time\n",
    "import random\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pandas\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "experiment_name = settings['experiment_name']\n",
    "test ='bandits'\n",
    "n_epochs = 100 #settings['n_epochs']\n",
    "patients_removed = [6, 14, 16]\n",
    "patients_left = [x for x in range(1,24) if x not in patients_removed]\n",
    "print(patients_left)\n",
    "p2p = P2P_AFPL(patients_left,5, test)\n",
    "accuracies_local2 = p2p.loop(n_epochs, p2p, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b32ea666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23]\n",
      "0\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.6906, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.7919, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "79.03225806451613\n",
      "client accuracy :  1\n",
      "77.77777777777779\n",
      "client accuracy :  2\n",
      "80.35714285714286\n",
      "client accuracy :  3\n",
      "60.37735849056604\n",
      "client accuracy :  4\n",
      "90.9090909090909\n",
      "client accuracy :  5\n",
      "79.54545454545455\n",
      "client accuracy :  6\n",
      "68.37606837606837\n",
      "client accuracy :  7\n",
      "89.1891891891892\n",
      "client accuracy :  8\n",
      "71.1864406779661\n",
      "client accuracy :  9\n",
      "97.16981132075472\n",
      "client accuracy :  10\n",
      "58.791208791208796\n",
      "client accuracy :  11\n",
      "75.71428571428571\n",
      "client accuracy :  12\n",
      "66.26984126984127\n",
      "client accuracy :  13\n",
      "78.04878048780488\n",
      "client accuracy :  14\n",
      "83.33333333333334\n",
      "client accuracy :  15\n",
      "88.57142857142857\n",
      "client accuracy :  16\n",
      "85.0\n",
      "client accuracy :  17\n",
      "55.55555555555556\n",
      "client accuracy :  18\n",
      "33.33333333333333\n",
      "client accuracy :  19\n",
      "88.67924528301887\n",
      "val accuracy before bandits:  73.91613361762616\n",
      "we are done\n",
      "client accuracy :  0\n",
      "79.03225806451613\n",
      "client accuracy :  1\n",
      "77.77777777777779\n",
      "client accuracy :  2\n",
      "80.35714285714286\n",
      "client accuracy :  3\n",
      "60.37735849056604\n",
      "client accuracy :  4\n",
      "90.9090909090909\n",
      "client accuracy :  5\n",
      "79.54545454545455\n",
      "client accuracy :  6\n",
      "68.37606837606837\n",
      "client accuracy :  7\n",
      "89.1891891891892\n",
      "client accuracy :  8\n",
      "71.1864406779661\n",
      "client accuracy :  9\n",
      "97.16981132075472\n",
      "client accuracy :  10\n",
      "58.791208791208796\n",
      "client accuracy :  11\n",
      "75.71428571428571\n",
      "client accuracy :  12\n",
      "66.26984126984127\n",
      "client accuracy :  13\n",
      "78.04878048780488\n",
      "client accuracy :  14\n",
      "83.33333333333334\n",
      "client accuracy :  15\n",
      "88.57142857142857\n",
      "client accuracy :  16\n",
      "85.0\n",
      "client accuracy :  17\n",
      "55.55555555555556\n",
      "client accuracy :  18\n",
      "33.33333333333333\n",
      "client accuracy :  19\n",
      "88.67924528301887\n",
      "val accuracy:  73.91613361762616\n",
      "client accuracy :  0\n",
      "75.80645161290323\n",
      "client accuracy :  1\n",
      "77.77777777777779\n",
      "client accuracy :  2\n",
      "80.35714285714286\n",
      "client accuracy :  3\n",
      "71.69811320754717\n",
      "client accuracy :  4\n",
      "88.31168831168831\n",
      "client accuracy :  5\n",
      "95.45454545454545\n",
      "client accuracy :  6\n",
      "68.37606837606837\n",
      "client accuracy :  7\n",
      "97.2972972972973\n",
      "client accuracy :  8\n",
      "72.88135593220339\n",
      "client accuracy :  9\n",
      "91.58878504672897\n",
      "client accuracy :  10\n",
      "54.94505494505495\n",
      "client accuracy :  11\n",
      "62.857142857142854\n",
      "client accuracy :  12\n",
      "62.450592885375485\n",
      "client accuracy :  13\n",
      "75.60975609756098\n",
      "client accuracy :  14\n",
      "76.19047619047619\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "78.04878048780488\n",
      "client accuracy :  17\n",
      "55.55555555555556\n",
      "client accuracy :  18\n",
      "85.18518518518519\n",
      "client accuracy :  19\n",
      "79.24528301886792\n",
      "test accuracy:  72.83687943262412\n",
      "1\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.4181, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(3.0346, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  72.77896233120114\n",
      "we are done\n",
      "val accuracy:  72.77896233120114\n",
      "test accuracy:  73.12056737588652\n",
      "2\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.7377, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.2291, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  79.24662402274343\n",
      "we are done\n",
      "val accuracy:  79.24662402274343\n",
      "test accuracy:  78.43971631205675\n",
      "3\n",
      "losses before:  0\n",
      "full train loss:  tensor(1.3371, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.6776, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  77.3276474769012\n",
      "we are done\n",
      "val accuracy:  77.3276474769012\n",
      "test accuracy:  77.37588652482269\n",
      "4\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.7917, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.3188, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  83.7953091684435\n",
      "we are done\n",
      "val accuracy:  83.7953091684435\n",
      "test accuracy:  83.61702127659575\n",
      "5\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.3944, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.7689, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "96.7741935483871\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "91.07142857142857\n",
      "client accuracy :  3\n",
      "75.47169811320755\n",
      "client accuracy :  4\n",
      "74.02597402597402\n",
      "client accuracy :  5\n",
      "86.36363636363636\n",
      "client accuracy :  6\n",
      "84.61538461538461\n",
      "client accuracy :  7\n",
      "89.1891891891892\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "100.0\n",
      "client accuracy :  10\n",
      "72.52747252747253\n",
      "client accuracy :  11\n",
      "78.57142857142857\n",
      "client accuracy :  12\n",
      "90.07936507936508\n",
      "client accuracy :  13\n",
      "78.04878048780488\n",
      "client accuracy :  14\n",
      "90.47619047619048\n",
      "client accuracy :  15\n",
      "85.71428571428571\n",
      "client accuracy :  16\n",
      "87.5\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "77.77777777777779\n",
      "client accuracy :  19\n",
      "90.56603773584906\n",
      "val accuracy before bandits:  85.14570007107321\n",
      "we are done\n",
      "client accuracy :  0\n",
      "96.7741935483871\n",
      "client accuracy :  1\n",
      "51.85185185185185\n",
      "client accuracy :  2\n",
      "91.07142857142857\n",
      "client accuracy :  3\n",
      "75.47169811320755\n",
      "client accuracy :  4\n",
      "74.02597402597402\n",
      "client accuracy :  5\n",
      "86.36363636363636\n",
      "client accuracy :  6\n",
      "84.61538461538461\n",
      "client accuracy :  7\n",
      "89.1891891891892\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "100.0\n",
      "client accuracy :  10\n",
      "72.52747252747253\n",
      "client accuracy :  11\n",
      "78.57142857142857\n",
      "client accuracy :  12\n",
      "90.07936507936508\n",
      "client accuracy :  13\n",
      "78.04878048780488\n",
      "client accuracy :  14\n",
      "90.47619047619048\n",
      "client accuracy :  15\n",
      "85.71428571428571\n",
      "client accuracy :  16\n",
      "87.5\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "77.77777777777779\n",
      "client accuracy :  19\n",
      "90.56603773584906\n",
      "val accuracy:  85.14570007107321\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "55.55555555555556\n",
      "client accuracy :  2\n",
      "89.28571428571429\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "77.92207792207793\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "88.88888888888889\n",
      "client accuracy :  7\n",
      "89.1891891891892\n",
      "client accuracy :  8\n",
      "96.61016949152543\n",
      "client accuracy :  9\n",
      "97.19626168224299\n",
      "client accuracy :  10\n",
      "78.02197802197803\n",
      "client accuracy :  11\n",
      "67.14285714285714\n",
      "client accuracy :  12\n",
      "88.14229249011858\n",
      "client accuracy :  13\n",
      "80.48780487804879\n",
      "client accuracy :  14\n",
      "90.47619047619048\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "75.60975609756098\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "51.85185185185185\n",
      "client accuracy :  19\n",
      "75.47169811320755\n",
      "test accuracy:  84.8936170212766\n",
      "6\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.7215, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.1470, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  86.7093105899076\n",
      "we are done\n",
      "val accuracy:  86.7093105899076\n",
      "test accuracy:  87.3758865248227\n",
      "7\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.2523, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5513, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  86.28287135749822\n",
      "we are done\n",
      "val accuracy:  86.28287135749822\n",
      "test accuracy:  86.45390070921985\n",
      "8\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.2587, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.6915, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  88.77043354655295\n",
      "we are done\n",
      "val accuracy:  88.77043354655295\n",
      "test accuracy:  88.65248226950354\n",
      "9\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1410, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4616, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  88.84150675195451\n",
      "we are done\n",
      "val accuracy:  88.84150675195451\n",
      "test accuracy:  88.58156028368795\n",
      "10\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.2659, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.8305, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "92.85714285714286\n",
      "client accuracy :  3\n",
      "45.28301886792453\n",
      "client accuracy :  4\n",
      "92.20779220779221\n",
      "client accuracy :  5\n",
      "79.54545454545455\n",
      "client accuracy :  6\n",
      "84.61538461538461\n",
      "client accuracy :  7\n",
      "83.78378378378379\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "96.22641509433963\n",
      "client accuracy :  10\n",
      "82.41758241758241\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "88.4920634920635\n",
      "client accuracy :  13\n",
      "85.36585365853658\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "87.5\n",
      "client accuracy :  17\n",
      "70.37037037037037\n",
      "client accuracy :  18\n",
      "81.48148148148148\n",
      "client accuracy :  19\n",
      "90.56603773584906\n",
      "val accuracy before bandits:  87.42004264392324\n",
      "we are done\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client accuracy :  2\n",
      "92.85714285714286\n",
      "client accuracy :  3\n",
      "45.28301886792453\n",
      "client accuracy :  4\n",
      "92.20779220779221\n",
      "client accuracy :  5\n",
      "79.54545454545455\n",
      "client accuracy :  6\n",
      "84.61538461538461\n",
      "client accuracy :  7\n",
      "83.78378378378379\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "96.22641509433963\n",
      "client accuracy :  10\n",
      "82.41758241758241\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "88.4920634920635\n",
      "client accuracy :  13\n",
      "85.36585365853658\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "87.5\n",
      "client accuracy :  17\n",
      "70.37037037037037\n",
      "client accuracy :  18\n",
      "81.48148148148148\n",
      "client accuracy :  19\n",
      "90.56603773584906\n",
      "val accuracy:  87.42004264392324\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "39.62264150943396\n",
      "client accuracy :  4\n",
      "84.4155844155844\n",
      "client accuracy :  5\n",
      "95.45454545454545\n",
      "client accuracy :  6\n",
      "91.45299145299145\n",
      "client accuracy :  7\n",
      "89.1891891891892\n",
      "client accuracy :  8\n",
      "94.91525423728814\n",
      "client accuracy :  9\n",
      "95.32710280373831\n",
      "client accuracy :  10\n",
      "81.86813186813187\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "84.18972332015811\n",
      "client accuracy :  13\n",
      "78.04878048780488\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "78.04878048780488\n",
      "client accuracy :  17\n",
      "74.07407407407408\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "75.47169811320755\n",
      "test accuracy:  86.17021276595744\n",
      "11\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.2118, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.6515, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  88.27292110874201\n",
      "we are done\n",
      "val accuracy:  88.27292110874201\n",
      "test accuracy:  88.08510638297872\n",
      "12\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1390, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.7259, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  88.20184790334044\n",
      "we are done\n",
      "val accuracy:  88.20184790334044\n",
      "test accuracy:  87.51773049645391\n",
      "13\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0602, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4797, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  89.97867803837953\n",
      "we are done\n",
      "val accuracy:  89.97867803837953\n",
      "test accuracy:  90.35460992907801\n",
      "14\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0513, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5612, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  89.97867803837953\n",
      "we are done\n",
      "val accuracy:  89.97867803837953\n",
      "test accuracy:  88.79432624113474\n",
      "15\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0188, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4794, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "96.7741935483871\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "92.85714285714286\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "88.03418803418803\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "92.46031746031747\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "88.09523809523809\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "85.0\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "96.29629629629629\n",
      "client accuracy :  19\n",
      "94.33962264150944\n",
      "val accuracy before bandits:  92.25302061122956\n",
      "we are done\n",
      "client accuracy :  0\n",
      "96.7741935483871\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "92.85714285714286\n",
      "client accuracy :  3\n",
      "88.67924528301887\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "88.03418803418803\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "92.46031746031747\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "88.09523809523809\n",
      "client accuracy :  15\n",
      "91.42857142857143\n",
      "client accuracy :  16\n",
      "85.0\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "96.29629629629629\n",
      "client accuracy :  19\n",
      "94.33962264150944\n",
      "val accuracy:  92.25302061122956\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "94.91525423728814\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "84.61538461538461\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "90.11857707509881\n",
      "client accuracy :  13\n",
      "78.04878048780488\n",
      "client accuracy :  14\n",
      "85.71428571428571\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "78.04878048780488\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "90.56603773584906\n",
      "test accuracy:  91.56028368794327\n",
      "16\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.1334, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5982, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  89.33901918976545\n",
      "we are done\n",
      "val accuracy:  89.33901918976545\n",
      "test accuracy:  87.87234042553192\n",
      "17\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0712, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.6573, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  89.90760483297797\n",
      "we are done\n",
      "val accuracy:  89.90760483297797\n",
      "test accuracy:  89.9290780141844\n",
      "18\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0220, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4593, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.25799573560768\n",
      "we are done\n",
      "val accuracy:  91.25799573560768\n",
      "test accuracy:  91.13475177304964\n",
      "19\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0067, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3819, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.47121535181236\n",
      "we are done\n",
      "val accuracy:  91.47121535181236\n",
      "test accuracy:  91.34751773049645\n",
      "20\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0044, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4540, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "89.28571428571429\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "86.36363636363636\n",
      "client accuracy :  6\n",
      "88.03418803418803\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "84.61538461538461\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "91.26984126984127\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "90.47619047619048\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.25302061122956\n",
      "we are done\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "89.28571428571429\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "86.36363636363636\n",
      "client accuracy :  6\n",
      "88.03418803418803\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "99.05660377358491\n",
      "client accuracy :  10\n",
      "84.61538461538461\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "91.26984126984127\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "90.47619047619048\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.25302061122956\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "84.61538461538461\n",
      "client accuracy :  11\n",
      "88.57142857142857\n",
      "client accuracy :  12\n",
      "88.93280632411067\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "83.33333333333334\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "87.8048780487805\n",
      "client accuracy :  17\n",
      "74.07407407407408\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  91.77304964539007\n",
      "21\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0325, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4218, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.6133617626155\n",
      "we are done\n",
      "val accuracy:  91.6133617626155\n",
      "test accuracy:  92.12765957446808\n",
      "22\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0041, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4600, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.32409381663112\n",
      "we are done\n",
      "val accuracy:  92.32409381663112\n",
      "test accuracy:  91.56028368794327\n",
      "23\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0133, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5024, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  90.90262970859986\n",
      "we are done\n",
      "val accuracy:  90.90262970859986\n",
      "test accuracy:  90.56737588652483\n",
      "24\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0083, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5606, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  90.68941009239516\n",
      "we are done\n",
      "val accuracy:  90.68941009239516\n",
      "test accuracy:  90.70921985815603\n",
      "25\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0067, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5547, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "96.7741935483871\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "88.03418803418803\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "84.06593406593407\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.07936507936508\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "85.71428571428571\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.03980099502488\n",
      "we are done\n",
      "client accuracy :  0\n",
      "96.7741935483871\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "96.42857142857143\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "88.03418803418803\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "84.06593406593407\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.07936507936508\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "85.71428571428571\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.03980099502488\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "91.45299145299145\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "81.86813186813187\n",
      "client accuracy :  11\n",
      "88.57142857142857\n",
      "client accuracy :  12\n",
      "85.37549407114624\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "78.57142857142857\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "87.8048780487805\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  90.70921985815603\n",
      "26\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0502, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5128, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  90.40511727078892\n",
      "we are done\n",
      "val accuracy:  90.40511727078892\n",
      "test accuracy:  90.49645390070921\n",
      "27\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0024, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5287, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.6133617626155\n",
      "we are done\n",
      "val accuracy:  91.6133617626155\n",
      "test accuracy:  91.13475177304964\n",
      "28\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0367, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.6062, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.25799573560768\n",
      "we are done\n",
      "val accuracy:  91.25799573560768\n",
      "test accuracy:  90.99290780141844\n",
      "29\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0020, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5722, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.96375266524521\n",
      "we are done\n",
      "val accuracy:  92.96375266524521\n",
      "test accuracy:  92.19858156028369\n",
      "30\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0025, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5922, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "88.03418803418803\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "84.61538461538461\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "90.07936507936508\n",
      "client accuracy :  13\n",
      "95.1219512195122\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.03980099502488\n",
      "we are done\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "88.03418803418803\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "84.61538461538461\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "90.07936507936508\n",
      "client accuracy :  13\n",
      "95.1219512195122\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "90.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.03980099502488\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "94.87179487179486\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "80.76923076923077\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "86.95652173913044\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "90.47619047619048\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "80.48780487804879\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "test accuracy:  91.48936170212765\n",
      "31\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0042, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5389, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.181947405828\n",
      "we are done\n",
      "val accuracy:  92.181947405828\n",
      "test accuracy:  92.12765957446808\n",
      "32\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0023, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5625, device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy before bandits:  92.181947405828\n",
      "we are done\n",
      "val accuracy:  92.181947405828\n",
      "test accuracy:  92.12765957446808\n",
      "33\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0020, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5316, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.3951670220327\n",
      "we are done\n",
      "val accuracy:  92.3951670220327\n",
      "test accuracy:  92.62411347517731\n",
      "34\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0020, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5646, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.46624022743426\n",
      "we are done\n",
      "val accuracy:  92.46624022743426\n",
      "test accuracy:  92.8368794326241\n",
      "35\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0065, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5216, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "88.88888888888889\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.07936507936508\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "we are done\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "88.88888888888889\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.07936507936508\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.75053304904051\n",
      "client accuracy :  0\n",
      "96.7741935483871\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "82.96703296703298\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "89.72332015810277\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "90.2439024390244\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "test accuracy:  92.62411347517731\n",
      "36\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0019, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5470, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.96375266524521\n",
      "we are done\n",
      "val accuracy:  92.96375266524521\n",
      "test accuracy:  92.8368794326241\n",
      "37\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0018, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5547, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  92.05673758865248\n",
      "38\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0018, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5370, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "we are done\n",
      "val accuracy:  92.75053304904051\n",
      "test accuracy:  92.48226950354609\n",
      "39\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0015, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5494, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.11087420042644\n",
      "we are done\n",
      "val accuracy:  92.11087420042644\n",
      "test accuracy:  92.97872340425532\n",
      "40\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0030, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5540, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "88.88888888888889\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "86.81318681318682\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.07936507936508\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "88.57142857142857\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.3951670220327\n",
      "we are done\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "88.88888888888889\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "86.81318681318682\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.07936507936508\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "88.57142857142857\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.3951670220327\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "84.61538461538461\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "90.11857707509881\n",
      "client accuracy :  13\n",
      "87.8048780487805\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "87.8048780487805\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  92.76595744680851\n",
      "41\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0010, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5452, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.96375266524521\n",
      "we are done\n",
      "val accuracy:  92.96375266524521\n",
      "test accuracy:  92.6950354609929\n",
      "42\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0008, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5342, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.17697228144989\n",
      "we are done\n",
      "val accuracy:  93.17697228144989\n",
      "test accuracy:  92.90780141843972\n",
      "43\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0011, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5143, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.67945984363894\n",
      "we are done\n",
      "val accuracy:  92.67945984363894\n",
      "test accuracy:  92.90780141843972\n",
      "44\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0012, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5286, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "we are done\n",
      "val accuracy:  92.75053304904051\n",
      "test accuracy:  92.97872340425532\n",
      "45\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0011, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5593, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "90.9090909090909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client accuracy :  6\n",
      "88.88888888888889\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.47619047619048\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "we are done\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "90.9090909090909\n",
      "client accuracy :  6\n",
      "88.88888888888889\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.47619047619048\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.75053304904051\n",
      "client accuracy :  0\n",
      "100.0\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "87.35177865612648\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "87.8048780487805\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "94.33962264150944\n",
      "test accuracy:  92.5531914893617\n",
      "46\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0018, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5889, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.96375266524521\n",
      "we are done\n",
      "val accuracy:  92.96375266524521\n",
      "test accuracy:  92.41134751773049\n",
      "47\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5728, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.89267945984363\n",
      "we are done\n",
      "val accuracy:  92.89267945984363\n",
      "test accuracy:  92.62411347517731\n",
      "48\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5608, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  92.90780141843972\n",
      "49\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5710, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.60838663823738\n",
      "we are done\n",
      "val accuracy:  92.60838663823738\n",
      "test accuracy:  92.97872340425532\n",
      "50\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5789, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "88.88888888888889\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "86.81318681318682\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "91.26984126984127\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "we are done\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "83.01886792452831\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "88.88888888888889\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "86.81318681318682\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "91.26984126984127\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.75053304904051\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "85.71428571428571\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "88.93280632411067\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "90.2439024390244\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  92.8368794326241\n",
      "51\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5645, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  93.19148936170212\n",
      "52\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5362, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.67945984363894\n",
      "we are done\n",
      "val accuracy:  92.67945984363894\n",
      "test accuracy:  93.12056737588652\n",
      "53\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5572, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.96375266524521\n",
      "we are done\n",
      "val accuracy:  92.96375266524521\n",
      "test accuracy:  92.48226950354609\n",
      "54\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5436, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  92.90780141843972\n",
      "55\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5458, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "88.88888888888889\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "91.26984126984127\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.89267945984363\n",
      "we are done\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "88.88888888888889\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "87.36263736263736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "91.26984126984127\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.89267945984363\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "85.71428571428571\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "88.93280632411067\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "90.2439024390244\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  92.90780141843972\n",
      "56\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5505, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "we are done\n",
      "val accuracy:  92.75053304904051\n",
      "test accuracy:  93.04964539007092\n",
      "57\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5456, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.67945984363894\n",
      "we are done\n",
      "val accuracy:  92.67945984363894\n",
      "test accuracy:  93.19148936170212\n",
      "58\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5520, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.96375266524521\n",
      "we are done\n",
      "val accuracy:  92.96375266524521\n",
      "test accuracy:  93.04964539007092\n",
      "59\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5326, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.67945984363894\n",
      "we are done\n",
      "val accuracy:  92.67945984363894\n",
      "test accuracy:  93.26241134751773\n",
      "60\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0008, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5338, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "88.88888888888889\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.47619047619048\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "95.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "88.88888888888889\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.47619047619048\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "95.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.82160625444207\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "94.87179487179486\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "85.71428571428571\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "89.32806324110672\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "95.1219512195122\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  93.12056737588652\n",
      "61\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5300, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  93.19148936170212\n",
      "62\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5237, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  93.12056737588652\n",
      "63\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5314, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  93.26241134751773\n",
      "64\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5414, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  93.19148936170212\n",
      "65\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5488, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "91.26984126984127\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.96375266524521\n",
      "we are done\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "91.26984126984127\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.96375266524521\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "94.87179487179486\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "85.71428571428571\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "89.32806324110672\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "92.85714285714286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "92.6829268292683\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  93.12056737588652\n",
      "66\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5694, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.89267945984363\n",
      "we are done\n",
      "val accuracy:  92.89267945984363\n",
      "test accuracy:  92.90780141843972\n",
      "67\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5547, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "we are done\n",
      "val accuracy:  92.75053304904051\n",
      "test accuracy:  92.97872340425532\n",
      "68\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5504, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.89267945984363\n",
      "we are done\n",
      "val accuracy:  92.89267945984363\n",
      "test accuracy:  93.04964539007092\n",
      "69\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5481, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  93.04964539007092\n",
      "70\n",
      "losses before:  0\n",
      "full train loss:  tensor(9.7158e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5385, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "88.88888888888889\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.47619047619048\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "88.88888888888889\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.47619047619048\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.82160625444207\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "86.81318681318682\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "89.32806324110672\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "92.6829268292683\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  93.04964539007092\n",
      "71\n",
      "losses before:  0\n",
      "full train loss:  tensor(8.8244e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5388, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  93.04964539007092\n",
      "72\n",
      "losses before:  0\n",
      "full train loss:  tensor(8.1005e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5507, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  92.97872340425532\n",
      "73\n",
      "losses before:  0\n",
      "full train loss:  tensor(7.1920e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5460, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  93.12056737588652\n",
      "74\n",
      "losses before:  0\n",
      "full train loss:  tensor(6.5079e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5531, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  92.97872340425532\n",
      "75\n",
      "losses before:  0\n",
      "full train loss:  tensor(5.2693e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5534, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "90.07936507936508\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.67945984363894\n",
      "we are done\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "92.85714285714286\n",
      "client accuracy :  12\n",
      "90.07936507936508\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.67945984363894\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "89.32806324110672\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "90.2439024390244\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "96.22641509433963\n",
      "test accuracy:  92.90780141843972\n",
      "76\n",
      "losses before:  0\n",
      "full train loss:  tensor(5.2459e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5601, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "we are done\n",
      "val accuracy:  92.75053304904051\n",
      "test accuracy:  92.8368794326241\n",
      "77\n",
      "losses before:  0\n",
      "full train loss:  tensor(4.5485e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5490, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.67945984363894\n",
      "we are done\n",
      "val accuracy:  92.67945984363894\n",
      "test accuracy:  92.97872340425532\n",
      "78\n",
      "losses before:  0\n",
      "full train loss:  tensor(4.4215e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5485, device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  93.04964539007092\n",
      "79\n",
      "losses before:  0\n",
      "full train loss:  tensor(4.2195e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5501, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  93.04964539007092\n",
      "80\n",
      "losses before:  0\n",
      "full train loss:  tensor(4.2070e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5486, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "86.81318681318682\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.07936507936508\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "we are done\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "86.81318681318682\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.07936507936508\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.75053304904051\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "89.32806324110672\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "92.6829268292683\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "test accuracy:  93.12056737588652\n",
      "81\n",
      "losses before:  0\n",
      "full train loss:  tensor(3.4960e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5534, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.60838663823738\n",
      "we are done\n",
      "val accuracy:  92.60838663823738\n",
      "test accuracy:  92.97872340425532\n",
      "82\n",
      "losses before:  0\n",
      "full train loss:  tensor(3.4772e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5547, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  92.97872340425532\n",
      "83\n",
      "losses before:  0\n",
      "full train loss:  tensor(3.5390e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5459, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  93.04964539007092\n",
      "84\n",
      "losses before:  0\n",
      "full train loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5463, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.89267945984363\n",
      "we are done\n",
      "val accuracy:  92.89267945984363\n",
      "test accuracy:  93.12056737588652\n",
      "85\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.9687e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5460, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.47619047619048\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.89267945984363\n",
      "we are done\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "96.29629629629629\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.47619047619048\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.89267945984363\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "94.01709401709401\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "90.0\n",
      "client accuracy :  12\n",
      "89.32806324110672\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "92.6829268292683\n",
      "client accuracy :  17\n",
      "85.18518518518519\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "test accuracy:  93.04964539007092\n",
      "86\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.7636e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5513, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.67945984363894\n",
      "we are done\n",
      "val accuracy:  92.67945984363894\n",
      "test accuracy:  93.12056737588652\n",
      "87\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.8674e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5467, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  92.97872340425532\n",
      "88\n",
      "losses before:  0\n",
      "full train loss:  tensor(3.0240e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5469, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "we are done\n",
      "val accuracy:  92.75053304904051\n",
      "test accuracy:  92.97872340425532\n",
      "89\n",
      "losses before:  0\n",
      "full train loss:  tensor(3.1659e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5451, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "we are done\n",
      "val accuracy:  92.75053304904051\n",
      "test accuracy:  93.12056737588652\n",
      "90\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.8662e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5517, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.47619047619048\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "86.79245283018868\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "89.74358974358975\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "87.36263736263736\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.47619047619048\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "92.5\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.82160625444207\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "93.16239316239316\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "89.72332015810277\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "92.6829268292683\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "test accuracy:  93.19148936170212\n",
      "91\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.7593e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5547, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "we are done\n",
      "val accuracy:  92.75053304904051\n",
      "test accuracy:  93.04964539007092\n",
      "92\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.5624e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5628, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "we are done\n",
      "val accuracy:  92.75053304904051\n",
      "test accuracy:  92.8368794326241\n",
      "93\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.5511e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5555, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "we are done\n",
      "val accuracy:  92.75053304904051\n",
      "test accuracy:  92.8368794326241\n",
      "94\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.7314e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5567, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "we are done\n",
      "val accuracy:  92.75053304904051\n",
      "test accuracy:  92.97872340425532\n",
      "95\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.5437e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5474, device='cuda:0', dtype=torch.float64)\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "88.88888888888889\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "86.81318681318682\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.07936507936508\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "95.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy before bandits:  92.60838663823738\n",
      "we are done\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "92.5925925925926\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "84.90566037735849\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "88.63636363636364\n",
      "client accuracy :  6\n",
      "88.88888888888889\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "100.0\n",
      "client accuracy :  9\n",
      "98.11320754716981\n",
      "client accuracy :  10\n",
      "86.81318681318682\n",
      "client accuracy :  11\n",
      "94.28571428571428\n",
      "client accuracy :  12\n",
      "90.07936507936508\n",
      "client accuracy :  13\n",
      "92.6829268292683\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "94.28571428571428\n",
      "client accuracy :  16\n",
      "95.0\n",
      "client accuracy :  17\n",
      "81.48148148148148\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "val accuracy:  92.60838663823738\n",
      "client accuracy :  0\n",
      "98.38709677419355\n",
      "client accuracy :  1\n",
      "100.0\n",
      "client accuracy :  2\n",
      "94.64285714285714\n",
      "client accuracy :  3\n",
      "90.56603773584906\n",
      "client accuracy :  4\n",
      "98.7012987012987\n",
      "client accuracy :  5\n",
      "97.72727272727273\n",
      "client accuracy :  6\n",
      "94.87179487179486\n",
      "client accuracy :  7\n",
      "100.0\n",
      "client accuracy :  8\n",
      "98.30508474576271\n",
      "client accuracy :  9\n",
      "96.26168224299066\n",
      "client accuracy :  10\n",
      "86.26373626373626\n",
      "client accuracy :  11\n",
      "91.42857142857143\n",
      "client accuracy :  12\n",
      "89.32806324110672\n",
      "client accuracy :  13\n",
      "90.2439024390244\n",
      "client accuracy :  14\n",
      "92.85714285714286\n",
      "client accuracy :  15\n",
      "97.14285714285714\n",
      "client accuracy :  16\n",
      "90.2439024390244\n",
      "client accuracy :  17\n",
      "88.88888888888889\n",
      "client accuracy :  18\n",
      "100.0\n",
      "client accuracy :  19\n",
      "98.11320754716981\n",
      "test accuracy:  93.19148936170212\n",
      "96\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.2695e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5460, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.67945984363894\n",
      "we are done\n",
      "val accuracy:  92.67945984363894\n",
      "test accuracy:  93.33333333333333\n",
      "97\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.1490e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5517, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.82160625444207\n",
      "we are done\n",
      "val accuracy:  92.82160625444207\n",
      "test accuracy:  93.12056737588652\n",
      "98\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.4119e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5523, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.75053304904051\n",
      "we are done\n",
      "val accuracy:  92.75053304904051\n",
      "test accuracy:  93.26241134751773\n",
      "99\n",
      "losses before:  0\n",
      "full train loss:  tensor(2.1690e-05, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5479, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.67945984363894\n",
      "we are done\n",
      "val accuracy:  92.67945984363894\n",
      "test accuracy:  93.33333333333333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "settings, save_dir = init()\n",
    "import collections\n",
    "from time import time\n",
    "import random\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pandas\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "experiment_name = settings['experiment_name']\n",
    "test ='local'\n",
    "n_epochs = 100 #settings['n_epochs']\n",
    "patients_removed = [6, 14, 16]\n",
    "patients_left = [x for x in range(1,24) if x not in patients_removed]\n",
    "print(patients_left)\n",
    "p2p = P2P_AFPL(patients_left,5, test)\n",
    "accuracies_local = p2p.loop(n_epochs, p2p, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2f31da0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f37a6a03c40>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracies_local,label='local')\n",
    "#plt.plot(accuracies_local2,label='IPFL, 5')\n",
    "plt.plot(accuracies_local3,label='IPFL, 10')\n",
    "#plt.plot(accuracies_local4,label='IPFL, without UCB')\n",
    "plt.plot(accuracies_fed,label='federated')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0adb81bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.33333333333333\n",
      "93.47517730496455\n",
      "93.97163120567376\n",
      "92.97872340425532\n"
     ]
    }
   ],
   "source": [
    "print(np.max(accuracies_local))\n",
    "print(np.max(accuracies_local2))\n",
    "print(np.max(accuracies_local3))\n",
    "print(np.max(accuracies_local4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5133a1",
   "metadata": {},
   "source": [
    "### Old results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0560f62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "0\n",
      "full train loss:  tensor(0.8770, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.1211, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  55.28846153846154\n",
      "we are done\n",
      "val accuracy:  55.28846153846154\n",
      "test accuracy:  55.97826086956522\n",
      "1\n",
      "full train loss:  tensor(0.6228, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.7745, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  67.54807692307693\n",
      "we are done\n",
      "val accuracy:  67.54807692307693\n",
      "test accuracy:  68.47826086956522\n",
      "2\n",
      "full train loss:  tensor(0.3428, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4439, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  78.60576923076923\n",
      "we are done\n",
      "val accuracy:  78.60576923076923\n",
      "test accuracy:  79.34782608695652\n",
      "3\n",
      "full train loss:  tensor(0.2666, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3545, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  83.17307692307693\n",
      "we are done\n",
      "val accuracy:  83.17307692307693\n",
      "test accuracy:  81.15942028985508\n",
      "4\n",
      "full train loss:  tensor(0.1415, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3333, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  86.53846153846155\n",
      "we are done\n",
      "val accuracy:  86.53846153846155\n",
      "test accuracy:  88.04347826086956\n",
      "5\n",
      "full train loss:  tensor(0.1105, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2119, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  88.9423076923077\n",
      "we are done\n",
      "val accuracy:  88.9423076923077\n",
      "test accuracy:  90.39855072463769\n",
      "6\n",
      "full train loss:  tensor(0.0510, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1762, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  89.42307692307693\n",
      "we are done\n",
      "val accuracy:  89.42307692307693\n",
      "test accuracy:  92.02898550724638\n",
      "7\n",
      "full train loss:  tensor(0.1075, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2772, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  88.9423076923077\n",
      "we are done\n",
      "val accuracy:  88.9423076923077\n",
      "test accuracy:  90.76086956521739\n",
      "8\n",
      "full train loss:  tensor(0.0646, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2728, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  89.90384615384616\n",
      "we are done\n",
      "val accuracy:  89.90384615384616\n",
      "test accuracy:  90.39855072463769\n",
      "9\n",
      "full train loss:  tensor(0.2209, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3396, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  87.74038461538461\n",
      "we are done\n",
      "val accuracy:  87.74038461538461\n",
      "test accuracy:  88.76811594202898\n",
      "10\n",
      "full train loss:  tensor(0.0914, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3034, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  88.46153846153845\n",
      "we are done\n",
      "val accuracy:  88.46153846153845\n",
      "test accuracy:  91.66666666666666\n",
      "11\n",
      "full train loss:  tensor(0.0095, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1741, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.82692307692307\n",
      "we are done\n",
      "val accuracy:  91.82692307692307\n",
      "test accuracy:  92.7536231884058\n",
      "12\n",
      "full train loss:  tensor(0.0224, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2090, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  90.14423076923077\n",
      "we are done\n",
      "val accuracy:  90.14423076923077\n",
      "test accuracy:  92.3913043478261\n",
      "13\n",
      "full train loss:  tensor(0.0053, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1289, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.54807692307693\n",
      "we are done\n",
      "val accuracy:  92.54807692307693\n",
      "test accuracy:  94.38405797101449\n",
      "14\n",
      "full train loss:  tensor(0.0516, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2427, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  89.66346153846155\n",
      "we are done\n",
      "val accuracy:  89.66346153846155\n",
      "test accuracy:  92.3913043478261\n",
      "15\n",
      "full train loss:  tensor(0.0054, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1716, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.82692307692307\n",
      "we are done\n",
      "val accuracy:  91.82692307692307\n",
      "test accuracy:  94.38405797101449\n",
      "16\n",
      "full train loss:  tensor(0.0035, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1678, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.0673076923077\n",
      "we are done\n",
      "val accuracy:  92.0673076923077\n",
      "test accuracy:  94.38405797101449\n",
      "17\n",
      "full train loss:  tensor(0.0056, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1820, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.78846153846155\n",
      "we are done\n",
      "val accuracy:  92.78846153846155\n",
      "test accuracy:  94.56521739130434\n",
      "18\n",
      "full train loss:  tensor(0.0012, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1831, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.54807692307693\n",
      "we are done\n",
      "val accuracy:  92.54807692307693\n",
      "test accuracy:  94.56521739130434\n",
      "19\n",
      "full train loss:  tensor(0.0020, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1776, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.02884615384616\n",
      "we are done\n",
      "val accuracy:  93.02884615384616\n",
      "test accuracy:  94.38405797101449\n",
      "20\n",
      "full train loss:  tensor(0.0021, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2059, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.3076923076923\n",
      "we are done\n",
      "val accuracy:  92.3076923076923\n",
      "test accuracy:  94.20289855072464\n",
      "21\n",
      "full train loss:  tensor(0.0008, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1882, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.78846153846155\n",
      "we are done\n",
      "val accuracy:  92.78846153846155\n",
      "test accuracy:  95.65217391304348\n",
      "22\n",
      "full train loss:  tensor(0.0011, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1910, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.26923076923077\n",
      "we are done\n",
      "val accuracy:  93.26923076923077\n",
      "test accuracy:  95.47101449275362\n",
      "23\n",
      "full train loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1689, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.54807692307693\n",
      "we are done\n",
      "val accuracy:  92.54807692307693\n",
      "test accuracy:  95.28985507246377\n",
      "24\n",
      "full train loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2100, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  90.86538461538461\n",
      "we are done\n",
      "val accuracy:  90.86538461538461\n",
      "test accuracy:  94.7463768115942\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "settings, save_dir = init()\n",
    "import collections\n",
    "from time import time\n",
    "import random\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pandas\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "experiment_name = settings['experiment_name']\n",
    "test ='local'\n",
    "n_epochs = 25 #settings['n_epochs']\n",
    "patients_left = [x for x in range(1,11)]\n",
    "print(patients_left)\n",
    "p2p = P2P_AFPL(patients_left,5, test)\n",
    "accuracies_local = p2p.loop(n_epochs, p2p, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4a94079e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "0\n",
      "full train loss:  tensor(0.6924, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.7759, device='cuda:0', dtype=torch.float64)\n",
      "[ 6.73076923  2.64423077  8.17307692  5.52884615 10.81730769  1.44230769\n",
      "  6.25       11.77884615  6.49038462  7.93269231]\n",
      "val accuracy before bandits:  67.78846153846155\n",
      "selected clients UCB:  [9 8 7 6 5 4 3 2 0]\n",
      "[0. 0. 0. 0. 0. 1. 1. 0. 1. 0.]\n",
      "loss after my code:  0.26546496236618555\n",
      "train loss after my code:  0.21744809254292563\n",
      "[ 9.61538462  3.60576923  6.73076923  6.00961538  9.13461538  1.68269231\n",
      "  6.25       11.29807692  6.49038462  7.69230769]\n",
      "val accuracy:  68.50961538461539\n",
      "[ 9.23913043  3.98550725  5.79710145  6.70289855  7.42753623  1.08695652\n",
      "  6.88405797 11.77536232  6.52173913  6.70289855]\n",
      "test accuracy:  66.12318840579711\n",
      "1\n",
      "full train loss:  tensor(0.2798, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3503, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  79.8076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [8 6 5 9 7 4 3 2 1]\n",
      "[0. 0. 0. 1. 1. 1. 1. 0. 1. 1.]\n",
      "loss after my code:  0.1976038260113196\n",
      "train loss after my code:  0.19164287791685147\n",
      "val accuracy:  78.125\n",
      "test accuracy:  78.98550724637681\n",
      "2\n",
      "full train loss:  tensor(0.4613, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5754, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  79.32692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [8 6 5 9 4 3 0 7 2]\n",
      "[1. 0. 0. 1. 0. 1. 1. 1. 1. 1.]\n",
      "loss after my code:  0.17054259217568754\n",
      "train loss after my code:  0.15009861445660647\n",
      "val accuracy:  81.73076923076923\n",
      "test accuracy:  78.98550724637681\n",
      "3\n",
      "full train loss:  tensor(0.2464, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2799, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  85.8173076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [8 6 5 9 3 0 7 4 2]\n",
      "[1. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "loss after my code:  0.17378326806685773\n",
      "train loss after my code:  0.16404889145728843\n",
      "val accuracy:  81.97115384615384\n",
      "test accuracy:  83.15217391304348\n",
      "4\n",
      "full train loss:  tensor(0.2843, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4546, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  86.0576923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [6 9 8 5 0 3 7 4 2]\n",
      "[1. 0. 1. 0. 1. 0. 1. 1. 1. 1.]\n",
      "loss after my code:  0.17953003652846702\n",
      "train loss after my code:  0.1580074232029173\n",
      "val accuracy:  83.41346153846155\n",
      "test accuracy:  88.22463768115942\n",
      "5\n",
      "full train loss:  tensor(0.3117, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5591, device='cuda:0', dtype=torch.float64)\n",
      "[10.81730769  4.80769231  8.41346154  5.76923077  9.85576923  2.88461538\n",
      "  6.25       16.82692308  6.25       10.33653846]\n",
      "val accuracy before bandits:  82.21153846153845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [6 9 8 0 5 7 4 3 2]\n",
      "[1. 0. 1. 1. 0. 0. 0. 0. 1. 0.]\n",
      "loss after my code:  0.13991698662429666\n",
      "train loss after my code:  0.14427295514741334\n",
      "[11.29807692  4.32692308  8.89423077  7.45192308 13.22115385  2.88461538\n",
      "  6.73076923 14.18269231  6.49038462 10.57692308]\n",
      "val accuracy:  86.0576923076923\n",
      "[10.6884058   4.52898551  9.05797101  7.60869565 13.4057971   2.7173913\n",
      "  7.60869565 14.49275362  6.70289855 10.50724638]\n",
      "test accuracy:  87.31884057971014\n",
      "6\n",
      "full train loss:  tensor(0.1505, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2553, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  87.98076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [8 6 0 9 5 3 7 4 2]\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "loss after my code:  0.11923981206654208\n",
      "train loss after my code:  0.10210093205259792\n",
      "val accuracy:  89.90384615384616\n",
      "test accuracy:  92.21014492753623\n",
      "7\n",
      "full train loss:  tensor(0.1319, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2681, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  87.25961538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [8 6 0 9 5 3 7 4 2]\n",
      "[1. 0. 1. 1. 0. 0. 0. 1. 1. 0.]\n",
      "loss after my code:  0.18750517875684883\n",
      "train loss after my code:  0.11621966309748621\n",
      "val accuracy:  86.53846153846155\n",
      "test accuracy:  86.23188405797102\n",
      "8\n",
      "full train loss:  tensor(0.1974, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3090, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  87.01923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [8 0 6 9 3 7 5 2 4]\n",
      "[1. 0. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "loss after my code:  0.16996271447775904\n",
      "train loss after my code:  0.14609510307927898\n",
      "val accuracy:  83.65384615384616\n",
      "test accuracy:  84.60144927536231\n",
      "9\n",
      "full train loss:  tensor(0.2474, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4365, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  86.0576923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [0 8 9 6 3 7 5 2 4]\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "loss after my code:  0.185379487926885\n",
      "train loss after my code:  0.10315709153940995\n",
      "val accuracy:  86.77884615384616\n",
      "test accuracy:  86.77536231884058\n",
      "10\n",
      "full train loss:  tensor(0.1803, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5034, device='cuda:0', dtype=torch.float64)\n",
      "[11.29807692  4.56730769  7.93269231  8.17307692 13.46153846  2.88461538\n",
      "  4.32692308 16.58653846  6.73076923 10.57692308]\n",
      "val accuracy before bandits:  86.53846153846155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [0 8 9 6 3 7 5 2 4]\n",
      "[0. 0. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      "loss after my code:  0.17281940400334747\n",
      "train loss after my code:  0.12079569142619101\n",
      "[11.29807692  4.56730769  6.73076923  8.41346154 13.70192308  2.88461538\n",
      "  6.73076923 11.29807692  6.73076923 10.57692308]\n",
      "val accuracy:  82.9326923076923\n",
      "[11.23188406  4.52898551  5.61594203  8.69565217 13.76811594  2.89855072\n",
      "  7.60869565 11.77536232  6.70289855 10.32608696]\n",
      "test accuracy:  83.15217391304348\n",
      "11\n",
      "full train loss:  tensor(0.0842, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1485, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.0673076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [8 0 6 3 9 7 5 2 4]\n",
      "[1. 0. 0. 1. 1. 0. 1. 1. 1. 1.]\n",
      "loss after my code:  0.09650440899215092\n",
      "train loss after my code:  0.06622291654837799\n",
      "val accuracy:  91.58653846153845\n",
      "test accuracy:  92.7536231884058\n",
      "12\n",
      "full train loss:  tensor(0.0695, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1274, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  90.38461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [8 0 6 3 9 7 5 4 2]\n",
      "[1. 0. 0. 1. 1. 0. 1. 1. 0. 0.]\n",
      "loss after my code:  0.09600419091111782\n",
      "train loss after my code:  0.05442204674780749\n",
      "val accuracy:  90.625\n",
      "test accuracy:  91.12318840579711\n",
      "13\n",
      "full train loss:  tensor(0.1261, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2078, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  87.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [8 0 6 3 9 7 4 5 2]\n",
      "[1. 0. 0. 0. 1. 0. 1. 0. 1. 1.]\n",
      "loss after my code:  0.16503662956667828\n",
      "train loss after my code:  0.14071889675832822\n",
      "val accuracy:  84.375\n",
      "test accuracy:  84.42028985507247\n",
      "14\n",
      "full train loss:  tensor(0.0481, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1216, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  94.47115384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [8 0 6 3 9 7 4 5 2]\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "loss after my code:  0.08979930010757226\n",
      "train loss after my code:  0.0543319833262939\n",
      "val accuracy:  93.99038461538461\n",
      "test accuracy:  95.1086956521739\n",
      "15\n",
      "full train loss:  tensor(0.0502, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1208, device='cuda:0', dtype=torch.float64)\n",
      "[10.81730769  4.56730769  9.375       8.41346154 13.94230769  3.125\n",
      "  6.97115385 16.58653846  6.73076923 10.09615385]\n",
      "val accuracy before bandits:  90.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [8 0 6 9 3 7 4 5 2]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
      "loss after my code:  0.10691395225822617\n",
      "train loss after my code:  0.06585379953720713\n",
      "[10.81730769  4.56730769  9.375       8.41346154 13.94230769  3.125\n",
      "  6.97115385 15.86538462  6.73076923 10.09615385]\n",
      "val accuracy:  89.90384615384616\n",
      "[10.50724638  4.52898551  8.87681159  8.87681159 13.76811594  2.89855072\n",
      "  7.60869565 15.39855072  6.70289855  9.96376812]\n",
      "test accuracy:  89.13043478260869\n",
      "16\n",
      "full train loss:  tensor(0.1180, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1677, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  88.9423076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [8 0 6 9 3 7 4 5 2]\n",
      "[1. 0. 1. 0. 0. 0. 1. 1. 0. 0.]\n",
      "loss after my code:  0.11551805940044571\n",
      "train loss after my code:  0.060609748210981335\n",
      "val accuracy:  93.02884615384616\n",
      "test accuracy:  93.84057971014492\n",
      "17\n",
      "full train loss:  tensor(0.0464, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1186, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.3076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [8 0 6 9 7 3 4 2 5]\n",
      "[1. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "loss after my code:  0.08385693841875635\n",
      "train loss after my code:  0.04304816488417735\n",
      "val accuracy:  94.47115384615384\n",
      "test accuracy:  94.02173913043478\n",
      "18\n",
      "full train loss:  tensor(0.0222, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1205, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.26923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [0 8 6 7 9 3 4 2 5]\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "loss after my code:  0.10913285448431204\n",
      "train loss after my code:  0.05424037449746431\n",
      "val accuracy:  91.34615384615384\n",
      "test accuracy:  92.7536231884058\n",
      "19\n",
      "full train loss:  tensor(0.0213, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1434, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  93.26923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [0 8 6 7 9 3 4 2 5]\n",
      "[1. 0. 1. 1. 1. 0. 1. 1. 0. 0.]\n",
      "loss after my code:  0.1284204612805796\n",
      "train loss after my code:  0.04291362940708886\n",
      "val accuracy:  91.34615384615384\n",
      "test accuracy:  92.21014492753623\n",
      "20\n",
      "full train loss:  tensor(0.0222, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1141, device='cuda:0', dtype=torch.float64)\n",
      "[10.81730769  4.80769231  9.61538462  6.97115385 13.70192308  3.36538462\n",
      "  6.73076923 18.99038462  6.73076923 10.57692308]\n",
      "val accuracy before bandits:  92.3076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [0 6 8 7 3 9 4 2 5]\n",
      "[1. 0. 1. 0. 1. 0. 1. 1. 1. 0.]\n",
      "loss after my code:  0.102241088898375\n",
      "train loss after my code:  0.03406102893496676\n",
      "[10.81730769  4.80769231  9.375       6.97115385 13.70192308  3.36538462\n",
      "  6.73076923 19.23076923  6.73076923 10.57692308]\n",
      "val accuracy:  92.3076923076923\n",
      "[10.14492754  4.89130435  9.42028986  8.87681159 13.22463768  2.89855072\n",
      "  7.60869565 20.28985507  6.70289855 10.32608696]\n",
      "test accuracy:  94.38405797101449\n",
      "21\n",
      "full train loss:  tensor(0.0384, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2207, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.54807692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [0 6 8 7 3 9 4 2 5]\n",
      "[1. 0. 1. 1. 1. 0. 1. 1. 1. 0.]\n",
      "loss after my code:  0.1986576152591462\n",
      "train loss after my code:  0.03528764905517825\n",
      "val accuracy:  93.26923076923077\n",
      "test accuracy:  90.03623188405797\n",
      "22\n",
      "full train loss:  tensor(0.0139, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1247, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  94.71153846153845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [0 6 8 7 3 4 9 2 5]\n",
      "[1. 0. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "loss after my code:  0.11473853327891549\n",
      "train loss after my code:  0.018277253094958416\n",
      "val accuracy:  95.1923076923077\n",
      "test accuracy:  94.02173913043478\n",
      "23\n",
      "full train loss:  tensor(0.0174, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2131, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.54807692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [0 6 8 7 3 4 9 2 5]\n",
      "[1. 0. 1. 1. 1. 0. 1. 1. 1. 0.]\n",
      "loss after my code:  0.20317335927825428\n",
      "train loss after my code:  0.0402307553539473\n",
      "val accuracy:  90.625\n",
      "test accuracy:  89.67391304347827\n",
      "24\n",
      "full train loss:  tensor(0.0328, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1856, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.58653846153845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [0 6 8 7 3 4 2 9 5]\n",
      "[1. 0. 0. 1. 1. 0. 1. 1. 0. 1.]\n",
      "loss after my code:  0.16976154800897825\n",
      "train loss after my code:  0.06314463690046976\n",
      "val accuracy:  90.86538461538461\n",
      "test accuracy:  90.39855072463769\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "settings, save_dir = init()\n",
    "import collections\n",
    "from time import time\n",
    "import random\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pandas\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "experiment_name = settings['experiment_name']\n",
    "test = settings['type']\n",
    "n_epochs = 25 #settings['n_epochs']\n",
    "patients_left = [x for x in range(1,11)]\n",
    "print(patients_left)\n",
    "p2p = P2P_AFPL(patients_left,9, test)\n",
    "accuracies_mine3 = p2p.loop(n_epochs, p2p, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "82d6da98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "0\n",
      "full train loss:  tensor(0.8770, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.1211, device='cuda:0', dtype=torch.float64)\n",
      "[5.04807692 1.92307692 6.49038462 5.28846154 9.13461538 2.16346154\n",
      " 6.25       9.85576923 2.64423077 6.49038462]\n",
      "val accuracy before bandits:  55.28846153846154\n",
      "selected clients UCB:  [9 8 7 6 5 4 3 2 0]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.2859861139561108\n",
      "train loss after my code:  0.19851739734617108\n",
      "[10.81730769  1.92307692  7.93269231  5.28846154 12.98076923  1.44230769\n",
      "  6.73076923 17.54807692  4.32692308 10.33653846]\n",
      "val accuracy:  79.32692307692307\n",
      "[10.14492754  2.17391304  8.15217391  7.06521739 11.95652174  0.9057971\n",
      "  7.24637681 18.11594203  4.16666667  9.96376812]\n",
      "test accuracy:  79.8913043478261\n",
      "1\n",
      "full train loss:  tensor(0.6245, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5831, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  78.36538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [9 8 7 6 5 4 3 2 1]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "loss after my code:  0.20980250516946303\n",
      "train loss after my code:  0.13914924381372462\n",
      "val accuracy:  86.29807692307693\n",
      "test accuracy:  86.95652173913044\n",
      "2\n",
      "full train loss:  tensor(0.4712, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.5346, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  75.48076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 0 9 8 7 6 4 3 2]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "loss after my code:  0.1479667285530356\n",
      "train loss after my code:  0.10086868863693085\n",
      "val accuracy:  88.22115384615384\n",
      "test accuracy:  89.85507246376811\n",
      "3\n",
      "full train loss:  tensor(0.1273, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2266, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  88.70192307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 0 9 8 7 6 4 3 2]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.135955988992845\n",
      "train loss after my code:  0.09411351460200368\n",
      "val accuracy:  88.46153846153845\n",
      "test accuracy:  89.13043478260869\n",
      "4\n",
      "full train loss:  tensor(0.2132, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3077, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  84.13461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 3 0 9 8 7 6 4 2]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "loss after my code:  0.1543432492502697\n",
      "train loss after my code:  0.10801937163198476\n",
      "val accuracy:  82.6923076923077\n",
      "test accuracy:  84.60144927536231\n",
      "5\n",
      "full train loss:  tensor(0.2490, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.3520, device='cuda:0', dtype=torch.float64)\n",
      "[ 9.61538462  3.60576923  9.61538462  5.76923077 13.70192308  2.16346154\n",
      "  6.25       15.38461538  6.49038462  7.69230769]\n",
      "val accuracy before bandits:  80.28846153846155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 3 0 9 8 7 6 4 2]\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "loss after my code:  0.15839623182180834\n",
      "train loss after my code:  0.10153259699840599\n",
      "[10.09615385  4.08653846  9.61538462  7.21153846 13.70192308  2.40384615\n",
      "  6.49038462 12.01923077  6.73076923 10.09615385]\n",
      "val accuracy:  82.45192307692307\n",
      "[ 9.42028986  4.89130435  9.7826087   7.42753623 13.76811594  1.99275362\n",
      "  7.78985507 11.77536232  6.70289855  9.05797101]\n",
      "test accuracy:  82.6086956521739\n",
      "6\n",
      "full train loss:  tensor(0.3781, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.4849, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  78.36538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 3 2 0 9 8 7 6 4]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "loss after my code:  0.125025594508371\n",
      "train loss after my code:  0.06691477157951756\n",
      "val accuracy:  89.42307692307693\n",
      "test accuracy:  90.21739130434783\n",
      "7\n",
      "full train loss:  tensor(0.1821, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2740, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  78.84615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 3 2 0 9 8 7 6 4]\n",
      "[0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "loss after my code:  0.14605296392283457\n",
      "train loss after my code:  0.10547486762261223\n",
      "val accuracy:  81.73076923076923\n",
      "test accuracy:  84.60144927536231\n",
      "8\n",
      "full train loss:  tensor(0.1485, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2294, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  87.98076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 6 3 2 0 9 8 7 4]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.11799463179684208\n",
      "train loss after my code:  0.07022959849959852\n",
      "val accuracy:  90.38461538461539\n",
      "test accuracy:  92.02898550724638\n",
      "9\n",
      "full train loss:  tensor(0.1574, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2514, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  85.33653846153845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 3 6 2 0 9 8 7 4]\n",
      "[0. 0. 0. 1. 0. 1. 1. 0. 0. 1.]\n",
      "loss after my code:  0.1390104027692879\n",
      "train loss after my code:  0.07823144537877519\n",
      "val accuracy:  86.29807692307693\n",
      "test accuracy:  89.4927536231884\n",
      "10\n",
      "full train loss:  tensor(0.1014, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2085, device='cuda:0', dtype=torch.float64)\n",
      "[11.29807692  4.56730769  8.89423077  6.97115385 13.22115385  1.92307692\n",
      "  6.49038462 18.26923077  6.25       10.57692308]\n",
      "val accuracy before bandits:  88.46153846153845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 3 6 9 2 0 8 7 4]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "loss after my code:  0.12051520788536253\n",
      "train loss after my code:  0.04543668735558795\n",
      "[11.29807692  4.56730769  9.85576923  6.97115385 13.70192308  1.92307692\n",
      "  6.49038462 17.78846154  6.73076923 10.57692308]\n",
      "val accuracy:  89.90384615384616\n",
      "[10.86956522  4.89130435  9.60144928  8.69565217 13.4057971   2.35507246\n",
      "  7.60869565 17.75362319  6.52173913 10.32608696]\n",
      "test accuracy:  92.02898550724638\n",
      "11\n",
      "full train loss:  tensor(0.0305, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1171, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.78846153846155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 3 6 9 2 0 8 7 4]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.08704881776682821\n",
      "train loss after my code:  0.03480990387961946\n",
      "val accuracy:  92.78846153846155\n",
      "test accuracy:  94.38405797101449\n",
      "12\n",
      "full train loss:  tensor(0.1154, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2467, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.34615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 3 6 9 2 0 8 7 4]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "loss after my code:  0.16458391995429297\n",
      "train loss after my code:  0.043014492707878375\n",
      "val accuracy:  89.1826923076923\n",
      "test accuracy:  91.84782608695652\n",
      "13\n",
      "full train loss:  tensor(0.1048, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2222, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  86.53846153846155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 3 6 9 2 0 8 7 4]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.1060180957581563\n",
      "train loss after my code:  0.025304686498466282\n",
      "val accuracy:  90.14423076923077\n",
      "test accuracy:  94.56521739130434\n",
      "14\n",
      "full train loss:  tensor(0.0820, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1740, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  86.29807692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 3 6 9 2 0 8 7 4]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.10642482738297025\n",
      "train loss after my code:  0.03571202422333433\n",
      "val accuracy:  90.38461538461539\n",
      "test accuracy:  92.3913043478261\n",
      "15\n",
      "full train loss:  tensor(0.0537, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1748, device='cuda:0', dtype=torch.float64)\n",
      "[11.05769231  4.56730769  9.13461538  7.69230769 13.46153846  2.88461538\n",
      "  7.21153846 19.23076923  6.73076923  9.85576923]\n",
      "val accuracy before bandits:  91.82692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 3 6 9 2 0 8 7 4]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "loss after my code:  0.10396844296557294\n",
      "train loss after my code:  0.0313634137605565\n",
      "[11.05769231  4.56730769  8.41346154  7.21153846 13.46153846  2.88461538\n",
      "  6.73076923 19.23076923  6.73076923 10.57692308]\n",
      "val accuracy:  90.86538461538461\n",
      "[10.32608696  4.89130435  8.33333333  8.69565217 13.22463768  3.07971014\n",
      "  7.78985507 19.56521739  6.70289855 10.32608696]\n",
      "test accuracy:  92.93478260869566\n",
      "16\n",
      "full train loss:  tensor(0.0784, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2186, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  89.66346153846155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 6 3 9 2 0 8 7 4]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "loss after my code:  0.1322800353754316\n",
      "train loss after my code:  0.03838820394266001\n",
      "val accuracy:  91.34615384615384\n",
      "test accuracy:  93.11594202898551\n",
      "17\n",
      "full train loss:  tensor(0.0829, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.2336, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  90.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 6 3 9 8 2 0 7 4]\n",
      "[0. 0. 0. 1. 0. 1. 0. 1. 1. 1.]\n",
      "loss after my code:  0.12491340379913829\n",
      "train loss after my code:  0.027139696928634733\n",
      "val accuracy:  92.0673076923077\n",
      "test accuracy:  93.29710144927536\n",
      "18\n",
      "full train loss:  tensor(0.0229, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1331, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  91.58653846153845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 3 9 6 8 7 2 0 4]\n",
      "[0. 0. 1. 0. 1. 0. 1. 0. 1. 1.]\n",
      "loss after my code:  0.11089912262509033\n",
      "train loss after my code:  0.01202027156621975\n",
      "val accuracy:  92.3076923076923\n",
      "test accuracy:  92.7536231884058\n",
      "19\n",
      "full train loss:  tensor(0.0269, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1279, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.54807692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 9 6 3 8 2 7 4 0]\n",
      "[0. 0. 0. 1. 1. 0. 1. 0. 1. 0.]\n",
      "loss after my code:  0.10206222968442806\n",
      "train loss after my code:  0.026740700373149774\n",
      "val accuracy:  91.58653846153845\n",
      "test accuracy:  92.93478260869566\n",
      "20\n",
      "full train loss:  tensor(0.0197, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1194, device='cuda:0', dtype=torch.float64)\n",
      "[ 9.61538462  4.56730769  9.61538462  7.69230769 13.70192308  3.125\n",
      "  6.73076923 18.50961538  6.73076923 10.57692308]\n",
      "val accuracy before bandits:  90.86538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 6 3 9 8 4 2 7 0]\n",
      "[0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      "loss after my code:  0.0919967827617351\n",
      "train loss after my code:  0.026993161194650634\n",
      "[10.09615385  4.80769231  9.375       7.93269231 13.70192308  3.125\n",
      "  7.21153846 18.26923077  6.73076923 10.57692308]\n",
      "val accuracy:  91.82692307692307\n",
      "[ 9.05797101  4.89130435  9.60144928  8.87681159 13.58695652  3.07971014\n",
      "  7.60869565 18.29710145  6.70289855 10.32608696]\n",
      "test accuracy:  92.02898550724638\n",
      "21\n",
      "full train loss:  tensor(0.0383, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1806, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.54807692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 6 9 3 8 4 2 7 0]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "loss after my code:  0.12320098491002296\n",
      "train loss after my code:  0.024341524616385585\n",
      "val accuracy:  91.58653846153845\n",
      "test accuracy:  92.93478260869566\n",
      "22\n",
      "full train loss:  tensor(0.0154, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1303, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.3076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 6 9 3 8 4 2 7 0]\n",
      "[0. 0. 1. 0. 1. 0. 1. 1. 1. 1.]\n",
      "loss after my code:  0.10632653406971411\n",
      "train loss after my code:  0.014540731382050458\n",
      "val accuracy:  91.34615384615384\n",
      "test accuracy:  93.84057971014492\n",
      "23\n",
      "full train loss:  tensor(0.0097, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1356, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.0673076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 6 9 8 4 3 2 7 0]\n",
      "[0. 0. 1. 1. 1. 0. 1. 0. 0. 1.]\n",
      "loss after my code:  0.12487424022108592\n",
      "train loss after my code:  0.014221520225829324\n",
      "val accuracy:  92.3076923076923\n",
      "test accuracy:  94.92753623188406\n",
      "24\n",
      "full train loss:  tensor(0.0113, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.1165, device='cuda:0', dtype=torch.float64)\n",
      "val accuracy before bandits:  92.78846153846155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected clients UCB:  [5 6 9 4 3 8 2 7 0]\n",
      "[0. 0. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "loss after my code:  0.0950316985156225\n",
      "train loss after my code:  0.012914950289718471\n",
      "val accuracy:  92.0673076923077\n",
      "test accuracy:  94.56521739130434\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "settings, save_dir = init()\n",
    "import collections\n",
    "from time import time\n",
    "import random\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pandas\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "experiment_name = settings['experiment_name']\n",
    "test = settings['type']\n",
    "n_epochs = 25 #settings['n_epochs']\n",
    "patients_left = [x for x in range(1,11)]\n",
    "print(patients_left)\n",
    "p2p = P2P_AFPL(patients_left,9, test)\n",
    "accuracies_mine2 = p2p.loop(n_epochs, p2p, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "15c1bfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0. 10.  8.  9.  2.  6. 13. 16.  9.]\n",
      " [ 6.  0. 19.  5. 16.  4. 18. 10. 14. 15.]\n",
      " [ 8.  5.  0. 10. 16.  2. 17. 11. 21. 16.]\n",
      " [ 7.  7. 21.  0. 16.  5. 14. 11. 18. 12.]\n",
      " [ 8.  7. 14.  9.  0.  1. 19. 11. 18. 14.]\n",
      " [ 5. 10.  9.  6.  8.  0. 14.  7.  9.  6.]\n",
      " [ 7.  9. 15.  3. 17.  2.  1.  8. 16. 13.]\n",
      " [ 5.  3.  5.  5.  4.  0.  4.  0. 17. 10.]\n",
      " [10.  5. 19. 15. 12.  2. 13. 13.  0. 14.]\n",
      " [ 8.  8. 15.  4. 17.  1. 12. 10. 10.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.transpose(phi))\n",
    "fig = plt.figure()\n",
    "plt.matshow(10-np.transpose(phi),cmap='gray')\n",
    "plt.xticks(np.arange(0,10,1));\n",
    "plt.yticks(np.arange(0,10,1)); # diagonal should be zeros but I fucked it up a little "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
