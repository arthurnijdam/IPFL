{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3662,
     "status": "ok",
     "timestamp": 1689631515231,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "pEEQKRK6udJH",
    "outputId": "3a75b7ac-5429-4f8f-ccc6-4fba2835bcb6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from os.path import join as osj\n",
    "from bisect import bisect\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import json\n",
    "#!pip install wfdb\n",
    "import wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1689631511242,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "liJLGi6XuKZn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.special import binom\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as tt\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.init as init\n",
    "\n",
    "from collections import Counter\n",
    "import operator\n",
    "import copy\n",
    "from itertools import product,combinations\n",
    "from time import time\n",
    "#from IPython.core.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## code extracted from https://www.kaggle.com/code/graymant/breast-cancer-diagnosis-with-pytorch\n",
    "## SV code extracted from https://"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/4\n",
      "local 25\n",
      "mean:  98.8088845496705\n",
      "std:  0.08650253915874684\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('2/4')\n",
    "experiments = ['MNIST_PRTFL_1','MNIST_PRTFL_2','MNIST_PRTFL_3','MNIST_PRTFL_4','MNIST_PRTFL_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/4\n",
      "local 10\n",
      "mean:  0.37913764645010983\n",
      "std:  0.011972140525672706\n",
      "local 25\n",
      "mean:  0.4111953569029286\n",
      "std:  0.03609604254985723\n",
      "local 25\n",
      "mean:  0.5306014367466483\n",
      "std:  0.05403436226461047\n",
      "local 100\n",
      "mean:  0.7230225301768556\n",
      "std:  0.0432305128397805\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('2/4')\n",
    "experiments = ['MIT_PRTFL_010_1','MIT_PRTFL_010_2','MIT_PRTFL_010_3','MIT_PRTFL_010_4','MIT_PRTFL_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "experiments = ['MIT_PRTFL_025_1','MIT_PRTFL_025_2','MIT_PRTFL_025_3','MIT_PRTFL_025_4','MIT_PRTFL_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "experiments = ['MIT_PRTFL_050_1','MIT_PRTFL_050_2','MIT_PRTFL_050_3','MIT_PRTFL_050_4','MIT_PRTFL_050_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "experiments = ['MIT_PRTFL_1','MIT_PRTFL_2','MIT_PRTFL_3','MIT_PRTFL_4','MIT_PRTFL_5']\n",
    "print('local 100')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/4\n",
      "local 10\n",
      "mean:  66.91391629806057\n",
      "std:  4.3647076882872184\n",
      "local 25\n",
      "mean:  76.13473970738346\n",
      "std:  3.2253715779104137\n",
      "local 25\n",
      "mean:  80.76216400136101\n",
      "std:  1.039545774967175\n",
      "local 100\n",
      "mean:  83.91289554270159\n",
      "std:  0.843495089886147\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('2/4')\n",
    "experiments = ['CHB_PRTFL_010_1','CHB_PRTFL_010_2','CHB_PRTFL_010_3','CHB_PRTFL_010_4','CHB_PRTFL_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "experiments = ['CHB_PRTFL_025_1','CHB_PRTFL_025_2','CHB_PRTFL_025_3','CHB_PRTFL_025_4','CHB_PRTFL_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "experiments = ['CHB_PRTFL_050_1','CHB_PRTFL_050_2','CHB_PRTFL_050_3','CHB_PRTFL_050_4','CHB_PRTFL_050_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "experiments = ['CHB_PRTFL_1','CHB_PRTFL_2','CHB_PRTFL_3','CHB_PRTFL_4','CHB_PRTFL_5']\n",
    "print('local 100')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/4\n",
      "local 25\n",
      "mean:  89.65584574078594\n",
      "std:  3.5661366866037185\n",
      "local 50\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "checkpoints_bandits/MNIST_federated_24_050_1/test_accuracy.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,experiment \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(experiments): \n\u001b[0;32m---> 17\u001b[0m     test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheckpoints_bandits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_accuracy.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m   \u001b[38;5;66;03m#  print(test_accuracy)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     accuracies\u001b[38;5;241m.\u001b[39mappend(test_accuracy)\n",
      "File \u001b[0;32m/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/lib/npyio.py:1308\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1306\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1308\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/lib/npyio.py:955\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m    953\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fname)\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 955\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datasource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m         encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fh, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/lib/_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mimer/NOBACKUP/groups/snic2022-22-122/arthur/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/lib/_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    531\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: checkpoints_bandits/MNIST_federated_24_050_1/test_accuracy.txt not found."
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('2/4')\n",
    "experiments = ['MNIST_federated_24_025_1','MNIST_federated_24_025_2','MNIST_federated_24_025_3','MNIST_federated_24_025_4','MNIST_federated_24_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "experiments = ['MNIST_federated_24_050_1','MNIST_federated_24_050_2','MNIST_federated_24_050_3','MNIST_federated_24_050_4','MNIST_federated_24_050_5']\n",
    "print('local 50')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "print('3/4')\n",
    "experiments = ['MNIST_federated_34_025_1','MNIST_federated_34_025_2','MNIST_federated_34_025_3','MNIST_federated_34_025_4','MNIST_federated_34_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "experiments = ['MNIST_federated_34_050_1','MNIST_federated_34_050_2','MNIST_federated_34_050_3','MNIST_federated_34_050_4','MNIST_federated_34_050_5']\n",
    "print('local 50')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/4\n",
      "local 25\n",
      "mean:  84.26165486941666\n",
      "std:  3.6025037795040347\n",
      "local 50\n",
      "mean:  91.90627288259702\n",
      "std:  0.5027358353113183\n",
      "3/4\n",
      "local 25\n",
      "mean:  85.9249937075258\n",
      "std:  1.2245510479402606\n",
      "local 50\n",
      "mean:  92.36345330984142\n",
      "std:  0.5912729669278042\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('2/4')\n",
    "experiments = ['MNIST_optimal_24_025_1','MNIST_optimal_24_025_2','MNIST_optimal_24_025_3','MNIST_optimal_24_025_4','MNIST_optimal_24_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "experiments = ['MNIST_optimal_24_050_1','MNIST_optimal_24_050_2','MNIST_optimal_24_050_3','MNIST_optimal_24_050_4','MNIST_optimal_24_050_5']\n",
    "print('local 50')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "print('3/4')\n",
    "experiments = ['MNIST_optimal_34_025_1','MNIST_optimal_34_025_2','MNIST_optimal_34_025_3','MNIST_optimal_34_025_4','MNIST_optimal_34_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "experiments = ['MNIST_optimal_34_050_1','MNIST_optimal_34_050_2','MNIST_optimal_34_050_3','MNIST_optimal_34_050_4','MNIST_optimal_34_050_5']\n",
    "print('local 50')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 percent\n",
      "local\n",
      "mean:  45.92628752745912\n",
      "std:  11.678797764800718\n",
      "2 percent\n",
      "bandits\n",
      "mean:  56.24603368318283\n",
      "std:  3.1221237054039115\n"
     ]
    }
   ],
   "source": [
    "print('2 percent')\n",
    "experiments = ['MNIST_local_24_002_1','MNIST_local_24_002_2','MNIST_local_24_002_3','MNIST_local_24_002_4','MNIST_local_24_002_5']\n",
    "print('local')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "print('2 percent')\n",
    "print('bandits')\n",
    "experiments = ['MNIST_bandits_10_24_002_1','MNIST_bandits_10_24_002_2','MNIST_bandits_10_24_002_3','MNIST_bandits_10_24_002_4','MNIST_bandits_10_24_002_5']\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centralized\n",
      "2/4\n",
      "local 10\n",
      "mean:  98.7698315840859\n",
      "std:  0.27855196715035085\n",
      "2/4\n",
      "local 25\n",
      "mean:  99.16524286062972\n",
      "std:  0.028464495459337467\n",
      "local 100\n",
      "mean:  99.48742982670247\n",
      "std:  0.1205671372734042\n",
      "/n\n",
      "centralized\n",
      "3/4\n",
      "local 10\n",
      "mean:  98.79687893279637\n",
      "std:  0.11412820587721847\n",
      "3/4\n",
      "local 25\n",
      "mean:  99.25497105461868\n",
      "std:  0.10631116074474106\n",
      "local 100\n",
      "mean:  99.6073496098666\n",
      "std:  0.0851323157578008\n",
      "4/4\n",
      "local 100\n",
      "mean:  99.63\n",
      "std:  0.09669539802906706\n"
     ]
    }
   ],
   "source": [
    "print('centralized')\n",
    "print('2/4')\n",
    "experiments = ['MNIST_centralized_24_010_1','MNIST_centralized_24_010_2','MNIST_centralized_24_010_3','MNIST_centralized_24_010_4','MNIST_centralized_24_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('2/4')\n",
    "experiments = ['MNIST_centralized_24_025_1','MNIST_centralized_24_025_2','MNIST_centralized_24_025_3','MNIST_centralized_24_025_4','MNIST_centralized_24_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "experiments = ['MNIST_centralized_24_1','MNIST_centralized_24_2','MNIST_centralized_24_3','MNIST_centralized_24_4','MNIST_centralized_24_5']\n",
    "print('local 100')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "print('/n')\n",
    "print('centralized')\n",
    "print('3/4')\n",
    "experiments = ['MNIST_centralized_34_010_1','MNIST_centralized_34_010_2','MNIST_centralized_34_010_3','MNIST_centralized_34_010_4','MNIST_centralized_34_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('3/4')\n",
    "experiments = ['MNIST_centralized_34_025_1','MNIST_centralized_34_025_2','MNIST_centralized_34_025_3','MNIST_centralized_34_025_4','MNIST_centralized_34_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "experiments = ['MNIST_centralized_34_1','MNIST_centralized_34_2','MNIST_centralized_34_3','MNIST_centralized_34_4','MNIST_centralized_34_5']\n",
    "print('local 100')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "print('4/4')\n",
    "experiments = ['MNIST_centralized_44_1','MNIST_centralized_44_2','MNIST_centralized_44_3','MNIST_centralized_44_4','MNIST_centralized_44_5']\n",
    "print('local 100')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFPL 0.25\n",
      "2/4\n",
      "local 10\n",
      "mean:  81.62557969245789\n",
      "std:  8.670992420422865\n",
      "2/4\n",
      "local 25\n",
      "mean:  93.07298022943617\n",
      "std:  3.4066368268835916\n",
      "3/4\n",
      "local 10\n",
      "mean:  88.93531336521521\n",
      "std:  1.9199599921388448\n",
      "2/4\n",
      "local 25\n",
      "mean:  94.83010319657687\n",
      "std:  0.4439045091376516\n",
      "\n",
      "\n",
      "AFPL 0.5\n",
      "2/4\n",
      "local 10\n",
      "mean:  83.84183548938248\n",
      "std:  8.606049468044235\n",
      "2/4\n",
      "local 25\n",
      "mean:  96.01171588967536\n",
      "std:  0.46685243704194046\n",
      "3/4\n",
      "local 10\n",
      "mean:  89.0964007047571\n",
      "std:  3.0996561850923174\n",
      "2/4\n",
      "local 25\n",
      "mean:  95.09187012333248\n",
      "std:  0.4114335110335308\n",
      "\n",
      "\n",
      "AFPL 0.75\n",
      "2/4\n",
      "local 10\n",
      "mean:  90.32462777642178\n",
      "std:  2.675137050595459\n",
      "2/4\n",
      "local 25\n",
      "mean:  96.69026116670736\n",
      "std:  0.6513991930552528\n",
      "3/4\n",
      "local 10\n",
      "mean:  89.92700729927007\n",
      "std:  2.3341276353549123\n",
      "2/4\n",
      "local 25\n",
      "mean:  95.60030203876163\n",
      "std:  0.3980983422052429\n"
     ]
    }
   ],
   "source": [
    "print('AFPL 0.25')\n",
    "print('2/4')\n",
    "experiments = ['MNIST_APFL1_24_010_1','MNIST_APFL1_24_010_2','MNIST_APFL1_24_010_3','MNIST_APFL1_24_010_4','MNIST_APFL1_24_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('2/4')\n",
    "experiments = ['MNIST_APFL1_24_025_1','MNIST_APFL1_24_025_2','MNIST_APFL1_24_025_3','MNIST_APFL1_24_025_4','MNIST_APFL1_24_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('3/4')\n",
    "experiments = ['MNIST_APFL1_34_010_1','MNIST_APFL1_34_010_2','MNIST_APFL1_34_010_3','MNIST_APFL1_34_010_4','MNIST_APFL1_34_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('2/4')\n",
    "experiments = ['MNIST_APFL1_34_025_1','MNIST_APFL1_34_025_2','MNIST_APFL1_34_025_3','MNIST_APFL1_34_025_4','MNIST_APFL1_34_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "print('\\n')\n",
    "print('AFPL 0.5')\n",
    "print('2/4')\n",
    "experiments = ['MNIST_APFL2_24_010_1','MNIST_APFL2_24_010_2','MNIST_APFL2_24_010_3','MNIST_APFL2_24_010_4','MNIST_APFL2_24_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('2/4')\n",
    "experiments = ['MNIST_APFL2_24_025_1','MNIST_APFL2_24_025_2','MNIST_APFL2_24_025_3','MNIST_APFL2_24_025_4','MNIST_APFL2_24_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('3/4')\n",
    "experiments = ['MNIST_APFL2_34_010_1','MNIST_APFL2_34_010_2','MNIST_APFL2_34_010_3','MNIST_APFL2_34_010_4','MNIST_APFL2_34_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('2/4')\n",
    "experiments = ['MNIST_APFL2_34_025_1','MNIST_APFL2_34_025_2','MNIST_APFL2_34_025_3','MNIST_APFL2_34_025_4','MNIST_APFL2_34_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "print('\\n')\n",
    "print('AFPL 0.75')\n",
    "print('2/4')\n",
    "experiments = ['MNIST_APFL3_24_010_1','MNIST_APFL3_24_010_2','MNIST_APFL3_24_010_3','MNIST_APFL3_24_010_4','MNIST_APFL3_24_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('2/4')\n",
    "experiments = ['MNIST_APFL3_24_025_1','MNIST_APFL3_24_025_2','MNIST_APFL3_24_025_3','MNIST_APFL3_24_025_4','MNIST_APFL3_24_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('3/4')\n",
    "experiments = ['MNIST_APFL3_34_010_1','MNIST_APFL3_34_010_2','MNIST_APFL3_34_010_3','MNIST_APFL3_34_010_4','MNIST_APFL3_34_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('2/4')\n",
    "experiments = ['MNIST_APFL3_34_025_1','MNIST_APFL3_34_025_2','MNIST_APFL3_34_025_3','MNIST_APFL3_34_025_4','MNIST_APFL3_34_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandits 5\n",
      "2/4\n",
      "local 10\n",
      "mean:  95.20624847449353\n",
      "std:  1.2850443453276388\n",
      "2/4\n",
      "local 25\n",
      "mean:  98.05223334146936\n",
      "std:  0.11067399608254423\n",
      "3/4\n",
      "local 10\n",
      "mean:  87.37477976340298\n",
      "std:  0.9364554733358477\n",
      "2/4\n",
      "local 25\n",
      "mean:  96.39567077774981\n",
      "std:  0.48163371960191237\n",
      "bandits 25\n",
      "2/4\n",
      "local 10\n",
      "mean:  96.17769099340981\n",
      "std:  0.5601327386826855\n",
      "2/4\n",
      "local 25\n",
      "mean:  98.24749816939223\n",
      "std:  0.14348975793702126\n",
      "3/4\n",
      "local 10\n",
      "mean:  87.91844953435692\n",
      "std:  0.9634515725791025\n",
      "2/4\n",
      "local 25\n",
      "mean:  96.68260760130883\n",
      "std:  0.30966134405698215\n",
      "bandits 100\n",
      "3/4\n",
      "local 10\n",
      "mean:  88.71885225270577\n",
      "std:  0.9613978077702017\n",
      "3/4\n",
      "local 25\n",
      "mean:  96.67253964258747\n",
      "std:  0.28935530557664124\n",
      "2/4\n",
      "local 10\n",
      "mean:  96.18257261410788\n",
      "std:  0.9827225049067857\n",
      "2/4\n",
      "local 25\n",
      "mean:  98.0619965828655\n",
      "std:  0.1688222256850429\n"
     ]
    }
   ],
   "source": [
    "print('bandits 5')\n",
    "print('2/4')\n",
    "experiments = ['MNIST_bandits_5_24_010_1','MNIST_bandits_5_24_010_2','MNIST_bandits_5_24_010_3','MNIST_bandits_5_24_010_4','MNIST_bandits_5_24_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('2/4')\n",
    "experiments = ['MNIST_bandits_5_24_025_1','MNIST_bandits_5_24_025_2','MNIST_bandits_5_24_025_3','MNIST_bandits_5_24_025_4','MNIST_bandits_5_24_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('3/4')\n",
    "experiments = ['MNIST_bandits_5_34_010_1','MNIST_bandits_5_34_010_2','MNIST_bandits_5_34_010_3','MNIST_bandits_5_34_010_4','MNIST_bandits_5_34_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('2/4')\n",
    "experiments = ['MNIST_bandits_5_34_025_1','MNIST_bandits_5_34_025_2','MNIST_bandits_5_34_025_3','MNIST_bandits_5_34_025_4','MNIST_bandits_5_34_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "print('bandits 25')\n",
    "print('2/4')\n",
    "experiments = ['MNIST_bandits_25_24_010_1','MNIST_bandits_25_24_010_2','MNIST_bandits_25_24_010_3','MNIST_bandits_25_24_010_4','MNIST_bandits_25_24_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('2/4')\n",
    "experiments = ['MNIST_bandits_25_24_025_1','MNIST_bandits_25_24_025_2','MNIST_bandits_25_24_025_3','MNIST_bandits_25_24_025_4','MNIST_bandits_25_24_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "print('3/4')\n",
    "experiments = ['MNIST_bandits_25_34_010_1','MNIST_bandits_25_34_010_2','MNIST_bandits_25_34_010_3','MNIST_bandits_25_34_010_4','MNIST_bandits_25_34_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('2/4')\n",
    "experiments = ['MNIST_bandits_25_34_025_1','MNIST_bandits_25_34_025_2','MNIST_bandits_25_34_025_3','MNIST_bandits_25_34_025_4','MNIST_bandits_25_34_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "print('bandits 100')\n",
    "print('3/4')\n",
    "experiments = ['MNIST_bandits_100_24_010_1','MNIST_bandits_100_24_010_2','MNIST_bandits_100_24_010_3','MNIST_bandits_100_24_010_4','MNIST_bandits_100_24_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('3/4')\n",
    "experiments = ['MNIST_bandits_100_24_025_1','MNIST_bandits_100_24_025_2','MNIST_bandits_100_24_025_3','MNIST_bandits_100_24_025_4','MNIST_bandits_100_24_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "print('2/4')\n",
    "experiments = ['MNIST_bandits_100_34_010_1','MNIST_bandits_100_34_010_2','MNIST_bandits_100_34_010_3','MNIST_bandits_100_34_010_4','MNIST_bandits_100_34_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('2/4')\n",
    "experiments = ['MNIST_bandits_100_34_025_1','MNIST_bandits_100_34_025_2','MNIST_bandits_100_34_025_3','MNIST_bandits_100_34_025_4','MNIST_bandits_100_34_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n",
      "local 10\n",
      "mean:  89.93204127863075\n",
      "std:  0.9847832694351485\n",
      "2/4\n",
      "local 25\n",
      "mean:  95.62043795620438\n",
      "std:  0.3559560942293252\n",
      "federated\n",
      "local 10\n",
      "mean:  90.56128869871634\n",
      "std:  1.5675006659776312\n",
      "2/4\n",
      "local 25\n",
      "mean:  95.16234583438208\n",
      "std:  0.6205081522498483\n",
      "bandits\n",
      "local 10\n",
      "mean:  86.59954694185754\n",
      "std:  2.1620106248304825\n",
      "2/4\n",
      "local 25\n",
      "mean:  96.8587968789328\n",
      "std:  0.31129372934790644\n",
      "optimal\n",
      "local 10\n",
      "mean:  89.21721620941354\n",
      "std:  2.747215543007968\n",
      "local 25\n",
      "mean:  94.4978605587717\n",
      "std:  0.6537586958544206\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('local')\n",
    "experiments = ['MNIST_local_34_010_1','MNIST_local_34_010_2','MNIST_local_34_010_3','MNIST_local_34_010_4','MNIST_local_34_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('2/4')\n",
    "experiments = ['MNIST_local_34_025_1','MNIST_local_34_025_2','MNIST_local_34_025_3','MNIST_local_34_025_4','MNIST_local_34_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "print('federated')\n",
    "experiments = ['MNIST_federated_34_010_1','MNIST_federated_34_010_2','MNIST_federated_34_010_3','MNIST_federated_34_010_4','MNIST_federated_34_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('2/4')\n",
    "experiments = ['MNIST_federated_34_025_1','MNIST_federated_34_025_2','MNIST_federated_34_025_3','MNIST_federated_34_025_4','MNIST_federated_34_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "print('bandits 10')\n",
    "experiments = ['MNIST_bandits_10_34_010_1','MNIST_bandits_10_34_010_2','MNIST_bandits_10_34_010_3','MNIST_bandits_10_34_010_4','MNIST_bandits_10_34_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('2/4')\n",
    "experiments = ['MNIST_bandits_10_34_025_1','MNIST_bandits_10_34_025_2','MNIST_bandits_10_34_025_3','MNIST_bandits_10_34_025_4','MNIST_bandits_10_34_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('optimal')\n",
    "experiments = ['MNIST_optimal_34_010_1','MNIST_optimal_34_010_2','MNIST_optimal_34_010_3','MNIST_optimal_34_010_4','MNIST_optimal_34_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "experiments = ['MNIST_optimal_34_025_1','MNIST_optimal_34_025_2','MNIST_optimal_34_025_3','MNIST_optimal_34_025_4','MNIST_optimal_34_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n",
      "local 10\n",
      "mean:  95.96289968269465\n",
      "std:  0.20860005486181518\n",
      "2/4\n",
      "local 25\n",
      "mean:  97.42738589211618\n",
      "std:  0.22134799216508846\n",
      "federated\n",
      "local 10\n",
      "mean:  84.4081034903588\n",
      "std:  2.7725456881134716\n",
      "2/4\n",
      "local 25\n",
      "mean:  89.65584574078594\n",
      "std:  3.5661366866037185\n",
      "bandits\n",
      "local 10\n",
      "mean:  95.88967537222359\n",
      "std:  1.0067980259894962\n",
      "2/4\n",
      "local 25\n",
      "mean:  97.96924578960214\n",
      "std:  0.08650253915874684\n",
      "optimal\n",
      "local 10\n",
      "mean:  97.7007566512082\n",
      "std:  0.17492284956962512\n",
      "local 25\n",
      "mean:  98.3402489626556\n",
      "std:  0.1058310148336835\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('local')\n",
    "experiments = ['MNIST_local_24_010_1','MNIST_local_24_010_2','MNIST_local_24_010_3','MNIST_local_24_010_4','MNIST_local_24_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('2/4')\n",
    "experiments = ['MNIST_local_24_025_1','MNIST_local_24_025_2','MNIST_local_24_025_3','MNIST_local_24_025_4','MNIST_local_24_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "print('federated')\n",
    "experiments = ['MNIST_federated_24_010_1','MNIST_federated_24_010_2','MNIST_federated_24_010_3','MNIST_federated_24_010_4','MNIST_federated_24_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('2/4')\n",
    "experiments = ['MNIST_federated_24_025_1','MNIST_federated_24_025_2','MNIST_federated_24_025_3','MNIST_federated_24_025_4','MNIST_federated_24_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "print('bandits')\n",
    "experiments = ['MNIST_bandits_10_24_010_1','MNIST_bandits_10_24_010_2','MNIST_bandits_10_24_010_3','MNIST_bandits_10_24_010_4','MNIST_bandits_10_24_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('2/4')\n",
    "experiments = ['MNIST_bandits_10_24_025_1','MNIST_bandits_10_24_025_2','MNIST_bandits_10_24_025_3','MNIST_bandits_10_24_025_4','MNIST_bandits_10_24_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "print('optimal')\n",
    "experiments = ['MNIST_optimal_24_010_1','MNIST_optimal_24_010_2','MNIST_optimal_24_010_3','MNIST_optimal_24_010_4','MNIST_optimal_24_010_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "experiments = ['MNIST_optimal_24_025_1','MNIST_optimal_24_025_2','MNIST_optimal_24_025_3','MNIST_optimal_24_025_4','MNIST_optimal_24_025_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local 10\n",
      "mean:  73.5352160598843\n",
      "std:  3.1838114358345506\n",
      "local 25\n",
      "mean:  78.76828853351479\n",
      "std:  1.1526452999170442\n",
      "local 50\n",
      "mean:  84.06260632868323\n",
      "std:  0.5153888051381146\n"
     ]
    }
   ],
   "source": [
    "experiments = ['CHB_bandits_010_22_1','CHB_bandits_010_22_2','CHB_bandits_010_22_3','CHB_bandits_010_22_4','CHB_bandits_010_22_5']\n",
    "print('local 10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "experiments = ['CHB_bandits_025_22_1','CHB_bandits_025_22_2','CHB_bandits_025_22_3','CHB_bandits_025_22_4','CHB_bandits_025_22_5']\n",
    "print('local 25')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))\n",
    "\n",
    "experiments = ['CHB_bandits_050_22_1','CHB_bandits_050_22_2','CHB_bandits_050_22_3','CHB_bandits_050_22_4','CHB_bandits_050_22_5']\n",
    "print('local 50')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies))\n",
    "print('std: ',np.std(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 101, 103, 105, 106, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 200, 201, 202, 203, 205, 207, 208, 209, 210, 212, 213, 214, 215, 219, 220, 221, 222, 223, 228, 230, 231, 232, 233, 234, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894]\n"
     ]
    }
   ],
   "source": [
    "print(patients_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandits\n",
      "local\n",
      "[98.13953488 94.85714286 90.         72.91338583 91.30952381 50.55555556\n",
      " 87.95180723 91.35802469 98.08219178 94.14965986 96.05633803 49.\n",
      " 67.14285714 79.06976744 88.3882149  63.84615385 92.8358209  95.34246575\n",
      " 93.71428571 84.72727273 62.96296296 97.81818182 81.70542636]\n",
      "better:  [103, 105, 106, 108, 109, 112, 113, 116, 118, 119, 123, 124, 200, 201, 202]\n",
      "8.375439789258474\n",
      "9.978761011436283\n",
      "worse:  [111, 114, 115, 117, 121, 122]\n",
      "5.207151930757796\n",
      "5.043131857280052\n",
      "same:  [100, 101]\n"
     ]
    }
   ],
   "source": [
    "#FL\n",
    "experiments = ['CHB_bandits_10_1','CHB_bandits_10_2','CHB_bandits_10_3','CHB_bandits_10_4','CHB_bandits_10_5']\n",
    "print('bandits')\n",
    "accuracies = np.zeros((5,23))\n",
    "for i,experiment in enumerate(experiments): \n",
    "    accuracies[i,:] = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracies.txt'))\n",
    "accuracies_bandits = np.mean(accuracies,axis=0)\n",
    "#FL\n",
    "experiments = ['CHB_local_1','CHB_local_2','CHB_local_3','CHB_local_4','CHB_local_5']\n",
    "print('local')\n",
    "accuracies = np.zeros((5,23))\n",
    "for i,experiment in enumerate(experiments): \n",
    "    accuracies[i,:] = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracies.txt'))\n",
    "accuracies_local = np.mean(accuracies,axis=0)\n",
    "print(accuracies_local)\n",
    "better = []\n",
    "how_better = []\n",
    "worse = []\n",
    "how_worse = []\n",
    "same = []\n",
    "for i in range(len(accuracies_bandits)):\n",
    "    if accuracies_local[i]<accuracies_bandits[i]:\n",
    "        better.append(patients_left[i])\n",
    "        how_better.append(accuracies_bandits[i]-accuracies_local[i])\n",
    "    if accuracies_local[i]>accuracies_bandits[i]:\n",
    "        worse.append(patients_left[i])\n",
    "        how_worse.append(accuracies_local[i]-accuracies_bandits[i])\n",
    "    if accuracies_local[i]==accuracies_bandits[i]:\n",
    "        same.append(patients_left[i])\n",
    "print('better: ',better)\n",
    "print(np.mean(how_better))\n",
    "print(np.std(how_better))\n",
    "print('worse: ',worse)\n",
    "print(np.mean(how_worse))\n",
    "print(np.std(how_worse))\n",
    "print('same: ',same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...  0.  1.  0.]\n",
      " [ 1.  0. 48. ...  0.  1.  1.]\n",
      " [ 1. 76.  0. ...  0.  1.  1.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 1.  0.  1. ...  0.  0.  0.]\n",
      " [ 2.  1.  1. ...  0.  1.  0.]]\n",
      "89.0\n",
      "(array([24, 24, 29, 43]), array([29, 75, 75, 29]))\n",
      "205\n",
      "212\n",
      "848\n"
     ]
    }
   ],
   "source": [
    "experiment='MIT3B_bandits_10_1'\n",
    "phi = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'phi99.txt'))\n",
    "print(phi)\n",
    "print(np.max(phi))\n",
    "print(np.where(phi==np.max(phi)))\n",
    "print(patients_left[24])\n",
    "print(patients_left[29])\n",
    "print(patients_left[75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local 100\n",
      "bandits_10\n",
      "better:  [100, 105, 106, 108, 109, 113, 114, 116, 118, 119, 124, 202, 205, 209, 210, 214, 219, 223, 228, 231, 233, 800, 802, 803, 804, 805, 806, 807, 810, 811, 812, 820, 821, 823, 826, 827, 828, 829, 841, 842, 843, 844, 845, 847, 849, 851, 852, 853, 855, 856, 857, 859, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 874, 875, 876, 877, 882, 883, 884, 885, 886, 888, 889, 890, 891, 893, 894]\n",
      "13.910264739802768\n",
      "10.846537493277642\n",
      "worse:  [200, 203, 207, 208, 213, 215, 221, 232, 801, 822, 824, 854, 860, 878, 879, 880, 881, 887, 892]\n",
      "1.8077163602389366\n",
      "2.3502364903570125\n",
      "same:  [101, 103, 111, 112, 115, 117, 121, 122, 123, 201, 212, 220, 222, 230, 234, 808, 809, 825, 840, 846, 848, 850, 858, 873]\n"
     ]
    }
   ],
   "source": [
    "experiments = ['MIT3B_local_1','MIT3B_local_2','MIT3B_local_3','MIT3B_local_4','MIT3B_local_5']\n",
    "print('local 100')\n",
    "accuracies = np.zeros((5,122))\n",
    "for i,experiment in enumerate(experiments): \n",
    "    accuracies[i,:] = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracies.txt'))\n",
    "accuracies_local = np.mean(accuracies,axis=0)*100\n",
    "experiments = ['MIT3B_bandits_10_1','MIT3B_bandits_10_2','MIT3B_bandits_10_3','MIT3B_bandits_10_4','MIT3B_bandits_10_5']\n",
    "print('bandits_10')\n",
    "#experiments = ['MIT3B_bandits_20_1','MIT3B_bandits_20_2','MIT3B_bandits_20_3','MIT3B_bandits_20_4','MIT3B_bandits_20_5']\n",
    "#print('bandits_10')\n",
    "accuracies =np.zeros((5,122))\n",
    "for i,experiment in enumerate(experiments): \n",
    "    accuracies[i,:] = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracies.txt'))\n",
    "accuracies_bandits = np.mean(accuracies,axis=0)*100\n",
    "\n",
    "better = []\n",
    "how_better = []\n",
    "worse = []\n",
    "how_worse = []\n",
    "same = []\n",
    "for i in range(len(accuracies_bandits)):\n",
    "    if accuracies_local[i]<accuracies_bandits[i]:\n",
    "        better.append(patients_left[i])\n",
    "        how_better.append(accuracies_bandits[i]-accuracies_local[i])\n",
    "    if accuracies_local[i]>accuracies_bandits[i]:\n",
    "        worse.append(patients_left[i])\n",
    "        how_worse.append(accuracies_local[i]-accuracies_bandits[i])\n",
    "    if accuracies_local[i]==accuracies_bandits[i]:\n",
    "        same.append(patients_left[i])\n",
    "print('better: ',better)\n",
    "print(np.mean(how_better))\n",
    "print(np.std(how_better))\n",
    "print('worse: ',worse)\n",
    "print(np.mean(how_worse))\n",
    "print(np.std(how_worse))\n",
    "print('same: ',same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.725936914753106\n"
     ]
    }
   ],
   "source": [
    "print((-np.sum(how_worse)+np.sum(how_better))/len(patients_left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n",
      "294.0\n",
      "0.0\n",
      "V\n",
      "0.0\n",
      "0.0\n",
      "S\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "N = [] \n",
    "V = []\n",
    "S = []\n",
    "for i in [212]: \n",
    "    N.append(np.count_nonzero(data_beats_tr[i]['class']=='N'))\n",
    "    V.append(np.count_nonzero(data_beats_tr[i]['class']=='V')+np.count_nonzero(data_beats_tr[i]['class']=='F'))\n",
    "    S.append(np.count_nonzero(data_beats_tr[i]['class']=='S'))\n",
    "print('N')\n",
    "print(np.mean(N))\n",
    "print(np.std(N))\n",
    "print('V')\n",
    "print(np.mean(V))\n",
    "print(np.std(V))\n",
    "print('S')\n",
    "print(np.mean(S))\n",
    "print(np.std(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandits_20\n",
      "mean:  76.22475275175059\n",
      "std:  1.4945827706345214\n",
      "bandits_20\n",
      "mean:  75.30578930817919\n",
      "std:  2.542568105887338\n",
      "bandits_20\n",
      "mean:  76.88651151427102\n",
      "std:  2.1285971118489897\n"
     ]
    }
   ],
   "source": [
    "experiments = ['MIT3B_bandits_010_20_1','MIT3B_bandits_010_20_2','MIT3B_bandits_010_20_3','MIT3B_bandits_010_20_4','MIT3B_bandits_010_20_5']\n",
    "print('bandits_20')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies)*100)\n",
    "print('std: ',np.std(accuracies)*100)\n",
    "\n",
    "experiments = ['MIT3B_bandits_025_20_1','MIT3B_bandits_025_20_2','MIT3B_bandits_025_20_3','MIT3B_bandits_025_20_4','MIT3B_bandits_025_20_5']\n",
    "print('bandits_20')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies)*100)\n",
    "print('std: ',np.std(accuracies)*100)\n",
    "\n",
    "experiments = ['MIT3B_bandits_050_20_1','MIT3B_bandits_050_20_2','MIT3B_bandits_050_20_3','MIT3B_bandits_050_20_4','MIT3B_bandits_050_20_5']\n",
    "print('bandits_20')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies)*100)\n",
    "print('std: ',np.std(accuracies)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandits_10\n",
      "mean:  77.68577318421154\n",
      "std:  3.2009819420301726\n",
      "bandits_20\n",
      "mean:  76.54731302487991\n",
      "std:  0.9063287872674072\n",
      "bandits_50\n",
      "mean:  76.72691118734195\n",
      "std:  1.433589851816387\n",
      "bandits_121\n",
      "mean:  76.45273418552547\n",
      "std:  1.7789325492625845\n",
      "local\n",
      "mean:  73.28691849682126\n",
      "std:  4.110598652014076\n",
      "federated\n",
      "mean:  33.33333333333333\n",
      "std:  0.0\n",
      "AFPL\n",
      "mean:  35.33916465648221\n",
      "std:  3.4742017631069757\n"
     ]
    }
   ],
   "source": [
    "#FL\n",
    "experiments = ['MIT3B_bandits_10_1','MIT3B_bandits_10_2','MIT3B_bandits_10_3','MIT3B_bandits_10_4','MIT3B_bandits_10_5']\n",
    "print('bandits_10')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies)*100)\n",
    "print('std: ',np.std(accuracies)*100)\n",
    "\n",
    "experiments = ['MIT3B_bandits_20_1','MIT3B_bandits_20_2','MIT3B_bandits_20_3','MIT3B_bandits_20_4','MIT3B_bandits_20_5']\n",
    "print('bandits_20')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies)*100)\n",
    "print('std: ',np.std(accuracies)*100)\n",
    "\n",
    "experiments = ['MIT3B_bandits_50_1','MIT3B_bandits_50_2','MIT3B_bandits_50_3','MIT3B_bandits_50_4','MIT3B_bandits_50_5']\n",
    "print('bandits_50')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies)*100)\n",
    "print('std: ',np.std(accuracies)*100)\n",
    "\n",
    "experiments = ['MIT3B_bandits_121_1','MIT3B_bandits_121_2','MIT3B_bandits_121_3','MIT3B_bandits_121_4','MIT3B_bandits_121_5']\n",
    "print('bandits_121')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies)*100)\n",
    "print('std: ',np.std(accuracies)*100)\n",
    "\n",
    "experiments = ['MIT3B_local_1','MIT3B_local_2','MIT3B_local_3','MIT3B_local_4','MIT3B_local_5']\n",
    "print('local')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies)*100)\n",
    "print('std: ',np.std(accuracies)*100)\n",
    "\n",
    "experiments = ['MIT3B_federated_1','MIT3B_federated_2','MIT3B_federated_3','MIT3B_federated_4','MIT3B_federated_5']\n",
    "print('federated')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies)*100)\n",
    "print('std: ',np.std(accuracies)*100)\n",
    "\n",
    "experiments = ['MIT3B_AFPL_1','MIT3B_AFPL_2','MIT3B_AFPL_3','MIT3B_AFPL_5']\n",
    "print('AFPL')\n",
    "accuracies = []\n",
    "for i,experiment in enumerate(experiments): \n",
    "    test_accuracy = np.loadtxt(os.path.join('checkpoints_bandits',experiment,'test_accuracy.txt'))\n",
    "  #  print(test_accuracy)\n",
    "    accuracies.append(test_accuracy)\n",
    "print('mean: ',np.mean(accuracies)*100)\n",
    "print('std: ',np.std(accuracies)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1689631518054,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "hj66LjJEuVpr",
    "outputId": "fd8cce1a-d490-4385-ba8f-26eb6e4c8879"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/data/RECORDS\n",
      "[100 101 102 103 104 105 106 107 108 109 111 112 113 114 115 116 117 118\n",
      " 119 121 122 123 124 200 201 202 203 205 207 208 209 210 212 213 214 215\n",
      " 217 219 220 221 222 223 228 230 231 232 233 234]\n"
     ]
    }
   ],
   "source": [
    "def read_dict_beats():\n",
    "    with open(DICT_BEATS, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def read_data_beats():\n",
    "    with open(DATA_BEATS, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def ensure_normalized_and_detrended(beats):\n",
    "    for key in beats.keys():\n",
    "        b = beats[key][\"beats\"]\n",
    "        if not np.allclose(np.linalg.norm(b, axis=1, ord=2), 1):\n",
    "            raise AssertionError(f\"Beats of patient {key} is not normalized.\")\n",
    "\n",
    "        p = np.polyfit(np.arange(b.shape[1]), b.T, deg=1)\n",
    "        if not np.allclose(p, 0):\n",
    "            raise AssertionError(f\"Beats of patient {key} is not detrended.\")\n",
    "\n",
    "DATA_ROOT =  \"/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/data\"\n",
    "DATA_BEATS = osj(DATA_ROOT, \"30min_beats.pkl\")\n",
    "\n",
    "RECORDS = osj(DATA_ROOT, \"RECORDS\")\n",
    "print(RECORDS)\n",
    "patient_ids = pd.read_csv(RECORDS,  header=None).to_numpy().reshape(-1)\n",
    "print(patient_ids)\n",
    "data_beats = read_data_beats()\n",
    "ensure_normalized_and_detrended(data_beats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39195,
     "status": "ok",
     "timestamp": 1689631557239,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "PjqoM_-5uxp2",
    "outputId": "5eb9cc02-3047-4770-e118-3a35a7d68657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102. 104. 107. 217.]\n"
     ]
    }
   ],
   "source": [
    "def get_paced_patients(patient_ids):\n",
    "    paced = []\n",
    "    for id_ in patient_ids:\n",
    "        annotation = wfdb.rdann(osj(DATA_ROOT, str(id_)), extension='atr')\n",
    "        labels = np.unique(annotation.symbol)\n",
    "        if (\"/\" in labels):\n",
    "            paced.append(id_)\n",
    "    return np.array(paced)\n",
    "#paced_patients = get_paced_patients(patient_ids)\n",
    "paced_patients = np.array([102, 104, 107, 217])\n",
    "excluded_patients = np.array([]) #np.array([105, 114, 201, 202,207, 209, 213, 222, 223, 234]) # according to paper\n",
    "print(np.concatenate((paced_patients,excluded_patients)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1689631557241,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "cY_UihBsvO4R",
    "outputId": "7f9e0efc-b44e-4912-e748-8baea250bc23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102. 104. 107. 217.]\n",
      "[100, 101, 103, 105, 106, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 200, 201, 202, 203, 205, 207, 208, 209, 210, 212, 213, 214, 215, 219, 220, 221, 222, 223, 228, 230, 231, 232, 233, 234]\n",
      "['N', 'A', 'V', 'Q', 'F', 'j', 'L', 'a', 'J', 'R', 'E', 'S', 'e']\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "patients_out = np.concatenate((paced_patients,excluded_patients))\n",
    "print(patients_out)\n",
    "patients_left = list(copy.deepcopy(patient_ids))\n",
    "\n",
    "for idx,i in enumerate(patient_ids):\n",
    "    if i in patients_out:\n",
    "        patients_left.remove(i)\n",
    "\n",
    "print(patients_left)\n",
    "\n",
    "#print(dict_beats[101]['beats'])\n",
    "#print(dict_beats[101]['class'])\n",
    "labels = ['N','V','S','Q','F']\n",
    "dictionary = {}\n",
    "for i in labels:\n",
    "    dictionary[i] = 0\n",
    "\n",
    "list1 = []\n",
    "array = np.zeros((len(patients_left),2))\n",
    "labels2 = []\n",
    "for idx,i in enumerate(patients_left):\n",
    "    for iii,idx in enumerate(data_beats[i]['class']): \n",
    "        if iii == 'Q':\n",
    "            del data_beats[i]['class'][idx]\n",
    "            del data_beats[i]['beats'][idx]\n",
    "            \n",
    "            \n",
    "    for ii in data_beats[i]['label']:\n",
    "        if ii not in labels2:\n",
    "            labels2.append(ii)\n",
    "    #print(len(data_beats[i]['class']))\n",
    "    list1.append(data_beats[i]['class'])\n",
    "   # counter = collections.Counter(data_beats[i]['class'])\n",
    "   # for j in counter.keys():\n",
    "   #     dictionary[j] += counter[j]\n",
    "   #     if j == 'N':\n",
    "   #         array[idx,0] += counter[j]\n",
    "   #     else:\n",
    "   #         array[idx,1] += counter[j]\n",
    "print(labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1689631557684,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "aB8si8DCvnLj"
   },
   "outputs": [],
   "source": [
    "def train_test_split(data_beats,seconds=5,factor=0.8):\n",
    "    data_beats_train = {}\n",
    "    data_beats_val = {}\n",
    "    data_beats_test = {}\n",
    "    for i in data_beats.keys():\n",
    "        data_beats_train[i] = {'class':None, 'beats':None}\n",
    "        data_beats_val[i] = {'class':None, 'beats':None}\n",
    "        data_beats_test[i] ={'class':None, 'beats':None}\n",
    "\n",
    "    for patient in data_beats.keys():\n",
    "        length = int(np.ceil(len(data_beats[patient]['beats'])*(seconds/30))) # only take first 5 seconds\n",
    "\n",
    "        random_test = np.arange(length)\n",
    "        random_train = np.random.choice(random_test,size=int(np.ceil(0.8*length)),replace=False)\n",
    "        for ii in random_train:\n",
    "            index = np.where(random_test == ii)[0]\n",
    "            random_test = np.delete(random_test,index)\n",
    "\n",
    "        random_val = np.arange(int(np.ceil(0.8*length)))\n",
    "        random_train = np.random.choice(random_val,size=int(np.ceil(0.8*0.8*length)),replace=False)\n",
    "        for ii in random_train:\n",
    "            index = np.where(random_val == ii)[0]\n",
    "            random_val = np.delete(random_val,index)\n",
    "\n",
    "        data_beats_train[patient]['class'] = data_beats[patient]['class'][np.sort(random_train)]\n",
    "        data_beats_test[patient]['class'] = data_beats[patient]['class'][random_test]\n",
    "        data_beats_val[patient]['class'] = data_beats[patient]['class'][random_val]\n",
    "        data_beats_train[patient]['beats'] = data_beats[patient]['beats'][np.sort(random_train)]\n",
    "        data_beats_test[patient]['beats'] = data_beats[patient]['beats'][random_test]\n",
    "        data_beats_val[patient]['beats'] = data_beats[patient]['beats'][random_val]\n",
    "\n",
    "\n",
    "    return data_beats_train, data_beats_val, data_beats_test\n",
    "#print(data_beats_train)\n",
    "seconds = 5\n",
    "data_beats_train, data_beats_val, data_beats_test  = train_test_split(data_beats,seconds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data_beats, seconds=5, data_fraction=0.25):\n",
    "    data_beats_train = {}\n",
    "    data_beats_val = {}\n",
    "    data_beats_test = {}\n",
    "    for i in data_beats.keys():\n",
    "        data_beats_train[i] = {'class': None, 'beats': None}\n",
    "        data_beats_val[i] = {'class': None, 'beats': None}\n",
    "        data_beats_test[i] = {'class': None, 'beats': None}\n",
    "\n",
    "    for patient in data_beats.keys():\n",
    "        length_train = int(np.ceil(len(data_beats[patient]['beats']) * (seconds / 30)))  # only take first 5 seconds\n",
    "\n",
    "        random_test = np.arange(int(np.ceil(len(data_beats[patient]['beats']))))\n",
    "        random_val= np.arange(length_train)\n",
    "        for ii in random_val:\n",
    "            random_test = np.delete(random_test,ii)\n",
    "\n",
    "        # Data fraction, take part of the data\n",
    "        random_val = np.random.choice(random_val, size=int(np.ceil(data_fraction* length_train)), replace=False)\n",
    "\n",
    "        random_train = np.random.choice(random_val, size=int(np.ceil(0.8 *data_fraction* length_train)), replace=False)\n",
    "        for ii in random_train:\n",
    "            index = np.where(random_val == ii)[0]\n",
    "            random_val = np.delete(random_val, index)\n",
    "\n",
    "\n",
    "        #random_val = np.arange(int(np.ceil(0.8 * length)))\n",
    "        #random_train = np.random.choice(random_val, size=int(np.ceil(0.8 * 0.8 * length)), replace=False)\n",
    "        #for ii in random_train:\n",
    "        #    index = np.where(random_val == ii)[0]\n",
    "        #    random_val = np.delete(random_val, index)\n",
    "\n",
    "        data_beats_train[patient]['class'] = data_beats[patient]['class'][np.sort(random_train)]\n",
    "        data_beats_test[patient]['class'] = data_beats[patient]['class'][random_test]\n",
    "        data_beats_val[patient]['class'] = data_beats[patient]['class'][random_val]\n",
    "        data_beats_train[patient]['beats'] = data_beats[patient]['beats'][np.sort(random_train)]\n",
    "        data_beats_test[patient]['beats'] = data_beats[patient]['beats'][random_test]\n",
    "        data_beats_val[patient]['beats'] = data_beats[patient]['beats'][random_val]\n",
    "\n",
    "    return data_beats_train, data_beats_val, data_beats_test\n",
    "\n",
    "seconds = 5\n",
    "data_beats_train, data_beats_val, data_beats_test  = train_test_split(data_beats,seconds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1689631557243,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "wyoYR2oQvlKP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/data/RECORDS_S\n",
      "[100 101 102 103 104 105 106 107 108 109 111 112 113 114 115 116 117 118\n",
      " 119 121 122 123 124 200 201 202 203 205 207 208 209 210 212 213 214 215\n",
      " 217 219 220 221 222 223 228 230 231 232 233 234]\n",
      "[800 801 802 803 804 805 806 807 808 809 810 811 812 820 821 822 823 824\n",
      " 825 826 827 828 829 840 841 842 843 844 845 846 847 848 849 850 851 852\n",
      " 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870\n",
      " 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888\n",
      " 889 890 891 892 893 894]\n"
     ]
    }
   ],
   "source": [
    "# TODO: concatenate the two datasets here\n",
    "# Load supraventricular dataset: \n",
    "DATA_ROOT =  \"/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/data\"\n",
    "DATA_BEATS = osj(DATA_ROOT, \"30min_beats_supraventricular.pkl\")\n",
    "\n",
    "RECORDS = osj(DATA_ROOT, \"RECORDS_S\")\n",
    "print(RECORDS)\n",
    "patient_ids_sup = pd.read_csv(RECORDS,  header=None).to_numpy().reshape(-1)\n",
    "print(patient_ids)\n",
    "print(patient_ids_sup)\n",
    "data_beats_sup = read_data_beats()\n",
    "ensure_normalized_and_detrended(data_beats_sup)\n",
    "seconds = 5\n",
    "data_beats_train_sup, data_beats_val_sup, data_beats_test_sup  = train_test_split(data_beats_sup,seconds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 200, 201, 202, 203, 205, 207, 208, 209, 210, 212, 213, 214, 215, 217, 219, 220, 221, 222, 223, 228, 230, 231, 232, 233, 234])\n",
      "dict_keys([800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894])\n"
     ]
    }
   ],
   "source": [
    "print(data_beats_train.keys())\n",
    "print(data_beats_train_sup.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 101, 103, 105, 106, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 200, 201, 202, 203, 205, 207, 208, 209, 210, 212, 213, 214, 215, 219, 220, 221, 222, 223, 228, 230, 231, 232, 233, 234, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894]\n",
      "[100 101 102 103 104 105 106 107 108 109 111 112 113 114 115 116 117 118\n",
      " 119 121 122 123 124 200 201 202 203 205 207 208 209 210 212 213 214 215\n",
      " 217 219 220 221 222 223 228 230 231 232 233 234]\n",
      "[100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 200, 201, 202, 203, 205, 207, 208, 209, 210, 212, 213, 214, 215, 217, 219, 220, 221, 222, 223, 228, 230, 231, 232, 233, 234, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894]\n"
     ]
    }
   ],
   "source": [
    "# concatenate the datasets\n",
    "data_beats_tr = {}\n",
    "data_beats_tr.update(data_beats_train)\n",
    "data_beats_tr.update(data_beats_train_sup)\n",
    "\n",
    "data_beats_v = {}\n",
    "data_beats_v.update(data_beats_val)\n",
    "data_beats_v.update(data_beats_val_sup)\n",
    "\n",
    "data_beats_t = {}\n",
    "data_beats_t.update(data_beats_test)\n",
    "data_beats_t.update(data_beats_test_sup)\n",
    "print(patients_left)\n",
    "print(patient_ids)\n",
    "print(list(data_beats_tr.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[['N' '1861']\n",
      " ['S' '30']\n",
      " ['V' '1']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N']\n",
      "101\n",
      "[['N' '1547']\n",
      " ['Q' '2']\n",
      " ['S' '3']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "102\n",
      "[['N' '81']\n",
      " ['V' '3']]\n",
      "['N']\n",
      "103\n",
      "[['N' '1733']\n",
      " ['S' '2']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "104\n",
      "[['N' '134']\n",
      " ['Q' '15']\n",
      " ['V' '1']]\n",
      "['N']\n",
      "105\n",
      "[['N' '2108']\n",
      " ['Q' '5']\n",
      " ['V' '28']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'V' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N']\n",
      "106\n",
      "[['N' '1197']\n",
      " ['V' '490']]\n",
      "['N' 'N' 'N' 'V' 'V' 'N' 'V' 'N' 'V' 'N' 'V' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "107\n",
      "[['V' '47']]\n",
      "['V']\n",
      "108\n",
      "[['F' '2']\n",
      " ['N' '1448']\n",
      " ['S' '4']\n",
      " ['V' '13']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "109\n",
      "[['N' '2075']\n",
      " ['V' '33']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N']\n",
      "111\n",
      "[['N' '1767']\n",
      " ['V' '1']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "112\n",
      "[['N' '2112']\n",
      " ['S' '2']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N']\n",
      "113\n",
      "[['N' '1491']\n",
      " ['S' '3']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "114\n",
      "[['F' '1']\n",
      " ['N' '1522']\n",
      " ['S' '12']\n",
      " ['V' '29']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "115\n",
      "[['N' '1625']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "116\n",
      "[['N' '1913']\n",
      " ['S' '1']\n",
      " ['V' '94']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N']\n",
      "117\n",
      "[['N' '1276']\n",
      " ['S' '1']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "118\n",
      "[['N' '1804']\n",
      " ['S' '79']\n",
      " ['V' '13']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'V' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N']\n",
      "119\n",
      "[['N' '1293']\n",
      " ['V' '361']]\n",
      "['N' 'V' 'V' 'N' 'N' 'V' 'N' 'N' 'N' 'N' 'N' 'N' 'V' 'N' 'V' 'N']\n",
      "121\n",
      "[['N' '1548']\n",
      " ['S' '1']\n",
      " ['V' '1']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "122\n",
      "[['N' '2061']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N']\n",
      "123\n",
      "[['N' '1260']\n",
      " ['V' '3']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "124\n",
      "[['F' '4']\n",
      " ['N' '1289']\n",
      " ['S' '16']\n",
      " ['V' '38']]\n",
      "['N' 'N' 'N' 'N' 'V' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'N']\n",
      "200\n",
      "[['F' '2']\n",
      " ['N' '1431']\n",
      " ['S' '26']\n",
      " ['V' '706']]\n",
      "['N' 'V' 'N' 'N' 'N' 'N' 'V' 'N' 'V' 'N' 'N' 'N' 'V' 'N' 'N' 'N' 'N' 'N'\n",
      " 'V' 'N' 'N' 'N']\n",
      "201\n",
      "[['F' '2']\n",
      " ['N' '1313']\n",
      " ['S' '123']\n",
      " ['V' '196']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "202\n",
      "[['F' '1']\n",
      " ['N' '1715']\n",
      " ['S' '49']\n",
      " ['V' '13']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "203\n",
      "[['F' '1']\n",
      " ['N' '2115']\n",
      " ['Q' '3']\n",
      " ['S' '1']\n",
      " ['V' '361']]\n",
      "['N' 'N' 'N' 'V' 'V' 'V' 'N' 'V' 'N' 'N' 'N' 'V' 'N' 'N' 'N' 'V' 'N' 'N'\n",
      " 'V' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "205\n",
      "[['F' '10']\n",
      " ['N' '2136']\n",
      " ['S' '3']\n",
      " ['V' '62']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N']\n",
      "207\n",
      "[['N' '1262']\n",
      " ['S' '106']\n",
      " ['V' '180']]\n",
      "['V' 'N' 'N' 'N' 'N' 'V' 'N' 'V' 'V' 'N' 'N' 'N' 'V' 'N' 'V' 'N']\n",
      "208\n",
      "[['F' '311']\n",
      " ['N' '1324']\n",
      " ['Q' '2']\n",
      " ['S' '2']\n",
      " ['V' '821']]\n",
      "['N' 'N' 'V' 'F' 'V' 'V' 'V' 'N' 'N' 'N' 'F' 'N' 'V' 'N' 'N' 'N' 'N' 'V'\n",
      " 'V' 'N' 'F' 'N' 'N' 'N' 'N']\n",
      "209\n",
      "[['N' '2183']\n",
      " ['S' '318']\n",
      " ['V' '1']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "210\n",
      "[['F' '8']\n",
      " ['N' '2015']\n",
      " ['S' '19']\n",
      " ['V' '164']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'V' 'S' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N']\n",
      "212\n",
      "[['N' '2288']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N']\n",
      "213\n",
      "[['F' '218']\n",
      " ['N' '2314']\n",
      " ['S' '24']\n",
      " ['V' '151']]\n",
      "['F' 'N' 'V' 'N' 'N' 'N' 'F' 'N' 'F' 'F' 'N' 'N' 'F' 'N' 'N' 'N' 'N' 'F'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "214\n",
      "[['F' '1']\n",
      " ['N' '1674']\n",
      " ['Q' '1']\n",
      " ['V' '207']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'V' 'N' 'N' 'N' 'V'\n",
      " 'N']\n",
      "215\n",
      "[['F' '1']\n",
      " ['N' '2663']\n",
      " ['S' '2']\n",
      " ['V' '134']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "217\n",
      "[['N' '216']\n",
      " ['V' '120']]\n",
      "['V' 'V' 'N']\n",
      "219\n",
      "[['F' '1']\n",
      " ['N' '1733']\n",
      " ['S' '4']\n",
      " ['V' '55']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "220\n",
      "[['N' '1623']\n",
      " ['S' '82']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "221\n",
      "[['N' '1700']\n",
      " ['V' '320']]\n",
      "['N' 'V' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'V' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'V' 'N' 'N']\n",
      "222\n",
      "[['N' '1868']\n",
      " ['S' '199']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N']\n",
      "223\n",
      "[['F' '13']\n",
      " ['N' '1674']\n",
      " ['S' '56']\n",
      " ['V' '426']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'V'\n",
      " 'N' 'N' 'N' 'N']\n",
      "228\n",
      "[['N' '1420']\n",
      " ['S' '3']\n",
      " ['V' '286']]\n",
      "['N' 'N' 'V' 'N' 'N' 'V' 'V' 'N' 'N' 'N' 'N' 'N' 'N' 'V' 'N' 'N' 'N']\n",
      "230\n",
      "[['N' '1877']\n",
      " ['V' '1']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "231\n",
      "[['N' '1306']\n",
      " ['V' '1']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "232\n",
      "[['N' '324']\n",
      " ['S' '1157']]\n",
      "['S' 'S' 'S' 'N' 'N' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S']\n",
      "233\n",
      "[['F' '7']\n",
      " ['N' '1859']\n",
      " ['S' '6']\n",
      " ['V' '692']]\n",
      "['N' 'F' 'N' 'V' 'V' 'V' 'N' 'V' 'N' 'N' 'N' 'V' 'N' 'S' 'V' 'N' 'V' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "234\n",
      "[['N' '2239']\n",
      " ['S' '50']\n",
      " ['V' '3']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N']\n",
      "800\n",
      "[['F' '1']\n",
      " ['N' '1533']\n",
      " ['S' '27']\n",
      " ['V' '6']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'N']\n",
      "801\n",
      "[['N' '2012']\n",
      " ['S' '46']\n",
      " ['V' '31']]\n",
      "['V' 'V' 'V' 'N' 'N' 'N' 'N' 'V' 'V' 'N' 'N' 'V' 'V' 'S' 'V' 'V' 'V' 'V'\n",
      " 'N' 'V' 'V']\n",
      "802\n",
      "[['N' '1310']\n",
      " ['V' '80']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "803\n",
      "[['F' '1']\n",
      " ['N' '1603']\n",
      " ['V' '117']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "804\n",
      "[['N' '2186']\n",
      " ['V' '174']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N']\n",
      "805\n",
      "[['N' '1726']\n",
      " ['V' '187']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'V' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N']\n",
      "806\n",
      "[['F' '1']\n",
      " ['N' '2457']\n",
      " ['S' '36']\n",
      " ['V' '23']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "807\n",
      "[['N' '1592']\n",
      " ['S' '24']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "808\n",
      "[['N' '1448']\n",
      " ['S' '20']\n",
      " ['V' '8']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "809\n",
      "[['N' '2006']\n",
      " ['S' '112']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N']\n",
      "810\n",
      "[['N' '1534']\n",
      " ['S' '8']\n",
      " ['V' '42']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "811\n",
      "[['N' '1178']\n",
      " ['V' '17']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "812\n",
      "[['N' '1470']\n",
      " ['S' '14']\n",
      " ['V' '49']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'V' 'N' 'N' 'N']\n",
      "820\n",
      "[['N' '1801']\n",
      " ['Q' '1']\n",
      " ['S' '154']\n",
      " ['V' '2']]\n",
      "['N' 'S' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'S' 'N' 'N'\n",
      " 'N']\n",
      "821\n",
      "[['N' '2063']\n",
      " ['Q' '1']\n",
      " ['S' '512']\n",
      " ['V' '33']]\n",
      "['S' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N']\n",
      "822\n",
      "[['N' '1336']\n",
      " ['S' '606']\n",
      " ['V' '1']]\n",
      "['S' 'N' 'S' 'S' 'S' 'S' 'S' 'N' 'S' 'N' 'S' 'S' 'S' 'S' 'S' 'N' 'N' 'N'\n",
      " 'S' 'S']\n",
      "823\n",
      "[['N' '2049']\n",
      " ['S' '333']]\n",
      "['N' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'S' 'N' 'N' 'N'\n",
      " 'S' 'N' 'N' 'N' 'N' 'N']\n",
      "824\n",
      "[['N' '1854']\n",
      " ['S' '156']\n",
      " ['V' '4']]\n",
      "['N' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N']\n",
      "825\n",
      "[['N' '2230']\n",
      " ['S' '100']]\n",
      "['S' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'S' 'N' 'N'\n",
      " 'N' 'S' 'N' 'N' 'N']\n",
      "826\n",
      "[['N' '2160']\n",
      " ['S' '55']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'S' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N']\n",
      "827\n",
      "[['N' '1533']\n",
      " ['S' '17']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "828\n",
      "[['N' '1463']\n",
      " ['S' '123']\n",
      " ['V' '6']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'S' 'N' 'S' 'N' 'N' 'N']\n",
      "829\n",
      "[['N' '1569']\n",
      " ['S' '68']]\n",
      "['S' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "840\n",
      "[['N' '1941']\n",
      " ['S' '44']\n",
      " ['V' '1']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N']\n",
      "841\n",
      "[['N' '1189']\n",
      " ['Q' '3']\n",
      " ['S' '98']\n",
      " ['V' '253']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "842\n",
      "[['N' '1995']\n",
      " ['S' '88']\n",
      " ['V' '47']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N']\n",
      "843\n",
      "[['N' '2198']\n",
      " ['S' '21']\n",
      " ['V' '36']]\n",
      "['N' 'N' 'N' 'V' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N']\n",
      "844\n",
      "[['N' '1373']\n",
      " ['S' '49']]\n",
      "['N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S']\n",
      "845\n",
      "[['N' '2369']\n",
      " ['Q' '1']\n",
      " ['S' '11']\n",
      " ['V' '23']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "846\n",
      "[['N' '1379']\n",
      " ['S' '20']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "847\n",
      "[['N' '1391']\n",
      " ['S' '41']\n",
      " ['V' '34']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'N']\n",
      "848\n",
      "[['N' '3519']\n",
      " ['S' '27']\n",
      " ['V' '1']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "849\n",
      "[['N' '1726']\n",
      " ['Q' '13']\n",
      " ['S' '57']\n",
      " ['V' '3']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "850\n",
      "[['N' '1525']\n",
      " ['S' '5']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "851\n",
      "[['N' '1791']\n",
      " ['S' '30']\n",
      " ['V' '367']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'V' 'N' 'N' 'N' 'V' 'V' 'V' 'N' 'N' 'N' 'N' 'V'\n",
      " 'N' 'N' 'V' 'N']\n",
      "852\n",
      "[['N' '1906']\n",
      " ['S' '309']\n",
      " ['V' '3']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N']\n",
      "853\n",
      "[['N' '1754']\n",
      " ['Q' '10']\n",
      " ['S' '36']\n",
      " ['V' '57']]\n",
      "['N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "854\n",
      "[['N' '1484']\n",
      " ['Q' '4']\n",
      " ['S' '390']\n",
      " ['V' '397']]\n",
      "['N' 'N' 'V' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'V' 'N' 'V' 'S' 'S' 'N'\n",
      " 'N' 'N' 'N' 'V' 'N']\n",
      "855\n",
      "[['N' '1738']\n",
      " ['Q' '1']\n",
      " ['S' '137']\n",
      " ['V' '239']]\n",
      "['N' 'N' 'V' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'S'\n",
      " 'N' 'N' 'N']\n",
      "856\n",
      "[['N' '2348']\n",
      " ['Q' '1']\n",
      " ['S' '7']\n",
      " ['V' '19']]\n",
      "['N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N']\n",
      "857\n",
      "[['N' '2011']\n",
      " ['S' '20']\n",
      " ['V' '120']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N']\n",
      "858\n",
      "[['N' '1804']\n",
      " ['S' '8']\n",
      " ['V' '3']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "859\n",
      "[['N' '2480']\n",
      " ['S' '63']\n",
      " ['V' '407']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'V' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'V' 'N' 'V' 'V']\n",
      "860\n",
      "[['N' '1392']\n",
      " ['S' '9']\n",
      " ['V' '612']]\n",
      "['N' 'N' 'V' 'N' 'N' 'V' 'N' 'N' 'N' 'V' 'N' 'N' 'V' 'V' 'V' 'V' 'V' 'V'\n",
      " 'N' 'N']\n",
      "861\n",
      "[['N' '1570']\n",
      " ['S' '474']\n",
      " ['V' '14']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'S']\n",
      "862\n",
      "[['N' '1777']\n",
      " ['Q' '5']\n",
      " ['S' '21']\n",
      " ['V' '18']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'V' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N']\n",
      "863\n",
      "[['N' '2128']\n",
      " ['Q' '1']\n",
      " ['S' '269']\n",
      " ['V' '203']]\n",
      "['N' 'N' 'N' 'V' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'V' 'N'\n",
      " 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "864\n",
      "[['N' '1455']\n",
      " ['S' '18']\n",
      " ['V' '104']]\n",
      "['N' 'S' 'N' 'V' 'N' 'V' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "865\n",
      "[['N' '720']\n",
      " ['Q' '6']\n",
      " ['S' '1717']\n",
      " ['V' '190']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "866\n",
      "[['N' '1692']\n",
      " ['S' '138']\n",
      " ['V' '390']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N']\n",
      "867\n",
      "[['N' '2323']\n",
      " ['S' '107']\n",
      " ['V' '68']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "868\n",
      "[['N' '2206']\n",
      " ['Q' '10']\n",
      " ['S' '160']\n",
      " ['V' '411']]\n",
      "['N' 'V' 'N' 'N' 'S' 'N' 'N' 'V' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'V' 'N' 'N'\n",
      " 'V' 'V' 'N' 'V' 'N' 'V' 'N' 'S' 'S' 'N']\n",
      "869\n",
      "[['N' '1251']\n",
      " ['S' '526']\n",
      " ['V' '22']]\n",
      "['N' 'S' 'N' 'S' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'S' 'S' 'N' 'N' 'N']\n",
      "870\n",
      "[['N' '1422']\n",
      " ['S' '449']\n",
      " ['V' '359']]\n",
      "['N' 'N' 'N' 'V' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'V' 'N' 'N' 'N' 'N' 'N'\n",
      " 'V' 'N' 'V' 'N']\n",
      "871\n",
      "[['N' '1477']\n",
      " ['S' '10']\n",
      " ['V' '8']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "872\n",
      "[['N' '1578']\n",
      " ['S' '6']\n",
      " ['V' '65']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'V' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "873\n",
      "[['F' '17']\n",
      " ['N' '1345']\n",
      " ['S' '13']\n",
      " ['V' '26']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "874\n",
      "[['N' '1827']\n",
      " ['S' '9']\n",
      " ['V' '29']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N']\n",
      "875\n",
      "[['F' '1']\n",
      " ['N' '1639']\n",
      " ['S' '7']\n",
      " ['V' '61']]\n",
      "['N' 'F' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'V' 'V' 'N' 'N' 'N' 'N' 'N']\n",
      "876\n",
      "[['N' '1671']\n",
      " ['S' '111']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "877\n",
      "[['N' '1535']\n",
      " ['S' '160']\n",
      " ['V' '1']]\n",
      "['S' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'V' 'N' 'N' 'N' 'S']\n",
      "878\n",
      "[['N' '1318']\n",
      " ['S' '57']\n",
      " ['V' '215']]\n",
      "['N' 'V' 'N' 'N' 'N' 'N' 'N' 'V' 'V' 'N' 'V' 'N' 'N' 'N' 'N' 'N']\n",
      "879\n",
      "[['N' '1283']\n",
      " ['S' '44']\n",
      " ['V' '389']]\n",
      "['N' 'N' 'V' 'N' 'N' 'N' 'V' 'N' 'N' 'V' 'S' 'V' 'N' 'N' 'N' 'V' 'V']\n",
      "880\n",
      "[['N' '2616']\n",
      " ['S' '180']\n",
      " ['V' '108']]\n",
      "['N' 'N' 'S' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'V' 'N' 'N']\n",
      "881\n",
      "[['N' '1087']\n",
      " ['Q' '3']\n",
      " ['S' '539']\n",
      " ['V' '255']]\n",
      "['N' 'N' 'S' 'S' 'S' 'S' 'N' 'N' 'S' 'V' 'N' 'N' 'V' 'N' 'N' 'N' 'N' 'N'\n",
      " 'V']\n",
      "882\n",
      "[['N' '1571']\n",
      " ['S' '34']\n",
      " ['V' '5']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "883\n",
      "[['N' '1479']\n",
      " ['S' '33']\n",
      " ['V' '3']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "884\n",
      "[['N' '2031']\n",
      " ['Q' '1']\n",
      " ['S' '48']\n",
      " ['V' '320']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'V' 'N' 'N' 'N' 'N' 'S'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "885\n",
      "[['N' '1244']\n",
      " ['Q' '1']\n",
      " ['S' '345']\n",
      " ['V' '41']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'V' 'N' 'N']\n",
      "886\n",
      "[['N' '1802']\n",
      " ['S' '26']\n",
      " ['V' '22']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "887\n",
      "[['N' '1962']\n",
      " ['Q' '1']\n",
      " ['S' '120']\n",
      " ['V' '157']]\n",
      "['N' 'V' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'V' 'V' 'N' 'N' 'V'\n",
      " 'N' 'N' 'N' 'N']\n",
      "888\n",
      "[['N' '1825']\n",
      " ['S' '54']\n",
      " ['V' '46']]\n",
      "['N' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S'\n",
      " 'V']\n",
      "889\n",
      "[['N' '1211']\n",
      " ['S' '131']\n",
      " ['V' '80']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N']\n",
      "890\n",
      "[['N' '1655']\n",
      " ['S' '70']\n",
      " ['V' '85']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'V' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "891\n",
      "[['N' '1778']\n",
      " ['S' '235']\n",
      " ['V' '157']]\n",
      "['V' 'N' 'N' 'N' 'N' 'N' 'N' 'V' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'V'\n",
      " 'S' 'N' 'N' 'V']\n",
      "892\n",
      "[['N' '1454']\n",
      " ['S' '416']\n",
      " ['V' '497']]\n",
      "['N' 'N' 'S' 'N' 'N' 'V' 'N' 'V' 'N' 'N' 'V' 'N' 'N' 'N' 'N' 'N' 'S' 'V'\n",
      " 'N' 'N' 'V' 'S' 'N' 'N']\n",
      "893\n",
      "[['N' '1809']\n",
      " ['V' '296']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N']\n",
      "894\n",
      "[['N' '1839']\n",
      " ['Q' '1']\n",
      " ['S' '71']\n",
      " ['V' '43']]\n",
      "['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N']\n"
     ]
    }
   ],
   "source": [
    "for patient in data_beats_v:\n",
    "    print(patient)\n",
    "    unique, counts = np.unique(data_beats_t[patient]['class'],return_counts=True)\n",
    "    print(np.asarray((unique, counts)).T)\n",
    "    print(data_beats_v[patient]['class'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1689631557685,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "qBVooYjHvy1s"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "class MIT_BIH(Dataset):\n",
    "    def __init__(self,patients,data):\n",
    "        self.patients = patients\n",
    "        self.data = data\n",
    "        self.to_one_dataset()\n",
    "\n",
    "    def to_one_dataset(self):\n",
    "        length_total = 0\n",
    "        for patient in self.patients:\n",
    "            length_total += len(self.data[patient]['beats'])\n",
    "           # print(len(self.data[patient]['beats']))\n",
    "        data_vector = torch.zeros(length_total,128)\n",
    "        labels_vector = torch.zeros(length_total)\n",
    "        k = 0\n",
    "        for i,patient in enumerate(self.patients):\n",
    "            data_vector[k:k+len(self.data[patient]['beats']),:] = torch.from_numpy(self.data[patient]['beats'])\n",
    "            classes = copy.deepcopy(self.data[patient]['class'])\n",
    "            indices = classes=='N'\n",
    "            indices2 = classes=='S'\n",
    "            indices3 = classes== 'V' \n",
    "            indices4 = classes== 'F'\n",
    "            indices5 = classes== 'Q'\n",
    "            \n",
    "            classes[indices] = 0\n",
    "            classes[indices2] = 1\n",
    "            classes[indices3] = 2\n",
    "            classes[indices4] = 2 # classify F as V \n",
    "            classes[indices5] = 3 \n",
    "            classes = np.array(classes,dtype='int')\n",
    "            labels_vector[k:k+len(self.data[patient]['beats'])] = torch.from_numpy(classes)\n",
    "            k += len(self.data[patient]['beats'])\n",
    "        #remove q entries \n",
    "        indices6 = np.array(labels_vector != 3)\n",
    "        self.y = torch.masked_select(labels_vector,torch.from_numpy(indices6)).long()\n",
    "        self.X = data_vector[indices6,:].double()\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return (self.X[idx,:],self.y[idx])\n",
    "patients_left = [x for x in list(data_beats_tr.keys()) if x not in paced_patients]\n",
    "\n",
    "mit_bih = MIT_BIH(patients_left,data_beats_tr)\n",
    "x_sample,y_sample = mit_bih.__getitem__(0)\n",
    "dataloader = DataLoader(mit_bih,batch_size=32,shuffle=True,num_workers=0)\n",
    "mit_bih_test = MIT_BIH(patients_left,data_beats_v)\n",
    "x_sample,y_sample = mit_bih_test.__getitem__(0)\n",
    "dataloader_test = DataLoader(mit_bih_test,batch_size=32,shuffle=False,num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1fac0f7220>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mit_bih.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1689631557686,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "-GlNOOk0xzXM"
   },
   "outputs": [],
   "source": [
    "# So, in the S dataset, there are a lot more 'unhealthy' patients than heal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6j5U13Lx33T"
   },
   "source": [
    "So, in the Supraventricular dataset, there are a lot more very 'unhealthy' patients than healthy or moderately unhealthy patients. Maybe, for the purposes of my paper, I should leave out patients that don't have arrhythmia episodes in their training/entire dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1689631557687,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "DckUDmpnF_Kw"
   },
   "outputs": [],
   "source": [
    "def get_base_model(in_channels):\n",
    "    \"\"\"\n",
    "    Returns the model from paper: Personalized Monitoring and Advance Warning System for Cardiac Arrhythmias.\n",
    "    \"\"\"\n",
    "    # Input size: 128x1\n",
    "    # 128x1 -> 122x32 -> 40x32 -> 34x16 -> 11x16 -> 5x16 -> 1x16\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv1d(in_channels, 32, kernel_size=7, padding=0, bias=True),\n",
    "        nn.MaxPool1d(3),\n",
    "        nn.Tanh(),\n",
    "\n",
    "        nn.Conv1d(32, 16, kernel_size=7, padding=0, bias=True),\n",
    "        nn.MaxPool1d(3),\n",
    "        nn.Tanh(),\n",
    "\n",
    "        nn.Conv1d(16, 16, kernel_size=7, padding=0, bias=True),\n",
    "        nn.MaxPool1d(3),\n",
    "        nn.Tanh(),\n",
    "\n",
    "        nn.Flatten(),\n",
    "\n",
    "        nn.Linear(16, 32, bias=True),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        nn.Linear(32, 3, bias=True),\n",
    "\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1689631558104,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "ElXCrmf5F_h-"
   },
   "outputs": [],
   "source": [
    "# Combinatorial UCB\n",
    "import math\n",
    "\n",
    "class combinatorial_UCB(object):\n",
    "    def __init__(self,n_clients,algorithm='UCB1_tuned'):\n",
    "        self.n_clients = n_clients\n",
    "\n",
    "        # define variables for storage\n",
    "        # which clients we select\n",
    "        self.times_selected = np.zeros((n_clients,n_clients)) # to record how often each client got selected\n",
    "        self.reward_per_client = np.zeros((n_clients,n_clients)) # to record what reward we collected per client\n",
    "        self.reward2_per_client = np.zeros((n_clients,n_clients)) # to record the squared reward per client (needed for UCB1-tuned)\n",
    "        # how many clients we select\n",
    "        self.n_clients_selected_arr = []\n",
    "        self.reward3_per_client = np.zeros((n_clients,n_clients-1))\n",
    "        self.times_selected2 = np.zeros((n_clients,n_clients-1))\n",
    "\n",
    "        self.algorithm = algorithm\n",
    "\n",
    "    def UCB(self,this_client,n):\n",
    "        #for this_client in range(self.n_clients):\n",
    "        other_clients = [x for x in range(self.n_clients) if x != this_client[0]]\n",
    "\n",
    "        upper_bound = np.zeros(self.n_clients)\n",
    "        for i,other_client in enumerate(other_clients):\n",
    "            if self.times_selected[this_client,other_client]==0: # make first iteration value high\n",
    "                upper_bound[other_client] = 1e500\n",
    "            else:\n",
    "                # We first calculate the average reward gained for this client\n",
    "                average_reward = self.reward_per_client[this_client,other_client] / self.times_selected[this_client,other_client]\n",
    "\n",
    "                # Then we compute the confidence interval [avg_reward - delta, avg_reward + delta]\n",
    "                if self.algorithm == 'UCB1':\n",
    "                    delta = math.sqrt( 2 * math.log(n) / self.times_selected[this_client,other_client])\n",
    "\n",
    "                if self.algorithm == 'UCB1_tuned':\n",
    "                    variance_bound = self.reward2_per_client[this_client,other_client] / self.times_selected[this_client,other_client] - average_reward**2\n",
    "                    variance_bound += math.sqrt(2 * math.log(n)/self.times_selected[this_client,other_client])\n",
    "\n",
    "                    factor = np.min([variance_bound, 1/4])\n",
    "                    delta = math.sqrt( factor * math.log(n) / self.times_selected[this_client,other_client] )\n",
    "\n",
    "                # upper bound\n",
    "                upper_bound[other_client] = average_reward + delta\n",
    "\n",
    "        if self.algorithm == 'random':\n",
    "            upper_bound = np.random.rand(self.n_clients)\n",
    "\n",
    "        # select the client with the highest upper bound\n",
    "        sorted_upper_bound = np.flip(np.argsort(upper_bound))\n",
    "\n",
    "        #n_clients_selected_arr.append(n_clients_selected)\n",
    "        selected_clients = sorted_upper_bound[:int(n+1)]\n",
    "\n",
    "        self.times_selected[this_client,selected_clients] += 1\n",
    "        return selected_clients\n",
    "\n",
    "    def collect_reward(self,this_client,selected_clients,observations):\n",
    "        # collect the reward\n",
    "        reward = observations[selected_clients]#df.iloc[n,selected_client]\n",
    "        self.reward_per_client[this_client,selected_clients] += reward\n",
    "        self.reward2_per_client[this_client,selected_clients] += reward**2\n",
    "\n",
    "        # reward for numbers of clients selected\n",
    "        n_clients_selected = len(selected_clients)-1\n",
    "        self.times_selected2[this_client,n_clients_selected] += 1\n",
    "        reward2 = np.abs(n_clients_selected - np.sum(observations))\n",
    "        self.reward3_per_client[this_client,n_clients_selected] += 1 - reward2 / self.n_clients\n",
    "\n",
    "\n",
    "    def to_client(self,this_client,n):\n",
    "        self.selected_clients = self.UCB(this_client,n)\n",
    "        return self.selected_clients\n",
    "\n",
    "    # Combinatorial UCB\n",
    "import math\n",
    "\n",
    "class combinatorial_UCB(object):\n",
    "    def __init__(self,n_clients,algorithm='UCB1_tuned'):\n",
    "        self.n_clients = n_clients\n",
    "\n",
    "        # define variables for storage\n",
    "        # which clients we select\n",
    "        self.times_selected = np.zeros((n_clients,n_clients)) # to record how often each client got selected\n",
    "        self.reward_per_client = np.zeros((n_clients,n_clients)) # to record what reward we collected per client\n",
    "        self.reward2_per_client = np.zeros((n_clients,n_clients)) # to record the squared reward per client (needed for UCB1-tuned)\n",
    "        # how many clients we select\n",
    "        self.n_clients_selected_arr = []\n",
    "        self.reward3_per_client = np.zeros((n_clients,n_clients-1))\n",
    "        self.times_selected2 = np.zeros((n_clients,n_clients-1))\n",
    "\n",
    "        self.algorithm = algorithm\n",
    "\n",
    "    def UCB(self,this_client,n):\n",
    "        #for this_client in range(self.n_clients):\n",
    "        other_clients = [x for x in range(self.n_clients) if x != this_client[0]]\n",
    "\n",
    "        upper_bound = np.zeros(self.n_clients)\n",
    "        for i,other_client in enumerate(other_clients):\n",
    "            if self.times_selected[this_client,other_client]==0: # make first iteration value high\n",
    "                upper_bound[other_client] = 1e500\n",
    "            else:\n",
    "                # We first calculate the average reward gained for this client\n",
    "                average_reward = self.reward_per_client[this_client,other_client] / self.times_selected[this_client,other_client]\n",
    "\n",
    "                # Then we compute the confidence interval [avg_reward - delta, avg_reward + delta]\n",
    "                if self.algorithm == 'UCB1':\n",
    "                    delta = math.sqrt( 2 * math.log(n) / self.times_selected[this_client,other_client])\n",
    "\n",
    "                if self.algorithm == 'UCB1_tuned':\n",
    "                    variance_bound = self.reward2_per_client[this_client,other_client] / self.times_selected[this_client,other_client] - average_reward**2\n",
    "                    variance_bound += math.sqrt(2 * math.log(n)/self.times_selected[this_client,other_client])\n",
    "\n",
    "                    factor = np.min([variance_bound, 1/4])\n",
    "                    delta = math.sqrt( factor * math.log(n) / self.times_selected[this_client,other_client] )\n",
    "\n",
    "                # upper bound\n",
    "                upper_bound[other_client] = average_reward + delta\n",
    "\n",
    "        if self.algorithm == 'random':\n",
    "            upper_bound = np.random.rand(self.n_clients)\n",
    "\n",
    "        # select the client with the highest upper bound\n",
    "        sorted_upper_bound = np.flip(np.argsort(upper_bound))\n",
    "\n",
    "        #n_clients_selected_arr.append(n_clients_selected)\n",
    "        selected_clients = sorted_upper_bound[:int(n+1)]\n",
    "\n",
    "        self.times_selected[this_client,selected_clients] += 1\n",
    "        return selected_clients\n",
    "\n",
    "    def collect_reward(self,this_client,selected_clients,observations):\n",
    "        # collect the reward\n",
    "        reward = observations[selected_clients]#df.iloc[n,selected_client]\n",
    "        self.reward_per_client[this_client,selected_clients] += reward\n",
    "        self.reward2_per_client[this_client,selected_clients] += reward**2\n",
    "\n",
    "        # reward for numbers of clients selected\n",
    "        n_clients_selected = len(selected_clients)-1\n",
    "        self.times_selected2[this_client,n_clients_selected] += 1\n",
    "        reward2 = np.abs(n_clients_selected - np.sum(observations))\n",
    "        self.reward3_per_client[this_client,n_clients_selected] += 1 - reward2 / self.n_clients\n",
    "\n",
    "\n",
    "    def to_client(self,this_client,n):\n",
    "        self.selected_clients = self.UCB(this_client,n)\n",
    "        return self.selected_clients\n",
    "\n",
    "    def to_server(self,this_client,observation):\n",
    "        self.collect_reward(this_client,self.selected_clients,observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1689632023097,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "LPVJ0bDBF_kn"
   },
   "outputs": [],
   "source": [
    "class P2P_AFPL():\n",
    "\n",
    "    def __init__(self,patients_left,train_data,test_data,real_test_data,test='local'):\n",
    "        self.selected_clients = patients_left\n",
    "        self.network = get_base_model(1)\n",
    "        self.best_test_loss = {}\n",
    "        self.best_test_loss_global = 1000000\n",
    "        self.current_test_loss = {}\n",
    "        self.current_train_loss = {}\n",
    "        self.test = test\n",
    "        self.total_clients = len(self.selected_clients)\n",
    "        self.patients_left = patients_left\n",
    "        self.client_models = {}\n",
    "        self.optimizers = {}\n",
    "        self.dataloaders = {}\n",
    "        self.len = {}\n",
    "        self.len_test = {}\n",
    "        self.dataloaders_test = {}\n",
    "        self.dataloaders_really_test = {}\n",
    "        self.len_really_test = {}\n",
    "        if self.test == 'AFPL':\n",
    "            self.client_models_global = {}\n",
    "\n",
    "        if self.test == 'bandits':\n",
    "            self.comb_UCB = combinatorial_UCB(self.total_clients)\n",
    "\n",
    "        for idx,i in enumerate(self.patients_left):\n",
    "            self.client_models[str(idx)] = copy.deepcopy(self.network).double().cuda()\n",
    "            self.optimizers[str(idx)] = torch.optim.SGD(self.client_models[str(idx)].parameters(),lr=0.01,momentum=0.5)\n",
    "            dataset_train=  MIT_BIH([self.patients_left[idx]],train_data)\n",
    "            self.len[str(idx)] = len(dataset_train)\n",
    "            self.dataloaders[str(idx)] = DataLoader(dataset_train,batch_size=32,shuffle=True,num_workers=0)\n",
    "\n",
    "\n",
    "            dataset_test= MIT_BIH([self.patients_left[idx]],test_data)\n",
    "            self.len_test[str(idx)] = len(dataset_test)\n",
    "            self.dataloaders_test[str(idx)] = DataLoader(dataset_test,batch_size=32,shuffle=False)\n",
    "            \n",
    "            dataset_really_test=  MIT_BIH([self.patients_left[idx]],real_test_data)\n",
    "            self.len_really_test[str(idx)] = len(dataset_really_test)\n",
    "            self.dataloaders_really_test[str(idx)] = DataLoader(dataset_really_test,batch_size=32,shuffle=True,num_workers=0)\n",
    "            \n",
    "            self.best_test_loss[str(idx)] = 10000000\n",
    "            self.current_test_loss[str(idx)] = 100000\n",
    "            self.current_train_loss[str(idx)] = 1000000\n",
    "            if self.test == 'AFPL':\n",
    "                self.client_models_global[str(idx)] = copy.deepcopy(self.network).double().cuda()\n",
    "                self.shared_model = copy.deepcopy(self.network).double().cuda()\n",
    "        self.dataset_train = dataset_train\n",
    "\n",
    "    def update_local_models(self,selected_clients):\n",
    "        self.dw = {}\n",
    "        loss_test = 0\n",
    "        loss_test2 = 0\n",
    "        losses = 0\n",
    "        losses2 = 0\n",
    "        loss_test3 = 0\n",
    "        losses3 = 0\n",
    "\n",
    "        for idx,i in enumerate(selected_clients):\n",
    "\n",
    "            dataloader = self.dataloaders[str(i)]\n",
    "            optimizer= torch.optim.Adam(self.client_models[str(i)].parameters(),lr=0.001*0.95**self.iteration)\n",
    "            self.client_models[str(i)].train()\n",
    "\n",
    "            if self.test == 'AFPL':\n",
    "                self.client_models_global[str(i)] = copy.deepcopy(self.shared_model)\n",
    "                self.client_models_global[str(i)].train()\n",
    "                optimizer_global = torch.optim.Adam(self.client_models_global[str(i)].parameters(),lr=0.001*0.95**self.iteration)\n",
    "\n",
    "            for batch_idx, (data, target) in enumerate(dataloader):\n",
    "                data   = data.double().unsqueeze(1).cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.client_models[str(i)](data)\n",
    "                output = F.log_softmax(output,dim=-1)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                #output = self.client_models[str(i)](data)\n",
    "                loss = F.nll_loss(output,target)\n",
    "\n",
    "                if self.test == 'AFPL':\n",
    "                    optimizer_global.zero_grad()\n",
    "                    output_global= self.client_models_global[str(i)](data)\n",
    "                    loss_global = F.nll_loss(output_global,target)\n",
    "                    loss_global.backward()\n",
    "                    optimizer_global.step()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            self.client_models[str(i)].eval()\n",
    "            dataloader_test = self.dataloaders_test[str(i)]\n",
    "            loss_test = 0\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (data, target) in enumerate(dataloader_test):\n",
    "                    data   = data.double().unsqueeze(1).cuda()\n",
    "                    target = target.long().cuda()\n",
    "                    output = self.client_models[str(i)](data)\n",
    "                    output = F.log_softmax(output,dim=-1)\n",
    "\n",
    "                    loss_test += F.nll_loss(output,target)\n",
    "                self.current_test_loss[str(i)] = loss_test/self.len_test[str(i)]\n",
    "                if self.current_test_loss[str(i)] < self.best_test_loss[str(i)]:\n",
    "                    torch.save(self.client_models[str(i)].state_dict(), os.path.join(save_dir, 'model', 'best_model'+str(i)+'.pt'))\n",
    "                    self.best_test_loss[str(i)] = self.current_test_loss[str(i)]\n",
    "\n",
    "            losses += loss_test /self.len_test[str(i)]\n",
    "            loss_test2 = 0\n",
    "            self.client_models[str(i)].eval()\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (data, target) in enumerate(dataloader):\n",
    "                    data   = data.double().unsqueeze(1).cuda()\n",
    "                    target = target.long().cuda()\n",
    "                    output = self.client_models[str(i)](data)\n",
    "                    output = F.log_softmax(output,dim=-1)\n",
    "\n",
    "                    loss_test2 += F.nll_loss(output,target)\n",
    "\n",
    "                losses2 += loss_test2/ self.len[str(i)]\n",
    "                self.current_train_loss[str(i)] = loss_test2/self.len[str(i)]\n",
    "\n",
    "        print('full train loss: ',losses2)\n",
    "        print('full loss: ',losses)\n",
    "\n",
    "        return losses2,losses\n",
    "\n",
    "    def combine_models(self,i,client_numbers,set_as=True):\n",
    "        zero_copy = copy.deepcopy(self.client_models[str(i)]) # This is used to collect the model in\n",
    "        j =0\n",
    "        client_numbers_plus_client = np.concatenate((client_numbers,np.array([int(i)])))# This is more efficient\n",
    "      #  alphas = zero_copy.alphas.detach()\n",
    "       # alphas[i] = 1 - torch.sum(\n",
    "       #     torch.tensor([iii for idx, iii in enumerate(alphas) if idx != i and idx in client_numbers]))\n",
    "        # It's not possible to set the value of self.alphas[i], so instead we determine it manually here\n",
    "        alphas = torch.ones(len(client_numbers_plus_client)).cuda()/(len(client_numbers_plus_client))\n",
    "        #print(alphas)\n",
    "        for ii in client_numbers_plus_client:\n",
    "          #  print(ii)\n",
    "            for (name, param),(name2,param2) in zip(zero_copy.named_parameters(),self.client_models[str(ii)].named_parameters()): #self.client_models[str(ii)].named_parameters()):\n",
    "\n",
    "                if name != 'alphas':\n",
    "                    if j == 0:\n",
    "                        param.data = torch.zeros(param.shape).cuda()\n",
    "\n",
    "                    param.data += alphas[j]*param2.data # we add all participating client's models to the one here.\n",
    "\n",
    "            j += 1\n",
    "\n",
    "        #self.client_models[str(i)] = zero_copy.double()\n",
    "        if set_as == True:\n",
    "            for (name,param),(name2,param2) in zip(self.client_models[str(i)].named_parameters(),zero_copy.named_parameters()):\n",
    "                param.data = param2.data\n",
    "            self.client_models[str(i)].double()\n",
    "        else:\n",
    "            return zero_copy.double()\n",
    "\n",
    "    def federated_averaging(self):\n",
    "        self.shared_model = copy.deepcopy(self.network).double().cuda()\n",
    "        n_clients = len(self.selected_clients)\n",
    "        weight = [self.len[str(x)] for x in self.selected_clients]\n",
    "        weight = weight / np.sum(weight)\n",
    "\n",
    "        losses = 0\n",
    "        losses2 = 0\n",
    "        #print(\"weights \",weight)\n",
    "        for idx,i in enumerate(self.selected_clients):\n",
    "            for (name, param),(name2,param2) in zip(self.shared_model.named_parameters()\n",
    "                                                      ,self.client_models[str(i)].named_parameters()):\n",
    "                if idx == 0:\n",
    "                    param.data = torch.zeros(param.shape).cuda().double()\n",
    "                param.data += weight[idx]*param2.data\n",
    "\n",
    "        self.shared_model = self.shared_model.double().eval()\n",
    "\n",
    "        for i in self.selected_clients:\n",
    "            self.client_models[str(i)] = copy.deepcopy(self.shared_model) #copy global model to the clients\n",
    "            loss_test = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(i)]):\n",
    "                data   = data.double().unsqueeze(1).cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.shared_model(data)\n",
    "\n",
    "                output = F.log_softmax(output,dim=-1)\n",
    "\n",
    "                loss_test += F.nll_loss(output,target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test = loss_test/self.len_test[str(i)]\n",
    "            losses += loss_test\n",
    "            if loss_test < self.best_test_loss[str(i)]:\n",
    "                    torch.save(self.client_models[str(i)].state_dict(), os.path.join(save_dir, 'model', 'best_model'+str(i)+'.pt'))\n",
    "                    self.best_test_loss[str(i)] = loss_test\n",
    "            self.client_models[str(i)].eval()\n",
    "            loss_test2 = 0\n",
    "            for batch_idx, (data,target) in enumerate(self.dataloaders[str(i)]):\n",
    "                data   = data.double().unsqueeze(1).cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.shared_model(data)\n",
    "                output = F.log_softmax(output,dim=-1)\n",
    "\n",
    "                loss_test2 += F.nll_loss(output,target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test2 = loss_test2/self.len[str(i)]\n",
    "            losses2 += loss_test2\n",
    "\n",
    "\n",
    "        return losses, losses2\n",
    "\n",
    "    def AFPL(self): #use alpha = 0.25 = 0.75 global model + 0.25 local model\n",
    "        self.shared_model_old = copy.deepcopy(self.shared_model)\n",
    "        self.shared_model = copy.deepcopy(self.network).double().cuda()\n",
    "        n_clients = len(self.selected_clients)\n",
    "        weight = [self.len[str(x)] for x in self.selected_clients]\n",
    "        weight = weight / np.sum(weight)\n",
    "\n",
    "        losses = 0\n",
    "        losses2 = 0\n",
    "\n",
    "        #accumulate local weights\n",
    "        for idx,i in enumerate(self.selected_clients):\n",
    "            for (name, param),(name2,param2),(name3,param3),(name4,param4) in zip(self.shared_model.named_parameters()\n",
    "                                                      ,self.client_models_global[str(i)].named_parameters(),\n",
    "                                                                  self.shared_model_old.named_parameters(),\n",
    "                                                        self.client_models[str(i)].named_parameters()):\n",
    "                if idx == 0:\n",
    "                    param.data = torch.zeros(param.shape).cuda().double()\n",
    "                param.data += weight[idx]*param2.data # accumulate local weights\n",
    "                param4.data = 0.25*param4.data + 0.75*param3.data # do AFPL local model update: note that we take the previous global model\n",
    "            self.client_models[str(i)] = self.client_models[str(i)].double()\n",
    "            self.client_models[str(i)].eval()\n",
    "            loss_test = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(i)]):\n",
    "                data   = data.double().unsqueeze(1).cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.client_models[str(i)](data)\n",
    "                output = F.log_softmax(output,dim=-1)\n",
    "\n",
    "                loss_test += F.nll_loss(output,target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test = loss_test/self.len_test[str(i)]\n",
    "            losses += loss_test\n",
    "            if loss_test < self.best_test_loss[str(i)]:\n",
    "                    torch.save(self.client_models[str(i)].state_dict(), os.path.join(save_dir, 'model', 'best_model'+str(i)+'.pt'))\n",
    "                    self.best_test_loss[str(i)] = loss_test\n",
    "            self.client_models[str(i)].eval()\n",
    "            loss_test2 = 0\n",
    "            for batch_idx, (data,target) in enumerate(self.dataloaders[str(i)]):\n",
    "                data   = data.double().unsqueeze(1).cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.client_models[str(i)](data)\n",
    "                output = F.log_softmax(output,dim=-1)\n",
    "\n",
    "                loss_test2 += F.nll_loss(output,target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test2 = loss_test2/self.len[str(i)]\n",
    "            losses2 += loss_test2\n",
    "\n",
    "        self.shared_model = self.shared_model.double()\n",
    "        return losses, losses2\n",
    "\n",
    "    def calc_accuracy(self,dataloader,length):\n",
    "        accuracies = np.zeros(len(self.selected_clients))\n",
    "        total = 0\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        self.accuracy_list = []\n",
    "        for i in self.selected_clients:\n",
    "            #dataloader = dataloader\n",
    "            intermediate_accuracy = 0\n",
    "            self.client_models[str(i)].eval()\n",
    "              #y_pred = []\n",
    "              #y_true = []\n",
    "            for batch_idx, (data, target) in enumerate(dataloader):\n",
    "                data = data.unsqueeze(1).double().cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = self.client_models[str(i)](data)\n",
    "                output = F.log_softmax(output,dim=-1)\n",
    "                output_array = output.detach().cpu().numpy()\n",
    "                output_class = np.argmax(output_array,axis=-1)\n",
    "                target_array = target.detach().cpu().numpy()\n",
    "                intermediate_accuracy += np.sum(output_class == target_array)\n",
    "                 # y_pred.append(list(output_class))\n",
    "                 # y_true.append(list(target_array))\n",
    "                y_true = np.hstack((y_true,[x for x in list(target_array)]))\n",
    "                y_pred = np.hstack((y_pred,[x for x in list(output_class)]))\n",
    "                true = [x for x in list(target_array)]\n",
    "                pred = [x for x in list(output_class)]\n",
    "                 # preds2 = np.hstack((preds2, [x for x in list(output_class2)]))\n",
    "\n",
    "\n",
    "            accuracy = intermediate_accuracy/length*100\n",
    "            self.accuracy_list.append(sklearn.metrics.balanced_accuracy_score(true,pred))\n",
    "              #print(i)\n",
    "\n",
    "            total += self.len_test[str(i)]\n",
    "            accuracies[i] = intermediate_accuracy\n",
    "        overall_accuracy = np.sum(accuracies)/total*100\n",
    "     #     print(y_true)\n",
    "     #     print(y_pred)\n",
    "        overall_accuracy = sklearn.metrics.balanced_accuracy_score(y_true,y_pred)\n",
    "        return overall_accuracy\n",
    "\n",
    "    def bandits(self,client,n):\n",
    "\n",
    "        selected_clients = []\n",
    "        other_clients = [x for x in range(self.total_clients) if x != client]\n",
    "          #print(other_clients)\n",
    "        ey = np.zeros(self.total_clients)# fix indices\n",
    "        current_test = np.zeros(self.total_clients)\n",
    "        collected_clients = []\n",
    "\n",
    "        selected_clients_UCB = self.comb_UCB.to_client([client],n)\n",
    "        if client == 14:\n",
    "            print('selected clients UCB: ',selected_clients_UCB)\n",
    "        old_accuracy = 0\n",
    "        for i in selected_clients_UCB:\n",
    "            shared_model = self.combine_models(client,[i],set_as=False)\n",
    "\n",
    "            if len(collected_clients)>0:\n",
    "                all_clients = collected_clients+[i]\n",
    "                shared_model2 = self.combine_models(client,all_clients,set_as=False)\n",
    "\n",
    "            shared_model.eval().cuda()\n",
    "            self.client_models[str(client)].eval().cuda()\n",
    "            loss_test = 0\n",
    "            loss_test2 = 0\n",
    "            loss_test3 = 0\n",
    "            accuracy_local = 0\n",
    "            accuracy_shared = 0\n",
    "\n",
    "            preds1 = []\n",
    "            targets = []\n",
    "            preds2 = []\n",
    "\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(client)]):\n",
    "                data = data.unsqueeze(1).double().cuda()\n",
    "                target = target.long().cuda()\n",
    "                output = shared_model(data)\n",
    "                output = F.log_softmax(output,dim=-1)\n",
    "                output2 = self.client_models[str(client)](data)\n",
    "                output2 = F.log_softmax(output2,dim=-1)\n",
    "                loss_test += F.nll_loss(output,target).detach().cpu().numpy()\n",
    "                loss_test2 += F.nll_loss(output2,target).detach().cpu().numpy()\n",
    "\n",
    "                if len(collected_clients)>0:\n",
    "                    output = shared_model2(data)\n",
    "                    output = F.log_softmax(output,dim=-1)\n",
    "                    loss_test3 += F.nll_loss(output,target).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "                output_array = output.detach().cpu().numpy()\n",
    "                output_class = np.argmax(output_array, axis=-1)\n",
    "                target_array = target.detach().cpu().numpy()\n",
    "                accuracy_shared += np.sum(output_class == target_array)\n",
    "\n",
    "                output_array2 = output2.detach().cpu().numpy()\n",
    "                output_class2 = np.argmax(output_array2, axis=-1)\n",
    "                accuracy_local += np.sum(output_class2 == target_array)\n",
    "\n",
    "                targets = np.hstack((targets,[x for x in list(target_array)]))\n",
    "                preds1 = np.hstack((preds1,[x for x in list(output_class)]))\n",
    "                preds2 = np.hstack((preds2, [x for x in list(output_class2)]))\n",
    "\n",
    "\n",
    "            accuracy_locals = accuracy_local / self.len_test[str(client)] * 100\n",
    "            accuracy_shareds = accuracy_shared / self.len_test[str(client)] *100\n",
    "            accuracy_locals = sklearn.metrics.balanced_accuracy_score(targets,preds2)\n",
    "            accuracy_shareds = sklearn.metrics.balanced_accuracy_score(targets,preds1)\n",
    "            #  if client == 14:\n",
    "            #    print('CLIENT: ',i)\n",
    "            #    print(accuracy_locals)\n",
    "            #    print(old_accuracy)\n",
    "            #    print(accuracy_shareds)\n",
    "\n",
    "              # ACCURACY-based client selection\n",
    "            if accuracy_shareds > accuracy_locals and accuracy_shareds > old_accuracy:\n",
    "                collected_clients.append(i)\n",
    "             #     if client == 14:\n",
    "             #       print('added i to collected clients')\n",
    "                old_accuracy = accuracy_shareds\n",
    "        loss_test = current_test[i]\n",
    "        #selected_clients = np.where(ey<=self.current_test_loss[str(client)].detach().cpu().numpy() )[0]\n",
    "        ###selected_clients = [other_clients[x] for x in selected_clients]\n",
    "\n",
    "        selected_clients = collected_clients\n",
    "\n",
    "        observation = np.zeros(self.total_clients)\n",
    "        observation[selected_clients] = 1\n",
    "        if client == 14:\n",
    "            print(observation)\n",
    "\n",
    "        self.comb_UCB.to_server(client,observation)\n",
    "\n",
    "\n",
    "        if len(selected_clients) > 0 :\n",
    "            self.combine_models(client,selected_clients,set_as=True)\n",
    "            loss_test = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloaders_test[str(client)]):\n",
    "                data = data.unsqueeze(1).double().cuda()\n",
    "                target = target.long().cuda()\n",
    "                output2 = self.client_models[str(client)](data)\n",
    "                output2 = F.log_softmax(output2,dim=-1)\n",
    "\n",
    "                loss_test += F.nll_loss(output2,target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test = loss_test/self.len_test[str(client)]\n",
    "            if loss_test < self.best_test_loss[str(client)]:\n",
    "                    torch.save(self.client_models[str(client)].state_dict(), os.path.join(save_dir, 'model', 'best_model'+str(i)+'.pt'))\n",
    "                    self.best_test_loss[str(client)] = loss_test\n",
    "            self.client_models[str(client)].eval()\n",
    "            loss_test2 = 0\n",
    "            for batch_idx, (data,target) in enumerate(self.dataloaders[str(client)]):\n",
    "                data = data.unsqueeze(1).double().cuda()\n",
    "                target = target.long().cuda()\n",
    "                output2 = self.client_models[str(client)](data)\n",
    "                output2 = F.log_softmax(output2,dim=-1)\n",
    "\n",
    "                loss_test2 += F.nll_loss(output2,target).detach().cpu().numpy()\n",
    "\n",
    "            loss_test2 = loss_test2/self.len[str(client)]\n",
    "        return loss_test,loss_test2,selected_clients\n",
    "\n",
    "    def loop(self,epochs,p2p,experiment_name):\n",
    "\n",
    "        loss_tests = []\n",
    "        loss_trains = []\n",
    "        loss_tests2 = []\n",
    "        loss_trains2 = []\n",
    "        accuracies = []\n",
    "        accuracies_train = []\n",
    "        best_accuracy = 0 \n",
    "        self.p2p = p2p\n",
    "        self.phis = np.zeros((self.total_clients, self.total_clients))\n",
    "        self.selected_clients_arr = np.zeros((epochs,self.total_clients,self.total_clients))\n",
    "\n",
    "        for i in range(epochs):\n",
    "            print(i)\n",
    "            self.iteration = i\n",
    "            list1 = []\n",
    "            self.selected_clients = [x for x in range(self.total_clients)]\n",
    "\n",
    "            loss_train,loss_test = self.update_local_models(self.selected_clients)\n",
    "            loss_tests.append(loss_test.detach().cpu().numpy())\n",
    "            loss_trains.append(loss_train.detach().cpu().numpy())\n",
    "\n",
    "            if self.test == 'AFPL':\n",
    "                losses2, losses3 = self.AFPL()\n",
    "\n",
    "            if self.test == 'local':\n",
    "                print('we are done')\n",
    "\n",
    "            if self.test == 'federated':\n",
    "                losses2, losses3 = self.federated_averaging()\n",
    "\n",
    "            if self.test == 'bandits':\n",
    "                losses2 = 0\n",
    "                losses3 = 0\n",
    "                for client in range(self.total_clients):\n",
    "                    loss_test2,loss_train2,selected_clients2= self.bandits(client,20)\n",
    "                    losses2 += loss_test2\n",
    "                    if len(selected_clients2)< 1:\n",
    "                        losses3+= self.current_train_loss[str(client)].detach().cpu().numpy()\n",
    "                    else:\n",
    "                        losses3 += loss_train2\n",
    "                    self.phis[client,selected_clients2] += 1\n",
    "                    self.selected_clients_arr[i,client,selected_clients2] += 1\n",
    "                fname = os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', experiment_name, 'phi'+str(i)+'.txt')\n",
    "                print(fname)\n",
    "                np.savetxt(fname,self.phis)\n",
    "                print('saved?')\n",
    "\n",
    "            if self.test == 'mine':\n",
    "                losses2 = 0\n",
    "                losses3 = 0\n",
    "                for client in range(self.total_clients):\n",
    "                    loss_test2,loss_train2,selected_clients2= self.my_method2(client)\n",
    "                    losses2 += loss_test2\n",
    "                    if len(selected_clients2)< 1:\n",
    "                        losses3+= self.current_train_loss[str(client)].detach().cpu().numpy()\n",
    "\n",
    "                    else:\n",
    "                        losses3 += loss_train2\n",
    "                    self.phis[client,selected_clients2] += 1\n",
    "                    #print(selected_clients2)\n",
    "                fname = os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', experiment_name, 'phi'+str(i)+'.txt')\n",
    "                np.savetxt(fname,self.phis)\n",
    "\n",
    "            if self.test == 'optimal':\n",
    "                losses2, losses3 = self.optimal_fedavg()\n",
    "                losses2 = losses2.detach().cpu().numpy()\n",
    "                losses3 = losses3.detach().cpu().numpy()\n",
    "\n",
    "            if self.test != 'local':\n",
    "                print('loss after my code: ',losses2)\n",
    "                print('train loss after my code: ',losses3)\n",
    "                loss_tests2.append(losses2)\n",
    "                loss_trains2.append(losses3)\n",
    "                fname = os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', experiment_name, 'losses_test.txt')\n",
    "                np.savetxt(fname,loss_tests2)\n",
    "                fname = os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', experiment_name, 'losses_train.txt')\n",
    "                np.savetxt(fname,loss_trains2)\n",
    "\n",
    "\n",
    "            else:\n",
    "                fname = os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', experiment_name, 'losses_test.txt')\n",
    "                np.savetxt(fname,loss_tests)\n",
    "                fname = os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', experiment_name, 'losses_train.txt')\n",
    "                np.savetxt(fname,loss_trains)\n",
    "\n",
    "\n",
    "            accuracy_val = self.calc_accuracy(self.dataloaders_test[str(i)],self.len_test[str(i)])\n",
    "            accuracy = self.calc_accuracy(self.dataloaders_really_test[str(i)],self.len_really_test[str(i)])\n",
    "            print(accuracy)\n",
    "            accuracies.append(accuracy)\n",
    "            if accuracy_val > best_accuracy:\n",
    "                print(best_accuracy)\n",
    "                print('accuracy is best accuracy')\n",
    "                print(self.accuracy_list)\n",
    "                best_accuracy = accuracy_val\n",
    "\n",
    "                # save all of this in a .txt file\n",
    "                fname = os.path.join('checkpoints_bandits', experiment_name, 'test_accuracies.txt')\n",
    "                np.savetxt(fname, self.accuracy_list)\n",
    "                fname = os.path.join('checkpoints_bandits', experiment_name, 'test_accuracy.txt')\n",
    "                np.savetxt(fname, [accuracy])\n",
    "            # accuracy_train = self.calc_accuracy(test=False)\n",
    "            # print(accuracy_train)\n",
    "            # accuracies_train.append(accuracy_train)\n",
    "        # print(self.phis)\n",
    "            #accuracy_train = self.calc_accuracy(test=False)\n",
    "            #print(accuracy_train)\n",
    "            #accuracies_train.append(accuracy_train)\n",
    "        #print(self.phis)\n",
    "        fname = os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', experiment_name, 'accuracies.txt')\n",
    "        np.savetxt(fname, accuracies)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_trains,label='train loss before')\n",
    "        plt.plot(loss_tests,label='test loss before')\n",
    "        plt.plot(loss_trains2,label='train loss after')\n",
    "        plt.plot(loss_tests2,label='test loss after')\n",
    "        plt.title('loss curve')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.savefig(os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', experiment_name, 'loss_curve.png'))\n",
    "        plt.clf()\n",
    "        plt.plot(accuracies,label='test')\n",
    "       # plt.plot(accuracies_train,label='train')\n",
    "        plt.title('accuracy progression')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', experiment_name, 'accuracy_progression.png'))\n",
    "        return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 371,
     "status": "ok",
     "timestamp": 1689631803563,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "TgLifLgsMso1",
    "outputId": "49265473-d319-4ee3-ee57-fbcc7d1e1d02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits\n"
     ]
    }
   ],
   "source": [
    "#DATA_ROOT =  \"drive/MyDrive/mit-bih-supraventricular-arrhythmia-database-1.0.0\"\n",
    "#os.mkdir(\"drive/MyDrive/checkpoints_bandits\")\n",
    "import yaml\n",
    "import os\n",
    "import shutil\n",
    "dir = \"test3\"\n",
    "def init():\n",
    "\n",
    "    if not os.path.isdir('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits'):\n",
    "        os.mkdir('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits')\n",
    "    if not os.path.isdir(os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', dir)):\n",
    "        os.mkdir(os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits',dir))\n",
    "    save_dir = os.path.join('/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits', )\n",
    "    if not os.path.isdir(os.path.join(save_dir, 'model')):\n",
    "        os.mkdir(os.path.join(save_dir, 'model'))\n",
    "        print('made dir')\n",
    "    #shutil.copyfile('settings/train_settings.yaml', save_dir + '/train_settings.yaml')\n",
    "    return save_dir\n",
    "\n",
    "save_dir = init()\n",
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n"
     ]
    }
   ],
   "source": [
    "print(len(patients_left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 341130,
     "status": "ok",
     "timestamp": 1689632369268,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "TRYGf4FhsHMu",
    "outputId": "fe213a66-7e69-4768-aaf5-ea5bca308d8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "full train loss:  tensor(0.7604, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.9148, device='cuda:0', dtype=torch.float64)\n",
      "selected clients UCB:  [21 20  1  2  3  4  5  6  7  8  9 10 11 12 13 15 16 17 18 19  0]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "/mimer/NOBACKUP/groups/snic2022-22-122/arthur/code/Federated_Averaging/checkpoints_bandits/test3/phi0.txt\n",
      "saved?\n",
      "loss after my code:  0.12254189426645579\n",
      "train loss after my code:  0.7613602317100479\n",
      "0.48137626262626265\n",
      "0\n",
      "accuracy is best accuracy\n",
      "[1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import collections\n",
    "from time import time\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pandas\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "experiment_name = dir #settings['experiment_name']\n",
    "test = 'bandits' #[20:]\n",
    "n_epochs = 1 #settings['n_epochs']\n",
    "\n",
    "#p2p = P2P_AFPL(patients_left,data_beats_tr,data_beats_v,data_beats_t,test)\n",
    "p2p = P2P_AFPL(patients_left[:22],data_beats_tr,data_beats_v,data_beats_t,test)\n",
    "accuracies_bandits_2 = p2p.loop(n_epochs,p2p,experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(p2p.phis>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "executionInfo": {
     "elapsed": 152,
     "status": "aborted",
     "timestamp": 1689630833968,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "Q081gVvrZpPQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "full train loss:  tensor(4.1405, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(4.8794, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.46775104415628865\n",
      "1\n",
      "full train loss:  tensor(3.5037, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(4.1225, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.4046125324063103\n",
      "2\n",
      "full train loss:  tensor(2.9144, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(3.4214, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.4038802520344838\n",
      "3\n",
      "full train loss:  tensor(2.4688, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.8855, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.3973932447615507\n",
      "4\n",
      "full train loss:  tensor(2.1248, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.4697, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.39638007353561355\n",
      "5\n",
      "full train loss:  tensor(1.8557, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(2.1541, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.415231341897554\n",
      "6\n",
      "full train loss:  tensor(1.6558, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.9151, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.3973932447615507\n",
      "7\n",
      "full train loss:  tensor(1.5160, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.7330, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.3973932447615507\n",
      "8\n",
      "full train loss:  tensor(1.3941, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.5975, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.3973932447615507\n",
      "9\n",
      "full train loss:  tensor(1.3043, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.4963, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.4017505432364962\n",
      "10\n",
      "full train loss:  tensor(1.2459, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.4147, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.41755733876794765\n",
      "11\n",
      "full train loss:  tensor(1.1883, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.3495, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.4394481208076997\n",
      "12\n",
      "full train loss:  tensor(1.1373, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.2932, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.46123461318242737\n",
      "13\n",
      "full train loss:  tensor(1.0985, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.2451, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.45138489658382414\n",
      "14\n",
      "full train loss:  tensor(1.0556, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.2040, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.4545767170472341\n",
      "15\n",
      "full train loss:  tensor(1.0263, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.1674, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.48798267202181655\n",
      "16\n",
      "full train loss:  tensor(1.0014, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.1350, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.5124056573097233\n",
      "17\n",
      "full train loss:  tensor(0.9694, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.1052, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.5174402317576746\n",
      "18\n",
      "full train loss:  tensor(0.9489, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.0795, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.530055206825716\n",
      "19\n",
      "full train loss:  tensor(0.9352, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.0535, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.5413827554594469\n",
      "20\n",
      "full train loss:  tensor(0.9006, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.0309, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.5571229517936626\n",
      "21\n",
      "full train loss:  tensor(0.8985, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(1.0085, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.5657274945739759\n",
      "22\n",
      "full train loss:  tensor(0.8690, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.9876, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.5779153813335801\n",
      "23\n",
      "full train loss:  tensor(0.8517, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.9682, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.5791787402240859\n",
      "24\n",
      "full train loss:  tensor(0.8367, device='cuda:0', dtype=torch.float64)\n",
      "full loss:  tensor(0.9506, device='cuda:0', dtype=torch.float64)\n",
      "we are done\n",
      "0.5828465894354181\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import collections\n",
    "from time import time\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pandas\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "experiment_name = 'test' #settings['experiment_name']\n",
    "test = 'local' #[20:]\n",
    "n_epochs = 25 #settings['n_epochs']\n",
    "\n",
    "p2p = P2P_AFPL(patients_left,data_beats_tr,data_beats_v,test)\n",
    "accuracies_bandits_2 = p2p.loop(n_epochs,p2p,experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 152,
     "status": "aborted",
     "timestamp": 1689630833968,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "Gvs-88a60noV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "#print(phi)\n",
    "phi_binary =np.array(np.array(p2p.phis,dtype='bool'),dtype='int')\n",
    "#print(phi_binary)\n",
    "phi_graph = nx.from_numpy_array(p2p.phis)\n",
    "\n",
    "def community_layout(g, partition):\n",
    "    \"\"\"\n",
    "    Compute the layout for a modular graph.\n",
    "\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    g -- networkx.Graph or networkx.DiGraph instance\n",
    "        graph to plot\n",
    "\n",
    "    partition -- dict mapping int node -> int community\n",
    "        graph partitions\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pos -- dict mapping int node -> (float x, float y)\n",
    "        node positions\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    pos_communities = _position_communities(g, partition, scale=3.)\n",
    "\n",
    "    pos_nodes = _position_nodes(g, partition, scale=1.)\n",
    "\n",
    "    # combine positions\n",
    "    pos = dict()\n",
    "    for node in g.nodes():\n",
    "        pos[node] = pos_communities[node] + pos_nodes[node]\n",
    "\n",
    "    return pos\n",
    "\n",
    "def _position_communities(g, partition, **kwargs):\n",
    "\n",
    "    # create a weighted graph, in which each node corresponds to a community,\n",
    "    # and each edge weight to the number of edges between communities\n",
    "    between_community_edges = _find_between_community_edges(g, partition)\n",
    "\n",
    "    communities = set(partition.values())\n",
    "    hypergraph = nx.DiGraph()\n",
    "    hypergraph.add_nodes_from(communities)\n",
    "    for (ci, cj), edges in between_community_edges.items():\n",
    "        hypergraph.add_edge(ci, cj, weight=len(edges))\n",
    "\n",
    "    # find layout for communities\n",
    "    pos_communities = nx.spring_layout(hypergraph, **kwargs)\n",
    "\n",
    "    # set node positions to position of community\n",
    "    pos = dict()\n",
    "    for node, community in partition.items():\n",
    "        pos[node] = pos_communities[community]\n",
    "\n",
    "    return pos\n",
    "\n",
    "def _find_between_community_edges(g, partition):\n",
    "\n",
    "    edges = dict()\n",
    "\n",
    "    for (ni, nj) in g.edges():\n",
    "        ci = partition[ni]\n",
    "        cj = partition[nj]\n",
    "\n",
    "        if ci != cj:\n",
    "            try:\n",
    "                edges[(ci, cj)] += [(ni, nj)]\n",
    "            except KeyError:\n",
    "                edges[(ci, cj)] = [(ni, nj)]\n",
    "\n",
    "    return edges\n",
    "\n",
    "def _position_nodes(g, partition, **kwargs):\n",
    "    \"\"\"\n",
    "    Positions nodes within communities.\n",
    "    \"\"\"\n",
    "\n",
    "    communities = dict()\n",
    "    for node, community in partition.items():\n",
    "        try:\n",
    "            communities[community] += [node]\n",
    "        except KeyError:\n",
    "            communities[community] = [node]\n",
    "\n",
    "    pos = dict()\n",
    "    for ci, nodes in communities.items():\n",
    "        subgraph = g.subgraph(nodes)\n",
    "        pos_subgraph = nx.spring_layout(subgraph, **kwargs)\n",
    "        pos.update(pos_subgraph)\n",
    "\n",
    "    return pos\n",
    "\n",
    "def test(g):\n",
    "# to install networkx 2.0 compatible version of python-louvain use:\n",
    "    # pip install -U git+https://github.com/taynaud/python-louvain.git@networkx2\n",
    "    from community import community_louvain\n",
    "\n",
    "    #g = nx.karate_club_graph()\n",
    "    partition = community_louvain.best_partition(g)\n",
    "    print(partition)\n",
    "    pos = community_layout(g, partition)\n",
    "\n",
    "    #nx.draw(g, pos, node_color=list(dict_partition.values())); plt.show()\n",
    "\n",
    "    nodelist = g.nodes()\n",
    "    widths = nx.get_edge_attributes(g,'weight')\n",
    "    cmap = plt.cm.get_cmap('cool')#Spectral\n",
    "    maxval = 27\n",
    "    plt.figure(figsize=(7,7))\n",
    "    nx.draw_networkx_nodes(g,pos,nodelist=nodelist,node_size=100,\n",
    "                          node_color= [cmap(v/maxval) for v in partition.values()])#list(partition.values()))\n",
    "    print(list(partition.values()))\n",
    "    labels = [str(i) for i in range(78)]\n",
    "    #labels = ['healthy','moderately unhealthy','very unhealthy']\n",
    "    for v in set(partition.values()):\n",
    "        plt.scatter([],[],c=[cmap(v/maxval)],label=labels[v])\n",
    "\n",
    "    nx.draw_networkx_edges(g,pos,edgelist=widths.keys(),width=list(widths.values()),edge_color='k')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return partition\n",
    "\n",
    "partition = test(phi_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 152,
     "status": "aborted",
     "timestamp": 1689630833969,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "k6kotP0C2Ly0"
   },
   "outputs": [],
   "source": [
    "print(partition)\n",
    "values = [x for x in partition.values()]\n",
    "print(values)\n",
    "values = np.array(values)\n",
    "unique_partitions = np.unique(values)\n",
    "print(np.histogram(values,bins=23)[0])\n",
    "print(np.argwhere(values==4))\n",
    "print(np.argwhere(values==7))\n",
    "print(np.argwhere(values==1))\n",
    "print(np.argwhere(values==11))\n",
    "print(np.argwhere(values==12))\n",
    "print(np.argwhere(values==13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 153,
     "status": "aborted",
     "timestamp": 1689630833971,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "PiOwweQhF_nd"
   },
   "outputs": [],
   "source": [
    "#print(p2p.phis[15,:])\n",
    "print(np.max(p2p.phis))\n",
    "print(np.where(p2p.phis>=5))\n",
    "print(p2p.phis[14,64])\n",
    "print(p2p.phis[64,14])\n",
    "#print(np.where(p2p.phis>0))\n",
    "print(np.sum(p2p.phis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 153,
     "status": "aborted",
     "timestamp": 1689630833972,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "Bwep8PWt9QWu"
   },
   "outputs": [],
   "source": [
    "print(np.where(p2p.phis>=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1689631580653,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "noIzKFz-v4-F",
    "outputId": "b92743ca-5200-48ca-810d-a9ebbacc4904"
   },
   "outputs": [],
   "source": [
    "patients_healthy = []\n",
    "patients_unhealthy = []\n",
    "patients_really_unhealthy = []\n",
    "for i in range(len(patients_left)):\n",
    "\n",
    "    mit_bih = MIT_BIH([patients_left[i]],data_beats_train)\n",
    "    #print('train ',torch.sum(mit_bih.y).numpy()/len(mit_bih.y))\n",
    "    fraction_train = torch.sum(mit_bih.y).numpy()/len(mit_bih.y)\n",
    "    mit_bih = MIT_BIH([patients_left[i]],data_beats_test)\n",
    "    #print('test ',torch.sum(mit_bih.y).numpy()/len(mit_bih.y))\n",
    "    fraction_test = torch.sum(mit_bih.y).numpy()/len(mit_bih.y)\n",
    "    if fraction_train == 0:\n",
    "        patients_healthy.append(patients_left[i])\n",
    "    else:\n",
    "        print('patient ',i)\n",
    "        print('N: ',np.count_nonzero(data_beats_train[patients_left[i]]['class']=='N'))\n",
    "        print('V: ',np.count_nonzero(data_beats_train[patients_left[i]]['class']=='V'))\n",
    "        V = np.count_nonzero(data_beats_train[patients_left[i]]['class']=='V')\n",
    "        S = np.count_nonzero(data_beats_train[patients_left[i]]['class']=='S')\n",
    "        F = np.count_nonzero(data_beats_train[patients_left[i]]['class']=='F')\n",
    "        print('S: ',np.count_nonzero(data_beats_train[patients_left[i]]['class']=='S'))\n",
    "        print('F: ',np.count_nonzero(data_beats_train[patients_left[i]]['class']=='F'))\n",
    "        if V + S + F >= 10:\n",
    "          patients_really_unhealthy.append(patients_left[i])\n",
    "        else:\n",
    "          patients_unhealthy.append(patients_left[i])\n",
    "print('healthy patients: ',patients_healthy)\n",
    "print('moderately unhealthy patients: ',patients_unhealthy)\n",
    "print('very unhealthy patients: ',patients_really_unhealthy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 153,
     "status": "aborted",
     "timestamp": 1689630833974,
     "user": {
      "displayName": "Arthur N",
      "userId": "05478761363995977809"
     },
     "user_tz": -120
    },
    "id": "Ifg5yp_kwUPi"
   },
   "outputs": [],
   "source": [
    "patients_healthy = []\n",
    "for i in range(len(patients_left)):\n",
    "\n",
    "    print('patient ',i)\n",
    "    print('N: ',np.count_nonzero(data_beats[patients_left[i]]['class']=='N'))\n",
    "    print('V: ',np.count_nonzero(data_beats[patients_left[i]]['class']=='V'))\n",
    "    print('S: ',np.count_nonzero(data_beats[patients_left[i]]['class']=='S'))\n",
    "    print('F: ',np.count_nonzero(data_beats[patients_left[i]]['class']=='F'))\n",
    "print('healthy patients: ',patients_healthy)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNgGa4yshAUa84ITihKtTaw",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
